{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (1) Reading the Training, the Development and the Testing Datasets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from os import listdir\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['anger-ratings-0to1.train.txt',\n",
       " 'fear-ratings-0to1.train.txt',\n",
       " 'joy-ratings-0to1.train.txt',\n",
       " 'sadness-ratings-0to1.train.txt']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "directory1 = 'data/train'\n",
    "paths1 = listdir(directory1)\n",
    "paths1.sort()\n",
    "paths1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define the path of training dataset\n",
    "path1 = paths1[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'anger'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If you want to restore x_train vectors, y_train_vectors, x_test_vectors, y_test_vectors: you can change the 'emotion' here \n",
    "# and then restore those vectors\n",
    "\n",
    "emotion = path1.split(\"-\")[0]\n",
    "emotion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10000</td>\n",
       "      <td>How the fu*k! Who the heck! moved my fridge!.....</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10001</td>\n",
       "      <td>So my Indian Uber driver just called someone t...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10002</td>\n",
       "      <td>@DPD_UK I asked for my parcel to be delivered ...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10003</td>\n",
       "      <td>so ef whichever butt wipe pulled the fire alar...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10004</td>\n",
       "      <td>Don't join @BTCare they put the phone down on ...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.896</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0                                                  1      2      3\n",
       "0  10000  How the fu*k! Who the heck! moved my fridge!.....  anger  0.938\n",
       "1  10001  So my Indian Uber driver just called someone t...  anger  0.896\n",
       "2  10002  @DPD_UK I asked for my parcel to be delivered ...  anger  0.896\n",
       "3  10003  so ef whichever butt wipe pulled the fire alar...  anger  0.896\n",
       "4  10004  Don't join @BTCare they put the phone down on ...  anger  0.896"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('%s/%s' %(directory1,path1), delimiter='\\t',header=None)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SentID</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Emotion</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10000</td>\n",
       "      <td>How the fu*k! Who the heck! moved my fridge!.....</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10001</td>\n",
       "      <td>So my Indian Uber driver just called someone t...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10002</td>\n",
       "      <td>@DPD_UK I asked for my parcel to be delivered ...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10003</td>\n",
       "      <td>so ef whichever butt wipe pulled the fire alar...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10004</td>\n",
       "      <td>Don't join @BTCare they put the phone down on ...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10005</td>\n",
       "      <td>My blood is boiling</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10006</td>\n",
       "      <td>When you've still got a whole season of Wentwo...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10007</td>\n",
       "      <td>@bt_uk why does tracking show my equipment del...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10008</td>\n",
       "      <td>@TeamShanny legit why i am so furious with him...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10009</td>\n",
       "      <td>How is it suppose to work if you do that? Wtf ...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.875</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SentID                                              Tweet Emotion  Rating\n",
       "0   10000  How the fu*k! Who the heck! moved my fridge!.....   anger   0.938\n",
       "1   10001  So my Indian Uber driver just called someone t...   anger   0.896\n",
       "2   10002  @DPD_UK I asked for my parcel to be delivered ...   anger   0.896\n",
       "3   10003  so ef whichever butt wipe pulled the fire alar...   anger   0.896\n",
       "4   10004  Don't join @BTCare they put the phone down on ...   anger   0.896\n",
       "5   10005                                My blood is boiling   anger   0.875\n",
       "6   10006  When you've still got a whole season of Wentwo...   anger   0.875\n",
       "7   10007  @bt_uk why does tracking show my equipment del...   anger   0.875\n",
       "8   10008  @TeamShanny legit why i am so furious with him...   anger   0.875\n",
       "9   10009  How is it suppose to work if you do that? Wtf ...   anger   0.875"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns = ['SentID', 'Tweet', 'Emotion', 'Rating']\n",
    "train[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if there are any duplicates(subset = all of the columns)\n",
    "\n",
    "assert train.duplicated().sum() == 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 857 entries, 0 to 856\n",
      "Data columns (total 4 columns):\n",
      " #   Column   Non-Null Count  Dtype  \n",
      "---  ------   --------------  -----  \n",
      " 0   SentID   857 non-null    int64  \n",
      " 1   Tweet    857 non-null    object \n",
      " 2   Emotion  857 non-null    object \n",
      " 3   Rating   857 non-null    float64\n",
      "dtypes: float64(1), int64(1), object(2)\n",
      "memory usage: 26.9+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# checking missing data & len(train),len(test)\n",
    "print(train.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             SentID      Rating\n",
      "count    857.000000  857.000000\n",
      "mean   10428.000000    0.496475\n",
      "std      247.538886    0.169169\n",
      "min    10000.000000    0.067000\n",
      "25%    10214.000000    0.375000\n",
      "50%    10428.000000    0.479000\n",
      "75%    10642.000000    0.604000\n",
      "max    10856.000000    0.938000\n"
     ]
    }
   ],
   "source": [
    "print(train.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['anger-ratings-0to1.dev.gold.txt',\n",
       " 'fear-ratings-0to1.dev.gold.txt',\n",
       " 'joy-ratings-0to1.dev.gold.txt',\n",
       " 'sadness-ratings-0to1.dev.gold.txt']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "directory2 = 'data/dev'\n",
    "paths2 = listdir(directory2)\n",
    "paths2.sort()\n",
    "paths2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define the path of training dataset\n",
    "path2 = emotion + \"-ratings-0to1.dev.gold.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SentID</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Emotion</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10857</td>\n",
       "      <td>@ZubairSabirPTI  pls dont insult the word 'Molna'</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10858</td>\n",
       "      <td>@ArcticFantasy I would have almost took offens...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10859</td>\n",
       "      <td>@IllinoisLoyalty that Rutgers game was an abom...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10860</td>\n",
       "      <td>@CozanGaming that's what lisa asked before she...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10861</td>\n",
       "      <td>Sometimes I get mad over something so minuscul...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10862</td>\n",
       "      <td>Sometimes I get mad over something so minuscul...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10863</td>\n",
       "      <td>I think @Sam_Canaday &amp;amp; @KYLEJDOWSON must a...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10864</td>\n",
       "      <td>My eyes have been dilated. I hate the world ri...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10865</td>\n",
       "      <td>@huwellwell One chosen by the CLP members! MP ...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10866</td>\n",
       "      <td>@huwellwell One chosen by the CLP members! MP ...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.438</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SentID                                              Tweet Emotion  Rating\n",
       "0   10857  @ZubairSabirPTI  pls dont insult the word 'Molna'   anger   0.479\n",
       "1   10858  @ArcticFantasy I would have almost took offens...   anger   0.458\n",
       "2   10859  @IllinoisLoyalty that Rutgers game was an abom...   anger   0.562\n",
       "3   10860  @CozanGaming that's what lisa asked before she...   anger   0.500\n",
       "4   10861  Sometimes I get mad over something so minuscul...   anger   0.708\n",
       "5   10862  Sometimes I get mad over something so minuscul...   anger   0.646\n",
       "6   10863  I think @Sam_Canaday &amp; @KYLEJDOWSON must a...   anger   0.250\n",
       "7   10864  My eyes have been dilated. I hate the world ri...   anger   0.812\n",
       "8   10865  @huwellwell One chosen by the CLP members! MP ...   anger   0.682\n",
       "9   10866  @huwellwell One chosen by the CLP members! MP ...   anger   0.438"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev = pd.read_csv('%s/%s' %(directory2,path2), delimiter='\\t',header=None)\n",
    "dev.columns = train.columns\n",
    "dev[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if there are any duplicates(subset = all of the columns)\n",
    "\n",
    "assert dev.duplicated().sum() == 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 84 entries, 0 to 83\n",
      "Data columns (total 4 columns):\n",
      " #   Column   Non-Null Count  Dtype  \n",
      "---  ------   --------------  -----  \n",
      " 0   SentID   84 non-null     int64  \n",
      " 1   Tweet    84 non-null     object \n",
      " 2   Emotion  84 non-null     object \n",
      " 3   Rating   84 non-null     float64\n",
      "dtypes: float64(1), int64(1), object(2)\n",
      "memory usage: 2.8+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# checking missing data & len(train),len(test)\n",
    "print(dev.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             SentID     Rating\n",
      "count     84.000000  84.000000\n",
      "mean   10898.500000   0.489607\n",
      "std       24.392622   0.156768\n",
      "min    10857.000000   0.125000\n",
      "25%    10877.750000   0.410250\n",
      "50%    10898.500000   0.500000\n",
      "75%    10919.250000   0.590500\n",
      "max    10940.000000   0.860000\n"
     ]
    }
   ],
   "source": [
    "print(dev.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['anger-ratings-0to1.test.gold.txt',\n",
       " 'fear-ratings-0to1.test.gold.txt',\n",
       " 'joy-ratings-0to1.test.gold.txt',\n",
       " 'sadness-ratings-0to1.test.gold.txt']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "directory3 = 'data/test'\n",
    "paths3 = listdir(directory3)\n",
    "paths3.sort()\n",
    "paths3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define the path of training dataset\n",
    "path3 = emotion + \"-ratings-0to1.test.gold.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SentID</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Emotion</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10941</td>\n",
       "      <td>At the point today where if someone says somet...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10942</td>\n",
       "      <td>@CorningFootball  IT'S GAME DAY!!!!      T MIN...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10943</td>\n",
       "      <td>This game has pissed me off more than any othe...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10944</td>\n",
       "      <td>@spamvicious I've just found out it's Candice ...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10945</td>\n",
       "      <td>@moocowward @mrsajhargreaves @Melly77 @GaryBar...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10946</td>\n",
       "      <td>@moocowward @mrsajhargreaves @Melly77 @GaryBar...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10947</td>\n",
       "      <td>wanna go home and focus up on this game . Don'...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10948</td>\n",
       "      <td>@virginmedia I've been disconnected whilst on ...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10949</td>\n",
       "      <td>@virginmedia I've been disconnected whilst on ...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10950</td>\n",
       "      <td>I wanna see you smile I don't wanna see you ma...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.250</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SentID                                              Tweet Emotion  Rating\n",
       "0   10941  At the point today where if someone says somet...   anger   0.319\n",
       "1   10942  @CorningFootball  IT'S GAME DAY!!!!      T MIN...   anger   0.144\n",
       "2   10943  This game has pissed me off more than any othe...   anger   0.898\n",
       "3   10944  @spamvicious I've just found out it's Candice ...   anger   0.271\n",
       "4   10945  @moocowward @mrsajhargreaves @Melly77 @GaryBar...   anger   0.646\n",
       "5   10946  @moocowward @mrsajhargreaves @Melly77 @GaryBar...   anger   0.583\n",
       "6   10947  wanna go home and focus up on this game . Don'...   anger   0.375\n",
       "7   10948  @virginmedia I've been disconnected whilst on ...   anger   0.625\n",
       "8   10949  @virginmedia I've been disconnected whilst on ...   anger   0.396\n",
       "9   10950  I wanna see you smile I don't wanna see you ma...   anger   0.250"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv('%s/%s' %(directory3,path3), delimiter='\\t',header=None)\n",
    "test.columns = train.columns\n",
    "\n",
    "test[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if there are any duplicates(subset = all of the columns)\n",
    "\n",
    "assert test.duplicated().sum() == 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 760 entries, 0 to 759\n",
      "Data columns (total 4 columns):\n",
      " #   Column   Non-Null Count  Dtype  \n",
      "---  ------   --------------  -----  \n",
      " 0   SentID   760 non-null    int64  \n",
      " 1   Tweet    760 non-null    object \n",
      " 2   Emotion  760 non-null    object \n",
      " 3   Rating   760 non-null    float64\n",
      "dtypes: float64(1), int64(1), object(2)\n",
      "memory usage: 23.9+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# checking missing data & len(train),len(test)\n",
    "print(test.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             SentID      Rating\n",
      "count    760.000000  760.000000\n",
      "mean   11320.500000    0.502149\n",
      "std      219.537392    0.171886\n",
      "min    10941.000000    0.032000\n",
      "25%    11130.750000    0.375000\n",
      "50%    11320.500000    0.496000\n",
      "75%    11510.250000    0.625000\n",
      "max    11700.000000    0.976000\n"
     ]
    }
   ],
   "source": [
    "print(test.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SentID</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Emotion</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10000</td>\n",
       "      <td>How the fu*k! Who the heck! moved my fridge!.....</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10001</td>\n",
       "      <td>So my Indian Uber driver just called someone t...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10002</td>\n",
       "      <td>@DPD_UK I asked for my parcel to be delivered ...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10003</td>\n",
       "      <td>so ef whichever butt wipe pulled the fire alar...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10004</td>\n",
       "      <td>Don't join @BTCare they put the phone down on ...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>936</th>\n",
       "      <td>10936</td>\n",
       "      <td>@Jen_ny69 People will always get offended ever...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>937</th>\n",
       "      <td>10937</td>\n",
       "      <td>@gayla_weeks1 I try not to let my anger seep i...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>938</th>\n",
       "      <td>10938</td>\n",
       "      <td>I hope my hustle don't offend nobody</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>939</th>\n",
       "      <td>10939</td>\n",
       "      <td>Just watched Django Unchained, Other people ma...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>940</th>\n",
       "      <td>10940</td>\n",
       "      <td>Lol little things like that make me so angry x</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.604</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>941 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     SentID                                              Tweet Emotion  Rating\n",
       "0     10000  How the fu*k! Who the heck! moved my fridge!.....   anger   0.938\n",
       "1     10001  So my Indian Uber driver just called someone t...   anger   0.896\n",
       "2     10002  @DPD_UK I asked for my parcel to be delivered ...   anger   0.896\n",
       "3     10003  so ef whichever butt wipe pulled the fire alar...   anger   0.896\n",
       "4     10004  Don't join @BTCare they put the phone down on ...   anger   0.896\n",
       "..      ...                                                ...     ...     ...\n",
       "936   10936  @Jen_ny69 People will always get offended ever...   anger   0.562\n",
       "937   10937  @gayla_weeks1 I try not to let my anger seep i...   anger   0.625\n",
       "938   10938               I hope my hustle don't offend nobody   anger   0.292\n",
       "939   10939  Just watched Django Unchained, Other people ma...   anger   0.229\n",
       "940   10940     Lol little things like that make me so angry x   anger   0.604\n",
       "\n",
       "[941 rows x 4 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# plan to train models on the combined training and development sets\n",
    "train = pd.concat([train, dev],axis=0,ignore_index=True)\n",
    "train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (2) Define Text Data Cleaning Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import re\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import bigrams\n",
    "\n",
    "import wordsegment as ws # $ pip install wordsegment    \n",
    "ws.load()     \n",
    "\n",
    "import emoji  # $ pip install emoji\n",
    "\n",
    "# As the glove model contains many words made with grammatical role, tense ,or derivational morphology,\n",
    "# we do not need WordNetLemmatizer or SnowballStemmer here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_text(text):\n",
    "    \n",
    "    # replace emoji to word\n",
    "    # text = emoji.demojize(text)\n",
    "    \n",
    "    # remove characters outside the ascii code 128\n",
    "    # text = ''.join([w if ord(w)<128 else ' ' for w in text])\n",
    "    \n",
    "    # replace '--' with a space\n",
    "    text = text.replace('--',' ')\n",
    "    \n",
    "    # remove any newline characters\n",
    "    text = text.replace('\\n',' ')\n",
    "    \n",
    "    # tweets mentions user using '@' followed by username. Replace all those with <user> to be usable for Glove\n",
    "    text = re.sub('@[^ ]+','<user>',text)\n",
    "    \n",
    "    # Replace all URLs with <url> to be usable for Glove\n",
    "    text = re.sub(r'\\d+','<number>',text)\n",
    "   \n",
    "    # Replace all numbers with <number> to be usable for Glove\n",
    "    text = re.sub(r'http\\S+','<url>',text)\n",
    "    \n",
    "    # turn some abbreviations into a whold word\n",
    "    text = re.sub(r\"\\'s\", \"\", text)\n",
    "    text = re.sub(r\"\\'m\", \" am\", text)\n",
    "    text = re.sub(r\"\\'ve\", \" have\", text)\n",
    "    text = re.sub(r\"can\\'t\", \"can not\", text)\n",
    "    text = re.sub(r\"won\\'t\", \"will not\", text)\n",
    "    text = re.sub(r\"n\\'t\", \" not\", text)\n",
    "    text = re.sub(r\"\\'re\", \" are\", text)\n",
    "    text = re.sub(r\"\\'d\", \" would\", text)\n",
    "    text = re.sub(r\"\\'ll\", \" will\", text)\n",
    "    text = re.sub(r\"fu\\*k\", \" fuck\", text)\n",
    "    text = re.sub(r\"f\\*c+\", \"fuck\", text)\n",
    "    text = text.replace(\"wtf\", \"what the fuck\")\n",
    "    \n",
    "    # prepare spaces between punctuation and words\n",
    "    text1 = text.split('...')\n",
    "    for i in range(len(text1)):\n",
    "        text1[i] = text1[i].replace('/',' / ').replace('\\\\',' \\ ').replace(',',' , ').replace('.',' . ').replace('?',' ? ').replace('!',' ! ').replace(\"'\",\" ' \").replace(':',' : ').replace(';',' ; ').replace('-',' - ').replace('(',' ( ').replace(')',' ) ').replace('[',' [ ').replace(']',' ] ').replace('&',' & ').replace('*',' * ').replace('{',' { ').replace('}',' } ').replace('-',' - ').replace('`',' ` ').replace('\"',' \" ').replace('>','> ').replace('<',' <')\n",
    "    text1 = ' '.join(text1)\n",
    "    \n",
    "    # split into tokens by white space\n",
    "    tokens = text1.split()\n",
    "    \n",
    "    return tokens\n",
    "\n",
    "def clean_text(text):\n",
    "   \n",
    "    tokens = normalize_text(text)\n",
    "    \n",
    "    new_tokens1 = []\n",
    "    for w in tokens:\n",
    "        if w == \"<user>\":\n",
    "            w = w\n",
    "        elif w == \"<url>\":\n",
    "            w = w\n",
    "        elif w == \"<number>\":\n",
    "            w = w\n",
    "        elif w in emoji.UNICODE_EMOJI:\n",
    "            w = w\n",
    "        else:\n",
    "            # prepare regex for char filtering: !\"#$%&'()*+, -./:;<=>?@[\\]^_`{|}~\n",
    "            re_punc = re.compile('[%s]' %re.escape(string.punctuation))\n",
    "            # remove punctuation from each word\n",
    "            w = re_punc.sub('', w)\n",
    "    \n",
    "            # remove remaining tokens that are not alphabetic\n",
    "            if w.isalpha():\n",
    "                w = w\n",
    "        new_tokens1.append(w) \n",
    "        \n",
    "    # filter out stop words\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [w for w in new_tokens1 if not w in stop_words]\n",
    "    \n",
    "    new_tokens2 = []\n",
    "    for w in tokens:\n",
    "        if w == \"<user>\":\n",
    "            w = w\n",
    "        elif w == \"<url>\":\n",
    "            w = w\n",
    "        elif w == \"<number>\":\n",
    "            w = w\n",
    "        elif w in emoji.UNICODE_EMOJI:\n",
    "            w = w\n",
    "        else:\n",
    "            # word segment will convert the hashtag based joined words, for example, it will segment #iamthebest to ['i','am','the','best']\n",
    "            w = ' '.join(ws.segment(w)) \n",
    "        new_tokens2.append(w)\n",
    "        \n",
    "    \n",
    "    # make lower case\n",
    "    tokens = [word.lower() for word in new_tokens2]\n",
    "    \n",
    "    \n",
    "    clean_text = ' '.join(tokens)\n",
    "    tokens = clean_text.split()\n",
    "    \n",
    "    new_tokens3 = []   \n",
    "    # filter out short tokens\n",
    "    for w in tokens:\n",
    "        if w in emoji.UNICODE_EMOJI:\n",
    "            w = w\n",
    "        else:\n",
    "            if len(w) > 1:\n",
    "                w =w\n",
    "        new_tokens3.append(w)\n",
    "    \n",
    "    return ' '.join(new_tokens3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<user> i left dad deal 😂 my work done soon felt wrath slipper 😷'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# do a sanity check\n",
    "text = \"@laura221b I've left it for my dad to deal with 😂 My work is done as soon as it's felt the wrath of my slipper 😷\"\n",
    "clean_text(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare for clean Hashtag Emotion Intensity Lexicons...\n",
    "\n",
    "def remove_stopwords(string):\n",
    "    split_string = \\\n",
    "        [word for word in string.split()\n",
    "         if word not in stopwords.words('english')]\n",
    "    \n",
    "    return \" \".join(split_string)\n",
    "\n",
    "def clean_str(string):  \n",
    "    string = string.replace(\"\\\\n\", \" \")\n",
    "    string = string.replace(\"_NEG\", \"\")\n",
    "    string = string.replace(\"_NEGFIRST\", \"\")\n",
    "    string = re.sub(r\"@[A-Za-z0-9_s(),!?\\'\\`]+\", \"\", string) # removing any twitter handle mentions\n",
    "\n",
    "    string = re.sub(r\"#\", \"\", string)\n",
    "    string = re.sub(r\"\\*\", \"\", string)\n",
    "    string = re.sub(r\"\\'s\", \"\", string)\n",
    "    string = re.sub(r\"\\'m\", \" am\", string)\n",
    "    string = re.sub(r\"\\'ve\", \" have\", string)\n",
    "    string = re.sub(r\"n\\'t\", \" not\", string)\n",
    "    string = re.sub(r\"\\'re\", \" are\", string)\n",
    "    string = re.sub(r\"\\'d\", \" would\", string)\n",
    "    string = re.sub(r\"\\'ll\", \" will\", string)\n",
    "    string = re.sub(r\",\", \"\", string)\n",
    "    string = re.sub(r\"!\", \" !\", string)\n",
    "    string = re.sub(r\"\\(\", \"\", string)\n",
    "    string = re.sub(r\"\\)\", \"\", string)\n",
    "    string = re.sub(r\"\\?\", \" ?\", string)\n",
    "    string = re.sub(r\"\\s{2,}\", \" \", string)\n",
    "\n",
    "    return remove_stopwords(string.strip().lower())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (3) Clean Text Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Tweet'] = train['Tweet'].apply(clean_text)\n",
    "\n",
    "test['Tweet'] = test['Tweet'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SentID</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Emotion</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10000</td>\n",
       "      <td>how fuck who heck moved fridge i knock landlor...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10001</td>\n",
       "      <td>so indian uber driver called someone n word if...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10002</td>\n",
       "      <td>&lt;user&gt; i asked parcel delivered pick store add...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10003</td>\n",
       "      <td>ef whichever butt wipe pulled fire alarm davis...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10004</td>\n",
       "      <td>do join &lt;user&gt; put phone talk rude taking mone...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10005</td>\n",
       "      <td>my blood boiling</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10006</td>\n",
       "      <td>when still got whole season wentworth watch st...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10007</td>\n",
       "      <td>&lt;user&gt; tracking show equipment delivered why s...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10008</td>\n",
       "      <td>&lt;user&gt; legit furious people fucking idiots</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10009</td>\n",
       "      <td>how suppose work wtf dude thanks pissing</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10010</td>\n",
       "      <td>im mad power rangers im incensed im furious</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>10011</td>\n",
       "      <td>wont use using &lt;user&gt; &lt;user&gt; these guys cant g...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>10012</td>\n",
       "      <td>bitches aggravate like inspires biggest cunt k...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>10013</td>\n",
       "      <td>why &lt;user&gt; come glasgow night i working i fuck...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>10014</td>\n",
       "      <td>fuking fuming 😤</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>10015</td>\n",
       "      <td>zero help &lt;user&gt; customer service just pushing...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>10016</td>\n",
       "      <td>&lt;user&gt; mention gra guy stops let &lt;number&gt; ppl ...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>10017</td>\n",
       "      <td>i hate lawn mower if soul i would condemn fier...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>10018</td>\n",
       "      <td>people offended kendall ends photo shoot like ...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>10019</td>\n",
       "      <td>i block everyone everywhere posting storm i th...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>10020</td>\n",
       "      <td>making buddy cry bitch wait revenge</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>10021</td>\n",
       "      <td>be s you tell true blooded hoop junkie switch ...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>10022</td>\n",
       "      <td>i got no response i rate customer amazon n why...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>10023</td>\n",
       "      <td>tasers immobilize taser someone fuck need shoo...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>10024</td>\n",
       "      <td>&lt;user&gt; &lt;user&gt; &lt;user&gt; the way blood boiling lit...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>10025</td>\n",
       "      <td>actually fuming i nothing wear saturday</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>10026</td>\n",
       "      <td>&lt;user&gt; straight people even arse straight guys...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>10027</td>\n",
       "      <td>bloody parking ticket fuming</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>10028</td>\n",
       "      <td>you ever find people around really irritate so...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>10029</td>\n",
       "      <td>i get angry people know stop sign francis fost...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>10030</td>\n",
       "      <td>this fuck boiling inside gonna good i let</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>10031</td>\n",
       "      <td>&lt;user&gt; &lt;user&gt; wow my bill &lt;number&gt; &lt;number&gt; ha...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>10032</td>\n",
       "      <td>i blame whole season natalie the season would ...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>10033</td>\n",
       "      <td>since update &lt;user&gt; loses power nearly &lt;number...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>10034</td>\n",
       "      <td>&lt;user&gt; i fly fit rage fair</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>10035</td>\n",
       "      <td>unbelievable takes &lt;number&gt; minutes get &lt;user&gt;...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>10036</td>\n",
       "      <td>&lt;user&gt; &lt;user&gt; we blaming &lt;number&gt; fucking idio...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>10037</td>\n",
       "      <td>&lt;user&gt; people infuriate</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>10038</td>\n",
       "      <td>&lt;user&gt; mine party decide party slowly transfor...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>10039</td>\n",
       "      <td>so angry &lt;user&gt; order &lt;number&gt; months ago i pl...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>10040</td>\n",
       "      <td>still log fucking snap chat snap chat snap</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>10041</td>\n",
       "      <td>&lt;user&gt; sam yes not helpful we need sorting asa...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>10042</td>\n",
       "      <td>someone let snakes in my house i bet it &lt;user&gt;...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>10043</td>\n",
       "      <td>ef whichever butt wipe pulled fire alarm davis...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>10044</td>\n",
       "      <td>why &lt;user&gt; come glasgow night i working i fuck...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>10045</td>\n",
       "      <td>feel furious</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>10046</td>\n",
       "      <td>some mexican ladies irritate fuck outta have l...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>10047</td>\n",
       "      <td>still log fucking snap chat snap chat</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>10048</td>\n",
       "      <td>i blame whole season natalie the season would ...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>10049</td>\n",
       "      <td>people irritate mf soul</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>10050</td>\n",
       "      <td>im angry</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>10051</td>\n",
       "      <td>people fuckin irritate</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>10052</td>\n",
       "      <td>&lt;user&gt; cruel cruel man there will be blood rev...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>10053</td>\n",
       "      <td>that way ur angry literally feel ur blood boiling</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>10054</td>\n",
       "      <td>&lt;user&gt; amount greedy mooching makes snarl</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.750</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    SentID                                              Tweet Emotion  Rating\n",
       "0    10000  how fuck who heck moved fridge i knock landlor...   anger   0.938\n",
       "1    10001  so indian uber driver called someone n word if...   anger   0.896\n",
       "2    10002  <user> i asked parcel delivered pick store add...   anger   0.896\n",
       "3    10003  ef whichever butt wipe pulled fire alarm davis...   anger   0.896\n",
       "4    10004  do join <user> put phone talk rude taking mone...   anger   0.896\n",
       "5    10005                                   my blood boiling   anger   0.875\n",
       "6    10006  when still got whole season wentworth watch st...   anger   0.875\n",
       "7    10007  <user> tracking show equipment delivered why s...   anger   0.875\n",
       "8    10008         <user> legit furious people fucking idiots   anger   0.875\n",
       "9    10009           how suppose work wtf dude thanks pissing   anger   0.875\n",
       "10   10010        im mad power rangers im incensed im furious   anger   0.667\n",
       "11   10011  wont use using <user> <user> these guys cant g...   anger   0.854\n",
       "12   10012  bitches aggravate like inspires biggest cunt k...   anger   0.854\n",
       "13   10013  why <user> come glasgow night i working i fuck...   anger   0.938\n",
       "14   10014                                    fuking fuming 😤   anger   0.854\n",
       "15   10015  zero help <user> customer service just pushing...   anger   0.854\n",
       "16   10016  <user> mention gra guy stops let <number> ppl ...   anger   0.854\n",
       "17   10017  i hate lawn mower if soul i would condemn fier...   anger   0.833\n",
       "18   10018  people offended kendall ends photo shoot like ...   anger   0.833\n",
       "19   10019  i block everyone everywhere posting storm i th...   anger   0.812\n",
       "20   10020                making buddy cry bitch wait revenge   anger   0.812\n",
       "21   10021  be s you tell true blooded hoop junkie switch ...   anger   0.891\n",
       "22   10022  i got no response i rate customer amazon n why...   anger   0.812\n",
       "23   10023  tasers immobilize taser someone fuck need shoo...   anger   0.812\n",
       "24   10024  <user> <user> <user> the way blood boiling lit...   anger   0.792\n",
       "25   10025            actually fuming i nothing wear saturday   anger   0.792\n",
       "26   10026  <user> straight people even arse straight guys...   anger   0.792\n",
       "27   10027                       bloody parking ticket fuming   anger   0.792\n",
       "28   10028  you ever find people around really irritate so...   anger   0.792\n",
       "29   10029  i get angry people know stop sign francis fost...   anger   0.792\n",
       "30   10030          this fuck boiling inside gonna good i let   anger   0.792\n",
       "31   10031  <user> <user> wow my bill <number> <number> ha...   anger   0.792\n",
       "32   10032  i blame whole season natalie the season would ...   anger   0.792\n",
       "33   10033  since update <user> loses power nearly <number...   anger   0.792\n",
       "34   10034                         <user> i fly fit rage fair   anger   0.792\n",
       "35   10035  unbelievable takes <number> minutes get <user>...   anger   0.792\n",
       "36   10036  <user> <user> we blaming <number> fucking idio...   anger   0.792\n",
       "37   10037                            <user> people infuriate   anger   0.792\n",
       "38   10038  <user> mine party decide party slowly transfor...   anger   0.792\n",
       "39   10039  so angry <user> order <number> months ago i pl...   anger   0.771\n",
       "40   10040         still log fucking snap chat snap chat snap   anger   0.900\n",
       "41   10041  <user> sam yes not helpful we need sorting asa...   anger   0.771\n",
       "42   10042  someone let snakes in my house i bet it <user>...   anger   0.771\n",
       "43   10043  ef whichever butt wipe pulled fire alarm davis...   anger   0.771\n",
       "44   10044  why <user> come glasgow night i working i fuck...   anger   0.733\n",
       "45   10045                                       feel furious   anger   0.771\n",
       "46   10046  some mexican ladies irritate fuck outta have l...   anger   0.771\n",
       "47   10047              still log fucking snap chat snap chat   anger   0.771\n",
       "48   10048  i blame whole season natalie the season would ...   anger   0.771\n",
       "49   10049                            people irritate mf soul   anger   0.771\n",
       "50   10050                                           im angry   anger   0.750\n",
       "51   10051                             people fuckin irritate   anger   0.750\n",
       "52   10052  <user> cruel cruel man there will be blood rev...   anger   0.840\n",
       "53   10053  that way ur angry literally feel ur blood boiling   anger   0.750\n",
       "54   10054          <user> amount greedy mooching makes snarl   anger   0.750"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# do a sanity check\n",
    "train[0:55]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SentID</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Emotion</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10000</td>\n",
       "      <td>how fuck who heck moved fridge i knock landlor...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10001</td>\n",
       "      <td>so indian uber driver called someone n word if...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10002</td>\n",
       "      <td>&lt;user&gt; i asked parcel delivered pick store add...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10003</td>\n",
       "      <td>ef whichever butt wipe pulled fire alarm davis...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10004</td>\n",
       "      <td>do join &lt;user&gt; put phone talk rude taking mone...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10005</td>\n",
       "      <td>my blood boiling</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10006</td>\n",
       "      <td>when still got whole season wentworth watch st...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10007</td>\n",
       "      <td>&lt;user&gt; tracking show equipment delivered why s...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10008</td>\n",
       "      <td>&lt;user&gt; legit furious people fucking idiots</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10009</td>\n",
       "      <td>how suppose work wtf dude thanks pissing</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.875</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SentID                                              Tweet Emotion  Rating\n",
       "0   10000  how fuck who heck moved fridge i knock landlor...   anger   0.938\n",
       "1   10001  so indian uber driver called someone n word if...   anger   0.896\n",
       "2   10002  <user> i asked parcel delivered pick store add...   anger   0.896\n",
       "3   10003  ef whichever butt wipe pulled fire alarm davis...   anger   0.896\n",
       "4   10004  do join <user> put phone talk rude taking mone...   anger   0.896\n",
       "5   10005                                   my blood boiling   anger   0.875\n",
       "6   10006  when still got whole season wentworth watch st...   anger   0.875\n",
       "7   10007  <user> tracking show equipment delivered why s...   anger   0.875\n",
       "8   10008         <user> legit furious people fucking idiots   anger   0.875\n",
       "9   10009           how suppose work wtf dude thanks pissing   anger   0.875"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# do a sanity check\n",
    "train[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the distribution of text length (from below: there is no need to truncate any of texts)\n",
    "def show_text_len(train):\n",
    "    train[\"text_len\"] = train['Tweet'].map(lambda x: len(x.split()))\n",
    "    return train[\"text_len\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    941.000000\n",
       "mean      10.695005\n",
       "std        4.586227\n",
       "min        1.000000\n",
       "25%        7.000000\n",
       "50%       11.000000\n",
       "75%       14.000000\n",
       "max       25.000000\n",
       "Name: text_len, dtype: float64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_text_len(train).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    760.000000\n",
       "mean      11.119737\n",
       "std        4.560254\n",
       "min        1.000000\n",
       "25%        8.000000\n",
       "50%       11.000000\n",
       "75%       14.000000\n",
       "max       23.000000\n",
       "Name: text_len, dtype: float64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_text_len(test).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is not any reviews' length = 0 after text cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tweets = list(train['Tweet'])\n",
    "train_intensities = list(train['Rating'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['how fuck who heck moved fridge i knock landlord door angry mad',\n",
       " 'so indian uber driver called someone n word if i moving vehicle i would jumped disgusted',\n",
       " '<user> i asked parcel delivered pick store address fuming poor customer service',\n",
       " 'ef whichever butt wipe pulled fire alarm davis bc i sound asleep pissed angry upset tired sad tired h angry',\n",
       " 'do join <user> put phone talk rude taking money acc willy nilly fuming',\n",
       " 'my blood boiling',\n",
       " 'when still got whole season wentworth watch stupid cunt work ruins us <user> raging old cunt',\n",
       " '<user> tracking show equipment delivered why service suddenly delayed we already <number> weeks fuming',\n",
       " '<user> legit furious people fucking idiots',\n",
       " 'how suppose work wtf dude thanks pissing',\n",
       " 'im mad power rangers im incensed im furious',\n",
       " 'wont use using <user> <user> these guys cant get nothing right fuming',\n",
       " 'bitches aggravate like inspires biggest cunt known man kind',\n",
       " 'why <user> come glasgow night i working i fucking gutted waiting appearance ages raging',\n",
       " 'fuking fuming 😤',\n",
       " 'zero help <user> customer service just pushing buck back forth promising callbacks dont happen anger loathing',\n",
       " '<user> mention gra guy stops let <number> ppl front go wtf my blood boiling',\n",
       " 'i hate lawn mower if soul i would condemn fiery pits hell',\n",
       " 'people offended kendall ends photo shoot like seriously shut fuck',\n",
       " 'i block everyone everywhere posting storm i think everyone aware damn rain quit damn',\n",
       " 'making buddy cry bitch wait revenge',\n",
       " 'be s you tell true blooded hoop junkie switch fuck <user> team juz destroyed team you juz insult',\n",
       " 'i got no response i rate customer amazon n why understand always amazon fault n carrier fault',\n",
       " 'tasers immobilize taser someone fuck need shoot one second later this really sick rage fuck murder',\n",
       " '<user> <user> <user> the way blood boiling little bastards',\n",
       " 'actually fuming i nothing wear saturday',\n",
       " '<user> straight people even arse straight guys think means threesome fine angry fuming',\n",
       " 'bloody parking ticket fuming',\n",
       " 'you ever find people around really irritate sometimes that right 😒',\n",
       " 'i get angry people know stop sign francis foster road',\n",
       " 'this fuck boiling inside gonna good i let',\n",
       " '<user> <user> wow my bill <number> <number> hav text u prove taken <number> s wines fuming con',\n",
       " 'i blame whole season natalie the season would different turned back alliance pissed',\n",
       " 'since update <user> loses power nearly <number> faster furious',\n",
       " '<user> i fly fit rage fair',\n",
       " 'unbelievable takes <number> minutes get <user> fault call hangs fuming treat customers fairly',\n",
       " '<user> <user> we blaming <number> fucking idiots putting world middle tantrums you one',\n",
       " '<user> people infuriate',\n",
       " '<user> mine party decide party slowly transformed vengeful hell cult white male resentment',\n",
       " 'so angry <user> order <number> months ago i placed order <number> card billed never received n disappointing',\n",
       " 'still log fucking snap chat snap chat snap',\n",
       " '<user> sam yes not helpful we need sorting asap you keep promising stuff happen fuming',\n",
       " 'someone let snakes in my house i bet it <user> i kill that bugger when i get my hands on him rage huck fp <number>',\n",
       " 'ef whichever butt wipe pulled fire alarm davis bc i sound asleep pissed upset tired sad tired h angry',\n",
       " 'why <user> come glasgow night i working i fucking gutted waiting appearance ages',\n",
       " 'feel furious',\n",
       " 'some mexican ladies irritate fuck outta have lil preschool fucking kids welfare amp all ll at smh',\n",
       " 'still log fucking snap chat snap chat',\n",
       " 'i blame whole season natalie the season would different turned back alliance pissed bitter',\n",
       " 'people irritate mf soul',\n",
       " 'im angry',\n",
       " 'people fuckin irritate',\n",
       " '<user> cruel cruel man there will be blood revenge',\n",
       " 'that way ur angry literally feel ur blood boiling',\n",
       " '<user> amount greedy mooching makes snarl',\n",
       " 'my mind raging want end',\n",
       " 'absolutely fuming woman jumped pre booked taxi drove 😡',\n",
       " 'i nothing hateful bitter fag',\n",
       " '<user> something needs done people hogging machines nobody use <number> machines one time angry not fair why pay',\n",
       " '<user> ikr people still got grudge reason like fuck',\n",
       " '<user> said talking wills uncontrollable animals moving another link these comments help fuming',\n",
       " '<user> <user> bad news ordered online gone happened order phone furious',\n",
       " 'so angry i wanna cry',\n",
       " 'oooo ooooh my god uuuugggghhhhhhhhh',\n",
       " 'boycotting <user> till butter pecan comes back i furious',\n",
       " 'in <number> black people still fighting recognized human beings cant sleep angry',\n",
       " 'mom cut phone i furious 🤗',\n",
       " 'once thing feed na ay raging something brother filling gaps',\n",
       " 'believe achilles killed angry',\n",
       " 'i lost couple niggas i want revenge put coach',\n",
       " '<user> poor packaging amazon fulfilled seller furious much 😕',\n",
       " 'where outrage black man kills another black man streets',\n",
       " 'makes fucking i rate jesus nobody calling ppl like hajime abusive stop strawmen lmao',\n",
       " 'absolutely fuming i scratched car',\n",
       " '<user> holy shit bee sting like fuck dying',\n",
       " 'how fuck who heck moved fridge i knock landlord door mad',\n",
       " 'i dislike people get offended littlest shit',\n",
       " 'what fuck i supposed lunch dinner money i work furious h angry day <number>',\n",
       " '<user> one person ruins season <number> i angry',\n",
       " 'what fuck i supposed lunch dinner money i work h angry day <number>',\n",
       " '<user> buses unreliable e ticket app unable get two buses late work fuming useless reply',\n",
       " 'so indian uber driver called someone n word if i moving vehicle i would jumped disgusted offended',\n",
       " 'the liberal outrage king saying n word really angers the white yuppie progressives go fuck shame blacks',\n",
       " 'just paid chicken <user> even get goes <number> dollars customer angry',\n",
       " 'mistake half assed excuse burning hell forever',\n",
       " '<user> years irrelevant its absolute joke man utd ticketing fuming no loyalty joke not impressed',\n",
       " '<user> part <number> buzzing cheeky squash ie two not expected sort it out food angry <user> <user>',\n",
       " 'tasers immobilize taser someone fuck need shoot one second later this really sick fuck murder',\n",
       " 'be s you tell true blooded hoop junkie switch fuck <user> team juz destroyed team you juz',\n",
       " '<user> fucked coupon goal raging',\n",
       " 'lvg bribed refs utd personal revenge that foul prick',\n",
       " 'now whole clown rage scared shitless i gonna go cry room',\n",
       " 'worst juror ever michelle you nicole biggest threat bitter bb <number>',\n",
       " 'your twitter picture makes fume',\n",
       " '<user> cruel cruel man there will be blood',\n",
       " 'that really madden career game sucks ea sports piss poor job every year shit',\n",
       " '<user> <user> ha right i san jose ca i offended right dave go walk something next time',\n",
       " '<user> something needs done people hogging machines nobody use <number> machines one time not fair why pay',\n",
       " 'i wonder american city next protest police shootings who next smh when will its top angry how many more times',\n",
       " '<user> <user> another angry white man']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check\n",
    "train_tweets[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.938,\n",
       " 0.8959999999999999,\n",
       " 0.8959999999999999,\n",
       " 0.8959999999999999,\n",
       " 0.8959999999999999,\n",
       " 0.875,\n",
       " 0.875,\n",
       " 0.875,\n",
       " 0.875,\n",
       " 0.875]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check\n",
    "train_intensities[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_tweets = list(test['Tweet'])\n",
    "test_intensities = list(test['Rating'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>max text length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>train</th>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       max text length\n",
       "train               25\n",
       "test                23"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show Max Text Length of All Datasets for comparsion\n",
    "\n",
    "all_tweets_max_len = pd.DataFrame(np.array([max(show_text_len(train)), max(show_text_len(test))]))\n",
    "\n",
    "all_tweets_max_len.index = ['train', 'test']\n",
    "all_tweets_max_len.columns = ['max text length']\n",
    "\n",
    "all_tweets_max_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "all_tweets_max_len.plot(kind='bar')\n",
    "plt.title('Max Text Length of All Datasets')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "we set the length to which each tweet vector will be zero padded to.\n",
    "this is based on the maximum length we got on the training set - we do not want to remove\n",
    "any words as the maximun length of the training set is not very big.\n",
    "'''\n",
    "\n",
    "max_len = max(show_text_len(train))\n",
    "max_len"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Text Data Preparation（Feature Extraction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (1) Load Pre-trained Word Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gensim\n",
    "from nltk import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vector_path = \"files/wv_models/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1) Glove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadGloveModel(gloveFile):\n",
    "    print(\"Loading Glove Model\")\n",
    "    f = open(gloveFile,'r', encoding = 'UTF-8')\n",
    "    model = {}\n",
    "    num = 1\n",
    "    for line in f:\n",
    "        try:\n",
    "            splitLine = line.split()\n",
    "            word = splitLine[0]\n",
    "            coefs = np.asarray(splitLine[1:], dtype = 'float32')\n",
    "            model[word] = coefs\n",
    "            num += 1\n",
    "        except Exception as e:\n",
    "            print(\"Failed at line \" + str(num))\n",
    "    print(\"Done. Found %s word vectors.\" %len(model),\" words loaded!\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Glove Model\n",
      "Done. Found 1193514 word vectors.  words loaded!\n"
     ]
    }
   ],
   "source": [
    "# To download the pretrained glove model (2B tweets, 27B tokens) - [https://nlp.stanford.edu/projects/glove/   glove.twitter.27B.zip]\n",
    "# choose glove.twitter.27B.200d.txt from glove.twitter.27B.zip. [200-dimension vectors]\n",
    "\n",
    "wv_model_path1 = word_vector_path + \"glove.twitter.27B.200d.txt\"\n",
    " \n",
    "wv_model_g = loadGloveModel(wv_model_path1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2) Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To download the pretrained word2vec model  - [https://github.com/FredericGodin/TwitterEmbeddings]\n",
    "\n",
    "wv_model_path2 = word_vector_path + \"word2vec_twitter_tokens.bin\"\n",
    "wv_model_w = gensim.models.KeyedVectors.load_word2vec_format(wv_model_path2, binary=True, unicode_errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word Vectors: 3039345\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dell\\Anaconda3\\envs\\tf2\\lib\\site-packages\\ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "words = list(wv_model_w.wv.vocab)\n",
    "print('Word Vectors: %d' % len(words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3) Define Averaged Word Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_dimensions_g = len(wv_model_g['word'])\n",
    "w2v_dimensions_w = len(wv_model_w['word'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200 400\n"
     ]
    }
   ],
   "source": [
    "print(w2v_dimensions_g,w2v_dimensions_w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_averaged_embeddings(tweet, model, dimensions):\n",
    "    tokens = word_tokenize(tweet)\n",
    "    vector_list = []\n",
    "    for token in tokens:\n",
    "        try:\n",
    "            vector_list.append(model[token])\n",
    "        except Exception as e:\n",
    "            pass\n",
    "    if len(vector_list) == 0:\n",
    "        uni_vec_rep = np.zeros(dimensions).tolist()\n",
    "    else:\n",
    "        uni_vec_rep = sum(vector_list) / float(len(vector_list))\n",
    "    return uni_vec_rep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (2) Load Lexicon Feature Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "lexicons_path = \"files/lexicons/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0.Emoji_Vectors',\n",
       " '1.NRC-Emotion-Intensity-Lexicon',\n",
       " '3.NRC-Emotion-Lexicon',\n",
       " '4.NRC-Hashtag-Emotion-Lexicon',\n",
       " '5.NRC-Emoticon-Lexicon',\n",
       " '6.NRC-Emoticon-AffLexNegLex',\n",
       " '7.NRC-Hashtag-Sentiment-AffLexNegLex',\n",
       " '8.NRC-Hashtag-Sentiment-Lexicon',\n",
       " '9.DepecheMood_V1.0']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paths2 = listdir(lexicons_path)\n",
    "paths2.sort()\n",
    "paths2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1) Emoji Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(('%s%s/' %(lexicons_path, paths2[0])) + listdir('%s%s/' %(lexicons_path, paths2[0]))[0], encoding = 'UTF-8') \\\n",
    "as emoji_file:\n",
    "    emoji_list = json.load(emoji_file)\n",
    "    \n",
    "emoji_dict = dict()\n",
    "for emoji in emoji_list:\n",
    "    emoji_dict[emoji[\"emoji\"]] = (emoji[\"name\"], emoji[\"polarity\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('joy', 3)\n"
     ]
    }
   ],
   "source": [
    "# do a sanity check\n",
    "print(emoji_dict[\"😂\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly_emoji_intensity = PolynomialFeatures(5)\n",
    "\n",
    "def get_emoji_intensity(tweet):\n",
    "    score = 0.0\n",
    "    for emoji in emoji_dict.keys():\n",
    "        count = tweet.count(emoji)\n",
    "        score += count * emoji_dict[emoji][1]\n",
    "        \n",
    "    return normalize(poly_emoji_intensity.fit_transform(np.array([score]).reshape(1, -1))[0].reshape(1, -1))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00387988, 0.01163963, 0.03491889, 0.10475666, 0.31426998,\n",
       "       0.94280993])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# do a sanity check\n",
    "get_emoji_intensity(\"😂\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2) Emotion Intensity Lexicon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "affect_intensity_file_path = ('%s%s/' %(lexicons_path, paths2[1])) + listdir('%s%s/' %(lexicons_path, paths2[1]))[0]\n",
    "\n",
    "def get_word_affect_intensity_dict(emotion):\n",
    "    word_intensities = dict()\n",
    "\n",
    "    with open(affect_intensity_file_path) as affect_intensity_file:\n",
    "        for line in affect_intensity_file:\n",
    "            word_int_array = line.replace(\"\\n\", \"\").split(\"\\t\")\n",
    "\n",
    "            if (word_int_array[1] == emotion):\n",
    "                word_intensities[word_int_array[0]] = float(word_int_array[2])\n",
    "\n",
    "    return word_intensities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'outraged': 0.964,\n",
       " 'brutality': 0.959,\n",
       " 'hatred': 0.953,\n",
       " 'hateful': 0.94,\n",
       " 'terrorize': 0.939,\n",
       " 'infuriated': 0.938,\n",
       " 'violently': 0.938,\n",
       " 'furious': 0.929,\n",
       " 'enraged': 0.927,\n",
       " 'furiously': 0.927,\n",
       " 'screwyou': 0.924,\n",
       " 'murderer': 0.922,\n",
       " 'fury': 0.922,\n",
       " 'execution': 0.917,\n",
       " 'angered': 0.916,\n",
       " 'savagery': 0.915,\n",
       " 'slaughtering': 0.914,\n",
       " 'veryangry': 0.913,\n",
       " 'assassinate': 0.912,\n",
       " 'fuckoff': 0.912,\n",
       " 'annihilation': 0.912,\n",
       " 'rage': 0.911,\n",
       " 'loathe': 0.909,\n",
       " 'damnation': 0.906,\n",
       " 'roadrage': 0.906,\n",
       " 'fucktard': 0.906,\n",
       " 'homicidal': 0.906,\n",
       " 'furor': 0.9,\n",
       " 'hostile': 0.898,\n",
       " 'annihilate': 0.898,\n",
       " 'murder': 0.897,\n",
       " 'raging': 0.896,\n",
       " 'sopissed': 0.894,\n",
       " 'pissed': 0.894,\n",
       " 'rape': 0.894,\n",
       " 'explosive': 0.894,\n",
       " 'obliterated': 0.894,\n",
       " 'vengeful': 0.894,\n",
       " 'ferocious': 0.894,\n",
       " 'infuriates': 0.894,\n",
       " 'killing': 0.893,\n",
       " 'combative': 0.891,\n",
       " 'gofuckyourself': 0.886,\n",
       " 'vengeance': 0.886,\n",
       " 'wrath': 0.885,\n",
       " 'torment': 0.885,\n",
       " 'vicious': 0.884,\n",
       " 'threatening': 0.882,\n",
       " 'massacre': 0.882,\n",
       " 'bloodthirsty': 0.875,\n",
       " 'abhorrent': 0.875,\n",
       " 'pissoff': 0.875,\n",
       " 'fighting': 0.868,\n",
       " 'annihilated': 0.865,\n",
       " 'attacking': 0.865,\n",
       " 'angriest': 0.864,\n",
       " 'bloodshed': 0.864,\n",
       " 'smite': 0.862,\n",
       " 'brawl': 0.861,\n",
       " 'assault': 0.859,\n",
       " 'assassination': 0.859,\n",
       " 'strangle': 0.859,\n",
       " 'explode': 0.859,\n",
       " 'malicious': 0.859,\n",
       " 'tirade': 0.859,\n",
       " 'hostility': 0.859,\n",
       " 'loathsome': 0.857,\n",
       " 'attack': 0.853,\n",
       " 'hell': 0.853,\n",
       " 'murderous': 0.853,\n",
       " 'malice': 0.852,\n",
       " 'terrorism': 0.851,\n",
       " 'beating': 0.849,\n",
       " 'pissingmeoff': 0.848,\n",
       " 'desecration': 0.848,\n",
       " 'outrage': 0.848,\n",
       " 'irate': 0.844,\n",
       " 'tumultuous': 0.844,\n",
       " 'destroying': 0.844,\n",
       " 'violent': 0.844,\n",
       " 'stab': 0.844,\n",
       " 'infuriate': 0.844,\n",
       " 'slaughter': 0.844,\n",
       " 'abomination': 0.844,\n",
       " 'obliterate': 0.843,\n",
       " 'dumbbitch': 0.841,\n",
       " 'belligerent': 0.841,\n",
       " 'detest': 0.838,\n",
       " 'hostilities': 0.837,\n",
       " 'prick': 0.835,\n",
       " 'cruelty': 0.833,\n",
       " 'horrid': 0.833,\n",
       " 'rampage': 0.833,\n",
       " 'rabid': 0.833,\n",
       " 'torture': 0.833,\n",
       " 'satanic': 0.828,\n",
       " 'hate': 0.828,\n",
       " 'hating': 0.828,\n",
       " 'tyrannical': 0.828,\n",
       " 'demonic': 0.828,\n",
       " 'ragemode': 0.828,\n",
       " 'despicable': 0.828,\n",
       " 'ruinous': 0.825,\n",
       " 'condemn': 0.825,\n",
       " 'extermination': 0.824,\n",
       " 'riots': 0.824,\n",
       " 'dickhead': 0.824,\n",
       " 'angry': 0.824,\n",
       " 'demolish': 0.824,\n",
       " 'livid': 0.821,\n",
       " 'madman': 0.82,\n",
       " 'vindictive': 0.819,\n",
       " 'ferocity': 0.818,\n",
       " 'terrorist': 0.818,\n",
       " 'venomous': 0.818,\n",
       " 'threaten': 0.818,\n",
       " 'hateyou': 0.818,\n",
       " 'effyou': 0.818,\n",
       " 'abhor': 0.816,\n",
       " 'carnage': 0.814,\n",
       " 'savage': 0.814,\n",
       " 'atrocity': 0.814,\n",
       " 'fuming': 0.812,\n",
       " 'pissedoff': 0.812,\n",
       " 'pissesmeoff': 0.812,\n",
       " 'fierce': 0.812,\n",
       " 'abuse': 0.812,\n",
       " 'barbaric': 0.812,\n",
       " 'berserk': 0.812,\n",
       " 'fucksake': 0.812,\n",
       " 'vendetta': 0.812,\n",
       " 'angrytweet': 0.812,\n",
       " 'destroyer': 0.812,\n",
       " 'tyrant': 0.812,\n",
       " 'anger': 0.811,\n",
       " 'pieceofshit': 0.81,\n",
       " 'slam': 0.803,\n",
       " 'punching': 0.803,\n",
       " 'homicide': 0.803,\n",
       " 'punched': 0.803,\n",
       " 'bitch': 0.803,\n",
       " 'fights': 0.803,\n",
       " 'destructive': 0.797,\n",
       " 'ruthless': 0.797,\n",
       " 'villainous': 0.797,\n",
       " 'slap': 0.791,\n",
       " 'destroyed': 0.788,\n",
       " 'ragetweet': 0.788,\n",
       " 'slaughterhouse': 0.788,\n",
       " 'retaliatory': 0.788,\n",
       " 'yelling': 0.788,\n",
       " 'riot': 0.788,\n",
       " 'punishing': 0.788,\n",
       " 'growthefuckup': 0.788,\n",
       " 'diabolical': 0.788,\n",
       " 'clash': 0.783,\n",
       " 'manslaughter': 0.783,\n",
       " 'hellish': 0.781,\n",
       " 'bloody': 0.781,\n",
       " 'loath': 0.781,\n",
       " 'quarrel': 0.781,\n",
       " 'detonation': 0.781,\n",
       " 'sinister': 0.781,\n",
       " 'fumin': 0.779,\n",
       " 'hateeee': 0.779,\n",
       " 'treacherous': 0.779,\n",
       " 'accusing': 0.779,\n",
       " 'madder': 0.773,\n",
       " 'retaliate': 0.773,\n",
       " 'revulsion': 0.773,\n",
       " 'horrific': 0.773,\n",
       " 'scorn': 0.769,\n",
       " 'bomb': 0.766,\n",
       " 'deplorable': 0.766,\n",
       " 'anarchist': 0.765,\n",
       " 'devastation': 0.765,\n",
       " 'resent': 0.765,\n",
       " 'firestorm': 0.765,\n",
       " 'contemptible': 0.764,\n",
       " 'shittest': 0.76,\n",
       " 'smash': 0.758,\n",
       " 'deadly': 0.758,\n",
       " 'soangry': 0.758,\n",
       " 'rant': 0.758,\n",
       " 'cruel': 0.758,\n",
       " 'outburst': 0.757,\n",
       " 'snarl': 0.754,\n",
       " 'crazed': 0.75,\n",
       " 'dontmesswithme': 0.75,\n",
       " 'profane': 0.75,\n",
       " 'aggravating': 0.75,\n",
       " 'douchebags': 0.75,\n",
       " 'offend': 0.75,\n",
       " 'horror': 0.75,\n",
       " 'revolting': 0.75,\n",
       " 'despise': 0.75,\n",
       " 'vulgarity': 0.75,\n",
       " 'growling': 0.75,\n",
       " 'stfu': 0.75,\n",
       " 'molestation': 0.742,\n",
       " 'fuckedoff': 0.742,\n",
       " 'erupt': 0.742,\n",
       " 'violence': 0.742,\n",
       " 'horrible': 0.742,\n",
       " 'screaming': 0.742,\n",
       " 'threat': 0.742,\n",
       " 'bastards': 0.741,\n",
       " 'revenge': 0.738,\n",
       " 'menacing': 0.735,\n",
       " 'crushing': 0.735,\n",
       " 'damn': 0.735,\n",
       " 'catastrophe': 0.735,\n",
       " 'demon': 0.735,\n",
       " 'argue': 0.734,\n",
       " 'fedup': 0.734,\n",
       " 'vehement': 0.734,\n",
       " 'thrash': 0.734,\n",
       " 'warfare': 0.734,\n",
       " 'revolt': 0.734,\n",
       " 'flog': 0.734,\n",
       " 'deplore': 0.734,\n",
       " 'persecute': 0.734,\n",
       " 'riotous': 0.734,\n",
       " 'altercation': 0.729,\n",
       " 'warlike': 0.728,\n",
       " 'mutiny': 0.727,\n",
       " 'shitday': 0.727,\n",
       " 'sabotage': 0.727,\n",
       " 'castrate': 0.727,\n",
       " 'strike': 0.721,\n",
       " 'malevolent': 0.721,\n",
       " 'disaster': 0.721,\n",
       " 'disastrous': 0.72,\n",
       " 'disdain': 0.719,\n",
       " 'choke': 0.719,\n",
       " 'arseholes': 0.719,\n",
       " 'devil': 0.719,\n",
       " 'scream': 0.719,\n",
       " 'spiteful': 0.719,\n",
       " 'bastarding': 0.719,\n",
       " 'scorching': 0.719,\n",
       " 'horseshit': 0.719,\n",
       " 'treachery': 0.719,\n",
       " 'slay': 0.719,\n",
       " 'brutal': 0.719,\n",
       " 'tumult': 0.719,\n",
       " 'madden': 0.719,\n",
       " 'aggravates': 0.719,\n",
       " 'vermin': 0.719,\n",
       " 'anarchism': 0.714,\n",
       " 'mutilation': 0.714,\n",
       " 'mangle': 0.714,\n",
       " 'criminal': 0.714,\n",
       " 'punch': 0.713,\n",
       " 'denunciation': 0.713,\n",
       " 'holocaust': 0.712,\n",
       " 'blasphemous': 0.712,\n",
       " 'battled': 0.712,\n",
       " 'dumbasses': 0.712,\n",
       " 'fatal': 0.712,\n",
       " 'virulence': 0.712,\n",
       " 'dontlikeyou': 0.712,\n",
       " 'hurting': 0.712,\n",
       " 'crucifixion': 0.712,\n",
       " 'deranged': 0.706,\n",
       " 'evil': 0.706,\n",
       " 'irritated': 0.706,\n",
       " 'atrocious': 0.706,\n",
       " 'assassin': 0.703,\n",
       " 'intimidation': 0.703,\n",
       " 'persecution': 0.703,\n",
       " 'slayer': 0.703,\n",
       " 'kidnap': 0.703,\n",
       " 'dicks': 0.703,\n",
       " 'scolding': 0.703,\n",
       " 'aggravated': 0.703,\n",
       " 'aggression': 0.702,\n",
       " 'armed': 0.7,\n",
       " 'poison': 0.697,\n",
       " 'snarling': 0.697,\n",
       " 'venom': 0.697,\n",
       " 'battle': 0.697,\n",
       " 'disgruntled': 0.693,\n",
       " 'assailant': 0.691,\n",
       " 'insidious': 0.691,\n",
       " 'resentment': 0.691,\n",
       " 'contemptuous': 0.69,\n",
       " 'lynch': 0.69,\n",
       " 'lunatic': 0.688,\n",
       " 'mad': 0.688,\n",
       " 'peeved': 0.688,\n",
       " 'bully': 0.688,\n",
       " 'temper': 0.688,\n",
       " 'infanticide': 0.688,\n",
       " 'curse': 0.688,\n",
       " 'domination': 0.688,\n",
       " 'imprisonment': 0.688,\n",
       " 'terrible': 0.688,\n",
       " 'disparage': 0.688,\n",
       " 'makesmemad': 0.688,\n",
       " 'volatility': 0.687,\n",
       " 'eradication': 0.685,\n",
       " 'scoundrel': 0.682,\n",
       " 'eradicate': 0.682,\n",
       " 'tantrum': 0.682,\n",
       " 'devastate': 0.682,\n",
       " 'agitation': 0.68,\n",
       " 'aggressively': 0.68,\n",
       " 'irritates': 0.676,\n",
       " 'dictatorship': 0.676,\n",
       " 'profanity': 0.673,\n",
       " 'dastardly': 0.672,\n",
       " 'expletive': 0.672,\n",
       " 'wreak': 0.672,\n",
       " 'contempt': 0.672,\n",
       " 'crime': 0.672,\n",
       " 'poisonous': 0.672,\n",
       " 'nasty': 0.672,\n",
       " 'aggravation': 0.672,\n",
       " 'condemnation': 0.672,\n",
       " 'egregious': 0.672,\n",
       " 'shove': 0.672,\n",
       " 'shoot': 0.672,\n",
       " 'shot': 0.672,\n",
       " 'crushed': 0.672,\n",
       " 'corrupting': 0.672,\n",
       " 'harmful': 0.672,\n",
       " 'cruelly': 0.672,\n",
       " 'maniac': 0.67,\n",
       " 'irritable': 0.667,\n",
       " 'shooting': 0.667,\n",
       " 'odious': 0.667,\n",
       " 'shout': 0.667,\n",
       " 'eruption': 0.667,\n",
       " 'cutthroat': 0.667,\n",
       " 'kick': 0.667,\n",
       " 'hateeveryone': 0.667,\n",
       " 'hit': 0.667,\n",
       " 'fight': 0.667,\n",
       " 'enemy': 0.667,\n",
       " 'combat': 0.667,\n",
       " 'aggressive': 0.667,\n",
       " 'punished': 0.662,\n",
       " 'yell': 0.661,\n",
       " 'ambush': 0.661,\n",
       " 'harass': 0.659,\n",
       " 'gore': 0.656,\n",
       " 'expel': 0.656,\n",
       " 'malignant': 0.656,\n",
       " 'destruction': 0.656,\n",
       " 'aggressor': 0.656,\n",
       " 'incense': 0.656,\n",
       " 'grudge': 0.656,\n",
       " 'antichrist': 0.656,\n",
       " 'cranky': 0.653,\n",
       " 'reprisal': 0.652,\n",
       " 'slave': 0.652,\n",
       " 'growl': 0.652,\n",
       " 'offended': 0.652,\n",
       " 'clashing': 0.652,\n",
       " 'insulting': 0.652,\n",
       " 'insurrection': 0.652,\n",
       " 'spank': 0.652,\n",
       " 'animosity': 0.652,\n",
       " 'denounce': 0.652,\n",
       " 'growls': 0.649,\n",
       " 'executioner': 0.644,\n",
       " 'twat': 0.644,\n",
       " 'doomsday': 0.643,\n",
       " 'bombard': 0.641,\n",
       " 'feud': 0.641,\n",
       " 'accused': 0.641,\n",
       " 'arson': 0.641,\n",
       " 'daemon': 0.641,\n",
       " 'shackle': 0.641,\n",
       " 'indignant': 0.641,\n",
       " 'obscenity': 0.641,\n",
       " 'spat': 0.641,\n",
       " 'havoc': 0.641,\n",
       " 'grr': 0.641,\n",
       " 'inexcusable': 0.641,\n",
       " 'expulsion': 0.641,\n",
       " 'reprimand': 0.641,\n",
       " 'somad': 0.637,\n",
       " 'poisoned': 0.636,\n",
       " 'kicking': 0.636,\n",
       " 'wound': 0.636,\n",
       " 'batter': 0.636,\n",
       " 'frustrated': 0.636,\n",
       " 'hanging': 0.636,\n",
       " 'disgusting': 0.636,\n",
       " 'spanking': 0.636,\n",
       " 'suicidal': 0.636,\n",
       " 'anarchy': 0.636,\n",
       " 'glaring': 0.636,\n",
       " 'combatant': 0.636,\n",
       " 'wrecked': 0.633,\n",
       " 'inflict': 0.633,\n",
       " 'grievous': 0.632,\n",
       " 'cheat': 0.63,\n",
       " 'prosecute': 0.63,\n",
       " 'agitated': 0.63,\n",
       " 'swastika': 0.627,\n",
       " 'enslaved': 0.625,\n",
       " 'scourge': 0.625,\n",
       " 'raid': 0.625,\n",
       " 'suffocation': 0.625,\n",
       " 'defamatory': 0.625,\n",
       " 'indict': 0.625,\n",
       " 'cursing': 0.625,\n",
       " 'provocation': 0.625,\n",
       " 'harassing': 0.625,\n",
       " 'injure': 0.625,\n",
       " 'betray': 0.625,\n",
       " 'thundering': 0.625,\n",
       " 'strife': 0.625,\n",
       " 'arsehole': 0.624,\n",
       " 'jerk': 0.621,\n",
       " 'retaliation': 0.621,\n",
       " 'fiend': 0.621,\n",
       " 'theft': 0.621,\n",
       " 'insane': 0.621,\n",
       " 'irritate': 0.621,\n",
       " 'deprivation': 0.621,\n",
       " 'convict': 0.621,\n",
       " 'cussed': 0.619,\n",
       " 'turmoil': 0.618,\n",
       " 'smack': 0.615,\n",
       " 'retribution': 0.614,\n",
       " 'adverse': 0.609,\n",
       " 'battery': 0.609,\n",
       " 'twats': 0.609,\n",
       " 'collision': 0.609,\n",
       " 'injurious': 0.609,\n",
       " 'rebellion': 0.609,\n",
       " 'slavery': 0.609,\n",
       " 'gang': 0.609,\n",
       " 'irritability': 0.609,\n",
       " 'bitterly': 0.609,\n",
       " 'oppressor': 0.609,\n",
       " 'antagonism': 0.609,\n",
       " 'intolerable': 0.609,\n",
       " 'disgraced': 0.608,\n",
       " 'diatribe': 0.606,\n",
       " 'sickening': 0.606,\n",
       " 'ranting': 0.606,\n",
       " 'asshole': 0.606,\n",
       " 'irks': 0.606,\n",
       " 'irritating': 0.606,\n",
       " 'discrimination': 0.606,\n",
       " 'bombardment': 0.606,\n",
       " 'thug': 0.606,\n",
       " 'antagonistic': 0.606,\n",
       " 'revolution': 0.606,\n",
       " 'blast': 0.606,\n",
       " 'frustrate': 0.604,\n",
       " 'tension': 0.603,\n",
       " 'manipulation': 0.603,\n",
       " 'oppression': 0.603,\n",
       " 'hurtful': 0.603,\n",
       " 'insult': 0.603,\n",
       " 'tiredofit': 0.603,\n",
       " 'bigot': 0.603,\n",
       " 'disgust': 0.602,\n",
       " 'spite': 0.6,\n",
       " 'intrusive': 0.598,\n",
       " 'harshness': 0.597,\n",
       " 'slur': 0.596,\n",
       " 'bitterness': 0.594,\n",
       " 'tempest': 0.594,\n",
       " 'miserable': 0.594,\n",
       " 'morbidity': 0.594,\n",
       " 'assail': 0.594,\n",
       " 'puncture': 0.594,\n",
       " 'invasion': 0.594,\n",
       " 'inferno': 0.594,\n",
       " 'casualty': 0.594,\n",
       " 'storming': 0.594,\n",
       " 'wretch': 0.594,\n",
       " 'consternation': 0.592,\n",
       " 'guillotine': 0.591,\n",
       " 'forcibly': 0.591,\n",
       " 'overpowering': 0.591,\n",
       " 'immoral': 0.591,\n",
       " 'guilty': 0.591,\n",
       " 'depraved': 0.591,\n",
       " 'raving': 0.591,\n",
       " 'soannoyed': 0.588,\n",
       " 'recalcitrant': 0.588,\n",
       " 'accursed': 0.588,\n",
       " 'screwed': 0.588,\n",
       " 'invader': 0.588,\n",
       " 'scare': 0.588,\n",
       " 'indignation': 0.587,\n",
       " 'jealousy': 0.587,\n",
       " 'vexed': 0.586,\n",
       " 'confront': 0.582,\n",
       " 'brute': 0.581,\n",
       " 'throttle': 0.579,\n",
       " 'provoking': 0.578,\n",
       " 'coup': 0.578,\n",
       " 'pillage': 0.578,\n",
       " 'damage': 0.578,\n",
       " 'shutup': 0.578,\n",
       " 'contentious': 0.578,\n",
       " 'shutit': 0.578,\n",
       " 'bickering': 0.578,\n",
       " 'incarceration': 0.578,\n",
       " 'butcher': 0.578,\n",
       " 'lash': 0.578,\n",
       " 'conflict': 0.578,\n",
       " 'blaze': 0.578,\n",
       " 'slut': 0.578,\n",
       " 'defiant': 0.578,\n",
       " 'wreck': 0.578,\n",
       " 'revolver': 0.578,\n",
       " 'yousuck': 0.578,\n",
       " 'criminality': 0.578,\n",
       " 'cancer': 0.577,\n",
       " 'frustration': 0.576,\n",
       " 'standoff': 0.576,\n",
       " 'gory': 0.576,\n",
       " 'dontmess': 0.576,\n",
       " 'alienation': 0.576,\n",
       " 'gun': 0.576,\n",
       " 'pernicious': 0.576,\n",
       " 'grope': 0.576,\n",
       " 'discord': 0.576,\n",
       " 'condescension': 0.576,\n",
       " 'discriminate': 0.576,\n",
       " 'blasphemy': 0.576,\n",
       " 'chaotic': 0.576,\n",
       " 'disturbance': 0.576,\n",
       " 'friggen': 0.575,\n",
       " 'jab': 0.574,\n",
       " 'monstrosity': 0.574,\n",
       " 'lunacy': 0.574,\n",
       " 'oppressive': 0.574,\n",
       " 'scandalous': 0.574,\n",
       " 'cursed': 0.574,\n",
       " 'sneer': 0.574,\n",
       " 'death': 0.574,\n",
       " 'shit': 0.573,\n",
       " 'slash': 0.571,\n",
       " 'unfair': 0.571,\n",
       " 'disparaging': 0.571,\n",
       " 'gallows': 0.57,\n",
       " 'escalate': 0.569,\n",
       " 'intolerant': 0.564,\n",
       " 'lawlessness': 0.563,\n",
       " 'bluddy': 0.562,\n",
       " 'dreadful': 0.562,\n",
       " 'arghh': 0.562,\n",
       " 'derogatory': 0.562,\n",
       " 'beast': 0.562,\n",
       " 'malign': 0.562,\n",
       " 'traitor': 0.562,\n",
       " 'grouchy': 0.562,\n",
       " 'slander': 0.562,\n",
       " 'wrangling': 0.562,\n",
       " 'taunt': 0.562,\n",
       " 'perdition': 0.562,\n",
       " 'frightful': 0.562,\n",
       " 'invade': 0.562,\n",
       " 'glare': 0.562,\n",
       " 'deceived': 0.562,\n",
       " 'torpedo': 0.562,\n",
       " 'bellows': 0.562,\n",
       " 'retards': 0.562,\n",
       " 'bearish': 0.562,\n",
       " 'rave': 0.561,\n",
       " 'hurt': 0.561,\n",
       " 'grating': 0.561,\n",
       " 'thief': 0.561,\n",
       " 'uncontrollable': 0.561,\n",
       " 'idiots': 0.561,\n",
       " 'devastating': 0.561,\n",
       " 'banshee': 0.561,\n",
       " 'cross': 0.561,\n",
       " 'betrayal': 0.561,\n",
       " 'fits': 0.561,\n",
       " 'shatter': 0.561,\n",
       " 'conflagration': 0.561,\n",
       " 'jeopardize': 0.561,\n",
       " 'dissension': 0.561,\n",
       " 'subjugation': 0.559,\n",
       " 'disturbed': 0.559,\n",
       " 'stomped': 0.557,\n",
       " 'grab': 0.557,\n",
       " 'ticked': 0.556,\n",
       " 'masochism': 0.556,\n",
       " 'grievance': 0.556,\n",
       " 'defiance': 0.552,\n",
       " 'blackmail': 0.55,\n",
       " 'offensive': 0.549,\n",
       " 'decry': 0.548,\n",
       " 'sin': 0.547,\n",
       " 'fustrated': 0.547,\n",
       " 'ire': 0.547,\n",
       " 'confine': 0.547,\n",
       " 'deceive': 0.547,\n",
       " 'arghhhh': 0.547,\n",
       " 'punishment': 0.547,\n",
       " 'violation': 0.547,\n",
       " 'preposterous': 0.547,\n",
       " 'disgraceful': 0.547,\n",
       " 'darkside': 0.547,\n",
       " 'frustrates': 0.547,\n",
       " 'overbearing': 0.547,\n",
       " 'misery': 0.547,\n",
       " 'firearms': 0.547,\n",
       " 'rebel': 0.547,\n",
       " 'shrill': 0.547,\n",
       " 'disparity': 0.547,\n",
       " 'hadenough': 0.546,\n",
       " 'stolen': 0.546,\n",
       " 'foul': 0.545,\n",
       " 'adversary': 0.545,\n",
       " 'conspirator': 0.545,\n",
       " 'skirmish': 0.545,\n",
       " 'ruined': 0.545,\n",
       " 'annoyin': 0.545,\n",
       " 'menace': 0.545,\n",
       " 'tackle': 0.545,\n",
       " 'humiliate': 0.545,\n",
       " 'prejudice': 0.545,\n",
       " 'resentful': 0.545,\n",
       " 'antagonist': 0.545,\n",
       " 'heated': 0.545,\n",
       " 'wanker': 0.545,\n",
       " 'callous': 0.545,\n",
       " 'argument': 0.545,\n",
       " 'sting': 0.544,\n",
       " 'outcry': 0.544,\n",
       " 'grumble': 0.544,\n",
       " 'robbery': 0.544,\n",
       " 'entangled': 0.544,\n",
       " 'resistance': 0.543,\n",
       " 'irreconcilable': 0.543,\n",
       " 'obstructive': 0.542,\n",
       " 'dismay': 0.54,\n",
       " 'mob': 0.538,\n",
       " 'juststop': 0.537,\n",
       " 'badness': 0.536,\n",
       " 'ridicule': 0.534,\n",
       " 'incendiary': 0.533,\n",
       " 'flares': 0.532,\n",
       " 'twofaced': 0.531,\n",
       " 'exacerbation': 0.531,\n",
       " 'prejudicial': 0.531,\n",
       " 'unbridled': 0.531,\n",
       " 'intruder': 0.531,\n",
       " 'communism': 0.531,\n",
       " 'uprising': 0.531,\n",
       " 'dispute': 0.531,\n",
       " 'reckless': 0.531,\n",
       " 'confinement': 0.531,\n",
       " 'degeneracy': 0.531,\n",
       " 'whip': 0.531,\n",
       " 'belittle': 0.531,\n",
       " 'allegation': 0.531,\n",
       " 'offender': 0.53,\n",
       " 'tackled': 0.53,\n",
       " 'dictatorial': 0.53,\n",
       " 'perversion': 0.53,\n",
       " 'unjust': 0.53,\n",
       " 'fiesty': 0.53,\n",
       " 'hassle': 0.53,\n",
       " 'unjustifiable': 0.53,\n",
       " 'bigoted': 0.53,\n",
       " 'dissonance': 0.53,\n",
       " 'prison': 0.529,\n",
       " 'trespass': 0.529,\n",
       " 'cantstandit': 0.529,\n",
       " 'hot': 0.529,\n",
       " 'renegade': 0.529,\n",
       " 'suicide': 0.521,\n",
       " 'annoy': 0.52,\n",
       " 'leavemealone': 0.517,\n",
       " 'depravity': 0.516,\n",
       " 'venting': 0.516,\n",
       " 'divorce': 0.516,\n",
       " 'dishonest': 0.516,\n",
       " 'prisoner': 0.516,\n",
       " 'duress': 0.516,\n",
       " 'inimical': 0.516,\n",
       " 'grrr': 0.516,\n",
       " 'idiotic': 0.516,\n",
       " 'treason': 0.516,\n",
       " 'tortious': 0.516,\n",
       " 'criticize': 0.516,\n",
       " 'disrespectful': 0.516,\n",
       " 'distrust': 0.516,\n",
       " 'cretins': 0.516,\n",
       " 'broil': 0.516,\n",
       " 'hangry': 0.515,\n",
       " 'unkind': 0.515,\n",
       " 'bile': 0.515,\n",
       " 'roar': 0.515,\n",
       " 'poaching': 0.515,\n",
       " 'unforgiving': 0.515,\n",
       " 'poachers': 0.515,\n",
       " 'pow': 0.515,\n",
       " 'unleash': 0.515,\n",
       " 'scold': 0.515,\n",
       " 'argumentation': 0.515,\n",
       " 'chaos': 0.515,\n",
       " 'frustrating': 0.515,\n",
       " 'jerks': 0.515,\n",
       " 'coercion': 0.515,\n",
       " 'grump': 0.515,\n",
       " 'victimized': 0.515,\n",
       " 'tussle': 0.514,\n",
       " 'bane': 0.511,\n",
       " 'accusation': 0.51,\n",
       " 'enmity': 0.51,\n",
       " 'repudiation': 0.51,\n",
       " 'banish': 0.509,\n",
       " 'disfigured': 0.508,\n",
       " 'storm': 0.507,\n",
       " 'derogation': 0.5,\n",
       " 'obstruct': 0.5,\n",
       " 'nobodycares': 0.5,\n",
       " 'rejects': 0.5,\n",
       " 'unruly': 0.5,\n",
       " 'crazy': 0.5,\n",
       " 'hammering': 0.5,\n",
       " 'malpractice': 0.5,\n",
       " 'frenzied': 0.5,\n",
       " 'suppression': 0.5,\n",
       " 'scoff': 0.5,\n",
       " 'possessed': 0.5,\n",
       " 'intractable': 0.5,\n",
       " 'fervor': 0.5,\n",
       " 'delusional': 0.5,\n",
       " 'brunt': 0.5,\n",
       " 'confined': 0.5,\n",
       " 'injustice': 0.5,\n",
       " 'shun': 0.5,\n",
       " 'defy': 0.5,\n",
       " 'anguish': 0.5,\n",
       " 'antithesis': 0.5,\n",
       " 'fear': 0.5,\n",
       " 'bout': 0.5,\n",
       " 'derision': 0.5,\n",
       " 'banished': 0.5,\n",
       " 'animus': 0.5,\n",
       " 'reject': 0.5,\n",
       " 'spear': 0.5,\n",
       " 'dominate': 0.5,\n",
       " 'patronising': 0.5,\n",
       " 'brazen': 0.5,\n",
       " 'disrupting': 0.5,\n",
       " 'ordeal': 0.5,\n",
       " 'foaming': 0.5,\n",
       " 'getoveryourself': 0.495,\n",
       " 'stupidpeople': 0.492,\n",
       " 'toughness': 0.492,\n",
       " 'sinful': 0.491,\n",
       " 'madness': 0.491,\n",
       " 'oppress': 0.49,\n",
       " 'avarice': 0.49,\n",
       " 'anathema': 0.485,\n",
       " 'incest': 0.485,\n",
       " 'dissident': 0.485,\n",
       " 'abolish': 0.485,\n",
       " 'smuggler': 0.485,\n",
       " 'claw': 0.485,\n",
       " 'revoke': 0.485,\n",
       " 'complaint': 0.485,\n",
       " 'infraction': 0.485,\n",
       " 'avenger': 0.485,\n",
       " 'pervert': 0.485,\n",
       " 'cutting': 0.485,\n",
       " 'usurp': 0.485,\n",
       " 'inhuman': 0.485,\n",
       " 'disservice': 0.485,\n",
       " 'annoyed': 0.485,\n",
       " 'stayaway': 0.485,\n",
       " 'disobedient': 0.485,\n",
       " 'alienate': 0.485,\n",
       " 'fricking': 0.485,\n",
       " 'demand': 0.485,\n",
       " 'disapproved': 0.485,\n",
       " 'oust': 0.484,\n",
       " 'litigious': 0.484,\n",
       " 'rivalry': 0.484,\n",
       " 'mocking': 0.484,\n",
       " 'obnoxious': 0.484,\n",
       " 'thresh': 0.484,\n",
       " 'restrain': 0.484,\n",
       " 'blame': 0.484,\n",
       " 'deceit': 0.484,\n",
       " 'strained': 0.484,\n",
       " 'penalty': 0.484,\n",
       " 'opposed': 0.484,\n",
       " 'disgrace': 0.484,\n",
       " 'imprisoned': 0.484,\n",
       " 'sucker': 0.484,\n",
       " 'suspicious': 0.484,\n",
       " 'upheaval': 0.484,\n",
       " 'renounce': 0.484,\n",
       " 'turbulence': 0.483,\n",
       " 'pound': 0.481,\n",
       " 'coldness': 0.477,\n",
       " 'ungrateful': 0.472,\n",
       " 'stoopid': 0.471,\n",
       " 'battalion': 0.471,\n",
       " 'armament': 0.47,\n",
       " 'jealous': 0.47,\n",
       " 'hostage': 0.47,\n",
       " 'adversity': 0.47,\n",
       " 'infidel': 0.47,\n",
       " 'ram': 0.47,\n",
       " 'annoying': 0.47,\n",
       " 'dispossessed': 0.47,\n",
       " 'feudalism': 0.47,\n",
       " 'gall': 0.47,\n",
       " 'accuser': 0.47,\n",
       " 'friction': 0.47,\n",
       " 'subversion': 0.47,\n",
       " 'plunder': 0.469,\n",
       " 'incite': 0.469,\n",
       " 'objection': 0.469,\n",
       " 'simmer': 0.469,\n",
       " 'offense': 0.469,\n",
       " 'complain': 0.469,\n",
       " 'injury': 0.469,\n",
       " 'disruption': 0.469,\n",
       " 'backoff': 0.469,\n",
       " 'steal': 0.469,\n",
       " 'angermanagement': 0.469,\n",
       " 'stifled': 0.469,\n",
       " 'smother': 0.469,\n",
       " 'selfish': 0.469,\n",
       " 'dislike': 0.469,\n",
       " 'recidivism': 0.469,\n",
       " 'disobey': 0.469,\n",
       " 'intolerance': 0.469,\n",
       " 'exile': 0.469,\n",
       " 'thump': 0.469,\n",
       " 'selfishness': 0.469,\n",
       " 'distress': 0.469,\n",
       " 'huff': 0.469,\n",
       " 'perpetrator': 0.469,\n",
       " 'subversive': 0.469,\n",
       " 'opposition': 0.469,\n",
       " 'insanity': 0.469,\n",
       " 'areyoukidding': 0.468,\n",
       " 'mug': 0.467,\n",
       " 'agony': 0.465,\n",
       " 'arrogant': 0.461,\n",
       " 'vent': 0.456,\n",
       " 'sux': 0.456,\n",
       " 'picketing': 0.456,\n",
       " 'elimination': 0.456,\n",
       " 'haughty': 0.456,\n",
       " 'troublesome': 0.455,\n",
       " 'mislead': 0.455,\n",
       " 'impermeable': 0.455,\n",
       " 'illegality': 0.455,\n",
       " 'constraint': 0.455,\n",
       " 'dying': 0.455,\n",
       " 'clamor': 0.455,\n",
       " 'flagrant': 0.455,\n",
       " 'illicit': 0.455,\n",
       " 'busted': 0.455,\n",
       " 'veto': 0.455,\n",
       " 'idiocy': 0.455,\n",
       " 'crabby': 0.455,\n",
       " 'stubbed': 0.455,\n",
       " 'grated': 0.455,\n",
       " 'desist': 0.453,\n",
       " 'suppress': 0.453,\n",
       " 'bad': 0.453,\n",
       " 'disagreeing': 0.453,\n",
       " 'struggle': 0.453,\n",
       " 'despotism': 0.453,\n",
       " 'disapproving': 0.453,\n",
       " 'bayonet': 0.453,\n",
       " 'intense': 0.453,\n",
       " 'hysterical': 0.453,\n",
       " 'usurped': 0.453,\n",
       " 'displeased': 0.453,\n",
       " 'godless': 0.453,\n",
       " 'unlawful': 0.451,\n",
       " 'wrongly': 0.448,\n",
       " 'repellent': 0.442,\n",
       " 'wrongful': 0.441,\n",
       " 'dishonor': 0.441,\n",
       " 'foe': 0.441,\n",
       " 'wasted': 0.441,\n",
       " 'psychosis': 0.441,\n",
       " 'aversion': 0.44,\n",
       " 'punitive': 0.439,\n",
       " 'ultimatum': 0.439,\n",
       " 'gahhh': 0.439,\n",
       " 'knuckles': 0.439,\n",
       " 'effigy': 0.439,\n",
       " 'upset': 0.439,\n",
       " 'schism': 0.439,\n",
       " 'separatist': 0.438,\n",
       " 'deny': 0.438,\n",
       " 'stupidity': 0.438,\n",
       " 'deleterious': 0.438,\n",
       " 'worthless': 0.438,\n",
       " 'abandonment': 0.438,\n",
       " 'mucked': 0.438,\n",
       " 'ransom': 0.438,\n",
       " 'irritation': 0.438,\n",
       " 'fugitive': 0.438,\n",
       " 'segregate': 0.437,\n",
       " 'oblivion': 0.437,\n",
       " 'payback': 0.436,\n",
       " 'incongruous': 0.435,\n",
       " 'eviction': 0.435,\n",
       " 'collusion': 0.432,\n",
       " 'rob': 0.431,\n",
       " 'ravenous': 0.429,\n",
       " 'infidelity': 0.429,\n",
       " 'overrun': 0.429,\n",
       " 'rejection': 0.426,\n",
       " 'stupidrain': 0.426,\n",
       " 'getoverit': 0.426,\n",
       " 'incredulous': 0.426,\n",
       " 'martial': 0.426,\n",
       " 'harbinger': 0.426,\n",
       " 'painful': 0.426,\n",
       " 'defense': 0.425,\n",
       " 'enforce': 0.424,\n",
       " 'fuss': 0.424,\n",
       " 'banger': 0.424,\n",
       " 'defraud': 0.424,\n",
       " 'commotion': 0.424,\n",
       " 'powerful': 0.424,\n",
       " 'fraudulent': 0.424,\n",
       " 'concealment': 0.424,\n",
       " 'indecency': 0.424,\n",
       " 'greed': 0.424,\n",
       " 'exasperation': 0.424,\n",
       " 'disobedience': 0.424,\n",
       " 'censor': 0.424,\n",
       " 'discontent': 0.424,\n",
       " 'fallacious': 0.424,\n",
       " 'gonorrhea': 0.424,\n",
       " 'unsympathetic': 0.424,\n",
       " 'cur': 0.422,\n",
       " 'duel': 0.422,\n",
       " 'banishment': 0.422,\n",
       " 'annoyance': 0.422,\n",
       " 'bang': 0.422,\n",
       " 'deportation': 0.422,\n",
       " 'penetration': 0.422,\n",
       " 'nettle': 0.422,\n",
       " 'scar': 0.422,\n",
       " 'misrepresented': 0.422,\n",
       " 'penitentiary': 0.422,\n",
       " 'sedition': 0.422,\n",
       " 'barb': 0.422,\n",
       " 'snubbed': 0.422,\n",
       " 'sarcasm': 0.422,\n",
       " 'cracked': 0.422,\n",
       " 'blatant': 0.42,\n",
       " 'force': 0.418,\n",
       " 'perverse': 0.415,\n",
       " 'wring': 0.415,\n",
       " 'grim': 0.413,\n",
       " 'bastion': 0.413,\n",
       " 'tiff': 0.412,\n",
       " 'sordid': 0.412,\n",
       " 'surly': 0.412,\n",
       " 'nothappy': 0.412,\n",
       " 'moody': 0.412,\n",
       " 'hunting': 0.411,\n",
       " 'indenture': 0.41,\n",
       " 'detainee': 0.409,\n",
       " 'supremacy': 0.409,\n",
       " 'compulsion': 0.409,\n",
       " 'reproach': 0.409,\n",
       " 'areyoukiddingme': 0.409,\n",
       " 'inept': 0.409,\n",
       " 'cantwin': 0.409,\n",
       " 'squelch': 0.409,\n",
       " 'forfeit': 0.409,\n",
       " 'blockade': 0.409,\n",
       " 'disappoint': 0.409,\n",
       " 'implicate': 0.409,\n",
       " 'sham': 0.409,\n",
       " 'awful': 0.409,\n",
       " 'contradict': 0.409,\n",
       " 'sneak': 0.409,\n",
       " 'lying': 0.408,\n",
       " 'badger': 0.406,\n",
       " 'forsaken': 0.406,\n",
       " 'antipathy': 0.406,\n",
       " 'inequality': 0.406,\n",
       " 'epidemic': 0.406,\n",
       " 'wop': 0.406,\n",
       " 'onerous': 0.406,\n",
       " 'tremor': 0.406,\n",
       " ...}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_intensities = get_word_affect_intensity_dict(emotion)\n",
    "word_intensities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly_emo_int = PolynomialFeatures(10)\n",
    "\n",
    "def get_emo_int_vector(tweet):\n",
    "    score = 0.0\n",
    "    for word in word_intensities.keys():\n",
    "        if word in tweet:\n",
    "            score += tweet.count(word) * float(word_intensities[word])\n",
    "    return normalize(poly_emo_int.fit_transform(np.array([score]).reshape(1, -1))[0].reshape(1, -1))[0]\n",
    "    # return [score]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.41320797, 0.3838702 , 0.35661542, 0.33129572, 0.30777372,\n",
       "       0.28592179, 0.26562134, 0.24676223, 0.22924211, 0.21296592,\n",
       "       0.19784534])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_emo_int_vector(\"furious\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3) SentiWordNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import sentiwordnet as swn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly_sentiwordnet = PolynomialFeatures(5)\n",
    "\n",
    "def get_sentiwordnetscore(tweet):\n",
    "    \n",
    "    score = np.zeros(2)\n",
    "    \n",
    "    for word in tweet.split():\n",
    "        synsetlist = list(swn.senti_synsets(word))\n",
    "        \n",
    "        if synsetlist:\n",
    "            score[0] += synsetlist[0].pos_score()\n",
    "            score[1] += synsetlist[0].neg_score()\n",
    "            \n",
    "#     return tweet_score.tolist()\n",
    "    return normalize(poly_sentiwordnet.fit_transform(np.array([score]).reshape(1, -1))[0].reshape(1, -1))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9.37500185e-01, 2.34375046e-01, 2.34375046e-01, 5.85937616e-02,\n",
       "       5.85937616e-02, 5.85937616e-02, 1.46484404e-02, 1.46484404e-02,\n",
       "       1.46484404e-02, 1.46484404e-02, 3.66211010e-03, 3.66211010e-03,\n",
       "       3.66211010e-03, 3.66211010e-03, 3.66211010e-03, 9.15527525e-04,\n",
       "       9.15527525e-04, 9.15527525e-04, 9.15527525e-04, 9.15527525e-04,\n",
       "       9.15527525e-04])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_sentiwordnetscore(\"furious\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4) Sentiment Emotion Presence Lexicon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_emotion_lex_file_path = ('%s%s/' %(lexicons_path, paths2[2])) + listdir('%s%s/' %(lexicons_path, paths2[2]))[0]\n",
    "\n",
    "def get_affect_presence_list(emotion):\n",
    "    word_list = list()\n",
    "    \n",
    "    with open(sentiment_emotion_lex_file_path) as sentiment_emotion_lex_file:\n",
    "        lines = sentiment_emotion_lex_file.readlines()[1:] \n",
    "        for line in lines:\n",
    "            word_array = line.replace(\"\\n\", \"\").split(\"\\t\")\n",
    "\n",
    "            if (word_array[1] == emotion and word_array[2] == '1'):\n",
    "                word_list.append(word_array[0])\n",
    "                \n",
    "    return word_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['abandoned',\n",
       " 'abandonment',\n",
       " 'abhor',\n",
       " 'abhorrent',\n",
       " 'abolish',\n",
       " 'abomination',\n",
       " 'abuse',\n",
       " 'accursed',\n",
       " 'accusation',\n",
       " 'accused',\n",
       " 'accuser',\n",
       " 'accusing',\n",
       " 'actionable',\n",
       " 'adder',\n",
       " 'adversary',\n",
       " 'adverse',\n",
       " 'adversity',\n",
       " 'advocacy',\n",
       " 'affront',\n",
       " 'aftermath',\n",
       " 'aggravated',\n",
       " 'aggravating',\n",
       " 'aggravation',\n",
       " 'aggression',\n",
       " 'aggressive',\n",
       " 'aggressor',\n",
       " 'agitated',\n",
       " 'agitation',\n",
       " 'agony',\n",
       " 'alcoholism',\n",
       " 'alienate',\n",
       " 'alienation',\n",
       " 'allegation',\n",
       " 'altercation',\n",
       " 'ambush',\n",
       " 'anarchism',\n",
       " 'anarchist',\n",
       " 'anarchy',\n",
       " 'anathema',\n",
       " 'anger',\n",
       " 'angry',\n",
       " 'anguish',\n",
       " 'animosity',\n",
       " 'animus',\n",
       " 'annihilate',\n",
       " 'annihilated',\n",
       " 'annihilation',\n",
       " 'annoy',\n",
       " 'annoyance',\n",
       " 'annoying',\n",
       " 'antagonism',\n",
       " 'antagonist',\n",
       " 'antagonistic',\n",
       " 'antichrist',\n",
       " 'antipathy',\n",
       " 'antisocial',\n",
       " 'antithesis',\n",
       " 'anxiety',\n",
       " 'argue',\n",
       " 'argument',\n",
       " 'argumentation',\n",
       " 'arguments',\n",
       " 'armament',\n",
       " 'armed',\n",
       " 'arraignment',\n",
       " 'arrogant',\n",
       " 'arson',\n",
       " 'assail',\n",
       " 'assailant',\n",
       " 'assassin',\n",
       " 'assassinate',\n",
       " 'assassination',\n",
       " 'assault',\n",
       " 'asshole',\n",
       " 'atrocious',\n",
       " 'atrocity',\n",
       " 'attack',\n",
       " 'attacking',\n",
       " 'attorney',\n",
       " 'avarice',\n",
       " 'avenger',\n",
       " 'averse',\n",
       " 'aversion',\n",
       " 'awful',\n",
       " 'backbone',\n",
       " 'bad',\n",
       " 'badger',\n",
       " 'badness',\n",
       " 'bane',\n",
       " 'bang',\n",
       " 'banger',\n",
       " 'banish',\n",
       " 'banished',\n",
       " 'banishment',\n",
       " 'bankruptcy',\n",
       " 'banshee',\n",
       " 'barb',\n",
       " 'barbaric',\n",
       " 'bark',\n",
       " 'barrier',\n",
       " 'bastion',\n",
       " 'battalion',\n",
       " 'batter',\n",
       " 'battery',\n",
       " 'battle',\n",
       " 'battled',\n",
       " 'bayonet',\n",
       " 'bear',\n",
       " 'bearish',\n",
       " 'beast',\n",
       " 'beating',\n",
       " 'bee',\n",
       " 'belittle',\n",
       " 'belligerent',\n",
       " 'bellows',\n",
       " 'belt',\n",
       " 'berserk',\n",
       " 'betray',\n",
       " 'betrayal',\n",
       " 'bias',\n",
       " 'bickering',\n",
       " 'bigot',\n",
       " 'bigoted',\n",
       " 'bile',\n",
       " 'birch',\n",
       " 'birthplace',\n",
       " 'bitch',\n",
       " 'bitterly',\n",
       " 'bitterness',\n",
       " 'blackmail',\n",
       " 'blame',\n",
       " 'blasphemous',\n",
       " 'blasphemy',\n",
       " 'blast',\n",
       " 'blatant',\n",
       " 'blaze',\n",
       " 'blemish',\n",
       " 'blockade',\n",
       " 'bloodshed',\n",
       " 'bloodthirsty',\n",
       " 'bloody',\n",
       " 'bogus',\n",
       " 'boisterous',\n",
       " 'bomb',\n",
       " 'bombard',\n",
       " 'bombardment',\n",
       " 'bothering',\n",
       " 'bout',\n",
       " 'boxing',\n",
       " 'brawl',\n",
       " 'brazen',\n",
       " 'brimstone',\n",
       " 'broil',\n",
       " 'broken',\n",
       " 'brunt',\n",
       " 'brutal',\n",
       " 'brutality',\n",
       " 'brute',\n",
       " 'buffet',\n",
       " 'bugaboo',\n",
       " 'bully',\n",
       " 'bummer',\n",
       " 'burial',\n",
       " 'burke',\n",
       " 'busted',\n",
       " 'butcher',\n",
       " 'cacophony',\n",
       " 'cad',\n",
       " 'callous',\n",
       " 'campaigning',\n",
       " 'cancer',\n",
       " 'cane',\n",
       " 'canker',\n",
       " 'cannon',\n",
       " 'carelessness',\n",
       " 'carnage',\n",
       " 'cash',\n",
       " 'casualty',\n",
       " 'catastrophe',\n",
       " 'caution',\n",
       " 'celebrity',\n",
       " 'censor',\n",
       " 'chaff',\n",
       " 'challenge',\n",
       " 'chant',\n",
       " 'chaos',\n",
       " 'chaotic',\n",
       " 'cheat',\n",
       " 'choke',\n",
       " 'claimant',\n",
       " 'clamor',\n",
       " 'clash',\n",
       " 'clashing',\n",
       " 'claw',\n",
       " 'coerce',\n",
       " 'coercion',\n",
       " 'coldness',\n",
       " 'collision',\n",
       " 'collusion',\n",
       " 'combat',\n",
       " 'combatant',\n",
       " 'combative',\n",
       " 'commotion',\n",
       " 'communism',\n",
       " 'complain',\n",
       " 'complaint',\n",
       " 'complicate',\n",
       " 'compress',\n",
       " 'compulsion',\n",
       " 'concealment',\n",
       " 'concussion',\n",
       " 'condemn',\n",
       " 'condemnation',\n",
       " 'condescension',\n",
       " 'confine',\n",
       " 'confined',\n",
       " 'confinement',\n",
       " 'confiscate',\n",
       " 'conflagration',\n",
       " 'conflict',\n",
       " 'confront',\n",
       " 'confusion',\n",
       " 'conquest',\n",
       " 'conspirator',\n",
       " 'consternation',\n",
       " 'constraint',\n",
       " 'contempt',\n",
       " 'contemptible',\n",
       " 'contemptuous',\n",
       " 'contentious',\n",
       " 'contraband',\n",
       " 'contradict',\n",
       " 'controversial',\n",
       " 'convict',\n",
       " 'coop',\n",
       " 'copycat',\n",
       " 'corrupting',\n",
       " 'counsellor',\n",
       " 'coup',\n",
       " 'court',\n",
       " 'crabby',\n",
       " 'cracked',\n",
       " 'cranky',\n",
       " 'crazed',\n",
       " 'crazy',\n",
       " 'crime',\n",
       " 'criminal',\n",
       " 'criminality',\n",
       " 'criticism',\n",
       " 'criticize',\n",
       " 'cross',\n",
       " 'crucifixion',\n",
       " 'cruel',\n",
       " 'cruelly',\n",
       " 'cruelty',\n",
       " 'crunch',\n",
       " 'crusade',\n",
       " 'crushed',\n",
       " 'crushing',\n",
       " 'cur',\n",
       " 'curse',\n",
       " 'cursed',\n",
       " 'cursing',\n",
       " 'cussed',\n",
       " 'cutthroat',\n",
       " 'cutting',\n",
       " 'dabbling',\n",
       " 'daemon',\n",
       " 'damage',\n",
       " 'dame',\n",
       " 'damn',\n",
       " 'damnation',\n",
       " 'darkness',\n",
       " 'dashed',\n",
       " 'dastardly',\n",
       " 'deadly',\n",
       " 'death',\n",
       " 'deceit',\n",
       " 'deceive',\n",
       " 'deceived',\n",
       " 'decry',\n",
       " 'defamatory',\n",
       " 'defect',\n",
       " 'defendant',\n",
       " 'defense',\n",
       " 'defiance',\n",
       " 'defiant',\n",
       " 'deflate',\n",
       " 'defraud',\n",
       " 'defy',\n",
       " 'degeneracy',\n",
       " 'delay',\n",
       " 'deleterious',\n",
       " 'delinquent',\n",
       " 'delusion',\n",
       " 'delusional',\n",
       " 'demand',\n",
       " 'demolish',\n",
       " 'demon',\n",
       " 'demonic',\n",
       " 'denounce',\n",
       " 'denunciation',\n",
       " 'deny',\n",
       " 'deplorable',\n",
       " 'deplore',\n",
       " 'deportation',\n",
       " 'depraved',\n",
       " 'depravity',\n",
       " 'depreciate',\n",
       " 'depreciated',\n",
       " 'depressed',\n",
       " 'deprivation',\n",
       " 'deranged',\n",
       " 'derision',\n",
       " 'derogation',\n",
       " 'derogatory',\n",
       " 'desecration',\n",
       " 'desert',\n",
       " 'deserted',\n",
       " 'deserve',\n",
       " 'desist',\n",
       " 'despair',\n",
       " 'despicable',\n",
       " 'despise',\n",
       " 'despotism',\n",
       " 'destroyed',\n",
       " 'destroyer',\n",
       " 'destroying',\n",
       " 'destruction',\n",
       " 'destructive',\n",
       " 'detainee',\n",
       " 'deterioration',\n",
       " 'detest',\n",
       " 'detonation',\n",
       " 'detract',\n",
       " 'devastate',\n",
       " 'devastating',\n",
       " 'devastation',\n",
       " 'devil',\n",
       " 'diabolical',\n",
       " 'diatribe',\n",
       " 'dictatorial',\n",
       " 'dictatorship',\n",
       " 'difficulty',\n",
       " 'disagree',\n",
       " 'disagreeing',\n",
       " 'disagreement',\n",
       " 'disallowed',\n",
       " 'disappoint',\n",
       " 'disappointed',\n",
       " 'disapprove',\n",
       " 'disapproved',\n",
       " 'disapproving',\n",
       " 'disaster',\n",
       " 'disastrous',\n",
       " 'disclaim',\n",
       " 'discontent',\n",
       " 'discord',\n",
       " 'discriminate',\n",
       " 'discrimination',\n",
       " 'disdain',\n",
       " 'disease',\n",
       " 'disfigured',\n",
       " 'disgrace',\n",
       " 'disgraced',\n",
       " 'disgraceful',\n",
       " 'disgruntled',\n",
       " 'disgust',\n",
       " 'disgusting',\n",
       " 'dishonest',\n",
       " 'dishonor',\n",
       " 'disillusionment',\n",
       " 'disinformation',\n",
       " 'dislike',\n",
       " 'disliked',\n",
       " 'dislocated',\n",
       " 'dismay',\n",
       " 'dismissal',\n",
       " 'disobedience',\n",
       " 'disobedient',\n",
       " 'disobey',\n",
       " 'disparage',\n",
       " 'disparaging',\n",
       " 'disparity',\n",
       " 'displaced',\n",
       " 'displeased',\n",
       " 'dispossessed',\n",
       " 'dispute',\n",
       " 'disqualified',\n",
       " 'disreputable',\n",
       " 'disrespect',\n",
       " 'disrespectful',\n",
       " 'disruption',\n",
       " 'dissension',\n",
       " 'disservice',\n",
       " 'dissident',\n",
       " 'dissolution',\n",
       " 'dissonance',\n",
       " 'distracted',\n",
       " 'distracting',\n",
       " 'distress',\n",
       " 'distressing',\n",
       " 'distrust',\n",
       " 'disturbance',\n",
       " 'disturbed',\n",
       " 'disused',\n",
       " 'divorce',\n",
       " 'dominate',\n",
       " 'domination',\n",
       " 'doomsday',\n",
       " 'dreadful',\n",
       " 'duel',\n",
       " 'dumps',\n",
       " 'dupe',\n",
       " 'duplicity',\n",
       " 'duress',\n",
       " 'dying',\n",
       " 'earthquake',\n",
       " 'effigy',\n",
       " 'egregious',\n",
       " 'elbow',\n",
       " 'elf',\n",
       " 'elimination',\n",
       " 'encumbrance',\n",
       " 'endless',\n",
       " 'enemy',\n",
       " 'enforce',\n",
       " 'enmity',\n",
       " 'enslaved',\n",
       " 'entangled',\n",
       " 'epidemic',\n",
       " 'eradicate',\n",
       " 'eradication',\n",
       " 'erupt',\n",
       " 'eruption',\n",
       " 'escalate',\n",
       " 'eschew',\n",
       " 'evade',\n",
       " 'eviction',\n",
       " 'evil',\n",
       " 'exacerbation',\n",
       " 'exaggerate',\n",
       " 'exasperation',\n",
       " 'excitation',\n",
       " 'excite',\n",
       " 'execution',\n",
       " 'executioner',\n",
       " 'exile',\n",
       " 'expel',\n",
       " 'expletive',\n",
       " 'explode',\n",
       " 'explosive',\n",
       " 'expulsion',\n",
       " 'extermination',\n",
       " 'extinguish',\n",
       " 'failing',\n",
       " 'fallacious',\n",
       " 'falsehood',\n",
       " 'falsification',\n",
       " 'fatal',\n",
       " 'fear',\n",
       " 'fee',\n",
       " 'feeling',\n",
       " 'fenced',\n",
       " 'ferocious',\n",
       " 'ferocity',\n",
       " 'fervor',\n",
       " 'feud',\n",
       " 'feudalism',\n",
       " 'fib',\n",
       " 'fiend',\n",
       " 'fierce',\n",
       " 'fight',\n",
       " 'fighting',\n",
       " 'firearms',\n",
       " 'fits',\n",
       " 'flagrant',\n",
       " 'fleece',\n",
       " 'flog',\n",
       " 'fluctuation',\n",
       " 'foe',\n",
       " 'foray',\n",
       " 'forbidding',\n",
       " 'force',\n",
       " 'forcibly',\n",
       " 'forearm',\n",
       " 'forfeit',\n",
       " 'forsaken',\n",
       " 'foul',\n",
       " 'fraud',\n",
       " 'fraudulent',\n",
       " 'frenetic',\n",
       " 'frenzied',\n",
       " 'friction',\n",
       " 'frightful',\n",
       " 'frowning',\n",
       " 'frustrate',\n",
       " 'frustrated',\n",
       " 'frustration',\n",
       " 'fugitive',\n",
       " 'fuming',\n",
       " 'furious',\n",
       " 'furiously',\n",
       " 'furnace',\n",
       " 'furor',\n",
       " 'fury',\n",
       " 'fuss',\n",
       " 'gall',\n",
       " 'gallows',\n",
       " 'gang',\n",
       " 'gent',\n",
       " 'gibberish',\n",
       " 'glare',\n",
       " 'glaring',\n",
       " 'gnome',\n",
       " 'godless',\n",
       " 'gonorrhea',\n",
       " 'gore',\n",
       " 'gory',\n",
       " 'grab',\n",
       " 'grated',\n",
       " 'grating',\n",
       " 'greed',\n",
       " 'grievance',\n",
       " 'grievous',\n",
       " 'grim',\n",
       " 'grope',\n",
       " 'growl',\n",
       " 'growling',\n",
       " 'grudge',\n",
       " 'gruff',\n",
       " 'grumble',\n",
       " 'grumpy',\n",
       " 'guillotine',\n",
       " 'guilty',\n",
       " 'gun',\n",
       " 'halter',\n",
       " 'hamstring',\n",
       " 'hanging',\n",
       " 'harass',\n",
       " 'harassing',\n",
       " 'harbinger',\n",
       " 'hardened',\n",
       " 'harmful',\n",
       " 'harry',\n",
       " 'harshness',\n",
       " 'hate',\n",
       " 'hateful',\n",
       " 'hating',\n",
       " 'hatred',\n",
       " 'haughty',\n",
       " 'havoc',\n",
       " 'hell',\n",
       " 'hellish',\n",
       " 'hiss',\n",
       " 'hit',\n",
       " 'hoax',\n",
       " 'holocaust',\n",
       " 'homeless',\n",
       " 'homicidal',\n",
       " 'homicide',\n",
       " 'honest',\n",
       " 'hood',\n",
       " 'hoot',\n",
       " 'hopelessness',\n",
       " 'horrible',\n",
       " 'horrid',\n",
       " 'horrific',\n",
       " 'horror',\n",
       " 'hostage',\n",
       " 'hostile',\n",
       " 'hostilities',\n",
       " 'hostility',\n",
       " 'hot',\n",
       " 'howl',\n",
       " 'huff',\n",
       " 'humbug',\n",
       " 'humiliate',\n",
       " 'hunting',\n",
       " 'hurt',\n",
       " 'hurtful',\n",
       " 'hurting',\n",
       " 'hysterical',\n",
       " 'idiocy',\n",
       " 'idiotic',\n",
       " 'ill',\n",
       " 'illegal',\n",
       " 'illegality',\n",
       " 'illegitimate',\n",
       " 'illicit',\n",
       " 'immaturity',\n",
       " 'immoral',\n",
       " 'immorality',\n",
       " 'impermeable',\n",
       " 'implicate',\n",
       " 'impotence',\n",
       " 'imprisoned',\n",
       " 'imprisonment',\n",
       " 'inadmissible',\n",
       " 'inappropriate',\n",
       " 'inattention',\n",
       " 'incarceration',\n",
       " 'incase',\n",
       " 'incendiary',\n",
       " 'incense',\n",
       " 'incest',\n",
       " 'incite',\n",
       " 'incompatible',\n",
       " 'incompetent',\n",
       " 'incongruous',\n",
       " 'inconsiderate',\n",
       " 'inconvenient',\n",
       " 'incredulous',\n",
       " 'incurable',\n",
       " 'indecency',\n",
       " 'indenture',\n",
       " 'indict',\n",
       " 'indifference',\n",
       " 'indignant',\n",
       " 'indignation',\n",
       " 'indoctrination',\n",
       " 'inept',\n",
       " 'inequality',\n",
       " 'inexcusable',\n",
       " 'infamous',\n",
       " 'infanticide',\n",
       " 'infantile',\n",
       " 'inferno',\n",
       " 'infidel',\n",
       " 'infidelity',\n",
       " 'inflict',\n",
       " 'infraction',\n",
       " 'inhibit',\n",
       " 'inhuman',\n",
       " 'inimical',\n",
       " 'injure',\n",
       " 'injurious',\n",
       " 'injury',\n",
       " 'injustice',\n",
       " 'inoperative',\n",
       " 'insane',\n",
       " 'insanity',\n",
       " 'insecure',\n",
       " 'insidious',\n",
       " 'insignificant',\n",
       " 'instinctive',\n",
       " 'insufficiency',\n",
       " 'insult',\n",
       " 'insulting',\n",
       " 'insurrection',\n",
       " 'intense',\n",
       " 'interminable',\n",
       " 'interrupt',\n",
       " 'intimidation',\n",
       " 'intolerable',\n",
       " 'intolerance',\n",
       " 'intolerant',\n",
       " 'intractable',\n",
       " 'intruder',\n",
       " 'intrusive',\n",
       " 'invade',\n",
       " 'invader',\n",
       " 'invasion',\n",
       " 'involution',\n",
       " 'involvement',\n",
       " 'irate',\n",
       " 'ire',\n",
       " 'irreconcilable',\n",
       " 'irritability',\n",
       " 'irritable',\n",
       " 'irritating',\n",
       " 'irritation',\n",
       " 'jab',\n",
       " 'jealous',\n",
       " 'jealousy',\n",
       " 'jeopardize',\n",
       " 'jerk',\n",
       " 'kick',\n",
       " 'kicking',\n",
       " 'kidnap',\n",
       " 'killing',\n",
       " 'lace',\n",
       " 'lagging',\n",
       " 'lash',\n",
       " 'latent',\n",
       " 'lava',\n",
       " 'lawlessness',\n",
       " 'lawsuit',\n",
       " 'lawyer',\n",
       " 'legalized',\n",
       " 'leukemia',\n",
       " 'libel',\n",
       " 'liberate',\n",
       " 'lie',\n",
       " 'lightning',\n",
       " 'limited',\n",
       " 'liquor',\n",
       " 'litigate',\n",
       " 'litigious',\n",
       " 'livid',\n",
       " 'loath',\n",
       " 'loathe',\n",
       " 'loathsome',\n",
       " 'lonely',\n",
       " 'lose',\n",
       " 'losing',\n",
       " 'loss',\n",
       " 'loudness',\n",
       " 'lunacy',\n",
       " 'lunatic',\n",
       " 'lying',\n",
       " 'lynch',\n",
       " 'mad',\n",
       " 'madden',\n",
       " 'madman',\n",
       " 'madness',\n",
       " 'malevolent',\n",
       " 'malice',\n",
       " 'malicious',\n",
       " 'malign',\n",
       " 'malignant',\n",
       " 'malpractice',\n",
       " 'mangle',\n",
       " 'maniac',\n",
       " 'manipulation',\n",
       " 'manslaughter',\n",
       " 'martial',\n",
       " 'masochism',\n",
       " 'massacre',\n",
       " 'mastery',\n",
       " 'meddle',\n",
       " 'melodrama',\n",
       " 'menace',\n",
       " 'menacing',\n",
       " 'mighty',\n",
       " 'militia',\n",
       " 'misbehavior',\n",
       " 'misconception',\n",
       " 'miserable',\n",
       " 'misery',\n",
       " 'mislead',\n",
       " 'misleading',\n",
       " 'misplace',\n",
       " 'misrepresented',\n",
       " 'misstatement',\n",
       " 'mistress',\n",
       " 'misunderstanding',\n",
       " 'mob',\n",
       " 'mocking',\n",
       " 'molestation',\n",
       " 'money',\n",
       " 'monstrosity',\n",
       " 'moody',\n",
       " 'moral',\n",
       " 'morals',\n",
       " 'morbidity',\n",
       " 'mortality',\n",
       " 'mosque',\n",
       " 'mosquito',\n",
       " 'mournful',\n",
       " 'muff',\n",
       " 'mug',\n",
       " 'mule',\n",
       " 'murder',\n",
       " 'murderer',\n",
       " 'murderous',\n",
       " 'musical',\n",
       " 'mutilation',\n",
       " 'mutiny',\n",
       " 'mutter',\n",
       " 'myopia',\n",
       " 'nag',\n",
       " 'nasty',\n",
       " 'negation',\n",
       " 'neglected',\n",
       " 'nepotism',\n",
       " 'nether',\n",
       " 'nettle',\n",
       " 'noisy',\n",
       " 'noncompliance',\n",
       " 'notoriety',\n",
       " 'nuisance',\n",
       " 'nurture',\n",
       " 'objection',\n",
       " 'obliging',\n",
       " 'obliterate',\n",
       " 'obliterated',\n",
       " 'oblivion',\n",
       " 'obnoxious',\n",
       " 'obscenity',\n",
       " 'obstacle',\n",
       " 'obstruct',\n",
       " 'obstructive',\n",
       " 'odious',\n",
       " 'offend',\n",
       " 'offended',\n",
       " 'offender',\n",
       " 'offense',\n",
       " 'offensive',\n",
       " 'onerous',\n",
       " 'opera',\n",
       " 'opinionated',\n",
       " 'opium',\n",
       " 'opponent',\n",
       " 'opposed',\n",
       " 'opposition',\n",
       " 'oppress',\n",
       " 'oppression',\n",
       " 'oppressive',\n",
       " 'oppressor',\n",
       " 'orc',\n",
       " 'orchestra',\n",
       " 'ordeal',\n",
       " 'oust',\n",
       " 'outburst',\n",
       " 'outcry',\n",
       " 'outrage',\n",
       " 'overbearing',\n",
       " 'overpowering',\n",
       " 'overpriced',\n",
       " 'owing',\n",
       " 'painful',\n",
       " 'paralysis',\n",
       " 'paralyzed',\n",
       " 'pare',\n",
       " 'patter',\n",
       " 'paucity',\n",
       " 'payback',\n",
       " 'penalty',\n",
       " 'penetration',\n",
       " 'penitentiary',\n",
       " 'perdition',\n",
       " 'pernicious',\n",
       " 'perpetrator',\n",
       " 'persecute',\n",
       " 'persecution',\n",
       " 'perverse',\n",
       " 'perversion',\n",
       " 'pervert',\n",
       " 'pessimism',\n",
       " 'pest',\n",
       " 'phony',\n",
       " 'picket',\n",
       " 'picketing',\n",
       " 'pillage',\n",
       " 'pique',\n",
       " 'pirate',\n",
       " 'pitfall',\n",
       " 'playful',\n",
       " 'plunder',\n",
       " 'poaching',\n",
       " 'poison',\n",
       " 'poisoned',\n",
       " 'poisonous',\n",
       " 'polemic',\n",
       " 'politics',\n",
       " 'possessed',\n",
       " 'possession',\n",
       " 'pound',\n",
       " 'poverty',\n",
       " 'pow',\n",
       " 'powerful',\n",
       " 'powerless',\n",
       " 'preclude',\n",
       " 'prejudice',\n",
       " 'prejudicial',\n",
       " 'presumptuous',\n",
       " 'pretending',\n",
       " 'prick',\n",
       " 'prison',\n",
       " 'prisoner',\n",
       " 'profane',\n",
       " 'profanity',\n",
       " 'prohibited',\n",
       " 'prosecute',\n",
       " 'provocation',\n",
       " 'provoking',\n",
       " 'pry',\n",
       " 'psychosis',\n",
       " 'punch',\n",
       " 'punished',\n",
       " 'punishing',\n",
       " 'punishment',\n",
       " 'punitive',\n",
       " 'quandary',\n",
       " 'quarrel',\n",
       " 'rabble',\n",
       " 'rabid',\n",
       " 'rage',\n",
       " 'raging',\n",
       " 'raid',\n",
       " 'rail',\n",
       " 'ram',\n",
       " 'rampage',\n",
       " 'ransom',\n",
       " 'rape',\n",
       " 'rapping',\n",
       " 'rascal',\n",
       " 'rating',\n",
       " 'rave',\n",
       " 'ravenous',\n",
       " 'raving',\n",
       " 'react',\n",
       " 'rebel',\n",
       " 'rebellion',\n",
       " 'recalcitrant',\n",
       " 'recession',\n",
       " 'recidivism',\n",
       " 'reckless',\n",
       " 'recklessness',\n",
       " 'reject',\n",
       " 'rejection',\n",
       " 'rejects',\n",
       " 'remand',\n",
       " 'remiss',\n",
       " 'remove',\n",
       " 'renegade',\n",
       " 'renounce',\n",
       " 'repay',\n",
       " 'repellent',\n",
       " 'reprimand',\n",
       " 'reprisal',\n",
       " 'reproach',\n",
       " 'repudiation',\n",
       " 'resent',\n",
       " 'resentful',\n",
       " 'resentment',\n",
       " 'resign',\n",
       " 'resistance',\n",
       " 'resisting',\n",
       " 'restitution',\n",
       " 'restrain',\n",
       " 'restriction',\n",
       " 'retaliate',\n",
       " 'retaliation',\n",
       " 'retaliatory',\n",
       " 'retract',\n",
       " 'retribution',\n",
       " 'revenge',\n",
       " 'reversal',\n",
       " 'revoke',\n",
       " 'revolt',\n",
       " 'revolting',\n",
       " 'revolution',\n",
       " 'revolver',\n",
       " 'revulsion',\n",
       " 'rheumatism',\n",
       " 'ribbon',\n",
       " 'ridicule',\n",
       " 'ridiculous',\n",
       " 'rifle',\n",
       " 'ringer',\n",
       " 'riot',\n",
       " 'riotous',\n",
       " 'rivalry',\n",
       " 'rob',\n",
       " 'robbery',\n",
       " 'rocket',\n",
       " 'rook',\n",
       " 'row',\n",
       " 'ruined',\n",
       " 'ruinous',\n",
       " 'ruthless',\n",
       " 'saber',\n",
       " 'sabotage',\n",
       " 'saloon',\n",
       " 'sarcasm',\n",
       " 'satanic',\n",
       " 'savage',\n",
       " 'savagery',\n",
       " 'scandalous',\n",
       " 'scapegoat',\n",
       " 'scar',\n",
       " 'scarcity',\n",
       " 'scare',\n",
       " 'schism',\n",
       " 'schizophrenia',\n",
       " 'scoff',\n",
       " 'scold',\n",
       " 'scolding',\n",
       " 'scorching',\n",
       " 'scorn',\n",
       " 'scorpion',\n",
       " 'scoundrel',\n",
       " 'scourge',\n",
       " 'scrapie',\n",
       " 'scream',\n",
       " 'screaming',\n",
       " 'screwed',\n",
       " 'sectarian',\n",
       " 'sedition',\n",
       " 'segregate',\n",
       " 'selfish',\n",
       " 'senseless',\n",
       " 'sentence',\n",
       " 'separatist',\n",
       " 'shackle',\n",
       " 'shaky',\n",
       " 'sham',\n",
       " 'sharpen',\n",
       " ...]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_list = get_affect_presence_list(emotion)\n",
    "word_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentiment_emotion_feature(tweet):\n",
    "    \n",
    "    vector = np.zeros(1)\n",
    "    for word in word_list:\n",
    "        if word in tweet.split():\n",
    "            vector[0] = 1.0\n",
    "    \n",
    "    return vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_sentiment_emotion_feature(\"furious\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5) Hashtag Emotion Intensity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "hashtag_emotion_lex_file_path = ('%s%s/' %(lexicons_path, paths2[3])) + listdir('%s%s/' %(lexicons_path, paths2[3]))[0]\n",
    "    \n",
    "def get_hashtag_emotion_intensity(emotion):\n",
    "    hastag_intensities = dict()\n",
    "    \n",
    "    with open(hashtag_emotion_lex_file_path) as hashtag_emotion_lex_file:\n",
    "        for line in hashtag_emotion_lex_file:\n",
    "            word_array = line.replace(\"\\n\", \"\").split(\"\\t\")\n",
    "            \n",
    "            if (word_array[0] == emotion):\n",
    "                hastag_intensities[clean_str(word_array[1])] = float(word_array[2])\n",
    "\n",
    "    return hastag_intensities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "hashtag_emotion_intensities = get_hashtag_emotion_intensity(emotion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly_hashtag_emotion = PolynomialFeatures(10)\n",
    "\n",
    "def get_hashtag_emotion_vector(tweet):\n",
    "    score = 0.0\n",
    "    for word in hashtag_emotion_intensities.keys():\n",
    "        if word in tweet:\n",
    "            score += tweet.count(word) * float(hashtag_emotion_intensities[word])\n",
    "            \n",
    "#     return [score]\n",
    "    return normalize(poly_hashtag_emotion.fit_transform(np.array([score]).reshape(1, -1))[0].reshape(1, -1))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9.02832881e-05, 2.27150070e-04, 5.71502825e-04, 1.43788412e-03,\n",
       "       3.61767372e-03, 9.10195956e-03, 2.29002597e-02, 5.76163729e-02,\n",
       "       1.44961082e-01, 3.64717774e-01, 9.17619079e-01])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_hashtag_emotion_vector(\"furious\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6) Emoticon Sentiment Lexicon¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bigrams-pmilexicon.txt', 'pairs-pmilexicon.txt', 'unigrams-pmilexicon.txt']"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "listdir('%s%s/' %(lexicons_path, paths2[4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "emoticon_lexicon_unigrams_file_path = ('%s%s/' %(lexicons_path, paths2[4])) + listdir('%s%s/' %(lexicons_path, paths2[4]))[2]\n",
    "emoticon_lexicon_bigrams_file_path = ('%s%s/' %(lexicons_path, paths2[4])) + listdir('%s%s/' %(lexicons_path, paths2[4]))[0]\n",
    "emoticon_lexicon_pairs_file_path = ('%s%s/' %(lexicons_path, paths2[4])) + listdir('%s%s/' %(lexicons_path, paths2[4]))[1]\n",
    "pair_split_string = \"---\"\n",
    "    \n",
    "def get_emoticon_lexicon_unigram_dict():\n",
    "    emoticon_lexicon_unigrams = dict()\n",
    "    with open(emoticon_lexicon_unigrams_file_path, encoding = 'UTF-8') as emoticon_lexicon_file:\n",
    "        for line in emoticon_lexicon_file:\n",
    "            word_array = line.replace(\"\\n\", \"\").split(\"\\t\")\n",
    "            emoticon_lexicon_unigrams[word_array[0]] = np.array([float(val) for val in word_array[1:]])\n",
    "    \n",
    "    return emoticon_lexicon_unigrams\n",
    "\n",
    "def get_emoticon_lexicon_bigram_dict():\n",
    "    emoticon_lexicon_bigrams = dict()\n",
    "    with open(emoticon_lexicon_bigrams_file_path, encoding = 'UTF-8') as emoticon_lexicon_file:\n",
    "        for line in emoticon_lexicon_file:\n",
    "            word_array = line.replace(\"\\n\", \"\").split(\"\\t\")\n",
    "            emoticon_lexicon_bigrams[word_array[0]] = np.array([float(val) for val in word_array[1:]])\n",
    "    \n",
    "    return emoticon_lexicon_bigrams\n",
    "\n",
    "def get_emoticon_lexicon_pairs_dict():\n",
    "    emoticon_lexicon_pairs = dict()\n",
    "    with open(emoticon_lexicon_pairs_file_path, encoding = 'UTF-8') as emoticon_lexicon_file:\n",
    "        for line in emoticon_lexicon_file:\n",
    "            word_array = line.replace(\"\\n\", \"\").split(\"\\t\")\n",
    "            pair = word_array[0].split(pair_split_string)\n",
    "            token_1 = clean_str(pair[0])\n",
    "            token_2 = clean_str(pair[1])\n",
    "            if token_1 and token_2:\n",
    "                token_1_dict = None\n",
    "                if token_1 in emoticon_lexicon_pairs.keys():\n",
    "                    token_1_dict = emoticon_lexicon_pairs[token_1]\n",
    "                else:\n",
    "                    token_1_dict = dict()\n",
    "                    \n",
    "                token_1_dict[token_2] = np.array([float(val) for val in word_array[1:]])\n",
    "                emoticon_lexicon_pairs[token_1] = token_1_dict\n",
    "    \n",
    "    return emoticon_lexicon_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "emoticon_lexicon_unigram_dict = get_emoticon_lexicon_unigram_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "emoticon_lexicon_bigram_dict = get_emoticon_lexicon_bigram_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "emoticon_lexicon_pairs_dict = get_emoticon_lexicon_pairs_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly_emoticon_lexicon = PolynomialFeatures(5)\n",
    "\n",
    "def get_unigram_sentiment_emoticon_lexicon_vector(tokens):\n",
    "    vector_list = np.zeros(3)\n",
    "    counter = 0\n",
    "    for token in tokens:\n",
    "        word = clean_str(token)\n",
    "        if word in emoticon_lexicon_unigram_dict.keys():\n",
    "            vector_list += emoticon_lexicon_unigram_dict[word]\n",
    "            counter += 1\n",
    "    if counter > 0:\n",
    "        vector_list /= counter\n",
    "        \n",
    "#     return vector_list\n",
    "    return normalize(poly_emoticon_lexicon.fit_transform(vector_list.reshape(1, -1))[0].reshape(1, -1))[0]\n",
    "\n",
    "\n",
    "def get_bigram_sentiment_emoticon_lexicon_vector(tokens):\n",
    "    bi_tokens = bigrams(tokens)\n",
    "    vector_list = np.zeros(3)\n",
    "    counter = 0\n",
    "    for bi_token in bi_tokens:\n",
    "        word = clean_str(\" \".join(bi_token))\n",
    "        if word in emoticon_lexicon_bigram_dict.keys():\n",
    "            vector_list += emoticon_lexicon_bigram_dict[word]\n",
    "            counter += 1\n",
    "    if counter > 0:\n",
    "        vector_list /= counter\n",
    "        \n",
    "#     return vector_list\n",
    "    return normalize(poly_emoji_intensity.fit_transform(vector_list.reshape(1, -1))[0].reshape(1, -1))[0].tolist()\n",
    "\n",
    "def get_pair_sentiment_emoticon_lexicon_vector(tokens):\n",
    "    vector_list = np.zeros(3)\n",
    "    counter = 0\n",
    "    \n",
    "    for i in range(len(tokens)):\n",
    "        word_1 = clean_str(tokens[i])\n",
    "        if word_1 in emoticon_lexicon_pairs_dict.keys():\n",
    "            token_1_dict = emoticon_lexicon_pairs_dict[word_1]\n",
    "            for j in range(i, len(tokens)):\n",
    "                word_2 = clean_str(tokens[j])\n",
    "                if word_2 in token_1_dict.keys():\n",
    "                    vector_list += token_1_dict[word_2]\n",
    "                    counter += 1\n",
    "                    \n",
    "    if counter > 0:\n",
    "        vector_list /= counter\n",
    "        \n",
    "#     return vector_list\n",
    "    return normalize(poly_emoji_intensity.fit_transform(vector_list.reshape(1, -1))[0].reshape(1, -1))[0].tolist()\n",
    "\n",
    "def get_sentiment_emoticon_lexicon_vector(tweet):\n",
    "    \n",
    "    tokens = word_tokenize(tweet)\n",
    "    final_list = np.asarray([])\n",
    "    \n",
    "    # Adding unigram features\n",
    "    final_list = np.append(\n",
    "        final_list,\n",
    "        get_unigram_sentiment_emoticon_lexicon_vector(tokens)\n",
    "    )\n",
    "    \n",
    "    final_list = np.append(\n",
    "        final_list,\n",
    "        get_bigram_sentiment_emoticon_lexicon_vector(tokens)\n",
    "    )\n",
    "    \n",
    "    final_list = np.append(\n",
    "        final_list,\n",
    "        get_pair_sentiment_emoticon_lexicon_vector(tokens)\n",
    "    )\n",
    "   \n",
    "    return final_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5.21931637e-10, 1.32048704e-10, 3.39255564e-08, 2.76623768e-08,\n",
       "       3.34083222e-11, 8.58316578e-09, 6.99858133e-09, 2.20516117e-06,\n",
       "       1.79805449e-06, 1.46610597e-06, 8.45230551e-12, 2.17154094e-09,\n",
       "       1.77064108e-09, 5.57905775e-07, 4.54907786e-07, 3.70924810e-07,\n",
       "       1.43335476e-04, 1.16873542e-04, 9.52968880e-05, 7.77036164e-05,\n",
       "       2.13843329e-12, 5.49399858e-10, 4.47972192e-10, 1.41150161e-07,\n",
       "       1.15091670e-07, 9.38439770e-08, 3.62638754e-05, 2.95690061e-05,\n",
       "       2.41101127e-05, 1.96590149e-05, 9.31680593e-03, 7.59678022e-03,\n",
       "       6.19429772e-03, 5.05073506e-03, 4.11829167e-03, 5.41023623e-13,\n",
       "       1.38998164e-10, 1.13336965e-10, 3.57109908e-08, 2.91181925e-08,\n",
       "       2.37425262e-08, 9.17476048e-06, 7.48095854e-06, 6.09985850e-06,\n",
       "       4.97373078e-06, 2.35715190e-03, 1.92198540e-03, 1.56715732e-03,\n",
       "       1.27783597e-03, 1.04192779e-03, 6.05592386e-01, 4.93790715e-01,\n",
       "       4.02629352e-01, 3.28297779e-01, 2.67688958e-01, 2.18269458e-01,\n",
       "       1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_sentiment_emoticon_lexicon_vector(\"furious\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7) Emoticon Sentiment Aff-Neg Lexicon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Emoticon-AFFLEX-NEGLEX-bigrams.txt', 'Emoticon-AFFLEX-NEGLEX-unigrams.txt']"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "listdir('%s%s/' %(lexicons_path, paths2[5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "emoticon_afflex_unigrams_file_path = ('%s%s/' %(lexicons_path, paths2[5])) + listdir('%s%s/' %(lexicons_path, paths2[5]))[1]\n",
    "emoticon_afflex_bigrams_file_path = ('%s%s/' %(lexicons_path, paths2[5])) + listdir('%s%s/' %(lexicons_path, paths2[5]))[0]\n",
    "    \n",
    "def get_emoticon_afflex_unigram_dict():\n",
    "    emoticon_afflex_unigrams = dict()\n",
    "    with open(emoticon_afflex_unigrams_file_path, encoding = 'UTF-8') as emoticon_lexicon_file:\n",
    "        for line in emoticon_lexicon_file:\n",
    "            word_array = line.replace(\"\\n\", \"\").split(\"\\t\")\n",
    "            emoticon_afflex_unigrams[word_array[0]] = np.array([float(val) for val in word_array[1:]])\n",
    "    \n",
    "    return emoticon_afflex_unigrams\n",
    "\n",
    "def get_emoticon_afflex_bigram_dict():\n",
    "    emoticon_afflex_bigrams = dict()\n",
    "    with open(emoticon_afflex_bigrams_file_path, encoding = 'UTF-8') as emoticon_lexicon_file:\n",
    "        for line in emoticon_lexicon_file:\n",
    "            word_array = line.replace(\"\\n\", \"\").split(\"\\t\")\n",
    "            emoticon_afflex_bigrams[word_array[0]] = np.array([float(val) for val in word_array[1:]])\n",
    "    \n",
    "    return emoticon_afflex_bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "emoticon_afflex_unigram_dict = get_emoticon_afflex_unigram_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "emoticon_afflex_bigram_dict = get_emoticon_afflex_bigram_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly_emoticon_lexicon = PolynomialFeatures(5)\n",
    "# poly_emoticon_lexicon = PolynomialFeatures(1)\n",
    "\n",
    "def get_unigram_sentiment_emoticon_afflex_vector(tokens):\n",
    "    vector_list = np.zeros(3)\n",
    "    counter = 0\n",
    "    for token in tokens:\n",
    "        word = clean_str(token)\n",
    "        if word in emoticon_afflex_unigram_dict.keys():\n",
    "            vector_list += emoticon_afflex_unigram_dict[word]\n",
    "            counter += 1\n",
    "    if counter > 0:\n",
    "        vector_list /= counter\n",
    "        \n",
    "#     return vector_list\n",
    "    return normalize(poly_emoticon_lexicon.fit_transform(vector_list.reshape(1, -1))[0].reshape(1, -1))[0]\n",
    "\n",
    "\n",
    "def get_bigram_sentiment_emoticon_afflex_vector(tokens):\n",
    "    bi_tokens = bigrams(tokens)\n",
    "    vector_list = np.zeros(3)\n",
    "    counter = 0\n",
    "    for bi_token in bi_tokens:\n",
    "        word = clean_str(\" \".join(bi_token))\n",
    "        if word in emoticon_afflex_bigram_dict.keys():\n",
    "            vector_list += emoticon_afflex_bigram_dict[word]\n",
    "            counter += 1\n",
    "    if counter > 0:\n",
    "        vector_list /= counter\n",
    "        \n",
    "#     return vector_list\n",
    "    return normalize(poly_emoticon_lexicon.fit_transform(vector_list.reshape(1, -1))[0].reshape(1, -1))[0]\n",
    "\n",
    "def get_sentiment_emoticon_afflex_vector(tweet):\n",
    "    final_list = np.asarray([])\n",
    "    tokens = word_tokenize(tweet)\n",
    "    \n",
    "    # Adding unigram features\n",
    "    final_list = np.append(final_list, get_unigram_sentiment_emoticon_afflex_vector(tokens))\n",
    "    \n",
    "    # Adding bigram featunigram_list =ures\n",
    "    final_list = np.append(final_list, get_bigram_sentiment_emoticon_afflex_vector(tokens))\n",
    "\n",
    "    return final_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.95719929e-10, 1.33357616e-10, 2.77003950e-08, 2.09731562e-08,\n",
       "       4.49415166e-11, 9.33503312e-09, 7.06795365e-09, 1.93902765e-06,\n",
       "       1.46812094e-06, 1.11157728e-06, 1.51452911e-11, 3.14590616e-09,\n",
       "       2.38190038e-09, 6.53452318e-07, 4.94756755e-07, 3.74601543e-07,\n",
       "       1.35731936e-04, 1.02768466e-04, 7.78104096e-05, 5.89135958e-05,\n",
       "       5.10396310e-12, 1.06017038e-09, 8.02700428e-10, 2.20213431e-07,\n",
       "       1.66733027e-07, 1.26240720e-07, 4.57416623e-05, 3.46329729e-05,\n",
       "       2.62221080e-05, 1.98538818e-05, 9.50123549e-03, 7.19379259e-03,\n",
       "       5.44672867e-03, 4.12395171e-03, 3.12242058e-03, 1.72003556e-12,\n",
       "       3.57277417e-10, 2.70510044e-10, 7.42119264e-08, 5.61890300e-08,\n",
       "       4.25431227e-08, 1.54149402e-05, 1.16713119e-05, 8.83685041e-06,\n",
       "       6.69075817e-06, 3.20191636e-03, 2.42430810e-03, 1.83554756e-03,\n",
       "       1.38977173e-03, 1.05225574e-03, 6.65086484e-01, 5.03565481e-01,\n",
       "       3.81271007e-01, 2.88676620e-01, 2.18569441e-01, 1.65488291e-01,\n",
       "       1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_sentiment_emoticon_afflex_vector(\"furious\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8) Hashtag Sentiment Aff-Neg Lexicon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['HS-AFFLEX-NEGLEX-bigrams.txt', 'HS-AFFLEX-NEGLEX-unigrams.txt']"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "listdir('%s%s/' %(lexicons_path, paths2[6]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "hashtag_affneglex_unigrams_file_path = ('%s%s/' %(lexicons_path, paths2[6])) + listdir('%s%s/' %(lexicons_path, paths2[6]))[1]\n",
    "hashtag_affneglex_bigrams_file_path = ('%s%s/' %(lexicons_path, paths2[6])) + listdir('%s%s/' %(lexicons_path, paths2[6]))[0]\n",
    "    \n",
    "def get_hashtag_affneglex_unigram_dict():\n",
    "    hashtag_affneglex_unigrams = dict()\n",
    "    with open(hashtag_affneglex_unigrams_file_path) as hashtag_sent_lex_file:\n",
    "        for line in hashtag_sent_lex_file:\n",
    "            word_array = line.replace(\"\\n\", \"\").split(\"\\t\")\n",
    "            hashtag_affneglex_unigrams[clean_str(word_array[0])] = np.array([float(val) for val in word_array[1:]])\n",
    "    \n",
    "    return hashtag_affneglex_unigrams\n",
    "\n",
    "def get_hashtag_affneglex_bigram_dict():\n",
    "    hashtag_affneglex_bigrams = dict()\n",
    "    with open(hashtag_affneglex_bigrams_file_path) as hashtag_sent_lex_file:\n",
    "        for line in hashtag_sent_lex_file:\n",
    "            word_array = line.replace(\"\\n\", \"\").split(\"\\t\")\n",
    "            hashtag_affneglex_bigrams[clean_str(word_array[0])] = np.array([float(val) for val in word_array[1:]])\n",
    "\n",
    "    return hashtag_affneglex_bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "hashtag_affneglex_unigram_dict = get_hashtag_affneglex_unigram_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "hashtag_affneglex_bigram_dict = get_hashtag_affneglex_bigram_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly_hashtag_sent_affneglex = PolynomialFeatures(5)\n",
    "\n",
    "def get_unigram_sentiment_hashtag_affneglex_vector(tokens):\n",
    "    vector_list = np.zeros(3)\n",
    "    counter = 0\n",
    "    for token in tokens:\n",
    "        word = clean_str(token)\n",
    "        if word in hashtag_affneglex_unigram_dict.keys():\n",
    "            vector_list += hashtag_affneglex_unigram_dict[word]\n",
    "            counter += 1\n",
    "    if counter > 0:\n",
    "        vector_list /= counter\n",
    "        \n",
    "#     return vector_list\n",
    "    return normalize(poly_hashtag_sent_affneglex.fit_transform(vector_list.reshape(1, -1))[0].reshape(1, -1))[0]\n",
    "\n",
    "def get_bigram_sentiment_hashtag_affneglex_vector(tokens):\n",
    "    bi_tokens = bigrams(tokens)\n",
    "    vector_list = np.zeros(3)\n",
    "    counter = 0\n",
    "    for bi_token in bi_tokens:\n",
    "        word = clean_str(\" \".join(bi_token))\n",
    "        if word in hashtag_affneglex_bigram_dict.keys():\n",
    "            vector_list += hashtag_affneglex_bigram_dict[word]\n",
    "            counter += 1\n",
    "    if counter > 0:\n",
    "        vector_list /= counter\n",
    "        \n",
    "#     return vector_list\n",
    "    return normalize(poly_hashtag_sent_affneglex.fit_transform(vector_list.reshape(1, -1))[0].reshape(1, -1))[0]\n",
    "\n",
    "def get_sentiment_hashtag_affneglex_vector(tweet):\n",
    "    final_list = np.asarray([])\n",
    "    tokens = word_tokenize(tweet)\n",
    "    \n",
    "    # Adding unigram features\n",
    "    final_list = np.append(final_list, get_unigram_sentiment_hashtag_affneglex_vector(tokens))\n",
    "    # Adding bigram features\n",
    "    final_list = np.append(final_list, get_bigram_sentiment_hashtag_affneglex_vector(tokens))\n",
    "\n",
    "    return final_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.50661452e-05, -5.16768782e-06,  6.02645810e-05,  1.35595307e-04,\n",
       "        1.77251692e-06, -2.06707513e-05, -4.65091904e-05,  2.41058324e-04,\n",
       "        5.42381229e-04,  1.22035777e-03, -6.07973304e-07,  7.09006769e-06,\n",
       "        1.59526523e-05, -8.26830051e-05, -1.86036762e-04, -4.18582713e-04,\n",
       "        9.64233296e-04,  2.16952492e-03,  4.88143106e-03,  1.09832199e-02,\n",
       "        2.08534843e-07, -2.43189322e-06, -5.47175974e-06,  2.83602708e-05,\n",
       "        6.38106092e-05,  1.43573871e-04, -3.30732020e-04, -7.44147046e-04,\n",
       "       -1.67433085e-03, -3.76724442e-03,  3.85693318e-03,  8.67809966e-03,\n",
       "        1.95257242e-02,  4.39328795e-02,  9.88489790e-02, -7.15274513e-08,\n",
       "        8.34139374e-07,  1.87681359e-06, -9.72757287e-06, -2.18870390e-05,\n",
       "       -4.92458377e-05,  1.13441083e-04,  2.55242437e-04,  5.74295483e-04,\n",
       "        1.29216484e-03, -1.32292808e-03, -2.97658818e-03, -6.69732341e-03,\n",
       "       -1.50689777e-02, -3.39051998e-02,  1.54277327e-02,  3.47123987e-02,\n",
       "        7.81028970e-02,  1.75731518e-01,  3.95395916e-01,  8.89640811e-01,\n",
       "        1.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_sentiment_hashtag_affneglex_vector(\"furious\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9) Hashtag Sentiment Lexicon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['HS-bigrams.txt', 'HS-pairs.txt', 'HS-unigrams.txt']"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "listdir('%s%s/' %(lexicons_path, paths2[7]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "hash_sent_lex_unigrams_file_path = ('%s%s/' %(lexicons_path, paths2[7])) + listdir('%s%s/' %(lexicons_path, paths2[7]))[2]\n",
    "hash_sent_lex_bigrams_file_path = ('%s%s/' %(lexicons_path, paths2[7])) + listdir('%s%s/' %(lexicons_path, paths2[7]))[0]\n",
    "hash_sent_lex_pairs_file_path = ('%s%s/' %(lexicons_path, paths2[7])) + listdir('%s%s/' %(lexicons_path, paths2[7]))[1]\n",
    "pair_split_string = \"---\"\n",
    "\n",
    "\n",
    "def get_hash_sent_lex_unigram_dict():\n",
    "    hash_sent_lex_unigrams = dict()\n",
    "    with open(hash_sent_lex_unigrams_file_path) as hash_sent_lex_file:\n",
    "        for line in hash_sent_lex_file:\n",
    "            word_array = line.replace(\"\\n\", \"\").split(\"\\t\")\n",
    "            if clean_str(word_array[0]):\n",
    "                hash_sent_lex_unigrams[word_array[0]] = np.array([float(val) for val in word_array[1:]])\n",
    "    \n",
    "    return hash_sent_lex_unigrams\n",
    "\n",
    "def get_hash_sent_lex_bigram_dict():\n",
    "    hash_sent_lex_bigrams = dict()\n",
    "    with open(hash_sent_lex_bigrams_file_path) as hash_sent_lex_file:\n",
    "        for line in hash_sent_lex_file:\n",
    "            word_array = line.replace(\"\\n\", \"\").split(\"\\t\")\n",
    "            if clean_str(word_array[0]):\n",
    "                hash_sent_lex_bigrams[word_array[0]] = np.array([float(val) for val in word_array[1:]])\n",
    "    \n",
    "    return hash_sent_lex_bigrams\n",
    "\n",
    "def get_hash_sent_lex_pairs_dict():\n",
    "    hash_sent_lex_pairs = dict()\n",
    "    with open(hash_sent_lex_pairs_file_path) as hash_sent_lex_file:\n",
    "        for line in hash_sent_lex_file:\n",
    "            word_array = line.replace(\"\\n\", \"\").split(\"\\t\")\n",
    "            pair = word_array[0].split(pair_split_string)\n",
    "            token_1 = clean_str(pair[0])\n",
    "            token_2 = clean_str(pair[1])\n",
    "            if token_1 and token_2:\n",
    "                token_1_dict = None\n",
    "                if token_1 in hash_sent_lex_pairs.keys():\n",
    "                    token_1_dict = hash_sent_lex_pairs[token_1]\n",
    "                else:\n",
    "                    token_1_dict = dict()\n",
    "                    \n",
    "                token_1_dict[token_2] = np.array([float(val) for val in word_array[1:]])\n",
    "                hash_sent_lex_pairs[token_1] = token_1_dict\n",
    "    \n",
    "    return hash_sent_lex_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "hash_sent_lex_unigram_dict = get_hash_sent_lex_unigram_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "hash_sent_lex_bigram_dict = get_hash_sent_lex_bigram_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "hash_sent_lex_pairs_dict = get_hash_sent_lex_pairs_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly_hash_sent_lex = PolynomialFeatures(5)\n",
    "\n",
    "def get_unigram_sentiment_hash_sent_lex_vector(tokens):\n",
    "    vector_list = np.zeros(3)\n",
    "    counter = 0\n",
    "    \n",
    "    for token in tokens:\n",
    "        word = clean_str(token)\n",
    "        if word in hash_sent_lex_unigram_dict.keys():\n",
    "            vector_list += hash_sent_lex_unigram_dict[word]\n",
    "            counter += 1\n",
    "\n",
    "    if counter > 0:\n",
    "        vector_list /= counter\n",
    "    \n",
    "#     return vector_list\n",
    "    return normalize(poly_hash_sent_lex.fit_transform(vector_list.reshape(1, -1))[0].reshape(1, -1))[0]\n",
    "    \n",
    "def get_bigram_sentiment_hash_sent_lex_vector(tokens):\n",
    "    bi_tokens = bigrams(tokens)\n",
    "    vector_list = np.zeros(3)\n",
    "    counter = 0\n",
    "    for bi_token in bi_tokens:\n",
    "        word = clean_str(\" \".join(bi_token))\n",
    "        if word in hash_sent_lex_bigram_dict.keys():\n",
    "            vector_list += hash_sent_lex_bigram_dict[word]\n",
    "            counter += 1\n",
    "    if counter > 0:\n",
    "        vector_list /= counter\n",
    "    \n",
    "#     return vector_list\n",
    "    return normalize(poly_hash_sent_lex.fit_transform(vector_list.reshape(1, -1))[0].reshape(1, -1))[0]\n",
    "\n",
    "def get_pair_sentiment_hash_sent_lex_vector(tokens):\n",
    "    vector_list = np.zeros(3)\n",
    "    counter = 0\n",
    "    \n",
    "    for i in range(len(tokens)):\n",
    "        word_1 = clean_str(tokens[i])\n",
    "        if word_1 in hash_sent_lex_pairs_dict.keys():\n",
    "            token_1_dict = hash_sent_lex_pairs_dict[word_1]\n",
    "            for j in range(i, len(tokens)):\n",
    "                word_2 = clean_str(tokens[j])\n",
    "                if word_2 in token_1_dict.keys():\n",
    "                    vector_list += token_1_dict[word_2]\n",
    "                    counter += 1\n",
    "    if counter > 0:\n",
    "        vector_list /= counter\n",
    "        \n",
    "#     return vector_list\n",
    "    return normalize(poly_hash_sent_lex.fit_transform(vector_list.reshape(1, -1))[0].reshape(1, -1))[0]\n",
    "    \n",
    "def get_sentiment_hash_sent_lex_vector(tweet):\n",
    "    final_list = np.asarray([])\n",
    "    \n",
    "    tokens = word_tokenize(tweet)\n",
    "    \n",
    "    # Adding unigram features\n",
    "    final_list = np.append(final_list, get_unigram_sentiment_hash_sent_lex_vector(tokens))\n",
    "    # Adding bigram features\n",
    "    final_list = np.append(final_list, get_bigram_sentiment_hash_sent_lex_vector(tokens))\n",
    "    # Adding pair features\n",
    "    final_list = np.append(final_list, get_pair_sentiment_hash_sent_lex_vector(tokens))\n",
    "\n",
    "    return final_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5.09887390e-09, 3.39075115e-09, 2.09053830e-07, 1.73361713e-07,\n",
       "       2.25484951e-09, 1.39020797e-07, 1.15285539e-07, 8.57120703e-06,\n",
       "       7.10783022e-06, 5.89429823e-06, 1.49947493e-09, 9.24488300e-08,\n",
       "       7.66648834e-08, 5.69985268e-06, 4.72670710e-06, 3.91970833e-06,\n",
       "       3.51419488e-04, 2.91421039e-04, 2.41666228e-04, 2.00406140e-04,\n",
       "       9.97150826e-10, 6.14784720e-08, 5.09821475e-08, 3.79040203e-06,\n",
       "       3.14326022e-06, 2.60660604e-06, 2.33693960e-04, 1.93794991e-04,\n",
       "       1.60708041e-04, 1.33270083e-04, 1.44081990e-02, 1.19482626e-02,\n",
       "       9.90831533e-03, 8.21665174e-03, 6.81380876e-03, 6.63105299e-10,\n",
       "       4.08831839e-08, 3.39031281e-08, 2.52061735e-06, 2.09026805e-06,\n",
       "       1.73339301e-06, 1.55406483e-04, 1.28873669e-04, 1.06870848e-04,\n",
       "       8.86246052e-05, 9.58145235e-03, 7.94559463e-03, 6.58902970e-03,\n",
       "       5.46407341e-03, 4.53118282e-03, 5.90736160e-01, 4.89878767e-01,\n",
       "       4.06240929e-01, 3.36882721e-01, 2.79366159e-01, 2.31669498e-01,\n",
       "       1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_sentiment_hash_sent_lex_vector(\"furious\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10) Depeche Mood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "depeche_mood_file_path = ('%s%s/' %(lexicons_path, paths2[8])) + listdir('%s%s/' %(lexicons_path, paths2[8]))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_depeche_vector_dict():\n",
    "    depeche_vector_dict = dict()\n",
    "    with open(depeche_mood_file_path) as depeche_mood_file:\n",
    "        lines = depeche_mood_file.readlines()[1:] \n",
    "        for line in lines:\n",
    "            word_array = line.replace(\"\\n\", \"\").split(\"\\t\")\n",
    "            depeche_vector_dict[word_array[0].split(\"#\")[0]] = np.array([float(val) for val in word_array[1:]])\n",
    "    \n",
    "    return depeche_vector_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "depeche_vector_dict = get_depeche_vector_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "print(len(depeche_vector_dict[\"0\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly_depm = PolynomialFeatures(5)\n",
    "\n",
    "def get_depeche_mood_vector(tweet):\n",
    "    vector_list = np.zeros(8)\n",
    "    tokens = word_tokenize(tweet)\n",
    "    counter = 0\n",
    "    \n",
    "    for token in tokens:\n",
    "        if token in depeche_vector_dict.keys():\n",
    "            vector_list += np.array(depeche_vector_dict[token])\n",
    "            counter += 1\n",
    "    \n",
    "    if counter > 0:\n",
    "        vector_list /= counter\n",
    "        \n",
    "    return normalize(poly_depm.fit_transform(vector_list.reshape(1, -1))[0].reshape(1, -1))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9.34469068e-01, 5.98056709e-02, 1.49434297e-01, ...,\n",
       "       1.06644824e-05, 5.70178406e-06, 3.04846875e-06])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_depeche_mood_vector(\"i am so mad about power rangers. i am incensed. i am furious.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (3)  Prepare Sentence Vectors as Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_active_vector_method(string):\n",
    "    return int(string)\n",
    "\n",
    "\n",
    "def vectorize_tweets(tweet_list, bin_string, vector_dict):\n",
    "\n",
    "    vectors = list()\n",
    "    frames = list()\n",
    "\n",
    "    '''Pre-trained Word embeddings'''\n",
    "    index = 0\n",
    "    if is_active_vector_method(bin_string[index]):\n",
    "        if index not in vector_dict.keys():\n",
    "            tmp_vector = \\\n",
    "                pd.DataFrame(list(map(lambda x: get_averaged_embeddings(x, wv_model_g, w2v_dimensions_g), tweet_list)))\n",
    "            vector_dict[index] = tmp_vector\n",
    "        frames.append(vector_dict[index])\n",
    "\n",
    "    index = 1\n",
    "    if is_active_vector_method(bin_string[index]):\n",
    "        if index not in vector_dict.keys():\n",
    "            tmp_vector = \\\n",
    "                pd.DataFrame(list(map(lambda x: get_averaged_embeddings(x, wv_model_w, w2v_dimensions_w), tweet_list)))\n",
    "            vector_dict[index] = tmp_vector\n",
    "        frames.append(vector_dict[index])\n",
    "\n",
    "\n",
    "    '''NRC Emotion Intensity Lexicon'''\n",
    "    index = 2\n",
    "    if is_active_vector_method(bin_string[index]):\n",
    "        if index not in vector_dict.keys():\n",
    "            tmp_vector = pd.DataFrame(list(map(lambda x: get_emo_int_vector(x), tweet_list)))\n",
    "            vector_dict[index] = tmp_vector\n",
    "        frames.append(vector_dict[index])\n",
    "\n",
    "    '''WordNet'''\n",
    "    index = 3\n",
    "    if is_active_vector_method(bin_string[index]):\n",
    "        if index not in vector_dict.keys():\n",
    "            tmp_vector = pd.DataFrame(list(map(lambda x: get_sentiwordnetscore(x), tweet_list)))\n",
    "            vector_dict[index] = tmp_vector\n",
    "        frames.append(vector_dict[index])\n",
    "\n",
    "    '''NRC Sentiment Lexicon'''\n",
    "    index = 4\n",
    "    if is_active_vector_method(bin_string[index]):\n",
    "        if index not in vector_dict.keys():\n",
    "            tmp_vector = pd.DataFrame(list(map(lambda x: get_sentiment_emotion_feature(x), tweet_list)))\n",
    "            vector_dict[index] = tmp_vector\n",
    "        frames.append(vector_dict[index])\n",
    "\n",
    "    index = 5\n",
    "    if is_active_vector_method(bin_string[index]):\n",
    "        if index not in vector_dict.keys():\n",
    "            tmp_vector = pd.DataFrame(list(map(lambda x: get_sentiment_emoticon_lexicon_vector(x), tweet_list)))\n",
    "            vector_dict[index] = tmp_vector\n",
    "        frames.append(vector_dict[index])\n",
    "\n",
    "    index = 6\n",
    "    if is_active_vector_method(bin_string[index]):\n",
    "        if index not in vector_dict.keys():\n",
    "            tmp_vector = pd.DataFrame(list(map(lambda x: get_sentiment_emoticon_afflex_vector(x), tweet_list)))\n",
    "            vector_dict[index] = tmp_vector\n",
    "        frames.append(vector_dict[index])\n",
    "\n",
    "    '''NRC Hashtag Lexicon'''\n",
    "    index = 7\n",
    "    if is_active_vector_method(bin_string[index]):\n",
    "        if index not in vector_dict.keys():\n",
    "            tmp_vector = pd.DataFrame(list(map(lambda x: get_hashtag_emotion_vector(x), tweet_list)))\n",
    "            vector_dict[index] = tmp_vector\n",
    "        frames.append(vector_dict[index])\n",
    "\n",
    "    index = 8\n",
    "    if is_active_vector_method(bin_string[index]):\n",
    "        if index not in vector_dict.keys():\n",
    "            tmp_vector = pd.DataFrame(list(map(lambda x: get_sentiment_hash_sent_lex_vector(x), tweet_list)))\n",
    "            vector_dict[index] = tmp_vector\n",
    "        frames.append(vector_dict[index])\n",
    "\n",
    "    index = 9\n",
    "    if is_active_vector_method(bin_string[index]):\n",
    "        if index not in vector_dict.keys():\n",
    "            tmp_vector = pd.DataFrame(list(map(lambda x: get_sentiment_hashtag_affneglex_vector(x), tweet_list)))\n",
    "            vector_dict[index] = tmp_vector\n",
    "        frames.append(vector_dict[index])\n",
    "\n",
    "   \n",
    "    index = 10\n",
    "    if is_active_vector_method(bin_string[index]):\n",
    "        if index not in vector_dict.keys():\n",
    "            tmp_vector = pd.DataFrame(list(map(lambda x: get_emoji_intensity(x), tweet_list)))\n",
    "            vector_dict[index] = tmp_vector\n",
    "        frames.append(vector_dict[index])\n",
    "        \n",
    "    index = 11\n",
    "    if is_active_vector_method(bin_string[index]):\n",
    "        if index not in vector_dict.keys():\n",
    "            tmp_vector = pd.DataFrame(list(map(lambda x: get_depeche_mood_vector(x), tweet_list)))\n",
    "            vector_dict[index] = tmp_vector\n",
    "        frames.append(vector_dict[index])\n",
    "\n",
    "    vectors = pd.concat(frames, axis=1)\n",
    "\n",
    "    return vectors.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_index_mapping = \\\n",
    "    {\n",
    "        0: \"Glove[Twitter]\",\n",
    "        1: \"Word2Vec[Twitter]\",\n",
    "        2: \"NRC-Emotion Intensity Lexicon\",\n",
    "        3: \"Wordnet-Affect\",\n",
    "        4: \"NRC-Emotion-Lexicon\",\n",
    "        5: \"NRC-Emoticon-Lexicon\",\n",
    "        6: \"NRC-Emoticon-AffLexNegLex\",\n",
    "        7: \"NRC-Hashtag-Emotion\",\n",
    "        8: \"NRC-Hashtag-Sentiment-Lexicon\",\n",
    "        9: \"NRC-Hashtag-Sentiment-AffLexNegLex\",\n",
    "        10: \"Emoji Intensity\",\n",
    "        11: \"Depeche Mood\"\n",
    "    \n",
    "    }\n",
    "\n",
    "\n",
    "def get_features_from_identifier(bin_string):\n",
    "    features = list()\n",
    "    for i in range(len(bin_string)):\n",
    "        if int(bin_string[i]):\n",
    "            features.append(feature_index_mapping[i])\n",
    "\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Glove[Twitter]',\n",
       " 'Word2Vec[Twitter]',\n",
       " 'NRC-Emotion-Lexicon',\n",
       " 'NRC-Emoticon-Lexicon',\n",
       " 'NRC-Hashtag-Sentiment-Lexicon',\n",
       " 'Emoji Intensity']"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string1 = \"110011001010\"\n",
    "get_features_from_identifier(string1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vector_dict = dict()\n",
    "test_vector_dict = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = vectorize_tweets(train_tweets, string1, train_vector_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "941\n",
      "943\n"
     ]
    }
   ],
   "source": [
    "print(len(x_train))\n",
    "dimension = len(x_train[0])\n",
    "print(dimension)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.array(x_train)\n",
    "score_train = np.array(train_intensities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = vectorize_tweets(test_tweets, string1, test_vector_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "760\n",
      "943\n"
     ]
    }
   ],
   "source": [
    "print(len(x_test))\n",
    "print(len(x_test[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vectors_path = \"files/\" + emotion + \"_vectors/train_vectors.npy\"\n",
    "test_vectors_path = \"files/\" + emotion + \"_vectors/test_vectors.npy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save vectors_dict\n",
    "import pickle\n",
    "with open(train_vectors_path, 'wb') as train_vectors_file:\n",
    "    pickle.dump(train_vector_dict, train_vectors_file)\n",
    "\n",
    "with open(test_vectors_path, 'wb') as test_vectors_file:\n",
    "    pickle.dump(test_vector_dict, test_vectors_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Restore vectors_dict\n",
    "import pickle\n",
    "with open(train_vectors_path, 'rb') as train_vectors_file:\n",
    "    train_vector_dict = pickle.load(train_vectors_file)\n",
    "\n",
    "with open(test_vectors_path, 'rb') as test_vectors_file:\n",
    "    test_vector_dict = pickle.load(test_vectors_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_vectors_path = \"files/\" + emotion + \"_vectors/x_train.npy\"\n",
    "y_train_vectors_path = \"files/\" + emotion + \"_vectors/y_train.npy\"\n",
    "\n",
    "x_test_vectors_path = \"files/\" + emotion + \"_vectors/x_test.npy\"\n",
    "y_test_vectors_path = \"files/\" + emotion + \"_vectors/y_test.npy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save train_vectors\n",
    "import pickle\n",
    "with open(x_train_vectors_path, 'wb') as x_train_vectors_file:\n",
    "    x_train = pickle.dump(x_train, x_train_vectors_file)\n",
    "with open(y_train_vectors_path, 'wb') as y_train_vectors_file:\n",
    "    score_train = pickle.dump(score_train, y_train_vectors_file)\n",
    "\n",
    "with open(x_test_vectors_path, 'wb') as x_test_vectors_file:\n",
    "    x_test = pickle.dump(x_test, x_test_vectors_file)\n",
    "with open(y_test_vectors_path, 'wb') as y_test_vectors_file:\n",
    "    test_intensities = pickle.dump(test_intensities, y_test_vectors_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Restore vectors_dict\n",
    "with open(x_train_vectors_path, 'rb') as x_train_vectors_file:\n",
    "    x_train = pickle.load(x_train_vectors_file)\n",
    "with open(y_train_vectors_path, 'rb') as y_train_vectors_file:\n",
    "    score_train = pickle.load(y_train_vectors_file)\n",
    "\n",
    "with open(x_test_vectors_path, 'rb') as x_test_vectors_file:\n",
    "    x_test = pickle.load(x_test_vectors_file)\n",
    "with open(y_test_vectors_path, 'rb') as y_test_vectors_file:\n",
    "    test_intensities = pickle.load(y_test_vectors_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.array(x_train)\n",
    "score_train = np.array(score_train)\n",
    "\n",
    "x_test = np.array(x_test)\n",
    "test_intensities = np.array(test_intensities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(941, 943) \n",
      " (941,) \n",
      " (760, 943) \n",
      " (760,)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape,'\\n',score_train.shape,'\\n',x_test.shape, '\\n', test_intensities.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Train a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "import numpy as np\n",
    "import scipy\n",
    "\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_lists(pred, gold):\n",
    "    if len(pred) == len(gold):\n",
    "        gold_scores=gold\n",
    "        pred_scores=pred         \n",
    "        \n",
    "        # lists storing gold and prediction scores where gold score >= 0.5\n",
    "        gold_scores_range_05_1=[]\n",
    "        pred_scores_range_05_1=[]\n",
    "         \n",
    "            \n",
    "        for i in range(len(gold_scores)):\n",
    "            if(gold_scores[i]>=0.5):\n",
    "                gold_scores_range_05_1.append(gold_scores[i])\n",
    "                pred_scores_range_05_1.append(pred_scores[i])\n",
    "                \n",
    "        # return zero correlation if predictions are constant\n",
    "        if np.std(pred_scores)==0 or np.std(gold_scores)==0:\n",
    "            return (0,0,0,0)\n",
    "        \n",
    "        pears_corr=scipy.stats.pearsonr(pred_scores,gold_scores)[0]                                    \n",
    "        spear_corr=scipy.stats.spearmanr(pred_scores,gold_scores)[0]   \n",
    "\n",
    "\n",
    "        pears_corr_range_05_1=scipy.stats.pearsonr(pred_scores_range_05_1,gold_scores_range_05_1)[0]                                    \n",
    "        spear_corr_range_05_1=scipy.stats.spearmanr(pred_scores_range_05_1,gold_scores_range_05_1)[0]           \n",
    "        \n",
    "      \n",
    "        return np.array([pears_corr,spear_corr,pears_corr_range_05_1,spear_corr_range_05_1])\n",
    "    else:\n",
    "        raise ValueError('Predictions and gold data have different number of lines.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1) XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from sklearn.metrics import make_scorer\n",
    "import scipy\n",
    "def pearson_score(ground_truth, predictions):\n",
    "    score = scipy.stats.pearsonr(predictions,ground_truth)[0]\n",
    "    return score\n",
    "PS = make_scorer(pearson_score, greater_is_better=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "ml_model = XGBRegressor(objective=\"reg:squarederror\",seed=0)\n",
    "\n",
    "# specify parameters and distributions to sample from\n",
    "param_dist = {\n",
    "     \"max_depth\": range(3, 11),\n",
    "     \"n_estimators\": [100,300,500,700,900,1000,3000]\n",
    " }\n",
    "\n",
    "\n",
    "# run randomized search\n",
    "grid_search = GridSearchCV(ml_model,param_grid=param_dist, cv=5, n_jobs=-1,return_train_score=True)\n",
    "\n",
    "trainingtime = pd.DataFrame(columns = [\"Model\", \"Training Time(Seconds)\"])\n",
    "start_time_XG =time.time()\n",
    "\n",
    "grid_search.fit(x_train, score_train)\n",
    "trainingtime.loc[0] = [\"XGBoost\", round((time.time()-start_time_XG), 2)] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-6.549811213701339"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "             colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "             importance_type='gain', interaction_constraints='',\n",
       "             learning_rate=0.300000012, max_delta_step=0, max_depth=3,\n",
       "             min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "             n_estimators=3000, n_jobs=0, num_parallel_tree=1,\n",
       "             objective='reg:squarederror', random_state=0, reg_alpha=0,\n",
       "             reg_lambda=1, scale_pos_weight=1, seed=0, subsample=1,\n",
       "             tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.999949962607008"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_estimator_.score(x_train, score_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.461423</td>\n",
       "      <td>0.090626</td>\n",
       "      <td>0.009973</td>\n",
       "      <td>4.422006e-07</td>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_depth': 3, 'n_estimators': 100}</td>\n",
       "      <td>-7.378642</td>\n",
       "      <td>-6.192932</td>\n",
       "      <td>-10.947039</td>\n",
       "      <td>...</td>\n",
       "      <td>-6.558108</td>\n",
       "      <td>3.488396</td>\n",
       "      <td>7</td>\n",
       "      <td>0.993411</td>\n",
       "      <td>0.995546</td>\n",
       "      <td>0.994963</td>\n",
       "      <td>0.994215</td>\n",
       "      <td>0.993169</td>\n",
       "      <td>0.994261</td>\n",
       "      <td>0.000901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>29.344921</td>\n",
       "      <td>0.522393</td>\n",
       "      <td>0.011569</td>\n",
       "      <td>4.885971e-04</td>\n",
       "      <td>3</td>\n",
       "      <td>300</td>\n",
       "      <td>{'max_depth': 3, 'n_estimators': 300}</td>\n",
       "      <td>-7.254624</td>\n",
       "      <td>-6.256571</td>\n",
       "      <td>-10.831378</td>\n",
       "      <td>...</td>\n",
       "      <td>-6.549893</td>\n",
       "      <td>3.471471</td>\n",
       "      <td>6</td>\n",
       "      <td>0.999893</td>\n",
       "      <td>0.999950</td>\n",
       "      <td>0.999982</td>\n",
       "      <td>0.999943</td>\n",
       "      <td>0.999934</td>\n",
       "      <td>0.999941</td>\n",
       "      <td>0.000029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>36.134564</td>\n",
       "      <td>0.492513</td>\n",
       "      <td>0.011768</td>\n",
       "      <td>1.162949e-03</td>\n",
       "      <td>3</td>\n",
       "      <td>500</td>\n",
       "      <td>{'max_depth': 3, 'n_estimators': 500}</td>\n",
       "      <td>-7.254550</td>\n",
       "      <td>-6.256521</td>\n",
       "      <td>-10.830824</td>\n",
       "      <td>...</td>\n",
       "      <td>-6.549845</td>\n",
       "      <td>3.471363</td>\n",
       "      <td>5</td>\n",
       "      <td>0.999893</td>\n",
       "      <td>0.999950</td>\n",
       "      <td>0.999984</td>\n",
       "      <td>0.999943</td>\n",
       "      <td>0.999934</td>\n",
       "      <td>0.999941</td>\n",
       "      <td>0.000029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>42.906255</td>\n",
       "      <td>0.766962</td>\n",
       "      <td>0.011569</td>\n",
       "      <td>4.885776e-04</td>\n",
       "      <td>3</td>\n",
       "      <td>700</td>\n",
       "      <td>{'max_depth': 3, 'n_estimators': 700}</td>\n",
       "      <td>-7.254508</td>\n",
       "      <td>-6.256492</td>\n",
       "      <td>-10.830795</td>\n",
       "      <td>...</td>\n",
       "      <td>-6.549837</td>\n",
       "      <td>3.471355</td>\n",
       "      <td>4</td>\n",
       "      <td>0.999893</td>\n",
       "      <td>0.999950</td>\n",
       "      <td>0.999984</td>\n",
       "      <td>0.999943</td>\n",
       "      <td>0.999934</td>\n",
       "      <td>0.999941</td>\n",
       "      <td>0.000029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>49.891773</td>\n",
       "      <td>0.651333</td>\n",
       "      <td>0.011968</td>\n",
       "      <td>2.611745e-07</td>\n",
       "      <td>3</td>\n",
       "      <td>900</td>\n",
       "      <td>{'max_depth': 3, 'n_estimators': 900}</td>\n",
       "      <td>-7.254476</td>\n",
       "      <td>-6.256476</td>\n",
       "      <td>-10.830775</td>\n",
       "      <td>...</td>\n",
       "      <td>-6.549834</td>\n",
       "      <td>3.471349</td>\n",
       "      <td>3</td>\n",
       "      <td>0.999893</td>\n",
       "      <td>0.999950</td>\n",
       "      <td>0.999984</td>\n",
       "      <td>0.999943</td>\n",
       "      <td>0.999934</td>\n",
       "      <td>0.999941</td>\n",
       "      <td>0.000029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>53.465017</td>\n",
       "      <td>0.701668</td>\n",
       "      <td>0.011768</td>\n",
       "      <td>3.988743e-04</td>\n",
       "      <td>3</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'max_depth': 3, 'n_estimators': 1000}</td>\n",
       "      <td>-7.254460</td>\n",
       "      <td>-6.256468</td>\n",
       "      <td>-10.830766</td>\n",
       "      <td>...</td>\n",
       "      <td>-6.549833</td>\n",
       "      <td>3.471345</td>\n",
       "      <td>2</td>\n",
       "      <td>0.999893</td>\n",
       "      <td>0.999950</td>\n",
       "      <td>0.999984</td>\n",
       "      <td>0.999943</td>\n",
       "      <td>0.999934</td>\n",
       "      <td>0.999941</td>\n",
       "      <td>0.000029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>124.332294</td>\n",
       "      <td>3.300808</td>\n",
       "      <td>0.015159</td>\n",
       "      <td>3.992081e-04</td>\n",
       "      <td>3</td>\n",
       "      <td>3000</td>\n",
       "      <td>{'max_depth': 3, 'n_estimators': 3000}</td>\n",
       "      <td>-7.254140</td>\n",
       "      <td>-6.256312</td>\n",
       "      <td>-10.830569</td>\n",
       "      <td>...</td>\n",
       "      <td>-6.549811</td>\n",
       "      <td>3.471283</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999893</td>\n",
       "      <td>0.999950</td>\n",
       "      <td>0.999984</td>\n",
       "      <td>0.999943</td>\n",
       "      <td>0.999934</td>\n",
       "      <td>0.999941</td>\n",
       "      <td>0.000029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>13.621173</td>\n",
       "      <td>0.160297</td>\n",
       "      <td>0.010372</td>\n",
       "      <td>1.352817e-03</td>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_depth': 4, 'n_estimators': 100}</td>\n",
       "      <td>-7.974948</td>\n",
       "      <td>-6.254964</td>\n",
       "      <td>-10.632250</td>\n",
       "      <td>...</td>\n",
       "      <td>-6.778814</td>\n",
       "      <td>3.499364</td>\n",
       "      <td>14</td>\n",
       "      <td>0.999606</td>\n",
       "      <td>0.999828</td>\n",
       "      <td>0.999835</td>\n",
       "      <td>0.999778</td>\n",
       "      <td>0.999779</td>\n",
       "      <td>0.999765</td>\n",
       "      <td>0.000083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>25.107853</td>\n",
       "      <td>0.228898</td>\n",
       "      <td>0.010173</td>\n",
       "      <td>3.990651e-04</td>\n",
       "      <td>4</td>\n",
       "      <td>300</td>\n",
       "      <td>{'max_depth': 4, 'n_estimators': 300}</td>\n",
       "      <td>-7.966026</td>\n",
       "      <td>-6.253286</td>\n",
       "      <td>-10.632172</td>\n",
       "      <td>...</td>\n",
       "      <td>-6.777028</td>\n",
       "      <td>3.499038</td>\n",
       "      <td>10</td>\n",
       "      <td>0.999897</td>\n",
       "      <td>0.999951</td>\n",
       "      <td>0.999984</td>\n",
       "      <td>0.999945</td>\n",
       "      <td>0.999936</td>\n",
       "      <td>0.999943</td>\n",
       "      <td>0.000028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>32.138850</td>\n",
       "      <td>0.281530</td>\n",
       "      <td>0.010572</td>\n",
       "      <td>4.885582e-04</td>\n",
       "      <td>4</td>\n",
       "      <td>500</td>\n",
       "      <td>{'max_depth': 4, 'n_estimators': 500}</td>\n",
       "      <td>-7.965983</td>\n",
       "      <td>-6.253238</td>\n",
       "      <td>-10.632206</td>\n",
       "      <td>...</td>\n",
       "      <td>-6.777029</td>\n",
       "      <td>3.499057</td>\n",
       "      <td>12</td>\n",
       "      <td>0.999897</td>\n",
       "      <td>0.999951</td>\n",
       "      <td>0.999984</td>\n",
       "      <td>0.999945</td>\n",
       "      <td>0.999936</td>\n",
       "      <td>0.999943</td>\n",
       "      <td>0.000028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>38.909144</td>\n",
       "      <td>0.249160</td>\n",
       "      <td>0.010771</td>\n",
       "      <td>3.988267e-04</td>\n",
       "      <td>4</td>\n",
       "      <td>700</td>\n",
       "      <td>{'max_depth': 4, 'n_estimators': 700}</td>\n",
       "      <td>-7.965951</td>\n",
       "      <td>-6.253208</td>\n",
       "      <td>-10.632234</td>\n",
       "      <td>...</td>\n",
       "      <td>-6.777028</td>\n",
       "      <td>3.499071</td>\n",
       "      <td>8</td>\n",
       "      <td>0.999897</td>\n",
       "      <td>0.999951</td>\n",
       "      <td>0.999984</td>\n",
       "      <td>0.999945</td>\n",
       "      <td>0.999937</td>\n",
       "      <td>0.999943</td>\n",
       "      <td>0.000028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>46.132626</td>\n",
       "      <td>0.208084</td>\n",
       "      <td>0.010971</td>\n",
       "      <td>6.308265e-04</td>\n",
       "      <td>4</td>\n",
       "      <td>900</td>\n",
       "      <td>{'max_depth': 4, 'n_estimators': 900}</td>\n",
       "      <td>-7.965918</td>\n",
       "      <td>-6.253187</td>\n",
       "      <td>-10.632262</td>\n",
       "      <td>...</td>\n",
       "      <td>-6.777028</td>\n",
       "      <td>3.499085</td>\n",
       "      <td>9</td>\n",
       "      <td>0.999897</td>\n",
       "      <td>0.999951</td>\n",
       "      <td>0.999984</td>\n",
       "      <td>0.999945</td>\n",
       "      <td>0.999937</td>\n",
       "      <td>0.999943</td>\n",
       "      <td>0.000028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>49.471696</td>\n",
       "      <td>0.357224</td>\n",
       "      <td>0.011968</td>\n",
       "      <td>1.168008e-07</td>\n",
       "      <td>4</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'max_depth': 4, 'n_estimators': 1000}</td>\n",
       "      <td>-7.965902</td>\n",
       "      <td>-6.253176</td>\n",
       "      <td>-10.632276</td>\n",
       "      <td>...</td>\n",
       "      <td>-6.777028</td>\n",
       "      <td>3.499091</td>\n",
       "      <td>11</td>\n",
       "      <td>0.999897</td>\n",
       "      <td>0.999951</td>\n",
       "      <td>0.999984</td>\n",
       "      <td>0.999945</td>\n",
       "      <td>0.999937</td>\n",
       "      <td>0.999943</td>\n",
       "      <td>0.000028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>119.825746</td>\n",
       "      <td>0.830625</td>\n",
       "      <td>0.014561</td>\n",
       "      <td>4.885776e-04</td>\n",
       "      <td>4</td>\n",
       "      <td>3000</td>\n",
       "      <td>{'max_depth': 4, 'n_estimators': 3000}</td>\n",
       "      <td>-7.965579</td>\n",
       "      <td>-6.252962</td>\n",
       "      <td>-10.632556</td>\n",
       "      <td>...</td>\n",
       "      <td>-6.777031</td>\n",
       "      <td>3.499227</td>\n",
       "      <td>13</td>\n",
       "      <td>0.999897</td>\n",
       "      <td>0.999951</td>\n",
       "      <td>0.999984</td>\n",
       "      <td>0.999945</td>\n",
       "      <td>0.999937</td>\n",
       "      <td>0.999943</td>\n",
       "      <td>0.000028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15.265375</td>\n",
       "      <td>0.583477</td>\n",
       "      <td>0.009973</td>\n",
       "      <td>1.784161e-07</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_depth': 5, 'n_estimators': 100}</td>\n",
       "      <td>-7.816655</td>\n",
       "      <td>-6.525084</td>\n",
       "      <td>-10.761075</td>\n",
       "      <td>...</td>\n",
       "      <td>-6.886288</td>\n",
       "      <td>3.492615</td>\n",
       "      <td>22</td>\n",
       "      <td>0.999900</td>\n",
       "      <td>0.999952</td>\n",
       "      <td>0.999986</td>\n",
       "      <td>0.999946</td>\n",
       "      <td>0.999937</td>\n",
       "      <td>0.999944</td>\n",
       "      <td>0.000028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>22.144179</td>\n",
       "      <td>0.502762</td>\n",
       "      <td>0.010372</td>\n",
       "      <td>4.885192e-04</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>{'max_depth': 5, 'n_estimators': 300}</td>\n",
       "      <td>-7.816746</td>\n",
       "      <td>-6.525164</td>\n",
       "      <td>-10.761109</td>\n",
       "      <td>...</td>\n",
       "      <td>-6.886308</td>\n",
       "      <td>3.492605</td>\n",
       "      <td>23</td>\n",
       "      <td>0.999900</td>\n",
       "      <td>0.999952</td>\n",
       "      <td>0.999986</td>\n",
       "      <td>0.999946</td>\n",
       "      <td>0.999937</td>\n",
       "      <td>0.999944</td>\n",
       "      <td>0.000028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>29.289271</td>\n",
       "      <td>0.620283</td>\n",
       "      <td>0.010771</td>\n",
       "      <td>3.990889e-04</td>\n",
       "      <td>5</td>\n",
       "      <td>500</td>\n",
       "      <td>{'max_depth': 5, 'n_estimators': 500}</td>\n",
       "      <td>-7.816821</td>\n",
       "      <td>-6.525195</td>\n",
       "      <td>-10.761129</td>\n",
       "      <td>...</td>\n",
       "      <td>-6.886325</td>\n",
       "      <td>3.492602</td>\n",
       "      <td>24</td>\n",
       "      <td>0.999900</td>\n",
       "      <td>0.999952</td>\n",
       "      <td>0.999986</td>\n",
       "      <td>0.999946</td>\n",
       "      <td>0.999937</td>\n",
       "      <td>0.999944</td>\n",
       "      <td>0.000028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>36.057171</td>\n",
       "      <td>0.647147</td>\n",
       "      <td>0.010771</td>\n",
       "      <td>3.989697e-04</td>\n",
       "      <td>5</td>\n",
       "      <td>700</td>\n",
       "      <td>{'max_depth': 5, 'n_estimators': 700}</td>\n",
       "      <td>-7.816882</td>\n",
       "      <td>-6.525215</td>\n",
       "      <td>-10.761149</td>\n",
       "      <td>...</td>\n",
       "      <td>-6.886340</td>\n",
       "      <td>3.492600</td>\n",
       "      <td>25</td>\n",
       "      <td>0.999900</td>\n",
       "      <td>0.999952</td>\n",
       "      <td>0.999986</td>\n",
       "      <td>0.999946</td>\n",
       "      <td>0.999937</td>\n",
       "      <td>0.999944</td>\n",
       "      <td>0.000028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>43.454987</td>\n",
       "      <td>0.557881</td>\n",
       "      <td>0.010970</td>\n",
       "      <td>4.156970e-07</td>\n",
       "      <td>5</td>\n",
       "      <td>900</td>\n",
       "      <td>{'max_depth': 5, 'n_estimators': 900}</td>\n",
       "      <td>-7.816916</td>\n",
       "      <td>-6.525235</td>\n",
       "      <td>-10.761169</td>\n",
       "      <td>...</td>\n",
       "      <td>-6.886349</td>\n",
       "      <td>3.492596</td>\n",
       "      <td>26</td>\n",
       "      <td>0.999900</td>\n",
       "      <td>0.999952</td>\n",
       "      <td>0.999986</td>\n",
       "      <td>0.999946</td>\n",
       "      <td>0.999937</td>\n",
       "      <td>0.999944</td>\n",
       "      <td>0.000028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>46.764536</td>\n",
       "      <td>0.819002</td>\n",
       "      <td>0.015558</td>\n",
       "      <td>8.190366e-03</td>\n",
       "      <td>5</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'max_depth': 5, 'n_estimators': 1000}</td>\n",
       "      <td>-7.816933</td>\n",
       "      <td>-6.525245</td>\n",
       "      <td>-10.761179</td>\n",
       "      <td>...</td>\n",
       "      <td>-6.886353</td>\n",
       "      <td>3.492594</td>\n",
       "      <td>27</td>\n",
       "      <td>0.999900</td>\n",
       "      <td>0.999952</td>\n",
       "      <td>0.999986</td>\n",
       "      <td>0.999946</td>\n",
       "      <td>0.999937</td>\n",
       "      <td>0.999944</td>\n",
       "      <td>0.000028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>116.160947</td>\n",
       "      <td>0.904858</td>\n",
       "      <td>0.014960</td>\n",
       "      <td>1.544895e-03</td>\n",
       "      <td>5</td>\n",
       "      <td>3000</td>\n",
       "      <td>{'max_depth': 5, 'n_estimators': 3000}</td>\n",
       "      <td>-7.817275</td>\n",
       "      <td>-6.525447</td>\n",
       "      <td>-10.761377</td>\n",
       "      <td>...</td>\n",
       "      <td>-6.886444</td>\n",
       "      <td>3.492555</td>\n",
       "      <td>28</td>\n",
       "      <td>0.999900</td>\n",
       "      <td>0.999952</td>\n",
       "      <td>0.999986</td>\n",
       "      <td>0.999946</td>\n",
       "      <td>0.999937</td>\n",
       "      <td>0.999944</td>\n",
       "      <td>0.000028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>13.206282</td>\n",
       "      <td>0.338638</td>\n",
       "      <td>0.009774</td>\n",
       "      <td>3.988029e-04</td>\n",
       "      <td>6</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_depth': 6, 'n_estimators': 100}</td>\n",
       "      <td>-7.973048</td>\n",
       "      <td>-6.357610</td>\n",
       "      <td>-11.246278</td>\n",
       "      <td>...</td>\n",
       "      <td>-7.114948</td>\n",
       "      <td>3.733327</td>\n",
       "      <td>42</td>\n",
       "      <td>0.999900</td>\n",
       "      <td>0.999953</td>\n",
       "      <td>0.999987</td>\n",
       "      <td>0.999947</td>\n",
       "      <td>0.999938</td>\n",
       "      <td>0.999945</td>\n",
       "      <td>0.000028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>20.018265</td>\n",
       "      <td>0.226566</td>\n",
       "      <td>0.009774</td>\n",
       "      <td>3.990412e-04</td>\n",
       "      <td>6</td>\n",
       "      <td>300</td>\n",
       "      <td>{'max_depth': 6, 'n_estimators': 300}</td>\n",
       "      <td>-7.972973</td>\n",
       "      <td>-6.357543</td>\n",
       "      <td>-11.246324</td>\n",
       "      <td>...</td>\n",
       "      <td>-7.114908</td>\n",
       "      <td>3.733316</td>\n",
       "      <td>41</td>\n",
       "      <td>0.999900</td>\n",
       "      <td>0.999953</td>\n",
       "      <td>0.999987</td>\n",
       "      <td>0.999947</td>\n",
       "      <td>0.999938</td>\n",
       "      <td>0.999945</td>\n",
       "      <td>0.000028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>26.992812</td>\n",
       "      <td>0.409070</td>\n",
       "      <td>0.010372</td>\n",
       "      <td>4.885388e-04</td>\n",
       "      <td>6</td>\n",
       "      <td>500</td>\n",
       "      <td>{'max_depth': 6, 'n_estimators': 500}</td>\n",
       "      <td>-7.972941</td>\n",
       "      <td>-6.357509</td>\n",
       "      <td>-11.246345</td>\n",
       "      <td>...</td>\n",
       "      <td>-7.114891</td>\n",
       "      <td>3.733308</td>\n",
       "      <td>40</td>\n",
       "      <td>0.999900</td>\n",
       "      <td>0.999953</td>\n",
       "      <td>0.999987</td>\n",
       "      <td>0.999947</td>\n",
       "      <td>0.999938</td>\n",
       "      <td>0.999945</td>\n",
       "      <td>0.000028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>34.211906</td>\n",
       "      <td>0.668417</td>\n",
       "      <td>0.010572</td>\n",
       "      <td>4.886166e-04</td>\n",
       "      <td>6</td>\n",
       "      <td>700</td>\n",
       "      <td>{'max_depth': 6, 'n_estimators': 700}</td>\n",
       "      <td>-7.972909</td>\n",
       "      <td>-6.357486</td>\n",
       "      <td>-11.246364</td>\n",
       "      <td>...</td>\n",
       "      <td>-7.114877</td>\n",
       "      <td>3.733300</td>\n",
       "      <td>39</td>\n",
       "      <td>0.999900</td>\n",
       "      <td>0.999953</td>\n",
       "      <td>0.999987</td>\n",
       "      <td>0.999947</td>\n",
       "      <td>0.999938</td>\n",
       "      <td>0.999945</td>\n",
       "      <td>0.000028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>40.885458</td>\n",
       "      <td>0.254186</td>\n",
       "      <td>0.011170</td>\n",
       "      <td>3.988982e-04</td>\n",
       "      <td>6</td>\n",
       "      <td>900</td>\n",
       "      <td>{'max_depth': 6, 'n_estimators': 900}</td>\n",
       "      <td>-7.972878</td>\n",
       "      <td>-6.357463</td>\n",
       "      <td>-11.246384</td>\n",
       "      <td>...</td>\n",
       "      <td>-7.114864</td>\n",
       "      <td>3.733293</td>\n",
       "      <td>38</td>\n",
       "      <td>0.999900</td>\n",
       "      <td>0.999953</td>\n",
       "      <td>0.999987</td>\n",
       "      <td>0.999947</td>\n",
       "      <td>0.999938</td>\n",
       "      <td>0.999945</td>\n",
       "      <td>0.000028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>44.451123</td>\n",
       "      <td>0.354567</td>\n",
       "      <td>0.010771</td>\n",
       "      <td>3.989220e-04</td>\n",
       "      <td>6</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'max_depth': 6, 'n_estimators': 1000}</td>\n",
       "      <td>-7.972862</td>\n",
       "      <td>-6.357451</td>\n",
       "      <td>-11.246394</td>\n",
       "      <td>...</td>\n",
       "      <td>-7.114857</td>\n",
       "      <td>3.733289</td>\n",
       "      <td>37</td>\n",
       "      <td>0.999900</td>\n",
       "      <td>0.999953</td>\n",
       "      <td>0.999987</td>\n",
       "      <td>0.999947</td>\n",
       "      <td>0.999938</td>\n",
       "      <td>0.999945</td>\n",
       "      <td>0.000028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>113.925924</td>\n",
       "      <td>0.438044</td>\n",
       "      <td>0.014761</td>\n",
       "      <td>9.770871e-04</td>\n",
       "      <td>6</td>\n",
       "      <td>3000</td>\n",
       "      <td>{'max_depth': 6, 'n_estimators': 3000}</td>\n",
       "      <td>-7.972546</td>\n",
       "      <td>-6.357222</td>\n",
       "      <td>-11.246588</td>\n",
       "      <td>...</td>\n",
       "      <td>-7.114721</td>\n",
       "      <td>3.733215</td>\n",
       "      <td>36</td>\n",
       "      <td>0.999900</td>\n",
       "      <td>0.999953</td>\n",
       "      <td>0.999987</td>\n",
       "      <td>0.999947</td>\n",
       "      <td>0.999938</td>\n",
       "      <td>0.999945</td>\n",
       "      <td>0.000028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>11.898380</td>\n",
       "      <td>0.361617</td>\n",
       "      <td>0.009575</td>\n",
       "      <td>7.977963e-04</td>\n",
       "      <td>7</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_depth': 7, 'n_estimators': 100}</td>\n",
       "      <td>-8.607065</td>\n",
       "      <td>-6.396606</td>\n",
       "      <td>-12.478342</td>\n",
       "      <td>...</td>\n",
       "      <td>-7.416383</td>\n",
       "      <td>3.943689</td>\n",
       "      <td>50</td>\n",
       "      <td>0.999901</td>\n",
       "      <td>0.999954</td>\n",
       "      <td>0.999987</td>\n",
       "      <td>0.999948</td>\n",
       "      <td>0.999939</td>\n",
       "      <td>0.999946</td>\n",
       "      <td>0.000028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>18.760628</td>\n",
       "      <td>0.127084</td>\n",
       "      <td>0.010572</td>\n",
       "      <td>1.196837e-03</td>\n",
       "      <td>7</td>\n",
       "      <td>300</td>\n",
       "      <td>{'max_depth': 7, 'n_estimators': 300}</td>\n",
       "      <td>-8.606983</td>\n",
       "      <td>-6.396541</td>\n",
       "      <td>-12.478381</td>\n",
       "      <td>...</td>\n",
       "      <td>-7.416391</td>\n",
       "      <td>3.943701</td>\n",
       "      <td>51</td>\n",
       "      <td>0.999901</td>\n",
       "      <td>0.999954</td>\n",
       "      <td>0.999987</td>\n",
       "      <td>0.999948</td>\n",
       "      <td>0.999939</td>\n",
       "      <td>0.999946</td>\n",
       "      <td>0.000028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>25.727795</td>\n",
       "      <td>0.192777</td>\n",
       "      <td>0.010372</td>\n",
       "      <td>4.886752e-04</td>\n",
       "      <td>7</td>\n",
       "      <td>500</td>\n",
       "      <td>{'max_depth': 7, 'n_estimators': 500}</td>\n",
       "      <td>-8.606942</td>\n",
       "      <td>-6.396510</td>\n",
       "      <td>-12.478408</td>\n",
       "      <td>...</td>\n",
       "      <td>-7.416399</td>\n",
       "      <td>3.943708</td>\n",
       "      <td>52</td>\n",
       "      <td>0.999901</td>\n",
       "      <td>0.999954</td>\n",
       "      <td>0.999987</td>\n",
       "      <td>0.999948</td>\n",
       "      <td>0.999939</td>\n",
       "      <td>0.999946</td>\n",
       "      <td>0.000028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>32.590442</td>\n",
       "      <td>0.297457</td>\n",
       "      <td>0.010372</td>\n",
       "      <td>4.885193e-04</td>\n",
       "      <td>7</td>\n",
       "      <td>700</td>\n",
       "      <td>{'max_depth': 7, 'n_estimators': 700}</td>\n",
       "      <td>-8.606912</td>\n",
       "      <td>-6.396490</td>\n",
       "      <td>-12.478424</td>\n",
       "      <td>...</td>\n",
       "      <td>-7.416404</td>\n",
       "      <td>3.943710</td>\n",
       "      <td>53</td>\n",
       "      <td>0.999901</td>\n",
       "      <td>0.999954</td>\n",
       "      <td>0.999987</td>\n",
       "      <td>0.999948</td>\n",
       "      <td>0.999939</td>\n",
       "      <td>0.999946</td>\n",
       "      <td>0.000028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>39.585735</td>\n",
       "      <td>0.235293</td>\n",
       "      <td>0.010771</td>\n",
       "      <td>3.990412e-04</td>\n",
       "      <td>7</td>\n",
       "      <td>900</td>\n",
       "      <td>{'max_depth': 7, 'n_estimators': 900}</td>\n",
       "      <td>-8.606881</td>\n",
       "      <td>-6.396470</td>\n",
       "      <td>-12.478439</td>\n",
       "      <td>...</td>\n",
       "      <td>-7.416410</td>\n",
       "      <td>3.943712</td>\n",
       "      <td>54</td>\n",
       "      <td>0.999901</td>\n",
       "      <td>0.999954</td>\n",
       "      <td>0.999987</td>\n",
       "      <td>0.999948</td>\n",
       "      <td>0.999939</td>\n",
       "      <td>0.999946</td>\n",
       "      <td>0.000028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>43.091559</td>\n",
       "      <td>0.281238</td>\n",
       "      <td>0.011170</td>\n",
       "      <td>3.989460e-04</td>\n",
       "      <td>7</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'max_depth': 7, 'n_estimators': 1000}</td>\n",
       "      <td>-8.606866</td>\n",
       "      <td>-6.396460</td>\n",
       "      <td>-12.478447</td>\n",
       "      <td>...</td>\n",
       "      <td>-7.416413</td>\n",
       "      <td>3.943713</td>\n",
       "      <td>55</td>\n",
       "      <td>0.999901</td>\n",
       "      <td>0.999954</td>\n",
       "      <td>0.999987</td>\n",
       "      <td>0.999948</td>\n",
       "      <td>0.999939</td>\n",
       "      <td>0.999946</td>\n",
       "      <td>0.000028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>112.648142</td>\n",
       "      <td>0.389142</td>\n",
       "      <td>0.013763</td>\n",
       "      <td>3.991605e-04</td>\n",
       "      <td>7</td>\n",
       "      <td>3000</td>\n",
       "      <td>{'max_depth': 7, 'n_estimators': 3000}</td>\n",
       "      <td>-8.606565</td>\n",
       "      <td>-6.396263</td>\n",
       "      <td>-12.478606</td>\n",
       "      <td>...</td>\n",
       "      <td>-7.416472</td>\n",
       "      <td>3.943735</td>\n",
       "      <td>56</td>\n",
       "      <td>0.999901</td>\n",
       "      <td>0.999954</td>\n",
       "      <td>0.999987</td>\n",
       "      <td>0.999948</td>\n",
       "      <td>0.999939</td>\n",
       "      <td>0.999946</td>\n",
       "      <td>0.000028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>11.760149</td>\n",
       "      <td>0.226495</td>\n",
       "      <td>0.009375</td>\n",
       "      <td>4.886750e-04</td>\n",
       "      <td>8</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_depth': 8, 'n_estimators': 100}</td>\n",
       "      <td>-8.034338</td>\n",
       "      <td>-6.396257</td>\n",
       "      <td>-10.990024</td>\n",
       "      <td>...</td>\n",
       "      <td>-7.117779</td>\n",
       "      <td>3.640090</td>\n",
       "      <td>43</td>\n",
       "      <td>0.999902</td>\n",
       "      <td>0.999955</td>\n",
       "      <td>0.999988</td>\n",
       "      <td>0.999948</td>\n",
       "      <td>0.999939</td>\n",
       "      <td>0.999947</td>\n",
       "      <td>0.000028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>18.628182</td>\n",
       "      <td>0.224896</td>\n",
       "      <td>0.010173</td>\n",
       "      <td>3.990651e-04</td>\n",
       "      <td>8</td>\n",
       "      <td>300</td>\n",
       "      <td>{'max_depth': 8, 'n_estimators': 300}</td>\n",
       "      <td>-8.034263</td>\n",
       "      <td>-6.396188</td>\n",
       "      <td>-10.990077</td>\n",
       "      <td>...</td>\n",
       "      <td>-7.117787</td>\n",
       "      <td>3.640110</td>\n",
       "      <td>44</td>\n",
       "      <td>0.999902</td>\n",
       "      <td>0.999955</td>\n",
       "      <td>0.999988</td>\n",
       "      <td>0.999948</td>\n",
       "      <td>0.999939</td>\n",
       "      <td>0.999947</td>\n",
       "      <td>0.000028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>25.800999</td>\n",
       "      <td>0.314285</td>\n",
       "      <td>0.010372</td>\n",
       "      <td>4.885971e-04</td>\n",
       "      <td>8</td>\n",
       "      <td>500</td>\n",
       "      <td>{'max_depth': 8, 'n_estimators': 500}</td>\n",
       "      <td>-8.034222</td>\n",
       "      <td>-6.396165</td>\n",
       "      <td>-10.990096</td>\n",
       "      <td>...</td>\n",
       "      <td>-7.117790</td>\n",
       "      <td>3.640114</td>\n",
       "      <td>45</td>\n",
       "      <td>0.999902</td>\n",
       "      <td>0.999955</td>\n",
       "      <td>0.999988</td>\n",
       "      <td>0.999948</td>\n",
       "      <td>0.999939</td>\n",
       "      <td>0.999947</td>\n",
       "      <td>0.000028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>32.518235</td>\n",
       "      <td>0.322182</td>\n",
       "      <td>0.010173</td>\n",
       "      <td>3.990174e-04</td>\n",
       "      <td>8</td>\n",
       "      <td>700</td>\n",
       "      <td>{'max_depth': 8, 'n_estimators': 700}</td>\n",
       "      <td>-8.034188</td>\n",
       "      <td>-6.396143</td>\n",
       "      <td>-10.990114</td>\n",
       "      <td>...</td>\n",
       "      <td>-7.117794</td>\n",
       "      <td>3.640119</td>\n",
       "      <td>46</td>\n",
       "      <td>0.999902</td>\n",
       "      <td>0.999955</td>\n",
       "      <td>0.999988</td>\n",
       "      <td>0.999948</td>\n",
       "      <td>0.999939</td>\n",
       "      <td>0.999947</td>\n",
       "      <td>0.000028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>39.573168</td>\n",
       "      <td>0.319585</td>\n",
       "      <td>0.011170</td>\n",
       "      <td>3.990414e-04</td>\n",
       "      <td>8</td>\n",
       "      <td>900</td>\n",
       "      <td>{'max_depth': 8, 'n_estimators': 900}</td>\n",
       "      <td>-8.034154</td>\n",
       "      <td>-6.396120</td>\n",
       "      <td>-10.990132</td>\n",
       "      <td>...</td>\n",
       "      <td>-7.117799</td>\n",
       "      <td>3.640123</td>\n",
       "      <td>47</td>\n",
       "      <td>0.999902</td>\n",
       "      <td>0.999955</td>\n",
       "      <td>0.999988</td>\n",
       "      <td>0.999948</td>\n",
       "      <td>0.999939</td>\n",
       "      <td>0.999947</td>\n",
       "      <td>0.000028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>42.992622</td>\n",
       "      <td>0.319795</td>\n",
       "      <td>0.010970</td>\n",
       "      <td>6.306756e-04</td>\n",
       "      <td>8</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'max_depth': 8, 'n_estimators': 1000}</td>\n",
       "      <td>-8.034137</td>\n",
       "      <td>-6.396108</td>\n",
       "      <td>-10.990141</td>\n",
       "      <td>...</td>\n",
       "      <td>-7.117801</td>\n",
       "      <td>3.640125</td>\n",
       "      <td>48</td>\n",
       "      <td>0.999902</td>\n",
       "      <td>0.999955</td>\n",
       "      <td>0.999988</td>\n",
       "      <td>0.999948</td>\n",
       "      <td>0.999939</td>\n",
       "      <td>0.999947</td>\n",
       "      <td>0.000028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>113.630315</td>\n",
       "      <td>0.945065</td>\n",
       "      <td>0.014561</td>\n",
       "      <td>1.196742e-03</td>\n",
       "      <td>8</td>\n",
       "      <td>3000</td>\n",
       "      <td>{'max_depth': 8, 'n_estimators': 3000}</td>\n",
       "      <td>-8.033796</td>\n",
       "      <td>-6.395879</td>\n",
       "      <td>-10.990321</td>\n",
       "      <td>...</td>\n",
       "      <td>-7.117842</td>\n",
       "      <td>3.640170</td>\n",
       "      <td>49</td>\n",
       "      <td>0.999902</td>\n",
       "      <td>0.999955</td>\n",
       "      <td>0.999988</td>\n",
       "      <td>0.999948</td>\n",
       "      <td>0.999939</td>\n",
       "      <td>0.999947</td>\n",
       "      <td>0.000028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>12.406421</td>\n",
       "      <td>0.284801</td>\n",
       "      <td>0.009774</td>\n",
       "      <td>3.988982e-04</td>\n",
       "      <td>9</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_depth': 9, 'n_estimators': 100}</td>\n",
       "      <td>-8.384569</td>\n",
       "      <td>-6.075902</td>\n",
       "      <td>-10.485391</td>\n",
       "      <td>...</td>\n",
       "      <td>-6.871226</td>\n",
       "      <td>3.449965</td>\n",
       "      <td>15</td>\n",
       "      <td>0.999904</td>\n",
       "      <td>0.999955</td>\n",
       "      <td>0.999988</td>\n",
       "      <td>0.999949</td>\n",
       "      <td>0.999941</td>\n",
       "      <td>0.999947</td>\n",
       "      <td>0.000027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>19.297991</td>\n",
       "      <td>0.253674</td>\n",
       "      <td>0.010173</td>\n",
       "      <td>3.988028e-04</td>\n",
       "      <td>9</td>\n",
       "      <td>300</td>\n",
       "      <td>{'max_depth': 9, 'n_estimators': 300}</td>\n",
       "      <td>-8.384656</td>\n",
       "      <td>-6.075840</td>\n",
       "      <td>-10.485356</td>\n",
       "      <td>...</td>\n",
       "      <td>-6.871256</td>\n",
       "      <td>3.449977</td>\n",
       "      <td>16</td>\n",
       "      <td>0.999904</td>\n",
       "      <td>0.999955</td>\n",
       "      <td>0.999988</td>\n",
       "      <td>0.999949</td>\n",
       "      <td>0.999941</td>\n",
       "      <td>0.999947</td>\n",
       "      <td>0.000027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>26.285105</td>\n",
       "      <td>0.203555</td>\n",
       "      <td>0.010173</td>\n",
       "      <td>3.988505e-04</td>\n",
       "      <td>9</td>\n",
       "      <td>500</td>\n",
       "      <td>{'max_depth': 9, 'n_estimators': 500}</td>\n",
       "      <td>-8.384720</td>\n",
       "      <td>-6.075809</td>\n",
       "      <td>-10.485335</td>\n",
       "      <td>...</td>\n",
       "      <td>-6.871283</td>\n",
       "      <td>3.449986</td>\n",
       "      <td>17</td>\n",
       "      <td>0.999904</td>\n",
       "      <td>0.999955</td>\n",
       "      <td>0.999988</td>\n",
       "      <td>0.999949</td>\n",
       "      <td>0.999941</td>\n",
       "      <td>0.999947</td>\n",
       "      <td>0.000027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>33.465701</td>\n",
       "      <td>0.255062</td>\n",
       "      <td>0.010771</td>\n",
       "      <td>7.463275e-04</td>\n",
       "      <td>9</td>\n",
       "      <td>700</td>\n",
       "      <td>{'max_depth': 9, 'n_estimators': 700}</td>\n",
       "      <td>-8.384752</td>\n",
       "      <td>-6.075786</td>\n",
       "      <td>-10.485315</td>\n",
       "      <td>...</td>\n",
       "      <td>-6.871292</td>\n",
       "      <td>3.449986</td>\n",
       "      <td>18</td>\n",
       "      <td>0.999904</td>\n",
       "      <td>0.999955</td>\n",
       "      <td>0.999988</td>\n",
       "      <td>0.999949</td>\n",
       "      <td>0.999941</td>\n",
       "      <td>0.999947</td>\n",
       "      <td>0.000027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>40.369239</td>\n",
       "      <td>0.238924</td>\n",
       "      <td>0.010771</td>\n",
       "      <td>3.988505e-04</td>\n",
       "      <td>9</td>\n",
       "      <td>900</td>\n",
       "      <td>{'max_depth': 9, 'n_estimators': 900}</td>\n",
       "      <td>-8.384783</td>\n",
       "      <td>-6.075762</td>\n",
       "      <td>-10.485295</td>\n",
       "      <td>...</td>\n",
       "      <td>-6.871302</td>\n",
       "      <td>3.449986</td>\n",
       "      <td>19</td>\n",
       "      <td>0.999904</td>\n",
       "      <td>0.999955</td>\n",
       "      <td>0.999988</td>\n",
       "      <td>0.999949</td>\n",
       "      <td>0.999941</td>\n",
       "      <td>0.999947</td>\n",
       "      <td>0.000027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>43.728456</td>\n",
       "      <td>0.217697</td>\n",
       "      <td>0.011370</td>\n",
       "      <td>7.978678e-04</td>\n",
       "      <td>9</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'max_depth': 9, 'n_estimators': 1000}</td>\n",
       "      <td>-8.384799</td>\n",
       "      <td>-6.075750</td>\n",
       "      <td>-10.485285</td>\n",
       "      <td>...</td>\n",
       "      <td>-6.871307</td>\n",
       "      <td>3.449985</td>\n",
       "      <td>20</td>\n",
       "      <td>0.999904</td>\n",
       "      <td>0.999955</td>\n",
       "      <td>0.999988</td>\n",
       "      <td>0.999949</td>\n",
       "      <td>0.999941</td>\n",
       "      <td>0.999947</td>\n",
       "      <td>0.000027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>113.295012</td>\n",
       "      <td>0.360757</td>\n",
       "      <td>0.014162</td>\n",
       "      <td>3.989697e-04</td>\n",
       "      <td>9</td>\n",
       "      <td>3000</td>\n",
       "      <td>{'max_depth': 9, 'n_estimators': 3000}</td>\n",
       "      <td>-8.385114</td>\n",
       "      <td>-6.075512</td>\n",
       "      <td>-10.485086</td>\n",
       "      <td>...</td>\n",
       "      <td>-6.871404</td>\n",
       "      <td>3.449982</td>\n",
       "      <td>21</td>\n",
       "      <td>0.999904</td>\n",
       "      <td>0.999955</td>\n",
       "      <td>0.999988</td>\n",
       "      <td>0.999949</td>\n",
       "      <td>0.999941</td>\n",
       "      <td>0.999947</td>\n",
       "      <td>0.000027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>12.848838</td>\n",
       "      <td>0.228623</td>\n",
       "      <td>0.009974</td>\n",
       "      <td>4.156970e-07</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_depth': 10, 'n_estimators': 100}</td>\n",
       "      <td>-8.785261</td>\n",
       "      <td>-5.625660</td>\n",
       "      <td>-10.357448</td>\n",
       "      <td>...</td>\n",
       "      <td>-7.046729</td>\n",
       "      <td>3.593277</td>\n",
       "      <td>29</td>\n",
       "      <td>0.999904</td>\n",
       "      <td>0.999955</td>\n",
       "      <td>0.999989</td>\n",
       "      <td>0.999949</td>\n",
       "      <td>0.999942</td>\n",
       "      <td>0.999948</td>\n",
       "      <td>0.000027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>19.864674</td>\n",
       "      <td>0.328874</td>\n",
       "      <td>0.010173</td>\n",
       "      <td>3.990650e-04</td>\n",
       "      <td>10</td>\n",
       "      <td>300</td>\n",
       "      <td>{'max_depth': 10, 'n_estimators': 300}</td>\n",
       "      <td>-8.785343</td>\n",
       "      <td>-5.625723</td>\n",
       "      <td>-10.357400</td>\n",
       "      <td>...</td>\n",
       "      <td>-7.046770</td>\n",
       "      <td>3.593295</td>\n",
       "      <td>30</td>\n",
       "      <td>0.999904</td>\n",
       "      <td>0.999955</td>\n",
       "      <td>0.999989</td>\n",
       "      <td>0.999949</td>\n",
       "      <td>0.999942</td>\n",
       "      <td>0.999948</td>\n",
       "      <td>0.000027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>26.806710</td>\n",
       "      <td>0.171841</td>\n",
       "      <td>0.010373</td>\n",
       "      <td>7.978916e-04</td>\n",
       "      <td>10</td>\n",
       "      <td>500</td>\n",
       "      <td>{'max_depth': 10, 'n_estimators': 500}</td>\n",
       "      <td>-8.785401</td>\n",
       "      <td>-5.625746</td>\n",
       "      <td>-10.357365</td>\n",
       "      <td>...</td>\n",
       "      <td>-7.046793</td>\n",
       "      <td>3.593311</td>\n",
       "      <td>31</td>\n",
       "      <td>0.999904</td>\n",
       "      <td>0.999955</td>\n",
       "      <td>0.999989</td>\n",
       "      <td>0.999949</td>\n",
       "      <td>0.999942</td>\n",
       "      <td>0.999948</td>\n",
       "      <td>0.000027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>33.747747</td>\n",
       "      <td>0.181962</td>\n",
       "      <td>0.010572</td>\n",
       "      <td>4.885388e-04</td>\n",
       "      <td>10</td>\n",
       "      <td>700</td>\n",
       "      <td>{'max_depth': 10, 'n_estimators': 700}</td>\n",
       "      <td>-8.785432</td>\n",
       "      <td>-5.625770</td>\n",
       "      <td>-10.357347</td>\n",
       "      <td>...</td>\n",
       "      <td>-7.046807</td>\n",
       "      <td>3.593321</td>\n",
       "      <td>32</td>\n",
       "      <td>0.999904</td>\n",
       "      <td>0.999955</td>\n",
       "      <td>0.999989</td>\n",
       "      <td>0.999949</td>\n",
       "      <td>0.999942</td>\n",
       "      <td>0.999948</td>\n",
       "      <td>0.000027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>40.761989</td>\n",
       "      <td>0.626765</td>\n",
       "      <td>0.010971</td>\n",
       "      <td>2.861023e-07</td>\n",
       "      <td>10</td>\n",
       "      <td>900</td>\n",
       "      <td>{'max_depth': 10, 'n_estimators': 900}</td>\n",
       "      <td>-8.785463</td>\n",
       "      <td>-5.625793</td>\n",
       "      <td>-10.357329</td>\n",
       "      <td>...</td>\n",
       "      <td>-7.046820</td>\n",
       "      <td>3.593331</td>\n",
       "      <td>33</td>\n",
       "      <td>0.999904</td>\n",
       "      <td>0.999955</td>\n",
       "      <td>0.999989</td>\n",
       "      <td>0.999949</td>\n",
       "      <td>0.999942</td>\n",
       "      <td>0.999948</td>\n",
       "      <td>0.000027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>41.181268</td>\n",
       "      <td>1.049817</td>\n",
       "      <td>0.008777</td>\n",
       "      <td>1.163015e-03</td>\n",
       "      <td>10</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'max_depth': 10, 'n_estimators': 1000}</td>\n",
       "      <td>-8.785479</td>\n",
       "      <td>-5.625805</td>\n",
       "      <td>-10.357320</td>\n",
       "      <td>...</td>\n",
       "      <td>-7.046827</td>\n",
       "      <td>3.593337</td>\n",
       "      <td>34</td>\n",
       "      <td>0.999904</td>\n",
       "      <td>0.999955</td>\n",
       "      <td>0.999989</td>\n",
       "      <td>0.999949</td>\n",
       "      <td>0.999942</td>\n",
       "      <td>0.999948</td>\n",
       "      <td>0.000027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>70.129251</td>\n",
       "      <td>2.967336</td>\n",
       "      <td>0.007979</td>\n",
       "      <td>6.306757e-04</td>\n",
       "      <td>10</td>\n",
       "      <td>3000</td>\n",
       "      <td>{'max_depth': 10, 'n_estimators': 3000}</td>\n",
       "      <td>-8.785789</td>\n",
       "      <td>-5.626041</td>\n",
       "      <td>-10.357139</td>\n",
       "      <td>...</td>\n",
       "      <td>-7.046962</td>\n",
       "      <td>3.593440</td>\n",
       "      <td>35</td>\n",
       "      <td>0.999904</td>\n",
       "      <td>0.999955</td>\n",
       "      <td>0.999989</td>\n",
       "      <td>0.999949</td>\n",
       "      <td>0.999942</td>\n",
       "      <td>0.999948</td>\n",
       "      <td>0.000027</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>56 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0       10.461423      0.090626         0.009973    4.422006e-07   \n",
       "1       29.344921      0.522393         0.011569    4.885971e-04   \n",
       "2       36.134564      0.492513         0.011768    1.162949e-03   \n",
       "3       42.906255      0.766962         0.011569    4.885776e-04   \n",
       "4       49.891773      0.651333         0.011968    2.611745e-07   \n",
       "5       53.465017      0.701668         0.011768    3.988743e-04   \n",
       "6      124.332294      3.300808         0.015159    3.992081e-04   \n",
       "7       13.621173      0.160297         0.010372    1.352817e-03   \n",
       "8       25.107853      0.228898         0.010173    3.990651e-04   \n",
       "9       32.138850      0.281530         0.010572    4.885582e-04   \n",
       "10      38.909144      0.249160         0.010771    3.988267e-04   \n",
       "11      46.132626      0.208084         0.010971    6.308265e-04   \n",
       "12      49.471696      0.357224         0.011968    1.168008e-07   \n",
       "13     119.825746      0.830625         0.014561    4.885776e-04   \n",
       "14      15.265375      0.583477         0.009973    1.784161e-07   \n",
       "15      22.144179      0.502762         0.010372    4.885192e-04   \n",
       "16      29.289271      0.620283         0.010771    3.990889e-04   \n",
       "17      36.057171      0.647147         0.010771    3.989697e-04   \n",
       "18      43.454987      0.557881         0.010970    4.156970e-07   \n",
       "19      46.764536      0.819002         0.015558    8.190366e-03   \n",
       "20     116.160947      0.904858         0.014960    1.544895e-03   \n",
       "21      13.206282      0.338638         0.009774    3.988029e-04   \n",
       "22      20.018265      0.226566         0.009774    3.990412e-04   \n",
       "23      26.992812      0.409070         0.010372    4.885388e-04   \n",
       "24      34.211906      0.668417         0.010572    4.886166e-04   \n",
       "25      40.885458      0.254186         0.011170    3.988982e-04   \n",
       "26      44.451123      0.354567         0.010771    3.989220e-04   \n",
       "27     113.925924      0.438044         0.014761    9.770871e-04   \n",
       "28      11.898380      0.361617         0.009575    7.977963e-04   \n",
       "29      18.760628      0.127084         0.010572    1.196837e-03   \n",
       "30      25.727795      0.192777         0.010372    4.886752e-04   \n",
       "31      32.590442      0.297457         0.010372    4.885193e-04   \n",
       "32      39.585735      0.235293         0.010771    3.990412e-04   \n",
       "33      43.091559      0.281238         0.011170    3.989460e-04   \n",
       "34     112.648142      0.389142         0.013763    3.991605e-04   \n",
       "35      11.760149      0.226495         0.009375    4.886750e-04   \n",
       "36      18.628182      0.224896         0.010173    3.990651e-04   \n",
       "37      25.800999      0.314285         0.010372    4.885971e-04   \n",
       "38      32.518235      0.322182         0.010173    3.990174e-04   \n",
       "39      39.573168      0.319585         0.011170    3.990414e-04   \n",
       "40      42.992622      0.319795         0.010970    6.306756e-04   \n",
       "41     113.630315      0.945065         0.014561    1.196742e-03   \n",
       "42      12.406421      0.284801         0.009774    3.988982e-04   \n",
       "43      19.297991      0.253674         0.010173    3.988028e-04   \n",
       "44      26.285105      0.203555         0.010173    3.988505e-04   \n",
       "45      33.465701      0.255062         0.010771    7.463275e-04   \n",
       "46      40.369239      0.238924         0.010771    3.988505e-04   \n",
       "47      43.728456      0.217697         0.011370    7.978678e-04   \n",
       "48     113.295012      0.360757         0.014162    3.989697e-04   \n",
       "49      12.848838      0.228623         0.009974    4.156970e-07   \n",
       "50      19.864674      0.328874         0.010173    3.990650e-04   \n",
       "51      26.806710      0.171841         0.010373    7.978916e-04   \n",
       "52      33.747747      0.181962         0.010572    4.885388e-04   \n",
       "53      40.761989      0.626765         0.010971    2.861023e-07   \n",
       "54      41.181268      1.049817         0.008777    1.163015e-03   \n",
       "55      70.129251      2.967336         0.007979    6.306757e-04   \n",
       "\n",
       "   param_max_depth param_n_estimators  \\\n",
       "0                3                100   \n",
       "1                3                300   \n",
       "2                3                500   \n",
       "3                3                700   \n",
       "4                3                900   \n",
       "5                3               1000   \n",
       "6                3               3000   \n",
       "7                4                100   \n",
       "8                4                300   \n",
       "9                4                500   \n",
       "10               4                700   \n",
       "11               4                900   \n",
       "12               4               1000   \n",
       "13               4               3000   \n",
       "14               5                100   \n",
       "15               5                300   \n",
       "16               5                500   \n",
       "17               5                700   \n",
       "18               5                900   \n",
       "19               5               1000   \n",
       "20               5               3000   \n",
       "21               6                100   \n",
       "22               6                300   \n",
       "23               6                500   \n",
       "24               6                700   \n",
       "25               6                900   \n",
       "26               6               1000   \n",
       "27               6               3000   \n",
       "28               7                100   \n",
       "29               7                300   \n",
       "30               7                500   \n",
       "31               7                700   \n",
       "32               7                900   \n",
       "33               7               1000   \n",
       "34               7               3000   \n",
       "35               8                100   \n",
       "36               8                300   \n",
       "37               8                500   \n",
       "38               8                700   \n",
       "39               8                900   \n",
       "40               8               1000   \n",
       "41               8               3000   \n",
       "42               9                100   \n",
       "43               9                300   \n",
       "44               9                500   \n",
       "45               9                700   \n",
       "46               9                900   \n",
       "47               9               1000   \n",
       "48               9               3000   \n",
       "49              10                100   \n",
       "50              10                300   \n",
       "51              10                500   \n",
       "52              10                700   \n",
       "53              10                900   \n",
       "54              10               1000   \n",
       "55              10               3000   \n",
       "\n",
       "                                     params  split0_test_score  \\\n",
       "0     {'max_depth': 3, 'n_estimators': 100}          -7.378642   \n",
       "1     {'max_depth': 3, 'n_estimators': 300}          -7.254624   \n",
       "2     {'max_depth': 3, 'n_estimators': 500}          -7.254550   \n",
       "3     {'max_depth': 3, 'n_estimators': 700}          -7.254508   \n",
       "4     {'max_depth': 3, 'n_estimators': 900}          -7.254476   \n",
       "5    {'max_depth': 3, 'n_estimators': 1000}          -7.254460   \n",
       "6    {'max_depth': 3, 'n_estimators': 3000}          -7.254140   \n",
       "7     {'max_depth': 4, 'n_estimators': 100}          -7.974948   \n",
       "8     {'max_depth': 4, 'n_estimators': 300}          -7.966026   \n",
       "9     {'max_depth': 4, 'n_estimators': 500}          -7.965983   \n",
       "10    {'max_depth': 4, 'n_estimators': 700}          -7.965951   \n",
       "11    {'max_depth': 4, 'n_estimators': 900}          -7.965918   \n",
       "12   {'max_depth': 4, 'n_estimators': 1000}          -7.965902   \n",
       "13   {'max_depth': 4, 'n_estimators': 3000}          -7.965579   \n",
       "14    {'max_depth': 5, 'n_estimators': 100}          -7.816655   \n",
       "15    {'max_depth': 5, 'n_estimators': 300}          -7.816746   \n",
       "16    {'max_depth': 5, 'n_estimators': 500}          -7.816821   \n",
       "17    {'max_depth': 5, 'n_estimators': 700}          -7.816882   \n",
       "18    {'max_depth': 5, 'n_estimators': 900}          -7.816916   \n",
       "19   {'max_depth': 5, 'n_estimators': 1000}          -7.816933   \n",
       "20   {'max_depth': 5, 'n_estimators': 3000}          -7.817275   \n",
       "21    {'max_depth': 6, 'n_estimators': 100}          -7.973048   \n",
       "22    {'max_depth': 6, 'n_estimators': 300}          -7.972973   \n",
       "23    {'max_depth': 6, 'n_estimators': 500}          -7.972941   \n",
       "24    {'max_depth': 6, 'n_estimators': 700}          -7.972909   \n",
       "25    {'max_depth': 6, 'n_estimators': 900}          -7.972878   \n",
       "26   {'max_depth': 6, 'n_estimators': 1000}          -7.972862   \n",
       "27   {'max_depth': 6, 'n_estimators': 3000}          -7.972546   \n",
       "28    {'max_depth': 7, 'n_estimators': 100}          -8.607065   \n",
       "29    {'max_depth': 7, 'n_estimators': 300}          -8.606983   \n",
       "30    {'max_depth': 7, 'n_estimators': 500}          -8.606942   \n",
       "31    {'max_depth': 7, 'n_estimators': 700}          -8.606912   \n",
       "32    {'max_depth': 7, 'n_estimators': 900}          -8.606881   \n",
       "33   {'max_depth': 7, 'n_estimators': 1000}          -8.606866   \n",
       "34   {'max_depth': 7, 'n_estimators': 3000}          -8.606565   \n",
       "35    {'max_depth': 8, 'n_estimators': 100}          -8.034338   \n",
       "36    {'max_depth': 8, 'n_estimators': 300}          -8.034263   \n",
       "37    {'max_depth': 8, 'n_estimators': 500}          -8.034222   \n",
       "38    {'max_depth': 8, 'n_estimators': 700}          -8.034188   \n",
       "39    {'max_depth': 8, 'n_estimators': 900}          -8.034154   \n",
       "40   {'max_depth': 8, 'n_estimators': 1000}          -8.034137   \n",
       "41   {'max_depth': 8, 'n_estimators': 3000}          -8.033796   \n",
       "42    {'max_depth': 9, 'n_estimators': 100}          -8.384569   \n",
       "43    {'max_depth': 9, 'n_estimators': 300}          -8.384656   \n",
       "44    {'max_depth': 9, 'n_estimators': 500}          -8.384720   \n",
       "45    {'max_depth': 9, 'n_estimators': 700}          -8.384752   \n",
       "46    {'max_depth': 9, 'n_estimators': 900}          -8.384783   \n",
       "47   {'max_depth': 9, 'n_estimators': 1000}          -8.384799   \n",
       "48   {'max_depth': 9, 'n_estimators': 3000}          -8.385114   \n",
       "49   {'max_depth': 10, 'n_estimators': 100}          -8.785261   \n",
       "50   {'max_depth': 10, 'n_estimators': 300}          -8.785343   \n",
       "51   {'max_depth': 10, 'n_estimators': 500}          -8.785401   \n",
       "52   {'max_depth': 10, 'n_estimators': 700}          -8.785432   \n",
       "53   {'max_depth': 10, 'n_estimators': 900}          -8.785463   \n",
       "54  {'max_depth': 10, 'n_estimators': 1000}          -8.785479   \n",
       "55  {'max_depth': 10, 'n_estimators': 3000}          -8.785789   \n",
       "\n",
       "    split1_test_score  split2_test_score  ...  mean_test_score  \\\n",
       "0           -6.192932         -10.947039  ...        -6.558108   \n",
       "1           -6.256571         -10.831378  ...        -6.549893   \n",
       "2           -6.256521         -10.830824  ...        -6.549845   \n",
       "3           -6.256492         -10.830795  ...        -6.549837   \n",
       "4           -6.256476         -10.830775  ...        -6.549834   \n",
       "5           -6.256468         -10.830766  ...        -6.549833   \n",
       "6           -6.256312         -10.830569  ...        -6.549811   \n",
       "7           -6.254964         -10.632250  ...        -6.778814   \n",
       "8           -6.253286         -10.632172  ...        -6.777028   \n",
       "9           -6.253238         -10.632206  ...        -6.777029   \n",
       "10          -6.253208         -10.632234  ...        -6.777028   \n",
       "11          -6.253187         -10.632262  ...        -6.777028   \n",
       "12          -6.253176         -10.632276  ...        -6.777028   \n",
       "13          -6.252962         -10.632556  ...        -6.777031   \n",
       "14          -6.525084         -10.761075  ...        -6.886288   \n",
       "15          -6.525164         -10.761109  ...        -6.886308   \n",
       "16          -6.525195         -10.761129  ...        -6.886325   \n",
       "17          -6.525215         -10.761149  ...        -6.886340   \n",
       "18          -6.525235         -10.761169  ...        -6.886349   \n",
       "19          -6.525245         -10.761179  ...        -6.886353   \n",
       "20          -6.525447         -10.761377  ...        -6.886444   \n",
       "21          -6.357610         -11.246278  ...        -7.114948   \n",
       "22          -6.357543         -11.246324  ...        -7.114908   \n",
       "23          -6.357509         -11.246345  ...        -7.114891   \n",
       "24          -6.357486         -11.246364  ...        -7.114877   \n",
       "25          -6.357463         -11.246384  ...        -7.114864   \n",
       "26          -6.357451         -11.246394  ...        -7.114857   \n",
       "27          -6.357222         -11.246588  ...        -7.114721   \n",
       "28          -6.396606         -12.478342  ...        -7.416383   \n",
       "29          -6.396541         -12.478381  ...        -7.416391   \n",
       "30          -6.396510         -12.478408  ...        -7.416399   \n",
       "31          -6.396490         -12.478424  ...        -7.416404   \n",
       "32          -6.396470         -12.478439  ...        -7.416410   \n",
       "33          -6.396460         -12.478447  ...        -7.416413   \n",
       "34          -6.396263         -12.478606  ...        -7.416472   \n",
       "35          -6.396257         -10.990024  ...        -7.117779   \n",
       "36          -6.396188         -10.990077  ...        -7.117787   \n",
       "37          -6.396165         -10.990096  ...        -7.117790   \n",
       "38          -6.396143         -10.990114  ...        -7.117794   \n",
       "39          -6.396120         -10.990132  ...        -7.117799   \n",
       "40          -6.396108         -10.990141  ...        -7.117801   \n",
       "41          -6.395879         -10.990321  ...        -7.117842   \n",
       "42          -6.075902         -10.485391  ...        -6.871226   \n",
       "43          -6.075840         -10.485356  ...        -6.871256   \n",
       "44          -6.075809         -10.485335  ...        -6.871283   \n",
       "45          -6.075786         -10.485315  ...        -6.871292   \n",
       "46          -6.075762         -10.485295  ...        -6.871302   \n",
       "47          -6.075750         -10.485285  ...        -6.871307   \n",
       "48          -6.075512         -10.485086  ...        -6.871404   \n",
       "49          -5.625660         -10.357448  ...        -7.046729   \n",
       "50          -5.625723         -10.357400  ...        -7.046770   \n",
       "51          -5.625746         -10.357365  ...        -7.046793   \n",
       "52          -5.625770         -10.357347  ...        -7.046807   \n",
       "53          -5.625793         -10.357329  ...        -7.046820   \n",
       "54          -5.625805         -10.357320  ...        -7.046827   \n",
       "55          -5.626041         -10.357139  ...        -7.046962   \n",
       "\n",
       "    std_test_score  rank_test_score  split0_train_score  split1_train_score  \\\n",
       "0         3.488396                7            0.993411            0.995546   \n",
       "1         3.471471                6            0.999893            0.999950   \n",
       "2         3.471363                5            0.999893            0.999950   \n",
       "3         3.471355                4            0.999893            0.999950   \n",
       "4         3.471349                3            0.999893            0.999950   \n",
       "5         3.471345                2            0.999893            0.999950   \n",
       "6         3.471283                1            0.999893            0.999950   \n",
       "7         3.499364               14            0.999606            0.999828   \n",
       "8         3.499038               10            0.999897            0.999951   \n",
       "9         3.499057               12            0.999897            0.999951   \n",
       "10        3.499071                8            0.999897            0.999951   \n",
       "11        3.499085                9            0.999897            0.999951   \n",
       "12        3.499091               11            0.999897            0.999951   \n",
       "13        3.499227               13            0.999897            0.999951   \n",
       "14        3.492615               22            0.999900            0.999952   \n",
       "15        3.492605               23            0.999900            0.999952   \n",
       "16        3.492602               24            0.999900            0.999952   \n",
       "17        3.492600               25            0.999900            0.999952   \n",
       "18        3.492596               26            0.999900            0.999952   \n",
       "19        3.492594               27            0.999900            0.999952   \n",
       "20        3.492555               28            0.999900            0.999952   \n",
       "21        3.733327               42            0.999900            0.999953   \n",
       "22        3.733316               41            0.999900            0.999953   \n",
       "23        3.733308               40            0.999900            0.999953   \n",
       "24        3.733300               39            0.999900            0.999953   \n",
       "25        3.733293               38            0.999900            0.999953   \n",
       "26        3.733289               37            0.999900            0.999953   \n",
       "27        3.733215               36            0.999900            0.999953   \n",
       "28        3.943689               50            0.999901            0.999954   \n",
       "29        3.943701               51            0.999901            0.999954   \n",
       "30        3.943708               52            0.999901            0.999954   \n",
       "31        3.943710               53            0.999901            0.999954   \n",
       "32        3.943712               54            0.999901            0.999954   \n",
       "33        3.943713               55            0.999901            0.999954   \n",
       "34        3.943735               56            0.999901            0.999954   \n",
       "35        3.640090               43            0.999902            0.999955   \n",
       "36        3.640110               44            0.999902            0.999955   \n",
       "37        3.640114               45            0.999902            0.999955   \n",
       "38        3.640119               46            0.999902            0.999955   \n",
       "39        3.640123               47            0.999902            0.999955   \n",
       "40        3.640125               48            0.999902            0.999955   \n",
       "41        3.640170               49            0.999902            0.999955   \n",
       "42        3.449965               15            0.999904            0.999955   \n",
       "43        3.449977               16            0.999904            0.999955   \n",
       "44        3.449986               17            0.999904            0.999955   \n",
       "45        3.449986               18            0.999904            0.999955   \n",
       "46        3.449986               19            0.999904            0.999955   \n",
       "47        3.449985               20            0.999904            0.999955   \n",
       "48        3.449982               21            0.999904            0.999955   \n",
       "49        3.593277               29            0.999904            0.999955   \n",
       "50        3.593295               30            0.999904            0.999955   \n",
       "51        3.593311               31            0.999904            0.999955   \n",
       "52        3.593321               32            0.999904            0.999955   \n",
       "53        3.593331               33            0.999904            0.999955   \n",
       "54        3.593337               34            0.999904            0.999955   \n",
       "55        3.593440               35            0.999904            0.999955   \n",
       "\n",
       "    split2_train_score  split3_train_score  split4_train_score  \\\n",
       "0             0.994963            0.994215            0.993169   \n",
       "1             0.999982            0.999943            0.999934   \n",
       "2             0.999984            0.999943            0.999934   \n",
       "3             0.999984            0.999943            0.999934   \n",
       "4             0.999984            0.999943            0.999934   \n",
       "5             0.999984            0.999943            0.999934   \n",
       "6             0.999984            0.999943            0.999934   \n",
       "7             0.999835            0.999778            0.999779   \n",
       "8             0.999984            0.999945            0.999936   \n",
       "9             0.999984            0.999945            0.999936   \n",
       "10            0.999984            0.999945            0.999937   \n",
       "11            0.999984            0.999945            0.999937   \n",
       "12            0.999984            0.999945            0.999937   \n",
       "13            0.999984            0.999945            0.999937   \n",
       "14            0.999986            0.999946            0.999937   \n",
       "15            0.999986            0.999946            0.999937   \n",
       "16            0.999986            0.999946            0.999937   \n",
       "17            0.999986            0.999946            0.999937   \n",
       "18            0.999986            0.999946            0.999937   \n",
       "19            0.999986            0.999946            0.999937   \n",
       "20            0.999986            0.999946            0.999937   \n",
       "21            0.999987            0.999947            0.999938   \n",
       "22            0.999987            0.999947            0.999938   \n",
       "23            0.999987            0.999947            0.999938   \n",
       "24            0.999987            0.999947            0.999938   \n",
       "25            0.999987            0.999947            0.999938   \n",
       "26            0.999987            0.999947            0.999938   \n",
       "27            0.999987            0.999947            0.999938   \n",
       "28            0.999987            0.999948            0.999939   \n",
       "29            0.999987            0.999948            0.999939   \n",
       "30            0.999987            0.999948            0.999939   \n",
       "31            0.999987            0.999948            0.999939   \n",
       "32            0.999987            0.999948            0.999939   \n",
       "33            0.999987            0.999948            0.999939   \n",
       "34            0.999987            0.999948            0.999939   \n",
       "35            0.999988            0.999948            0.999939   \n",
       "36            0.999988            0.999948            0.999939   \n",
       "37            0.999988            0.999948            0.999939   \n",
       "38            0.999988            0.999948            0.999939   \n",
       "39            0.999988            0.999948            0.999939   \n",
       "40            0.999988            0.999948            0.999939   \n",
       "41            0.999988            0.999948            0.999939   \n",
       "42            0.999988            0.999949            0.999941   \n",
       "43            0.999988            0.999949            0.999941   \n",
       "44            0.999988            0.999949            0.999941   \n",
       "45            0.999988            0.999949            0.999941   \n",
       "46            0.999988            0.999949            0.999941   \n",
       "47            0.999988            0.999949            0.999941   \n",
       "48            0.999988            0.999949            0.999941   \n",
       "49            0.999989            0.999949            0.999942   \n",
       "50            0.999989            0.999949            0.999942   \n",
       "51            0.999989            0.999949            0.999942   \n",
       "52            0.999989            0.999949            0.999942   \n",
       "53            0.999989            0.999949            0.999942   \n",
       "54            0.999989            0.999949            0.999942   \n",
       "55            0.999989            0.999949            0.999942   \n",
       "\n",
       "    mean_train_score  std_train_score  \n",
       "0           0.994261         0.000901  \n",
       "1           0.999941         0.000029  \n",
       "2           0.999941         0.000029  \n",
       "3           0.999941         0.000029  \n",
       "4           0.999941         0.000029  \n",
       "5           0.999941         0.000029  \n",
       "6           0.999941         0.000029  \n",
       "7           0.999765         0.000083  \n",
       "8           0.999943         0.000028  \n",
       "9           0.999943         0.000028  \n",
       "10          0.999943         0.000028  \n",
       "11          0.999943         0.000028  \n",
       "12          0.999943         0.000028  \n",
       "13          0.999943         0.000028  \n",
       "14          0.999944         0.000028  \n",
       "15          0.999944         0.000028  \n",
       "16          0.999944         0.000028  \n",
       "17          0.999944         0.000028  \n",
       "18          0.999944         0.000028  \n",
       "19          0.999944         0.000028  \n",
       "20          0.999944         0.000028  \n",
       "21          0.999945         0.000028  \n",
       "22          0.999945         0.000028  \n",
       "23          0.999945         0.000028  \n",
       "24          0.999945         0.000028  \n",
       "25          0.999945         0.000028  \n",
       "26          0.999945         0.000028  \n",
       "27          0.999945         0.000028  \n",
       "28          0.999946         0.000028  \n",
       "29          0.999946         0.000028  \n",
       "30          0.999946         0.000028  \n",
       "31          0.999946         0.000028  \n",
       "32          0.999946         0.000028  \n",
       "33          0.999946         0.000028  \n",
       "34          0.999946         0.000028  \n",
       "35          0.999947         0.000028  \n",
       "36          0.999947         0.000028  \n",
       "37          0.999947         0.000028  \n",
       "38          0.999947         0.000028  \n",
       "39          0.999947         0.000028  \n",
       "40          0.999947         0.000028  \n",
       "41          0.999947         0.000028  \n",
       "42          0.999947         0.000027  \n",
       "43          0.999947         0.000027  \n",
       "44          0.999947         0.000027  \n",
       "45          0.999947         0.000027  \n",
       "46          0.999947         0.000027  \n",
       "47          0.999947         0.000027  \n",
       "48          0.999947         0.000027  \n",
       "49          0.999948         0.000027  \n",
       "50          0.999948         0.000027  \n",
       "51          0.999948         0.000027  \n",
       "52          0.999948         0.000027  \n",
       "53          0.999948         0.000027  \n",
       "54          0.999948         0.000027  \n",
       "55          0.999948         0.000027  \n",
       "\n",
       "[56 rows x 22 columns]"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(grid_search.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 3, 'n_estimators': 3000}"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "             colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "             importance_type='gain', interaction_constraints='',\n",
       "             learning_rate=0.300000012, max_delta_step=0, max_depth=3,\n",
       "             min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "             n_estimators=3000, n_jobs=0, num_parallel_tree=1,\n",
       "             objective='reg:squarederror', random_state=0, reg_alpha=0,\n",
       "             reg_lambda=1, scale_pos_weight=1, seed=0, subsample=1,\n",
       "             tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ml_model_best = grid_search.best_estimator_\n",
    "\n",
    "ml_model_best.fit(x_train, score_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import learning_curve\n",
    "def plot_learningcurve(classifier, X, y, plt_titile):\n",
    "    # check whether there is overfitting or underfitting by learning_curve\n",
    "    # choose five kinds of fraction of the maximum size of the training set: np.linspace(0.1,1.0,5)\n",
    "    train_size, train_score, test_score = learning_curve(classifier, X, y, cv=5, train_sizes=np.linspace(0.1,1.0,5))\n",
    "    train_scores_mean = np.mean(train_score, axis=1)\n",
    "    train_scores_std = np.std(train_score, axis=1)\n",
    "    test_scores_mean = np.mean(test_score, axis=1)\n",
    "    test_scores_std = np.std(test_score, axis=1)\n",
    "    plt.fill_between(train_size, train_scores_mean - train_scores_std, train_scores_mean + train_scores_std, alpha=0.1, color=\"r\")\n",
    "    plt.fill_between(train_size, test_scores_mean - test_scores_std, test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n",
    "    plt.plot(train_size, train_scores_mean,'o--', color=\"r\",label=\"Training score\")\n",
    "    plt.plot(train_size, test_scores_mean,'o-', color=\"g\",label=\"Testing score\")\n",
    "    plt.grid()\n",
    "    plt.title(plt_titile)\n",
    "    plt.legend(loc=\"best\")\n",
    "    return plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_learningcurve(grid_search.best_estimator_, x_train, score_train, 'Learning Curve (XGBoost)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.55461669, 0.54493187, 0.41524068, 0.40655476])"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = ml_model_best.predict(x_test)\n",
    "\n",
    "score1 = evaluate_lists(y_pred, test_intensities)\n",
    "score1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgboost_path = \"files/final_models/\" + \"xgboost_\"+ emotion + \".dat\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(xgboost_path, 'wb') as xgboost_file:\n",
    "    pickle.dump(grid_search.best_estimator_, xgboost_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = pickle.load(open(xgboost_path,'rb'))\n",
    "#model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2) Feedfoward Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "class LinearModel(torch.nn.Module):\n",
    "    def __init__(self,n_feature,n_hidden,n_output):\n",
    "        super(LinearModel,self).__init__() \n",
    "        self.hidden = torch.nn.Linear(n_feature,n_hidden)\n",
    "        self.hidden.weight = torch.nn.init.xavier_normal(self.hidden.weight)\n",
    "        self.dropout = torch.nn.Dropout(p=0.25)\n",
    "        self.predict = torch.nn.Linear(n_hidden,n_output)\n",
    "    def forward(self,x):\n",
    "        out=F.relu(self.hidden(x))\n",
    "        out=self.dropout(out)\n",
    "        out=F.sigmoid(self.predict(out))\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0756, -0.0836, -0.0385,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0514,  0.0338, -0.0090,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.1991,  0.0680, -0.0421,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        ...,\n",
      "        [ 0.0401,  0.0761,  0.0360,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.2155, -0.0807, -0.0340,  ...,  0.2165,  0.4331,  0.8661],\n",
      "        [ 0.1619,  0.3391, -0.0114,  ...,  0.0000,  0.0000,  0.0000]]) \n",
      " tensor([0.4380, 0.6460, 0.5830, 0.2500, 0.4790, 0.7710, 0.3330, 0.6250, 0.3750,\n",
      "        0.5420, 0.4790, 0.5530, 0.3750, 0.7500, 0.1880, 0.7080, 0.4790, 0.2950,\n",
      "        0.4380, 0.3330, 0.4580, 0.3750, 0.8400, 0.5000, 0.3540, 0.3540, 0.5620,\n",
      "        0.5000, 0.6040, 0.8750, 0.5620, 0.4380, 0.6670, 0.4170, 0.4170, 0.3750,\n",
      "        0.4170, 0.4380, 0.2710, 0.7500, 0.4680, 0.6250, 0.2500, 0.6250, 0.6040,\n",
      "        0.4380, 0.4140, 0.5420, 0.3120, 0.3960, 0.7500, 0.4790, 0.4580, 0.5000,\n",
      "        0.1880, 0.4790, 0.3330, 0.5000, 0.4790, 0.4580, 0.8750, 0.6460, 0.2710,\n",
      "        0.3220, 0.8310, 0.8540, 0.5620, 0.7290, 0.6460, 0.3960, 0.8640, 0.3750,\n",
      "        0.4790, 0.4170, 0.7080, 0.5830, 0.3960, 0.6880, 0.3330, 0.5380, 0.6880,\n",
      "        0.2310, 0.4790, 0.7290, 0.7500, 0.3330, 0.6040, 0.3750, 0.5000, 0.5000,\n",
      "        0.6250, 0.8540, 0.1460, 0.8630, 0.1670, 0.5620, 0.5620, 0.8750, 0.4580,\n",
      "        0.4790, 0.7080, 0.3540, 0.3330, 0.4380, 0.5620, 0.4170, 0.8330, 0.4790,\n",
      "        0.3750, 0.6880, 0.6880, 0.1670, 0.5420, 0.4220, 0.4250, 0.5000, 0.4440,\n",
      "        0.2920, 0.4170, 0.3750, 0.3540, 0.1880, 0.6880, 0.8120, 0.3960, 0.5420,\n",
      "        0.4170, 0.4170])\n"
     ]
    }
   ],
   "source": [
    "import torch.utils.data as Data\n",
    "batch_size = 128\n",
    "dataset = Data.TensorDataset(torch.tensor(x_train.astype(np.float32)), torch.tensor(score_train.astype(np.float32)))\n",
    "data_iter = Data.DataLoader(dataset = dataset,batch_size = batch_size, shuffle = True, num_workers = 2)\n",
    "\n",
    "for X,y in data_iter:\n",
    "    print(X, '\\n', y)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearModel(\n",
      "  (hidden): Linear(in_features=943, out_features=10000, bias=True)\n",
      "  (dropout): Dropout(p=0.25, inplace=False)\n",
      "  (predict): Linear(in_features=10000, out_features=1, bias=True)\n",
      ")\n",
      "<generator object Module.parameters at 0x0000018581693A40>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dell\\Anaconda3\\envs\\tf2\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: nn.init.xavier_normal is now deprecated in favor of nn.init.xavier_normal_.\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "# architecure: 1→10000→1\n",
    "net = LinearModel(x_train.shape[1],10000,1)\n",
    "print(net)\n",
    "print(net.parameters())    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Parameter containing:\n",
      "tensor([[ 0.0076, -0.0204,  0.0135,  ...,  0.0281,  0.0192, -0.0024],\n",
      "        [ 0.0111, -0.0064,  0.0138,  ..., -0.0060,  0.0154,  0.0121],\n",
      "        [-0.0038,  0.0079,  0.0155,  ...,  0.0191, -0.0143, -0.0017],\n",
      "        ...,\n",
      "        [ 0.0218,  0.0165,  0.0221,  ...,  0.0161, -0.0286,  0.0119],\n",
      "        [-0.0032, -0.0171, -0.0022,  ..., -0.0078,  0.0190, -0.0187],\n",
      "        [ 0.0218, -0.0126, -0.0032,  ...,  0.0061,  0.0074,  0.0027]],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([ 0.0270, -0.0245, -0.0111,  ...,  0.0282,  0.0122, -0.0234],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([[-0.0004, -0.0008, -0.0052,  ..., -0.0054,  0.0071,  0.0078]],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([-7.5975e-05], requires_grad=True)]\n"
     ]
    }
   ],
   "source": [
    "para = list(net.parameters())\n",
    "print(para)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    lr: 0.001\n",
      "    weight_decay: 0\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(net.parameters())\n",
    "print(optimizer)\n",
    "\n",
    "loss_func = torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_test = Data.TensorDataset(torch.tensor(x_test.astype(np.float32)), torch.tensor(test_intensities.astype(np.float32)))\n",
    "data_iter_test = Data.DataLoader(dataset = dataset_test,batch_size = batch_size, num_workers = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dell\\Anaconda3\\envs\\tf2\\lib\\site-packages\\torch\\nn\\functional.py:1351: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch10,train_loss0.005195647943764925\n",
      "epoch10,test_loss0.014882498420774937\n",
      "epoch20,train_loss0.001754283206537366\n",
      "epoch20,test_loss0.014777092263102531\n",
      "epoch30,train_loss0.0027791340835392475\n",
      "epoch30,test_loss0.015882274135947227\n",
      "epoch40,train_loss0.0016866286750882864\n",
      "epoch40,test_loss0.015930119901895523\n",
      "epoch50,train_loss0.000772111932747066\n",
      "epoch50,test_loss0.015104605816304684\n",
      "epoch60,train_loss0.0007879032636992633\n",
      "epoch60,test_loss0.01459458190947771\n",
      "epoch70,train_loss0.0008189725922420621\n",
      "epoch70,test_loss0.015058445744216442\n",
      "epoch80,train_loss0.0014398365747183561\n",
      "epoch80,test_loss0.014773046597838402\n",
      "epoch90,train_loss0.0005511101917363703\n",
      "epoch90,test_loss0.014524186961352825\n",
      "epoch100,train_loss0.0006121308542788029\n",
      "epoch100,test_loss0.014798984862864017\n",
      "epoch110,train_loss0.0005509922630153596\n",
      "epoch110,test_loss0.014379068277776241\n",
      "epoch120,train_loss0.00044124547275714576\n",
      "epoch120,test_loss0.014316979795694351\n",
      "epoch130,train_loss0.0007609485764987767\n",
      "epoch130,test_loss0.014333788305521011\n",
      "epoch140,train_loss0.00030958311981521547\n",
      "epoch140,test_loss0.013979495503008366\n",
      "epoch150,train_loss0.0005357750924304128\n",
      "epoch150,test_loss0.013640742748975754\n",
      "epoch160,train_loss0.0004652057250496\n",
      "epoch160,test_loss0.014192930422723293\n",
      "epoch170,train_loss0.00025874533457681537\n",
      "epoch170,test_loss0.014559469185769558\n",
      "epoch180,train_loss0.00037023151526227593\n",
      "epoch180,test_loss0.0139004522934556\n",
      "epoch190,train_loss0.0006116255535744131\n",
      "epoch190,test_loss0.014130774885416031\n",
      "epoch200,train_loss0.00017058390949387103\n",
      "epoch200,test_loss0.013844878412783146\n",
      "epoch210,train_loss0.00034930490073747933\n",
      "epoch210,test_loss0.01398443803191185\n",
      "epoch220,train_loss0.000303169566905126\n",
      "epoch220,test_loss0.013513037003576756\n",
      "epoch230,train_loss0.00026342348428443074\n",
      "epoch230,test_loss0.014236089773476124\n",
      "epoch240,train_loss0.00046593352453783154\n",
      "epoch240,test_loss0.013880033046007156\n",
      "epoch250,train_loss0.00040329754119738936\n",
      "epoch250,test_loss0.013685476034879684\n",
      "epoch260,train_loss0.0002832822792697698\n",
      "epoch260,test_loss0.013676718808710575\n",
      "epoch270,train_loss0.00020940871036145836\n",
      "epoch270,test_loss0.013793246820569038\n",
      "epoch280,train_loss0.0002511860220693052\n",
      "epoch280,test_loss0.013680716045200825\n",
      "epoch290,train_loss0.00013820060121361166\n",
      "epoch290,test_loss0.013867323286831379\n",
      "epoch300,train_loss0.0005200722953304648\n",
      "epoch300,test_loss0.013704733923077583\n",
      "epoch310,train_loss0.0011158385314047337\n",
      "epoch310,test_loss0.013417818583548069\n",
      "epoch320,train_loss0.00032865320099517703\n",
      "epoch320,test_loss0.013860362581908703\n",
      "epoch330,train_loss0.00012202929065097123\n",
      "epoch330,test_loss0.013940592296421528\n",
      "epoch340,train_loss0.00025289677432738245\n",
      "epoch340,test_loss0.013859101571142673\n",
      "epoch350,train_loss0.00023205054458230734\n",
      "epoch350,test_loss0.013635794632136822\n",
      "epoch360,train_loss0.0004781631869263947\n",
      "epoch360,test_loss0.014003629796206951\n",
      "epoch370,train_loss0.00023108739696908742\n",
      "epoch370,test_loss0.013622271828353405\n",
      "epoch380,train_loss0.0002021368418354541\n",
      "epoch380,test_loss0.013847938738763332\n",
      "epoch390,train_loss0.000363517930964008\n",
      "epoch390,test_loss0.013539956882596016\n",
      "epoch400,train_loss0.0003508611989673227\n",
      "epoch400,test_loss0.01375073567032814\n",
      "epoch410,train_loss0.00025735903182066977\n",
      "epoch410,test_loss0.013575475662946701\n",
      "epoch420,train_loss0.0003344840952195227\n",
      "epoch420,test_loss0.01383970957249403\n",
      "epoch430,train_loss0.00012100768071832135\n",
      "epoch430,test_loss0.013878016732633114\n",
      "epoch440,train_loss0.0001848245010478422\n",
      "epoch440,test_loss0.014072241261601448\n",
      "epoch450,train_loss0.00014904611452948302\n",
      "epoch450,test_loss0.013669847510755062\n",
      "epoch460,train_loss0.0002752887667156756\n",
      "epoch460,test_loss0.013791801407933235\n",
      "epoch470,train_loss0.00022675567015539855\n",
      "epoch470,test_loss0.013836783356964588\n",
      "epoch480,train_loss0.000164498807862401\n",
      "epoch480,test_loss0.013819333165884018\n",
      "epoch490,train_loss0.0004002268542535603\n",
      "epoch490,test_loss0.013724763877689838\n",
      "epoch500,train_loss0.00017555267550051212\n",
      "epoch500,test_loss0.013579667545855045\n",
      "epoch510,train_loss0.00013021442282479256\n",
      "epoch510,test_loss0.013384946621954441\n",
      "epoch520,train_loss0.000173856460605748\n",
      "epoch520,test_loss0.013891786336898804\n",
      "epoch530,train_loss0.0003641153743956238\n",
      "epoch530,test_loss0.013880862854421139\n",
      "epoch540,train_loss0.00024604270583949983\n",
      "epoch540,test_loss0.014095867983996868\n",
      "epoch550,train_loss0.00024153081176336855\n",
      "epoch550,test_loss0.014013859443366528\n",
      "epoch560,train_loss0.00028069643303751945\n",
      "epoch560,test_loss0.01418797392398119\n",
      "epoch570,train_loss0.0006086558569222689\n",
      "epoch570,test_loss0.014019672758877277\n",
      "epoch580,train_loss0.00036510618519969285\n",
      "epoch580,test_loss0.013693003915250301\n",
      "epoch590,train_loss0.00024705842952243984\n",
      "epoch590,test_loss0.013871297240257263\n",
      "epoch600,train_loss0.0003024553298018873\n",
      "epoch600,test_loss0.013986770063638687\n",
      "epoch610,train_loss0.0003603860386647284\n",
      "epoch610,test_loss0.014193801209330559\n",
      "epoch620,train_loss0.0001806085929274559\n",
      "epoch620,test_loss0.014275426976382732\n",
      "epoch630,train_loss0.00032924945116974413\n",
      "epoch630,test_loss0.014105294831097126\n",
      "epoch640,train_loss0.00025118186022154987\n",
      "epoch640,test_loss0.013874085620045662\n",
      "epoch650,train_loss0.0001785037893569097\n",
      "epoch650,test_loss0.014028633013367653\n",
      "epoch660,train_loss0.0002729127591010183\n",
      "epoch660,test_loss0.013609720394015312\n",
      "epoch670,train_loss0.0001738255232339725\n",
      "epoch670,test_loss0.01411392167210579\n",
      "epoch680,train_loss0.0003467081405688077\n",
      "epoch680,test_loss0.01395657192915678\n",
      "epoch690,train_loss0.00015309812442865223\n",
      "epoch690,test_loss0.014034477062523365\n",
      "epoch700,train_loss0.00019515505118761212\n",
      "epoch700,test_loss0.01400893833488226\n",
      "epoch710,train_loss0.00013111122825648636\n",
      "epoch710,test_loss0.014368901960551739\n",
      "epoch720,train_loss0.00021448811457958072\n",
      "epoch720,test_loss0.01404615119099617\n",
      "epoch730,train_loss0.00010648850002326071\n",
      "epoch730,test_loss0.014063791371881962\n",
      "epoch740,train_loss0.00019266844901721925\n",
      "epoch740,test_loss0.014257288537919521\n",
      "epoch750,train_loss0.000229395242058672\n",
      "epoch750,test_loss0.014340910129249096\n",
      "epoch760,train_loss0.0002194366097683087\n",
      "epoch760,test_loss0.014393405988812447\n",
      "epoch770,train_loss0.00023226179473567754\n",
      "epoch770,test_loss0.014298043213784695\n",
      "epoch780,train_loss0.00017530229524709284\n",
      "epoch780,test_loss0.014335873536765575\n",
      "epoch790,train_loss0.0002755559398792684\n",
      "epoch790,test_loss0.01404882688075304\n",
      "epoch800,train_loss0.0002806380798574537\n",
      "epoch800,test_loss0.014754880219697952\n",
      "epoch810,train_loss0.00014419447688851506\n",
      "epoch810,test_loss0.01427711546421051\n",
      "epoch820,train_loss0.00028639225638471544\n",
      "epoch820,test_loss0.014523226767778397\n",
      "epoch830,train_loss0.00022342012380249798\n",
      "epoch830,test_loss0.014431597664952278\n",
      "epoch840,train_loss0.00024011412460822612\n",
      "epoch840,test_loss0.014968384057283401\n",
      "epoch850,train_loss0.0001890822168206796\n",
      "epoch850,test_loss0.01461793389171362\n",
      "epoch860,train_loss0.000266364892013371\n",
      "epoch860,test_loss0.015062486752867699\n",
      "epoch870,train_loss0.00021216532331891358\n",
      "epoch870,test_loss0.014351453632116318\n",
      "epoch880,train_loss0.00018992417608387768\n",
      "epoch880,test_loss0.014639818109571934\n",
      "epoch890,train_loss0.00011842072126455605\n",
      "epoch890,test_loss0.014691060408949852\n",
      "epoch900,train_loss0.00025373222888447344\n",
      "epoch900,test_loss0.014641259796917439\n",
      "epoch910,train_loss0.00014931325858924538\n",
      "epoch910,test_loss0.015038441866636276\n",
      "epoch920,train_loss0.0002531864447519183\n",
      "epoch920,test_loss0.014653269201517105\n",
      "epoch930,train_loss0.0003561183111742139\n",
      "epoch930,test_loss0.014635141007602215\n",
      "epoch940,train_loss0.0002840851666405797\n",
      "epoch940,test_loss0.014950437471270561\n",
      "epoch950,train_loss0.00020916314679197967\n",
      "epoch950,test_loss0.01461047027260065\n",
      "epoch960,train_loss0.00037357723340392113\n",
      "epoch960,test_loss0.014742732048034668\n",
      "epoch970,train_loss0.0001529129222035408\n",
      "epoch970,test_loss0.01460329256951809\n",
      "epoch980,train_loss0.0001818945602281019\n",
      "epoch980,test_loss0.01424381323158741\n",
      "epoch990,train_loss0.0001873575965873897\n",
      "epoch990,test_loss0.01507494319230318\n",
      "epoch1000,train_loss0.00020217445853631943\n",
      "epoch1000,test_loss0.014570930041372776\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "\n",
    "\n",
    "start_time_NN =time.time()\n",
    "\n",
    "train_losses = []\n",
    "\n",
    "test_losses = []\n",
    "\n",
    "num_epochs = 1000\n",
    "train_interval = 10\n",
    "test_interval = 10\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    net.train()\n",
    "    for X,y in data_iter:\n",
    "        prediction = net(X)\n",
    "        loss = loss_func(prediction,y.view(-1,1))\n",
    "    \n",
    "    # reset gradient, equal to net.zero_grad()\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward() \n",
    "        optimizer.step()\n",
    "        \n",
    "        \n",
    "\n",
    "    if((epoch+1)%train_interval==0):\n",
    "        print(\"epoch{},train_loss{}\".format(epoch+1,loss.data))\n",
    "        train_losses.append(loss.item())\n",
    "   \n",
    "\n",
    "      \n",
    "    net.eval()\n",
    "    with torch.no_grad():\n",
    "        \n",
    "        for X_test, y_test in data_iter_test:\n",
    "            \n",
    "            prediction1 = net(X_test)\n",
    "            loss1 = loss_func(prediction1, y_test.view(-1,1))\n",
    "            \n",
    "    if ((epoch+1) % test_interval == 0):       \n",
    "        print(\"epoch{},test_loss{}\".format(epoch+1,loss1.data))\n",
    "        #test_loss += float(loss1.item())\n",
    "        test_losses.append(loss1.item())\n",
    "        \n",
    "trainingtime.loc[1] = [\"Simple Neural Network\", round((time.time()-start_time_NN), 2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = range(len(train_losses))\n",
    "train_y = train_losses\n",
    "\n",
    "train_iters = len(data_iter)\n",
    "#test_x = np.arange(1, len(test_losses)+1) * train_iters*test_interval \n",
    "test_x = range(len(test_losses))\n",
    "test_y = test_losses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8,8))\n",
    "plt.plot(train_x, train_y, label='Train')\n",
    "plt.plot(test_x, test_y, label='Test')\n",
    "plt.legend(loc='lower right')\n",
    "plt.ylabel('loss value')\n",
    "plt.xlabel('Iteration')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(760,)"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_tensor = net(torch.tensor(x_test.astype(np.float32)))\n",
    "# len(y_pred)\n",
    "y_pred_array = y_pred_tensor.detach().numpy()\n",
    "y_pred_a = np.concatenate((y_pred_array), axis=None)\n",
    "y_pred_a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.62521337, 0.62674571, 0.39018269, 0.41500164])"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score2 = evaluate_lists(y_pred_a, test_intensities)\n",
    "score2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'files/final_models/simpleNN_anger.pkl.tar'"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_neural_network_path = \"files/final_models/\" + \"simpleNN_\"+ emotion + \".pkl.tar\"\n",
    "simple_neural_network_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.save(net, simple_neural_network_path) \n",
    "torch.save({'state_dict': net.state_dict()}, simple_neural_network_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Compare the Performance and Training Time Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Training Time(Seconds)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>1039.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Simple Neural Network</td>\n",
       "      <td>2554.42</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Model  Training Time(Seconds)\n",
       "0                XGBoost                 1039.67\n",
       "1  Simple Neural Network                 2554.42"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainingtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingtime.to_csv(\"training_time_\"+emotion+\".csv\",mode='w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pears-corr</th>\n",
       "      <th>spear-corr</th>\n",
       "      <th>pears-corr-range-05-1</th>\n",
       "      <th>spear-corr-range-05-1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>xgboost</th>\n",
       "      <td>0.554617</td>\n",
       "      <td>0.544932</td>\n",
       "      <td>0.415241</td>\n",
       "      <td>0.406555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>simpleNN</th>\n",
       "      <td>0.625213</td>\n",
       "      <td>0.626746</td>\n",
       "      <td>0.390183</td>\n",
       "      <td>0.415002</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          pears-corr  spear-corr  pears-corr-range-05-1  spear-corr-range-05-1\n",
       "xgboost     0.554617    0.544932               0.415241               0.406555\n",
       "simpleNN    0.625213    0.626746               0.390183               0.415002"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_score = pd.DataFrame(data = [score1,score2], columns = ['pears-corr','spear-corr','pears-corr-range-05-1','spear-corr-range-05-1'],\\\n",
    "             index = ['xgboost','simpleNN'])\n",
    "all_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_score.to_csv('score_'+emotion+'.csv',mode='w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
