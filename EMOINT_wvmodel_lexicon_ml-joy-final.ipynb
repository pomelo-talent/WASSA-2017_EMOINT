{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (1) Reading the Training, the Development and the Testing Datasets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from os import listdir\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['anger-ratings-0to1.train.txt',\n",
       " 'fear-ratings-0to1.train.txt',\n",
       " 'joy-ratings-0to1.train.txt',\n",
       " 'sadness-ratings-0to1.train.txt']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "directory1 = 'data/train'\n",
    "paths1 = listdir(directory1)\n",
    "paths1.sort()\n",
    "paths1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define the path of training dataset\n",
    "path1 = paths1[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'joy'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If you want to restore x_train vectors, y_train_vectors, x_test_vectors, y_test_vectors: you can change the 'emotion' here \n",
    "# and then restore those vectors\n",
    "\n",
    "emotion = path1.split(\"-\")[0]\n",
    "emotion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30000</td>\n",
       "      <td>Just got back from seeing @GaryDelaney in Burs...</td>\n",
       "      <td>joy</td>\n",
       "      <td>0.980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30001</td>\n",
       "      <td>Oh dear an evening of absolute hilarity I don'...</td>\n",
       "      <td>joy</td>\n",
       "      <td>0.958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30002</td>\n",
       "      <td>Been waiting all week for this game ‚ù§Ô∏è‚ù§Ô∏è‚ù§Ô∏è #ch...</td>\n",
       "      <td>joy</td>\n",
       "      <td>0.940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30003</td>\n",
       "      <td>@gardiner_love : Thank you so much, Gloria! Yo...</td>\n",
       "      <td>joy</td>\n",
       "      <td>0.938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30004</td>\n",
       "      <td>I feel so blessed to work with the family that...</td>\n",
       "      <td>joy</td>\n",
       "      <td>0.938</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0                                                  1    2      3\n",
       "0  30000  Just got back from seeing @GaryDelaney in Burs...  joy  0.980\n",
       "1  30001  Oh dear an evening of absolute hilarity I don'...  joy  0.958\n",
       "2  30002  Been waiting all week for this game ‚ù§Ô∏è‚ù§Ô∏è‚ù§Ô∏è #ch...  joy  0.940\n",
       "3  30003  @gardiner_love : Thank you so much, Gloria! Yo...  joy  0.938\n",
       "4  30004  I feel so blessed to work with the family that...  joy  0.938"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('%s/%s' %(directory1,path1), delimiter='\\t',header=None)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SentID</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Emotion</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30000</td>\n",
       "      <td>Just got back from seeing @GaryDelaney in Burs...</td>\n",
       "      <td>joy</td>\n",
       "      <td>0.980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30001</td>\n",
       "      <td>Oh dear an evening of absolute hilarity I don'...</td>\n",
       "      <td>joy</td>\n",
       "      <td>0.958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30002</td>\n",
       "      <td>Been waiting all week for this game ‚ù§Ô∏è‚ù§Ô∏è‚ù§Ô∏è #ch...</td>\n",
       "      <td>joy</td>\n",
       "      <td>0.940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30003</td>\n",
       "      <td>@gardiner_love : Thank you so much, Gloria! Yo...</td>\n",
       "      <td>joy</td>\n",
       "      <td>0.938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30004</td>\n",
       "      <td>I feel so blessed to work with the family that...</td>\n",
       "      <td>joy</td>\n",
       "      <td>0.938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>30005</td>\n",
       "      <td>Today I reached 1000 subscribers on YT!! , #go...</td>\n",
       "      <td>joy</td>\n",
       "      <td>0.926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>30006</td>\n",
       "      <td>@Singaholic121 Good morning, love! Happy first...</td>\n",
       "      <td>joy</td>\n",
       "      <td>0.924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>30007</td>\n",
       "      <td>#BridgetJonesBaby is the best thing I've seen ...</td>\n",
       "      <td>joy</td>\n",
       "      <td>0.922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>30008</td>\n",
       "      <td>Just got back from seeing @GaryDelaney in Burs...</td>\n",
       "      <td>joy</td>\n",
       "      <td>0.920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>30009</td>\n",
       "      <td>@IndyMN I thought the holidays could not get a...</td>\n",
       "      <td>joy</td>\n",
       "      <td>0.917</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SentID                                              Tweet Emotion  Rating\n",
       "0   30000  Just got back from seeing @GaryDelaney in Burs...     joy   0.980\n",
       "1   30001  Oh dear an evening of absolute hilarity I don'...     joy   0.958\n",
       "2   30002  Been waiting all week for this game ‚ù§Ô∏è‚ù§Ô∏è‚ù§Ô∏è #ch...     joy   0.940\n",
       "3   30003  @gardiner_love : Thank you so much, Gloria! Yo...     joy   0.938\n",
       "4   30004  I feel so blessed to work with the family that...     joy   0.938\n",
       "5   30005  Today I reached 1000 subscribers on YT!! , #go...     joy   0.926\n",
       "6   30006  @Singaholic121 Good morning, love! Happy first...     joy   0.924\n",
       "7   30007  #BridgetJonesBaby is the best thing I've seen ...     joy   0.922\n",
       "8   30008  Just got back from seeing @GaryDelaney in Burs...     joy   0.920\n",
       "9   30009  @IndyMN I thought the holidays could not get a...     joy   0.917"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns = ['SentID', 'Tweet', 'Emotion', 'Rating']\n",
    "train[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if there are any duplicates(subset = all of the columns)\n",
    "\n",
    "assert train.duplicated().sum() == 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 823 entries, 0 to 822\n",
      "Data columns (total 4 columns):\n",
      " #   Column   Non-Null Count  Dtype  \n",
      "---  ------   --------------  -----  \n",
      " 0   SentID   823 non-null    int64  \n",
      " 1   Tweet    823 non-null    object \n",
      " 2   Emotion  823 non-null    object \n",
      " 3   Rating   823 non-null    float64\n",
      "dtypes: float64(1), int64(1), object(2)\n",
      "memory usage: 25.8+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# checking missing data & len(train),len(test)\n",
    "print(train.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            SentID      Rating\n",
      "count    823.00000  823.000000\n",
      "mean   30411.00000    0.492618\n",
      "std      237.72393    0.204334\n",
      "min    30000.00000    0.019000\n",
      "25%    30205.50000    0.340000\n",
      "50%    30411.00000    0.480000\n",
      "75%    30616.50000    0.646000\n",
      "max    30822.00000    0.980000\n"
     ]
    }
   ],
   "source": [
    "print(train.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['anger-ratings-0to1.dev.gold.txt',\n",
       " 'fear-ratings-0to1.dev.gold.txt',\n",
       " 'joy-ratings-0to1.dev.gold.txt',\n",
       " 'sadness-ratings-0to1.dev.gold.txt']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "directory2 = 'data/dev'\n",
    "paths2 = listdir(directory2)\n",
    "paths2.sort()\n",
    "paths2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define the path of training dataset\n",
    "path2 = emotion + \"-ratings-0to1.dev.gold.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SentID</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Emotion</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30823</td>\n",
       "      <td>@theclobra lol I thought maybe, couldn't decid...</td>\n",
       "      <td>joy</td>\n",
       "      <td>0.312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30824</td>\n",
       "      <td>Nawaz Sharif is getting more funnier than @kap...</td>\n",
       "      <td>joy</td>\n",
       "      <td>0.700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30825</td>\n",
       "      <td>Nawaz Sharif is getting more funnier than @kap...</td>\n",
       "      <td>joy</td>\n",
       "      <td>0.580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30826</td>\n",
       "      <td>@tomderivan73 üòÅ...I'll just people watch and e...</td>\n",
       "      <td>joy</td>\n",
       "      <td>0.438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30827</td>\n",
       "      <td>I love my family so much #lucky #grateful #sma...</td>\n",
       "      <td>joy</td>\n",
       "      <td>0.936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>30828</td>\n",
       "      <td>I love my family so much #lucky #grateful #sma...</td>\n",
       "      <td>joy</td>\n",
       "      <td>0.792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>30829</td>\n",
       "      <td>@Casper10666 I assure you there is no laughter...</td>\n",
       "      <td>joy</td>\n",
       "      <td>0.167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>30830</td>\n",
       "      <td>If any trump supporters and Hillary haters wan...</td>\n",
       "      <td>joy</td>\n",
       "      <td>0.100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>30831</td>\n",
       "      <td>Google caffeine-an sprightly lengthening into ...</td>\n",
       "      <td>joy</td>\n",
       "      <td>0.200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>30832</td>\n",
       "      <td>This tweet is dedicated to my back pain, which...</td>\n",
       "      <td>joy</td>\n",
       "      <td>0.229</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SentID                                              Tweet Emotion  Rating\n",
       "0   30823  @theclobra lol I thought maybe, couldn't decid...     joy   0.312\n",
       "1   30824  Nawaz Sharif is getting more funnier than @kap...     joy   0.700\n",
       "2   30825  Nawaz Sharif is getting more funnier than @kap...     joy   0.580\n",
       "3   30826  @tomderivan73 üòÅ...I'll just people watch and e...     joy   0.438\n",
       "4   30827  I love my family so much #lucky #grateful #sma...     joy   0.936\n",
       "5   30828  I love my family so much #lucky #grateful #sma...     joy   0.792\n",
       "6   30829  @Casper10666 I assure you there is no laughter...     joy   0.167\n",
       "7   30830  If any trump supporters and Hillary haters wan...     joy   0.100\n",
       "8   30831  Google caffeine-an sprightly lengthening into ...     joy   0.200\n",
       "9   30832  This tweet is dedicated to my back pain, which...     joy   0.229"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev = pd.read_csv('%s/%s' %(directory2,path2), delimiter='\\t',header=None)\n",
    "dev.columns = train.columns\n",
    "dev[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if there are any duplicates(subset = all of the columns)\n",
    "\n",
    "assert dev.duplicated().sum() == 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 79 entries, 0 to 78\n",
      "Data columns (total 4 columns):\n",
      " #   Column   Non-Null Count  Dtype  \n",
      "---  ------   --------------  -----  \n",
      " 0   SentID   79 non-null     int64  \n",
      " 1   Tweet    79 non-null     object \n",
      " 2   Emotion  79 non-null     object \n",
      " 3   Rating   79 non-null     float64\n",
      "dtypes: float64(1), int64(1), object(2)\n",
      "memory usage: 2.6+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# checking missing data & len(train),len(test)\n",
    "print(dev.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             SentID     Rating\n",
      "count     79.000000  79.000000\n",
      "mean   30862.000000   0.483392\n",
      "std       22.949219   0.219682\n",
      "min    30823.000000   0.038000\n",
      "25%    30842.500000   0.312000\n",
      "50%    30862.000000   0.479000\n",
      "75%    30881.500000   0.653000\n",
      "max    30901.000000   0.936000\n"
     ]
    }
   ],
   "source": [
    "print(dev.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['anger-ratings-0to1.test.gold.txt',\n",
       " 'fear-ratings-0to1.test.gold.txt',\n",
       " 'joy-ratings-0to1.test.gold.txt',\n",
       " 'sadness-ratings-0to1.test.gold.txt']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "directory3 = 'data/test'\n",
    "paths3 = listdir(directory3)\n",
    "paths3.sort()\n",
    "paths3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define the path of training dataset\n",
    "path3 = emotion + \"-ratings-0to1.test.gold.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SentID</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Emotion</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30902</td>\n",
       "      <td>You must be knowing #blithe means (adj.)  Happ...</td>\n",
       "      <td>joy</td>\n",
       "      <td>0.583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30903</td>\n",
       "      <td>Old saying 'A #smile shared is one gained for ...</td>\n",
       "      <td>joy</td>\n",
       "      <td>0.500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30904</td>\n",
       "      <td>Bridget Jones' Baby was bloody hilarious üòÖ #Br...</td>\n",
       "      <td>joy</td>\n",
       "      <td>0.860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30905</td>\n",
       "      <td>@Elaminova sparkling water makes your life spa...</td>\n",
       "      <td>joy</td>\n",
       "      <td>0.521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30906</td>\n",
       "      <td>I'm tired of everybody telling me to chill out...</td>\n",
       "      <td>joy</td>\n",
       "      <td>0.042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>30907</td>\n",
       "      <td>#GBBO can cheer me up ‚ò∫Ô∏è</td>\n",
       "      <td>joy</td>\n",
       "      <td>0.417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>30908</td>\n",
       "      <td>&amp;amp; as much as I hate for a dude to cheat, w...</td>\n",
       "      <td>joy</td>\n",
       "      <td>0.160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>30909</td>\n",
       "      <td>@GOT7Official @jrjyp happy birthday jin young!...</td>\n",
       "      <td>joy</td>\n",
       "      <td>0.750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>30910</td>\n",
       "      <td>@GOT7Official @jrjyp happy birthday jin young!...</td>\n",
       "      <td>joy</td>\n",
       "      <td>0.688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>30911</td>\n",
       "      <td>The race advances only by the extra achievemen...</td>\n",
       "      <td>joy</td>\n",
       "      <td>0.340</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SentID                                              Tweet Emotion  Rating\n",
       "0   30902  You must be knowing #blithe means (adj.)  Happ...     joy   0.583\n",
       "1   30903  Old saying 'A #smile shared is one gained for ...     joy   0.500\n",
       "2   30904  Bridget Jones' Baby was bloody hilarious üòÖ #Br...     joy   0.860\n",
       "3   30905  @Elaminova sparkling water makes your life spa...     joy   0.521\n",
       "4   30906  I'm tired of everybody telling me to chill out...     joy   0.042\n",
       "5   30907                           #GBBO can cheer me up ‚ò∫Ô∏è     joy   0.417\n",
       "6   30908  &amp; as much as I hate for a dude to cheat, w...     joy   0.160\n",
       "7   30909  @GOT7Official @jrjyp happy birthday jin young!...     joy   0.750\n",
       "8   30910  @GOT7Official @jrjyp happy birthday jin young!...     joy   0.688\n",
       "9   30911  The race advances only by the extra achievemen...     joy   0.340"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv('%s/%s' %(directory3,path3), delimiter='\\t',header=None)\n",
    "test.columns = train.columns\n",
    "\n",
    "test[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if there are any duplicates(subset = all of the columns)\n",
    "\n",
    "assert test.duplicated().sum() == 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 714 entries, 0 to 713\n",
      "Data columns (total 4 columns):\n",
      " #   Column   Non-Null Count  Dtype  \n",
      "---  ------   --------------  -----  \n",
      " 0   SentID   714 non-null    int64  \n",
      " 1   Tweet    714 non-null    object \n",
      " 2   Emotion  714 non-null    object \n",
      " 3   Rating   714 non-null    float64\n",
      "dtypes: float64(1), int64(1), object(2)\n",
      "memory usage: 22.4+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# checking missing data & len(train),len(test)\n",
    "print(test.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             SentID      Rating\n",
      "count    714.000000  714.000000\n",
      "mean   31258.500000    0.508958\n",
      "std      206.258333    0.217295\n",
      "min    30902.000000    0.000000\n",
      "25%    31080.250000    0.340000\n",
      "50%    31258.500000    0.500000\n",
      "75%    31436.750000    0.673000\n",
      "max    31615.000000    0.980000\n"
     ]
    }
   ],
   "source": [
    "print(test.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SentID</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Emotion</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30000</td>\n",
       "      <td>Just got back from seeing @GaryDelaney in Burs...</td>\n",
       "      <td>joy</td>\n",
       "      <td>0.980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30001</td>\n",
       "      <td>Oh dear an evening of absolute hilarity I don'...</td>\n",
       "      <td>joy</td>\n",
       "      <td>0.958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30002</td>\n",
       "      <td>Been waiting all week for this game ‚ù§Ô∏è‚ù§Ô∏è‚ù§Ô∏è #ch...</td>\n",
       "      <td>joy</td>\n",
       "      <td>0.940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30003</td>\n",
       "      <td>@gardiner_love : Thank you so much, Gloria! Yo...</td>\n",
       "      <td>joy</td>\n",
       "      <td>0.938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30004</td>\n",
       "      <td>I feel so blessed to work with the family that...</td>\n",
       "      <td>joy</td>\n",
       "      <td>0.938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>897</th>\n",
       "      <td>30897</td>\n",
       "      <td>It feels good to get outside for a minute and ...</td>\n",
       "      <td>joy</td>\n",
       "      <td>0.580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>898</th>\n",
       "      <td>30898</td>\n",
       "      <td>@r0Ils ppl get triggered over u smiling they'r...</td>\n",
       "      <td>joy</td>\n",
       "      <td>0.170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>899</th>\n",
       "      <td>30899</td>\n",
       "      <td>@GigaFag @pipertownsend_ snapchat new would be...</td>\n",
       "      <td>joy</td>\n",
       "      <td>0.396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>900</th>\n",
       "      <td>30900</td>\n",
       "      <td>@GigaFag @pipertownsend_ snapchat new would be...</td>\n",
       "      <td>joy</td>\n",
       "      <td>0.156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>901</th>\n",
       "      <td>30901</td>\n",
       "      <td>A hearty Jonza! to all my friends and follower.</td>\n",
       "      <td>joy</td>\n",
       "      <td>0.704</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>902 rows √ó 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     SentID                                              Tweet Emotion  Rating\n",
       "0     30000  Just got back from seeing @GaryDelaney in Burs...     joy   0.980\n",
       "1     30001  Oh dear an evening of absolute hilarity I don'...     joy   0.958\n",
       "2     30002  Been waiting all week for this game ‚ù§Ô∏è‚ù§Ô∏è‚ù§Ô∏è #ch...     joy   0.940\n",
       "3     30003  @gardiner_love : Thank you so much, Gloria! Yo...     joy   0.938\n",
       "4     30004  I feel so blessed to work with the family that...     joy   0.938\n",
       "..      ...                                                ...     ...     ...\n",
       "897   30897  It feels good to get outside for a minute and ...     joy   0.580\n",
       "898   30898  @r0Ils ppl get triggered over u smiling they'r...     joy   0.170\n",
       "899   30899  @GigaFag @pipertownsend_ snapchat new would be...     joy   0.396\n",
       "900   30900  @GigaFag @pipertownsend_ snapchat new would be...     joy   0.156\n",
       "901   30901    A hearty Jonza! to all my friends and follower.     joy   0.704\n",
       "\n",
       "[902 rows x 4 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# plan to train models on the combined training and development sets\n",
    "train = pd.concat([train, dev],axis=0,ignore_index=True)\n",
    "train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (2) Define Text Data Cleaning Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import re\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import bigrams\n",
    "\n",
    "import wordsegment as ws # $ pip install wordsegment    \n",
    "ws.load()     \n",
    "\n",
    "import emoji  # $ pip install emoji\n",
    "\n",
    "# As the glove model contains many words made with grammatical role, tense ,or derivational morphology,\n",
    "# we do not need WordNetLemmatizer or SnowballStemmer here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_text(text):\n",
    "    \n",
    "    # replace emoji to word\n",
    "    # text = emoji.demojize(text)\n",
    "    \n",
    "    # remove characters outside the ascii code 128\n",
    "    # text = ''.join([w if ord(w)<128 else ' ' for w in text])\n",
    "    \n",
    "    # replace '--' with a space\n",
    "    text = text.replace('--',' ')\n",
    "    \n",
    "    # remove any newline characters\n",
    "    text = text.replace('\\n',' ')\n",
    "    \n",
    "    # tweets mentions user using '@' followed by username. Replace all those with <user> to be usable for Glove\n",
    "    text = re.sub('@[^ ]+','<user>',text)\n",
    "    \n",
    "    # Replace all URLs with <url> to be usable for Glove\n",
    "    text = re.sub(r'\\d+','<number>',text)\n",
    "   \n",
    "    # Replace all numbers with <number> to be usable for Glove\n",
    "    text = re.sub(r'http\\S+','<url>',text)\n",
    "    \n",
    "    # turn some abbreviations into a whold word\n",
    "    text = re.sub(r\"\\'s\", \"\", text)\n",
    "    text = re.sub(r\"\\'m\", \" am\", text)\n",
    "    text = re.sub(r\"\\'ve\", \" have\", text)\n",
    "    text = re.sub(r\"can\\'t\", \"can not\", text)\n",
    "    text = re.sub(r\"won\\'t\", \"will not\", text)\n",
    "    text = re.sub(r\"n\\'t\", \" not\", text)\n",
    "    text = re.sub(r\"\\'re\", \" are\", text)\n",
    "    text = re.sub(r\"\\'d\", \" would\", text)\n",
    "    text = re.sub(r\"\\'ll\", \" will\", text)\n",
    "    text = re.sub(r\"fu\\*k\", \" fuck\", text)\n",
    "    text = re.sub(r\"f\\*c+\", \"fuck\", text)\n",
    "    text = text.replace(\"wtf\", \"what the fuck\")\n",
    "    \n",
    "    # prepare spaces between punctuation and words\n",
    "    text1 = text.split('...')\n",
    "    for i in range(len(text1)):\n",
    "        text1[i] = text1[i].replace('/',' / ').replace('\\\\',' \\ ').replace(',',' , ').replace('.',' . ').replace('?',' ? ').replace('!',' ! ').replace(\"'\",\" ' \").replace(':',' : ').replace(';',' ; ').replace('-',' - ').replace('(',' ( ').replace(')',' ) ').replace('[',' [ ').replace(']',' ] ').replace('&',' & ').replace('*',' * ').replace('{',' { ').replace('}',' } ').replace('-',' - ').replace('`',' ` ').replace('\"',' \" ').replace('>','> ').replace('<',' <')\n",
    "    text1 = ' '.join(text1)\n",
    "    \n",
    "    # split into tokens by white space\n",
    "    tokens = text1.split()\n",
    "    \n",
    "    return tokens\n",
    "\n",
    "def clean_text(text):\n",
    "   \n",
    "    tokens = normalize_text(text)\n",
    "    \n",
    "    new_tokens1 = []\n",
    "    for w in tokens:\n",
    "        if w == \"<user>\":\n",
    "            w = w\n",
    "        elif w == \"<url>\":\n",
    "            w = w\n",
    "        elif w == \"<number>\":\n",
    "            w = w\n",
    "        elif w in emoji.UNICODE_EMOJI:\n",
    "            w = w\n",
    "        else:\n",
    "            # prepare regex for char filtering: !\"#$%&'()*+, -./:;<=>?@[\\]^_`{|}~\n",
    "            re_punc = re.compile('[%s]' %re.escape(string.punctuation))\n",
    "            # remove punctuation from each word\n",
    "            w = re_punc.sub('', w)\n",
    "    \n",
    "            # remove remaining tokens that are not alphabetic\n",
    "            if w.isalpha():\n",
    "                w = w\n",
    "        new_tokens1.append(w) \n",
    "        \n",
    "    # filter out stop words\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [w for w in new_tokens1 if not w in stop_words]\n",
    "    \n",
    "    new_tokens2 = []\n",
    "    for w in tokens:\n",
    "        if w == \"<user>\":\n",
    "            w = w\n",
    "        elif w == \"<url>\":\n",
    "            w = w\n",
    "        elif w == \"<number>\":\n",
    "            w = w\n",
    "        elif w in emoji.UNICODE_EMOJI:\n",
    "            w = w\n",
    "        else:\n",
    "            # word segment will convert the hashtag based joined words, for example, it will segment #iamthebest to ['i','am','the','best']\n",
    "            w = ' '.join(ws.segment(w)) \n",
    "        new_tokens2.append(w)\n",
    "        \n",
    "    \n",
    "    # make lower case\n",
    "    tokens = [word.lower() for word in new_tokens2]\n",
    "    \n",
    "    \n",
    "    clean_text = ' '.join(tokens)\n",
    "    tokens = clean_text.split()\n",
    "    \n",
    "    new_tokens3 = []   \n",
    "    # filter out short tokens\n",
    "    for w in tokens:\n",
    "        if w in emoji.UNICODE_EMOJI:\n",
    "            w = w\n",
    "        else:\n",
    "            if len(w) > 1:\n",
    "                w =w\n",
    "        new_tokens3.append(w)\n",
    "    \n",
    "    return ' '.join(new_tokens3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<user> i left dad deal üòÇ my work done soon felt wrath slipper üò∑'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# do a sanity check\n",
    "text = \"@laura221b I've left it for my dad to deal with üòÇ My work is done as soon as it's felt the wrath of my slipper üò∑\"\n",
    "clean_text(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare for clean Hashtag Emotion Intensity Lexicons...\n",
    "\n",
    "def remove_stopwords(string):\n",
    "    split_string = \\\n",
    "        [word for word in string.split()\n",
    "         if word not in stopwords.words('english')]\n",
    "    \n",
    "    return \" \".join(split_string)\n",
    "\n",
    "def clean_str(string):  \n",
    "    string = string.replace(\"\\\\n\", \" \")\n",
    "    string = string.replace(\"_NEG\", \"\")\n",
    "    string = string.replace(\"_NEGFIRST\", \"\")\n",
    "    string = re.sub(r\"@[A-Za-z0-9_s(),!?\\'\\`]+\", \"\", string) # removing any twitter handle mentions\n",
    "\n",
    "    string = re.sub(r\"#\", \"\", string)\n",
    "    string = re.sub(r\"\\*\", \"\", string)\n",
    "    string = re.sub(r\"\\'s\", \"\", string)\n",
    "    string = re.sub(r\"\\'m\", \" am\", string)\n",
    "    string = re.sub(r\"\\'ve\", \" have\", string)\n",
    "    string = re.sub(r\"n\\'t\", \" not\", string)\n",
    "    string = re.sub(r\"\\'re\", \" are\", string)\n",
    "    string = re.sub(r\"\\'d\", \" would\", string)\n",
    "    string = re.sub(r\"\\'ll\", \" will\", string)\n",
    "    string = re.sub(r\",\", \"\", string)\n",
    "    string = re.sub(r\"!\", \" !\", string)\n",
    "    string = re.sub(r\"\\(\", \"\", string)\n",
    "    string = re.sub(r\"\\)\", \"\", string)\n",
    "    string = re.sub(r\"\\?\", \" ?\", string)\n",
    "    string = re.sub(r\"\\s{2,}\", \" \", string)\n",
    "\n",
    "    return remove_stopwords(string.strip().lower())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (3) Clean Text Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Tweet'] = train['Tweet'].apply(clean_text)\n",
    "\n",
    "test['Tweet'] = test['Tweet'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SentID</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Emotion</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30000</td>\n",
       "      <td>just got back seeing &lt;user&gt; burslem amazing fa...</td>\n",
       "      <td>joy</td>\n",
       "      <td>0.980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30001</td>\n",
       "      <td>oh dear evening absolute hilarity i think i la...</td>\n",
       "      <td>joy</td>\n",
       "      <td>0.958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30002</td>\n",
       "      <td>been waiting week game cheer friday</td>\n",
       "      <td>joy</td>\n",
       "      <td>0.940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30003</td>\n",
       "      <td>&lt;user&gt; thank much gloria you sweet thoughtful ...</td>\n",
       "      <td>joy</td>\n",
       "      <td>0.938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30004</td>\n",
       "      <td>i feel blessed work family i nanny nothing lov...</td>\n",
       "      <td>joy</td>\n",
       "      <td>0.938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>30005</td>\n",
       "      <td>today i reached &lt;number&gt; subscribers yt good d...</td>\n",
       "      <td>joy</td>\n",
       "      <td>0.926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>30006</td>\n",
       "      <td>&lt;user&gt; good morning love happy first day fall ...</td>\n",
       "      <td>joy</td>\n",
       "      <td>0.924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>30007</td>\n",
       "      <td>bridget jones baby best thing i seen ages so f...</td>\n",
       "      <td>joy</td>\n",
       "      <td>0.922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>30008</td>\n",
       "      <td>just got back seeing &lt;user&gt; burslem amazing fa...</td>\n",
       "      <td>joy</td>\n",
       "      <td>0.920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>30009</td>\n",
       "      <td>&lt;user&gt; i thought holidays could get cheerful i...</td>\n",
       "      <td>joy</td>\n",
       "      <td>0.917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>30010</td>\n",
       "      <td>i still so happy na blast</td>\n",
       "      <td>joy</td>\n",
       "      <td>0.917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>30011</td>\n",
       "      <td>it meant happy happy</td>\n",
       "      <td>joy</td>\n",
       "      <td>0.917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>30012</td>\n",
       "      <td>yeah paul glorious bb &lt;number&gt;</td>\n",
       "      <td>joy</td>\n",
       "      <td>0.917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>30013</td>\n",
       "      <td>my morning started amazing hopefully whole day...</td>\n",
       "      <td>joy</td>\n",
       "      <td>0.917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>30014</td>\n",
       "      <td>üò± &lt;user&gt; üòÇ üòÇ whole time watching &lt;user&gt; lost g...</td>\n",
       "      <td>joy</td>\n",
       "      <td>0.900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>30015</td>\n",
       "      <td>&lt;user&gt; love much smile</td>\n",
       "      <td>joy</td>\n",
       "      <td>0.896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>30016</td>\n",
       "      <td>&lt;user&gt; &lt;user&gt; however rei offer job today well...</td>\n",
       "      <td>joy</td>\n",
       "      <td>0.896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>30017</td>\n",
       "      <td>&lt;number&gt; days go pack go &lt;number&gt; days go gipe...</td>\n",
       "      <td>joy</td>\n",
       "      <td>0.880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>30018</td>\n",
       "      <td>&lt;user&gt; you beyond wonderful your singing prowe...</td>\n",
       "      <td>joy</td>\n",
       "      <td>0.879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>30019</td>\n",
       "      <td>&lt;user&gt; luck ii i changing many ways bc him it ...</td>\n",
       "      <td>joy</td>\n",
       "      <td>0.877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>30020</td>\n",
       "      <td>&lt;user&gt; i love parody accounts well done vote t...</td>\n",
       "      <td>joy</td>\n",
       "      <td>0.875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>30021</td>\n",
       "      <td>when wake dream laughing something stupid make...</td>\n",
       "      <td>joy</td>\n",
       "      <td>0.875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>30022</td>\n",
       "      <td>i future planned i feel much happier goals lif...</td>\n",
       "      <td>joy</td>\n",
       "      <td>0.875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>30023</td>\n",
       "      <td>online day come play i happy happy horny playf...</td>\n",
       "      <td>joy</td>\n",
       "      <td>0.875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>30024</td>\n",
       "      <td>&lt;user&gt; wonderful experience watching yesterday...</td>\n",
       "      <td>joy</td>\n",
       "      <td>0.872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>30025</td>\n",
       "      <td>&lt;user&gt; happy birthday blessed day love toronto...</td>\n",
       "      <td>joy</td>\n",
       "      <td>0.868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>30026</td>\n",
       "      <td>&lt;user&gt; you make world joyful place the nice bot</td>\n",
       "      <td>joy</td>\n",
       "      <td>0.864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>30027</td>\n",
       "      <td>morning of course sunny monday morning cheerfu...</td>\n",
       "      <td>joy</td>\n",
       "      <td>0.863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>30028</td>\n",
       "      <td>&lt;user&gt; good morning love happy first day fall ...</td>\n",
       "      <td>joy</td>\n",
       "      <td>0.860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30029</td>\n",
       "      <td>it first day off all i happy sipping pumpkin s...</td>\n",
       "      <td>joy</td>\n",
       "      <td>0.860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>30030</td>\n",
       "      <td>re tweet ed gunny smith &lt;number&gt; &lt;user&gt; like t...</td>\n",
       "      <td>joy</td>\n",
       "      <td>0.860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>30031</td>\n",
       "      <td>&lt;user&gt; happy birthday hope wonderful day fille...</td>\n",
       "      <td>joy</td>\n",
       "      <td>0.854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>30032</td>\n",
       "      <td>love love love fun relaxation is key</td>\n",
       "      <td>joy</td>\n",
       "      <td>0.854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>30033</td>\n",
       "      <td>this day you made n n let us re hoi rejoice gl...</td>\n",
       "      <td>joy</td>\n",
       "      <td>0.854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>30034</td>\n",
       "      <td>i love laugh share laughter way share joy</td>\n",
       "      <td>joy</td>\n",
       "      <td>0.854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>30035</td>\n",
       "      <td>second day job already got &lt;number&gt; dollar tip...</td>\n",
       "      <td>joy</td>\n",
       "      <td>0.854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>30036</td>\n",
       "      <td>i fan endless laughter friends enjoying happin...</td>\n",
       "      <td>joy</td>\n",
       "      <td>0.854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>30037</td>\n",
       "      <td>thought gets day thought smile never fails mak...</td>\n",
       "      <td>joy</td>\n",
       "      <td>0.854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>30038</td>\n",
       "      <td>today i reached &lt;number&gt; subscribers yt happy ...</td>\n",
       "      <td>joy</td>\n",
       "      <td>0.849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>30039</td>\n",
       "      <td>getting comedic relief w &lt;user&gt; season premier...</td>\n",
       "      <td>joy</td>\n",
       "      <td>0.846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>30040</td>\n",
       "      <td>&lt;user&gt; &lt;user&gt; fun funniest person funs ville m...</td>\n",
       "      <td>joy</td>\n",
       "      <td>0.840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>30041</td>\n",
       "      <td>&lt;user&gt; &lt;user&gt; omd &lt;number&gt; cracking thanks fol...</td>\n",
       "      <td>joy</td>\n",
       "      <td>0.840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>30042</td>\n",
       "      <td>&lt;user&gt; oh fantastic i bet super exhilarating</td>\n",
       "      <td>joy</td>\n",
       "      <td>0.840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>30043</td>\n",
       "      <td>&lt;user&gt; well done ladies a great award amazing ...</td>\n",
       "      <td>joy</td>\n",
       "      <td>0.840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>30044</td>\n",
       "      <td>vals always smiling i love gb bo</td>\n",
       "      <td>joy</td>\n",
       "      <td>0.840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>30045</td>\n",
       "      <td>had great time skywalker s open gym tonight co...</td>\n",
       "      <td>joy</td>\n",
       "      <td>0.833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>30046</td>\n",
       "      <td>i love cheery adoring &lt;user&gt; gets every time p...</td>\n",
       "      <td>joy</td>\n",
       "      <td>0.833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>30047</td>\n",
       "      <td>good morning joyful people choose happiness gr...</td>\n",
       "      <td>joy</td>\n",
       "      <td>0.833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>30048</td>\n",
       "      <td>re tweet ed gunny smith &lt;number&gt; &lt;user&gt; like t...</td>\n",
       "      <td>joy</td>\n",
       "      <td>0.833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>30049</td>\n",
       "      <td>wishing happy birthday awesome dancer ruthann ...</td>\n",
       "      <td>joy</td>\n",
       "      <td>0.833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>30050</td>\n",
       "      <td>thank &lt;user&gt; balloons today smile good day &lt;nu...</td>\n",
       "      <td>joy</td>\n",
       "      <td>0.833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>30051</td>\n",
       "      <td>omg you got watch new series this us wow best ...</td>\n",
       "      <td>joy</td>\n",
       "      <td>0.827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>30052</td>\n",
       "      <td>today first time math professor let us live ea...</td>\n",
       "      <td>joy</td>\n",
       "      <td>0.827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>30053</td>\n",
       "      <td>food gets delivered cheering happy</td>\n",
       "      <td>joy</td>\n",
       "      <td>0.827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>30054</td>\n",
       "      <td>you know love smile whenever talk someone</td>\n",
       "      <td>joy</td>\n",
       "      <td>0.820</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    SentID                                              Tweet Emotion  Rating\n",
       "0    30000  just got back seeing <user> burslem amazing fa...     joy   0.980\n",
       "1    30001  oh dear evening absolute hilarity i think i la...     joy   0.958\n",
       "2    30002                been waiting week game cheer friday     joy   0.940\n",
       "3    30003  <user> thank much gloria you sweet thoughtful ...     joy   0.938\n",
       "4    30004  i feel blessed work family i nanny nothing lov...     joy   0.938\n",
       "5    30005  today i reached <number> subscribers yt good d...     joy   0.926\n",
       "6    30006  <user> good morning love happy first day fall ...     joy   0.924\n",
       "7    30007  bridget jones baby best thing i seen ages so f...     joy   0.922\n",
       "8    30008  just got back seeing <user> burslem amazing fa...     joy   0.920\n",
       "9    30009  <user> i thought holidays could get cheerful i...     joy   0.917\n",
       "10   30010                          i still so happy na blast     joy   0.917\n",
       "11   30011                               it meant happy happy     joy   0.917\n",
       "12   30012                     yeah paul glorious bb <number>     joy   0.917\n",
       "13   30013  my morning started amazing hopefully whole day...     joy   0.917\n",
       "14   30014  üò± <user> üòÇ üòÇ whole time watching <user> lost g...     joy   0.900\n",
       "15   30015                             <user> love much smile     joy   0.896\n",
       "16   30016  <user> <user> however rei offer job today well...     joy   0.896\n",
       "17   30017  <number> days go pack go <number> days go gipe...     joy   0.880\n",
       "18   30018  <user> you beyond wonderful your singing prowe...     joy   0.879\n",
       "19   30019  <user> luck ii i changing many ways bc him it ...     joy   0.877\n",
       "20   30020  <user> i love parody accounts well done vote t...     joy   0.875\n",
       "21   30021  when wake dream laughing something stupid make...     joy   0.875\n",
       "22   30022  i future planned i feel much happier goals lif...     joy   0.875\n",
       "23   30023  online day come play i happy happy horny playf...     joy   0.875\n",
       "24   30024  <user> wonderful experience watching yesterday...     joy   0.872\n",
       "25   30025  <user> happy birthday blessed day love toronto...     joy   0.868\n",
       "26   30026    <user> you make world joyful place the nice bot     joy   0.864\n",
       "27   30027  morning of course sunny monday morning cheerfu...     joy   0.863\n",
       "28   30028  <user> good morning love happy first day fall ...     joy   0.860\n",
       "29   30029  it first day off all i happy sipping pumpkin s...     joy   0.860\n",
       "30   30030  re tweet ed gunny smith <number> <user> like t...     joy   0.860\n",
       "31   30031  <user> happy birthday hope wonderful day fille...     joy   0.854\n",
       "32   30032               love love love fun relaxation is key     joy   0.854\n",
       "33   30033  this day you made n n let us re hoi rejoice gl...     joy   0.854\n",
       "34   30034          i love laugh share laughter way share joy     joy   0.854\n",
       "35   30035  second day job already got <number> dollar tip...     joy   0.854\n",
       "36   30036  i fan endless laughter friends enjoying happin...     joy   0.854\n",
       "37   30037  thought gets day thought smile never fails mak...     joy   0.854\n",
       "38   30038  today i reached <number> subscribers yt happy ...     joy   0.849\n",
       "39   30039  getting comedic relief w <user> season premier...     joy   0.846\n",
       "40   30040  <user> <user> fun funniest person funs ville m...     joy   0.840\n",
       "41   30041  <user> <user> omd <number> cracking thanks fol...     joy   0.840\n",
       "42   30042       <user> oh fantastic i bet super exhilarating     joy   0.840\n",
       "43   30043  <user> well done ladies a great award amazing ...     joy   0.840\n",
       "44   30044                   vals always smiling i love gb bo     joy   0.840\n",
       "45   30045  had great time skywalker s open gym tonight co...     joy   0.833\n",
       "46   30046  i love cheery adoring <user> gets every time p...     joy   0.833\n",
       "47   30047  good morning joyful people choose happiness gr...     joy   0.833\n",
       "48   30048  re tweet ed gunny smith <number> <user> like t...     joy   0.833\n",
       "49   30049  wishing happy birthday awesome dancer ruthann ...     joy   0.833\n",
       "50   30050  thank <user> balloons today smile good day <nu...     joy   0.833\n",
       "51   30051  omg you got watch new series this us wow best ...     joy   0.827\n",
       "52   30052  today first time math professor let us live ea...     joy   0.827\n",
       "53   30053                 food gets delivered cheering happy     joy   0.827\n",
       "54   30054          you know love smile whenever talk someone     joy   0.820"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# do a sanity check\n",
    "train[0:55]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SentID</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Emotion</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30000</td>\n",
       "      <td>just got back seeing &lt;user&gt; burslem amazing fa...</td>\n",
       "      <td>joy</td>\n",
       "      <td>0.980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30001</td>\n",
       "      <td>oh dear evening absolute hilarity i think i la...</td>\n",
       "      <td>joy</td>\n",
       "      <td>0.958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30002</td>\n",
       "      <td>been waiting week game cheer friday</td>\n",
       "      <td>joy</td>\n",
       "      <td>0.940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30003</td>\n",
       "      <td>&lt;user&gt; thank much gloria you sweet thoughtful ...</td>\n",
       "      <td>joy</td>\n",
       "      <td>0.938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30004</td>\n",
       "      <td>i feel blessed work family i nanny nothing lov...</td>\n",
       "      <td>joy</td>\n",
       "      <td>0.938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>30005</td>\n",
       "      <td>today i reached &lt;number&gt; subscribers yt good d...</td>\n",
       "      <td>joy</td>\n",
       "      <td>0.926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>30006</td>\n",
       "      <td>&lt;user&gt; good morning love happy first day fall ...</td>\n",
       "      <td>joy</td>\n",
       "      <td>0.924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>30007</td>\n",
       "      <td>bridget jones baby best thing i seen ages so f...</td>\n",
       "      <td>joy</td>\n",
       "      <td>0.922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>30008</td>\n",
       "      <td>just got back seeing &lt;user&gt; burslem amazing fa...</td>\n",
       "      <td>joy</td>\n",
       "      <td>0.920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>30009</td>\n",
       "      <td>&lt;user&gt; i thought holidays could get cheerful i...</td>\n",
       "      <td>joy</td>\n",
       "      <td>0.917</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SentID                                              Tweet Emotion  Rating\n",
       "0   30000  just got back seeing <user> burslem amazing fa...     joy   0.980\n",
       "1   30001  oh dear evening absolute hilarity i think i la...     joy   0.958\n",
       "2   30002                been waiting week game cheer friday     joy   0.940\n",
       "3   30003  <user> thank much gloria you sweet thoughtful ...     joy   0.938\n",
       "4   30004  i feel blessed work family i nanny nothing lov...     joy   0.938\n",
       "5   30005  today i reached <number> subscribers yt good d...     joy   0.926\n",
       "6   30006  <user> good morning love happy first day fall ...     joy   0.924\n",
       "7   30007  bridget jones baby best thing i seen ages so f...     joy   0.922\n",
       "8   30008  just got back seeing <user> burslem amazing fa...     joy   0.920\n",
       "9   30009  <user> i thought holidays could get cheerful i...     joy   0.917"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# do a sanity check\n",
    "train[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the distribution of text length (from below: there is no need to truncate any of texts)\n",
    "def show_text_len(train):\n",
    "    train[\"text_len\"] = train['Tweet'].map(lambda x: len(x.split()))\n",
    "    return train[\"text_len\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    902.000000\n",
       "mean      11.018847\n",
       "std        4.483374\n",
       "min        2.000000\n",
       "25%        8.000000\n",
       "50%       11.000000\n",
       "75%       14.000000\n",
       "max       29.000000\n",
       "Name: text_len, dtype: float64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_text_len(train).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    714.000000\n",
       "mean      10.925770\n",
       "std        4.709077\n",
       "min        2.000000\n",
       "25%        7.000000\n",
       "50%       11.000000\n",
       "75%       14.000000\n",
       "max       31.000000\n",
       "Name: text_len, dtype: float64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_text_len(test).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is not any reviews' length = 0 after text cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tweets = list(train['Tweet'])\n",
    "train_intensities = list(train['Rating'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['just got back seeing <user> burslem amazing face still hurts laughing much hilarious',\n",
       " 'oh dear evening absolute hilarity i think i laughed much long time üòÇ',\n",
       " 'been waiting week game cheer friday',\n",
       " '<user> thank much gloria you sweet thoughtful you made day joyful i love',\n",
       " 'i feel blessed work family i nanny nothing love amp appreciation makes smile',\n",
       " 'today i reached <number> subscribers yt good day thankful',\n",
       " '<user> good morning love happy first day fall let make awesome autumn memories anna bailey laughter smile',\n",
       " 'bridget jones baby best thing i seen ages so funny i missed bridget love team mark',\n",
       " 'just got back seeing <user> burslem amazing face still hurts laughing much',\n",
       " '<user> i thought holidays could get cheerful i met the nice bot',\n",
       " 'i still so happy na blast',\n",
       " 'it meant happy happy',\n",
       " 'yeah paul glorious bb <number>',\n",
       " 'my morning started amazing hopefully whole day going want go n great day',\n",
       " 'üò± <user> üòÇ üòÇ whole time watching <user> lost glasses it hilarious <user>',\n",
       " '<user> love much smile',\n",
       " '<user> <user> however rei offer job today well ca believe exponentially freaking joyous i feel',\n",
       " '<number> days go pack go <number> days go gipe go i excited smiling',\n",
       " '<user> you beyond wonderful your singing prowess phenomenal damn i elated watch act this is us',\n",
       " '<user> luck ii i changing many ways bc him it scary joyful feeling making strong',\n",
       " '<user> i love parody accounts well done vote trump lol hilarious',\n",
       " 'when wake dream laughing something stupid makes laugh hilarious',\n",
       " 'i future planned i feel much happier goals life happy i got this yay',\n",
       " 'online day come play i happy happy horny playful sweet sour',\n",
       " '<user> wonderful experience watching yesterday <user> thank you laughter',\n",
       " '<user> happy birthday blessed day love toronto bday',\n",
       " '<user> you make world joyful place the nice bot',\n",
       " 'morning of course sunny monday morning cheerfully welcome us back work',\n",
       " '<user> good morning love happy first day fall let make awesome autumn memories anna bailey',\n",
       " 'it first day off all i happy sipping pumpkin spice flavored coffee smiling happy fall everyone am writing',\n",
       " 're tweet ed gunny smith <number> <user> like today i happy alive blessed rejoice',\n",
       " '<user> happy birthday hope wonderful day filled lots joy laughter lt <number> despite tum blr jerk',\n",
       " 'love love love fun relaxation is key',\n",
       " 'this day you made n n let us re hoi rejoice glad i n n n naja n good morning',\n",
       " 'i love laugh share laughter way share joy',\n",
       " 'second day job already got <number> dollar tip dude whose constantly twitching eye lololol cheering',\n",
       " 'i fan endless laughter friends enjoying happiness together friday feeling weekend',\n",
       " 'thought gets day thought smile never fails making smile üíö',\n",
       " 'today i reached <number> subscribers yt happy good day thankful',\n",
       " 'getting comedic relief w <user> season premiere modern family just girl needs hilarious',\n",
       " '<user> <user> fun funniest person funs ville much hilarity usual thank',\n",
       " '<user> <user> omd <number> cracking thanks follow brian i need levity balance cynicism i share w michael',\n",
       " '<user> oh fantastic i bet super exhilarating',\n",
       " '<user> well done ladies a great award amazing team a delight present award',\n",
       " 'vals always smiling i love gb bo',\n",
       " 'had great time skywalker s open gym tonight come every wednesday <number> <number> hillsboro train us open gym cheer tumbling',\n",
       " 'i love cheery adoring <user> gets every time produces new content',\n",
       " 'good morning joyful people choose happiness great day today morning joyful happiness grand mercure jkt ke mayor an',\n",
       " 're tweet ed gunny smith <number> <user> like today i happy alive blessed',\n",
       " 'wishing happy birthday awesome dancer ruthann we hope day magical bday eat cake',\n",
       " 'thank <user> balloons today smile good day <number>',\n",
       " 'omg you got watch new series this us wow best tv show i seen long time n tears laughter more tears',\n",
       " 'today first time math professor let us live early class time <number> min feels good happy wednesday',\n",
       " 'food gets delivered cheering happy',\n",
       " 'you know love smile whenever talk someone',\n",
       " 'what lively lovely shower üòá',\n",
       " 'what great training course lots photos fun laughter photo soon booster course fun laughter',\n",
       " '<user> hahahaha ridiculous but thank joyous evening xx',\n",
       " 'i happy i come across <user> notebooks handmade would love talk must have want need happy amazing',\n",
       " 'second day job already got <number> dollar tip dude whose constantly twitching eye lololol',\n",
       " 'made night <user> reid included tonight hilarity some points brilliant thanks <user>',\n",
       " 'by way i wearing smile gave today n',\n",
       " '<user> always indeed wonderful experience flying guys today best in business delight happy me',\n",
       " '<user> ah i got work much rejoicing lol thanks get taht',\n",
       " 'getting comedic relief w <user> season premiere modern family just girl needs',\n",
       " '<user> thank happy birthday well',\n",
       " 'i really love customer service <user> always nice helpful cheerful',\n",
       " '<user> <user> on php <number> though kar dash ian stuff goes head hilarious like gleeful little boys',\n",
       " '<user> glad see fun sun water sports always fun challenging exhilarating happiness beauty',\n",
       " 'may day filled peace love n laughter have nice day full success j ummah mubarak good morning <user>',\n",
       " '<number> days go pack go <number> days go gipe go i excited',\n",
       " 'it funny everyone came life like far i cheerful self confident could make <number> abla kam l fg <number> kda',\n",
       " 'happy birthday <user> cheer chick jeep jeep girl i drive a jeep jeep jeep cheer',\n",
       " 'the nice bot melb js here smile wink across web the nice bot',\n",
       " 'a smile brightens day day everyone around remember smile free',\n",
       " 'i watching joyful noise <number> time cuz i love movie <user>',\n",
       " 'indian time already ur birthday <user> have stupendous birthday wish success laughter lots love hugs x',\n",
       " 'i future planned i feel much happier goals life i got this yay',\n",
       " 'bridget jones baby best thing i seen ages so funny i missed bridget love hilarious team mark',\n",
       " 'had great time skywalker s open gym tonight come every wednesday <number> <number> hillsboro train us open gym tumbling',\n",
       " '<user> hahaha u da best bro ever luv u hearty hearts',\n",
       " '<user> yes amp cheering homecoming game',\n",
       " 'i would like congratulate people saudi arabia happy joyous national day may great time',\n",
       " '<user> i lively listen',\n",
       " '<user> i ca wait',\n",
       " '<user> you beyond wonderful your singing prowess phenomenal damn i elated watch act this is us ü§ó',\n",
       " '<user> <user> <user> <user> <user> very pleasing ty',\n",
       " '<user> wait she said cheerfully grinned',\n",
       " '<user> sweet amp playful üòç',\n",
       " 'good morning trondheim optimism productivity',\n",
       " 'thank disney themed episode letting discover amazing <user> hilarious',\n",
       " 'pet store worker ask would o want play exhilarating feeling',\n",
       " '<user> good morning let start smile n let enjoy life cheerful way n do worry happy',\n",
       " 'currently listening <user> amp <user> <user> podcasts can guys please move yvr hilarious miss you',\n",
       " '<user> <user> <user> found thin mints freezer clean could elated',\n",
       " '<user> i cheery',\n",
       " 'probably best ot period i ever seen absolutely exhilarating wch <number> team na',\n",
       " 're watching raising hope hubs time totally forgot hilarious üòÇ here we go',\n",
       " '<user> always indeed wonderful experience flying guys today best in business happy me',\n",
       " '<user> looking back recent tweet s seen one right great perfect hilarious speechless deal']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check\n",
    "train_tweets[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.98,\n",
       " 0.958,\n",
       " 0.94,\n",
       " 0.938,\n",
       " 0.938,\n",
       " 0.9259999999999999,\n",
       " 0.924,\n",
       " 0.922,\n",
       " 0.92,\n",
       " 0.917]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check\n",
    "train_intensities[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_tweets = list(test['Tweet'])\n",
    "test_intensities = list(test['Rating'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>max text length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>train</th>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       max text length\n",
       "train               29\n",
       "test                31"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show Max Text Length of All Datasets for comparsion\n",
    "\n",
    "all_tweets_max_len = pd.DataFrame(np.array([max(show_text_len(train)), max(show_text_len(test))]))\n",
    "\n",
    "all_tweets_max_len.index = ['train', 'test']\n",
    "all_tweets_max_len.columns = ['max text length']\n",
    "\n",
    "all_tweets_max_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "all_tweets_max_len.plot(kind='bar')\n",
    "plt.title('Max Text Length of All Datasets')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "we set the length to which each tweet vector will be zero padded to.\n",
    "this is based on the maximum length we got on the training set - we do not want to remove\n",
    "any words as the maximun length of the training set is not very big.\n",
    "'''\n",
    "\n",
    "max_len = max(show_text_len(train))\n",
    "max_len"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Text Data PreparationÔºàFeature Extraction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (1) Load Pre-trained Word Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gensim\n",
    "from nltk import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vector_path = \"files/wv_models/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1) Glove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadGloveModel(gloveFile):\n",
    "    print(\"Loading Glove Model\")\n",
    "    f = open(gloveFile,'r', encoding = 'UTF-8')\n",
    "    model = {}\n",
    "    num = 1\n",
    "    for line in f:\n",
    "        try:\n",
    "            splitLine = line.split()\n",
    "            word = splitLine[0]\n",
    "            coefs = np.asarray(splitLine[1:], dtype = 'float32')\n",
    "            model[word] = coefs\n",
    "            num += 1\n",
    "        except Exception as e:\n",
    "            print(\"Failed at line \" + str(num))\n",
    "    print(\"Done. Found %s word vectors.\" %len(model),\" words loaded!\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Glove Model\n",
      "Done. Found 1193514 word vectors.  words loaded!\n"
     ]
    }
   ],
   "source": [
    "# To download the pretrained glove model (2B tweets, 27B tokens) - [https://nlp.stanford.edu/projects/glove/   glove.twitter.27B.zip]\n",
    "# choose glove.twitter.27B.200d.txt from glove.twitter.27B.zip. [200-dimension vectors]\n",
    "\n",
    "wv_model_path1 = word_vector_path + \"glove.twitter.27B.200d.txt\"\n",
    " \n",
    "wv_model_g = loadGloveModel(wv_model_path1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2) Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To download the pretrained word2vec model  - [https://github.com/FredericGodin/TwitterEmbeddings]\n",
    "\n",
    "wv_model_path2 = word_vector_path + \"word2vec_twitter_tokens.bin\"\n",
    "wv_model_w = gensim.models.KeyedVectors.load_word2vec_format(wv_model_path2, binary=True, unicode_errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word Vectors: 3039345\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dell\\Anaconda3\\envs\\tf2\\lib\\site-packages\\ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "words = list(wv_model_w.wv.vocab)\n",
    "print('Word Vectors: %d' % len(words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3) Define Averaged Word Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_dimensions_g = len(wv_model_g['word'])\n",
    "w2v_dimensions_w = len(wv_model_w['word'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200 400\n"
     ]
    }
   ],
   "source": [
    "print(w2v_dimensions_g,w2v_dimensions_w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_averaged_embeddings(tweet, model, dimensions):\n",
    "    tokens = word_tokenize(tweet)\n",
    "    vector_list = []\n",
    "    for token in tokens:\n",
    "        try:\n",
    "            vector_list.append(model[token])\n",
    "        except Exception as e:\n",
    "            pass\n",
    "    if len(vector_list) == 0:\n",
    "        uni_vec_rep = np.zeros(dimensions).tolist()\n",
    "    else:\n",
    "        uni_vec_rep = sum(vector_list) / float(len(vector_list))\n",
    "    return uni_vec_rep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (2) Load Lexicon Feature Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "lexicons_path = \"files/lexicons/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0.Emoji_Vectors',\n",
       " '1.NRC-Emotion-Intensity-Lexicon',\n",
       " '3.NRC-Emotion-Lexicon',\n",
       " '4.NRC-Hashtag-Emotion-Lexicon',\n",
       " '5.NRC-Emoticon-Lexicon',\n",
       " '6.NRC-Emoticon-AffLexNegLex',\n",
       " '7.NRC-Hashtag-Sentiment-AffLexNegLex',\n",
       " '8.NRC-Hashtag-Sentiment-Lexicon',\n",
       " '9.DepecheMood_V1.0']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paths2 = listdir(lexicons_path)\n",
    "paths2.sort()\n",
    "paths2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1) Emoji Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(('%s%s/' %(lexicons_path, paths2[0])) + listdir('%s%s/' %(lexicons_path, paths2[0]))[0], encoding = 'UTF-8') \\\n",
    "as emoji_file:\n",
    "    emoji_list = json.load(emoji_file)\n",
    "    \n",
    "emoji_dict = dict()\n",
    "for emoji in emoji_list:\n",
    "    emoji_dict[emoji[\"emoji\"]] = (emoji[\"name\"], emoji[\"polarity\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('joy', 3)\n"
     ]
    }
   ],
   "source": [
    "# do a sanity check\n",
    "print(emoji_dict[\"üòÇ\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly_emoji_intensity = PolynomialFeatures(5)\n",
    "\n",
    "def get_emoji_intensity(tweet):\n",
    "    score = 0.0\n",
    "    for emoji in emoji_dict.keys():\n",
    "        count = tweet.count(emoji)\n",
    "        score += count * emoji_dict[emoji][1]\n",
    "        \n",
    "    return normalize(poly_emoji_intensity.fit_transform(np.array([score]).reshape(1, -1))[0].reshape(1, -1))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00387988, 0.01163963, 0.03491889, 0.10475666, 0.31426998,\n",
       "       0.94280993])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# do a sanity check\n",
    "get_emoji_intensity(\"üòÇ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2) Emotion Intensity Lexicon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "affect_intensity_file_path = ('%s%s/' %(lexicons_path, paths2[1])) + listdir('%s%s/' %(lexicons_path, paths2[1]))[0]\n",
    "\n",
    "def get_word_affect_intensity_dict(emotion):\n",
    "    word_intensities = dict()\n",
    "\n",
    "    with open(affect_intensity_file_path) as affect_intensity_file:\n",
    "        for line in affect_intensity_file:\n",
    "            word_int_array = line.replace(\"\\n\", \"\").split(\"\\t\")\n",
    "\n",
    "            if (word_int_array[1] == emotion):\n",
    "                word_intensities[word_int_array[0]] = float(word_int_array[2])\n",
    "\n",
    "    return word_intensities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'happiest': 0.986,\n",
       " 'happiness': 0.984,\n",
       " 'bliss': 0.971,\n",
       " 'celebrating': 0.97,\n",
       " 'jubilant': 0.969,\n",
       " 'ecstatic': 0.954,\n",
       " 'elation': 0.944,\n",
       " 'beaming': 0.938,\n",
       " 'bestdayever': 0.938,\n",
       " 'loveee': 0.932,\n",
       " 'celebration': 0.929,\n",
       " 'awesomeness': 0.926,\n",
       " 'joy': 0.924,\n",
       " 'excitement': 0.922,\n",
       " 'joyous': 0.922,\n",
       " 'happily': 0.922,\n",
       " 'exuberance': 0.922,\n",
       " 'makesmehappy': 0.922,\n",
       " 'euphoria': 0.922,\n",
       " 'fabulous': 0.922,\n",
       " 'lovee': 0.92,\n",
       " 'gratitude': 0.914,\n",
       " 'merriment': 0.912,\n",
       " 'spectacular': 0.912,\n",
       " 'happydance': 0.912,\n",
       " 'purebliss': 0.909,\n",
       " 'overjoyed': 0.909,\n",
       " 'triumphant': 0.907,\n",
       " 'cheerful': 0.906,\n",
       " 'lovelovelove': 0.906,\n",
       " 'ecstasy': 0.906,\n",
       " 'cheer': 0.897,\n",
       " 'elated': 0.894,\n",
       " 'delighted': 0.891,\n",
       " 'exhilaration': 0.891,\n",
       " 'peaceofmind': 0.891,\n",
       " 'jolly': 0.891,\n",
       " 'lovethis': 0.891,\n",
       " 'excitation': 0.891,\n",
       " 'pleasures': 0.891,\n",
       " 'laugh': 0.891,\n",
       " 'marvelously': 0.881,\n",
       " 'loving': 0.879,\n",
       " 'blissful': 0.879,\n",
       " 'joyful': 0.879,\n",
       " 'outstanding': 0.879,\n",
       " 'pleasurable': 0.877,\n",
       " 'yaaaay': 0.875,\n",
       " 'happyplace': 0.875,\n",
       " 'overthemoon': 0.875,\n",
       " 'glee': 0.875,\n",
       " 'enthusiastic': 0.875,\n",
       " 'lovinglife': 0.875,\n",
       " 'iloveher': 0.875,\n",
       " 'sohappy': 0.868,\n",
       " 'laughing': 0.864,\n",
       " 'superb': 0.864,\n",
       " 'woohoo': 0.864,\n",
       " 'wonderful': 0.863,\n",
       " 'ilovechristmas': 0.859,\n",
       " 'cheering': 0.859,\n",
       " 'magnificent': 0.859,\n",
       " 'celebrated': 0.859,\n",
       " 'hooray': 0.859,\n",
       " 'loved': 0.859,\n",
       " 'brilliant': 0.859,\n",
       " 'hallelujah': 0.859,\n",
       " 'tearsofjoy': 0.859,\n",
       " 'yayyyy': 0.859,\n",
       " 'glory': 0.859,\n",
       " 'heavenly': 0.853,\n",
       " 'exciting': 0.853,\n",
       " 'thrilled': 0.851,\n",
       " 'mademyday': 0.848,\n",
       " 'hohoho': 0.845,\n",
       " 'wonderfully': 0.844,\n",
       " 'favoriteholiday': 0.844,\n",
       " 'blessing': 0.844,\n",
       " 'celebrate': 0.844,\n",
       " 'festive': 0.833,\n",
       " 'paradise': 0.833,\n",
       " 'celebrations': 0.833,\n",
       " 'sweetness': 0.833,\n",
       " 'marvellous': 0.833,\n",
       " 'blessed': 0.833,\n",
       " 'compliment': 0.831,\n",
       " 'allsmiles': 0.828,\n",
       " 'love': 0.828,\n",
       " 'enchanting': 0.828,\n",
       " 'smiling': 0.828,\n",
       " 'homesweethome': 0.826,\n",
       " 'laughter': 0.824,\n",
       " 'marvelous': 0.824,\n",
       " 'thankyougod': 0.824,\n",
       " 'goodmood': 0.819,\n",
       " 'excited': 0.818,\n",
       " 'goodness': 0.818,\n",
       " 'rejoicing': 0.818,\n",
       " 'happyheart': 0.818,\n",
       " 'excellence': 0.818,\n",
       " 'joys': 0.818,\n",
       " 'sensational': 0.818,\n",
       " 'delightful': 0.818,\n",
       " 'celebratory': 0.818,\n",
       " 'greatful': 0.816,\n",
       " 'jovial': 0.814,\n",
       " 'smiley': 0.812,\n",
       " 'victorious': 0.812,\n",
       " 'enjoy': 0.812,\n",
       " 'rejoice': 0.812,\n",
       " 'greatday': 0.812,\n",
       " 'lovemaking': 0.812,\n",
       " 'bonanza': 0.812,\n",
       " 'excellent': 0.812,\n",
       " 'splendid': 0.812,\n",
       " 'glorious': 0.812,\n",
       " 'whatmakesmesmile': 0.811,\n",
       " 'goodtimes': 0.811,\n",
       " 'happyday': 0.809,\n",
       " 'myfavorite': 0.804,\n",
       " 'pleasure': 0.803,\n",
       " 'yayyy': 0.803,\n",
       " 'gladness': 0.803,\n",
       " 'yeahhhh': 0.803,\n",
       " 'thankyoulord': 0.803,\n",
       " 'giggle': 0.802,\n",
       " 'happytweet': 0.797,\n",
       " 'dancing': 0.797,\n",
       " 'yesss': 0.797,\n",
       " 'lovemylife': 0.797,\n",
       " 'success': 0.797,\n",
       " 'lovinlife': 0.797,\n",
       " 'magnificence': 0.797,\n",
       " 'happier': 0.797,\n",
       " 'grateful': 0.789,\n",
       " 'splendor': 0.788,\n",
       " 'fun': 0.788,\n",
       " 'happy': 0.788,\n",
       " 'amuse': 0.788,\n",
       " 'sothankful': 0.781,\n",
       " 'solucky': 0.781,\n",
       " 'radiant': 0.781,\n",
       " 'enchanted': 0.781,\n",
       " 'glad': 0.781,\n",
       " 'giggling': 0.781,\n",
       " 'beautiful': 0.781,\n",
       " 'glorify': 0.781,\n",
       " 'perfection': 0.779,\n",
       " 'christmassy': 0.779,\n",
       " 'romance': 0.779,\n",
       " 'heavens': 0.779,\n",
       " 'thrilling': 0.776,\n",
       " 'happyvalentinesday': 0.773,\n",
       " 'entertain': 0.773,\n",
       " 'miraculous': 0.773,\n",
       " 'fiesta': 0.773,\n",
       " 'cheered': 0.773,\n",
       " 'positivity': 0.773,\n",
       " 'congrats': 0.773,\n",
       " 'cheers': 0.773,\n",
       " 'lovable': 0.773,\n",
       " 'funday': 0.772,\n",
       " 'enjoying': 0.771,\n",
       " 'thebest': 0.766,\n",
       " 'lifeisgood': 0.766,\n",
       " 'smiles': 0.766,\n",
       " 'christmasspirit': 0.766,\n",
       " 'amused': 0.766,\n",
       " 'goodfeeling': 0.766,\n",
       " 'sosweet': 0.766,\n",
       " 'cuddling': 0.766,\n",
       " 'party': 0.765,\n",
       " 'delight': 0.765,\n",
       " 'orgasm': 0.765,\n",
       " 'positive': 0.761,\n",
       " 'cheerfulness': 0.758,\n",
       " 'enlighten': 0.758,\n",
       " 'sweetheart': 0.758,\n",
       " 'miracles': 0.758,\n",
       " 'christmastime': 0.757,\n",
       " 'giddy': 0.757,\n",
       " 'laughs': 0.75,\n",
       " 'pleasing': 0.75,\n",
       " 'blessings': 0.75,\n",
       " 'romantic': 0.75,\n",
       " 'gratify': 0.75,\n",
       " 'smile': 0.75,\n",
       " 'happyholidays': 0.75,\n",
       " 'tistheseason': 0.75,\n",
       " 'greatness': 0.75,\n",
       " 'friendliness': 0.75,\n",
       " 'frolic': 0.748,\n",
       " 'positiveenergy': 0.742,\n",
       " 'jubilee': 0.742,\n",
       " 'enthusiasm': 0.742,\n",
       " 'miracle': 0.742,\n",
       " 'magical': 0.742,\n",
       " 'goodvibes': 0.742,\n",
       " 'selflove': 0.742,\n",
       " 'triumph': 0.742,\n",
       " 'rewarding': 0.742,\n",
       " 'feelgood': 0.736,\n",
       " 'prosperity': 0.735,\n",
       " 'admiration': 0.734,\n",
       " 'feelinggood': 0.734,\n",
       " 'tgif': 0.734,\n",
       " 'passionate': 0.734,\n",
       " 'goodday': 0.734,\n",
       " 'greatnight': 0.734,\n",
       " 'behappy': 0.734,\n",
       " 'victory': 0.734,\n",
       " 'vivacious': 0.734,\n",
       " 'luxurious': 0.734,\n",
       " 'enchant': 0.734,\n",
       " 'glorification': 0.733,\n",
       " 'glowing': 0.729,\n",
       " 'sing': 0.729,\n",
       " 'yessss': 0.728,\n",
       " 'fulfillment': 0.728,\n",
       " 'breathtaking': 0.728,\n",
       " 'cheery': 0.727,\n",
       " 'hurrah': 0.727,\n",
       " 'merry': 0.727,\n",
       " 'thankful': 0.727,\n",
       " 'win': 0.727,\n",
       " 'christmasbreak': 0.727,\n",
       " 'atpeace': 0.727,\n",
       " 'award': 0.727,\n",
       " 'santa': 0.727,\n",
       " 'radiance': 0.725,\n",
       " 'inspiration': 0.725,\n",
       " 'pleased': 0.725,\n",
       " 'uplift': 0.723,\n",
       " 'optimistic': 0.723,\n",
       " 'thrill': 0.721,\n",
       " 'holidays': 0.721,\n",
       " 'heaven': 0.721,\n",
       " 'lucky': 0.721,\n",
       " 'godisgreat': 0.721,\n",
       " 'praising': 0.719,\n",
       " 'heartfelt': 0.719,\n",
       " 'thriving': 0.719,\n",
       " 'perfect': 0.719,\n",
       " 'congratulatory': 0.719,\n",
       " 'brighten': 0.719,\n",
       " 'amusement': 0.719,\n",
       " 'harmony': 0.719,\n",
       " 'lover': 0.719,\n",
       " 'xmas': 0.719,\n",
       " 'lovely': 0.719,\n",
       " 'utopian': 0.719,\n",
       " 'achievement': 0.712,\n",
       " 'bestfeeling': 0.712,\n",
       " 'holiday': 0.712,\n",
       " 'luxury': 0.712,\n",
       " 'merrychristmas': 0.712,\n",
       " 'treasures': 0.712,\n",
       " 'luckiest': 0.712,\n",
       " 'yay': 0.712,\n",
       " 'magic': 0.712,\n",
       " 'intimate': 0.71,\n",
       " 'soblessed': 0.706,\n",
       " 'yaaay': 0.706,\n",
       " 'rave': 0.706,\n",
       " 'chuckle': 0.706,\n",
       " 'proud': 0.704,\n",
       " 'goodlife': 0.703,\n",
       " 'lovelife': 0.703,\n",
       " 'sweetest': 0.703,\n",
       " 'appreciates': 0.703,\n",
       " 'satisfying': 0.703,\n",
       " 'amazingly': 0.703,\n",
       " 'goodnews': 0.703,\n",
       " 'winning': 0.703,\n",
       " 'beautification': 0.703,\n",
       " 'gooood': 0.703,\n",
       " 'cherish': 0.703,\n",
       " 'truelove': 0.703,\n",
       " 'fuckyeah': 0.703,\n",
       " 'cuddled': 0.703,\n",
       " 'optimism': 0.703,\n",
       " 'entertained': 0.7,\n",
       " 'yaay': 0.7,\n",
       " 'excite': 0.697,\n",
       " 'newbeginnings': 0.693,\n",
       " 'praisejesus': 0.691,\n",
       " 'birthday': 0.691,\n",
       " 'honored': 0.688,\n",
       " 'favorite': 0.688,\n",
       " 'adoration': 0.688,\n",
       " 'metime': 0.688,\n",
       " 'greatfriends': 0.688,\n",
       " 'holidayseason': 0.688,\n",
       " 'angelic': 0.688,\n",
       " 'godsend': 0.688,\n",
       " 'content': 0.688,\n",
       " 'exquisite': 0.688,\n",
       " 'thankyoujesus': 0.688,\n",
       " 'entertaining': 0.688,\n",
       " 'exaltation': 0.682,\n",
       " 'luscious': 0.682,\n",
       " 'precious': 0.682,\n",
       " 'brightens': 0.682,\n",
       " 'appreciated': 0.682,\n",
       " 'smiled': 0.682,\n",
       " 'bestfriends': 0.682,\n",
       " 'goodhealth': 0.682,\n",
       " 'memoriesiwontforget': 0.682,\n",
       " 'majestic': 0.682,\n",
       " 'tranquility': 0.679,\n",
       " 'positively': 0.676,\n",
       " 'embrace': 0.676,\n",
       " 'marry': 0.676,\n",
       " 'hug': 0.672,\n",
       " 'dearest': 0.672,\n",
       " 'grin': 0.672,\n",
       " 'giggles': 0.672,\n",
       " 'relaxation': 0.672,\n",
       " 'accomplished': 0.672,\n",
       " 'enliven': 0.672,\n",
       " 'weeeee': 0.672,\n",
       " 'contentment': 0.672,\n",
       " 'bday': 0.672,\n",
       " 'hilarious': 0.672,\n",
       " 'bountiful': 0.667,\n",
       " 'boisterous': 0.667,\n",
       " 'adore': 0.667,\n",
       " 'fulfilled': 0.667,\n",
       " 'victor': 0.667,\n",
       " 'fulfill': 0.664,\n",
       " 'cuddles': 0.662,\n",
       " 'prosperous': 0.66,\n",
       " 'satisfy': 0.656,\n",
       " 'glow': 0.656,\n",
       " 'serenity': 0.656,\n",
       " 'happynewyear': 0.656,\n",
       " 'encouraged': 0.656,\n",
       " 'innerpeace': 0.656,\n",
       " 'christmaseve': 0.656,\n",
       " 'appreciation': 0.656,\n",
       " 'pleasant': 0.656,\n",
       " 'humor': 0.656,\n",
       " 'captivate': 0.656,\n",
       " 'romanticism': 0.656,\n",
       " 'besties': 0.656,\n",
       " 'praised': 0.652,\n",
       " 'fortunes': 0.652,\n",
       " 'relaxing': 0.652,\n",
       " 'abundance': 0.652,\n",
       " 'treasure': 0.652,\n",
       " 'satisfaction': 0.652,\n",
       " 'praises': 0.652,\n",
       " 'engaged': 0.652,\n",
       " 'affection': 0.647,\n",
       " 'complement': 0.647,\n",
       " 'nothingbetter': 0.647,\n",
       " 'relieved': 0.647,\n",
       " 'carnival': 0.643,\n",
       " 'saintly': 0.641,\n",
       " 'uplifting': 0.641,\n",
       " 'wedding': 0.641,\n",
       " 'divine': 0.641,\n",
       " 'harmoniously': 0.641,\n",
       " 'champion': 0.641,\n",
       " 'priceless': 0.641,\n",
       " 'achieve': 0.641,\n",
       " 'jackpot': 0.641,\n",
       " 'sensuality': 0.641,\n",
       " 'thanksgiving': 0.641,\n",
       " 'exalt': 0.636,\n",
       " 'twinkle': 0.636,\n",
       " 'comforting': 0.636,\n",
       " 'honeymoon': 0.636,\n",
       " 'cuddle': 0.636,\n",
       " 'climax': 0.636,\n",
       " 'winner': 0.636,\n",
       " 'peaceful': 0.636,\n",
       " 'reverie': 0.636,\n",
       " 'yayy': 0.636,\n",
       " 'felicity': 0.636,\n",
       " 'xoxo': 0.634,\n",
       " 'stargazing': 0.625,\n",
       " 'praisegod': 0.625,\n",
       " 'reward': 0.625,\n",
       " 'generosity': 0.625,\n",
       " 'fondness': 0.625,\n",
       " 'gorgeous': 0.625,\n",
       " 'sweet': 0.625,\n",
       " 'amusing': 0.625,\n",
       " 'hearts': 0.625,\n",
       " 'festival': 0.625,\n",
       " 'snuggling': 0.625,\n",
       " 'brighter': 0.625,\n",
       " 'sex': 0.622,\n",
       " 'beauty': 0.621,\n",
       " 'kind': 0.621,\n",
       " 'applause': 0.621,\n",
       " 'parade': 0.621,\n",
       " 'genial': 0.621,\n",
       " 'newlife': 0.618,\n",
       " 'aspiring': 0.618,\n",
       " 'fulfilling': 0.618,\n",
       " 'godbless': 0.616,\n",
       " 'virtuous': 0.613,\n",
       " 'kiss': 0.61,\n",
       " 'adorable': 0.609,\n",
       " 'awards': 0.609,\n",
       " 'rekindle': 0.609,\n",
       " 'super': 0.609,\n",
       " 'enlightenment': 0.609,\n",
       " 'rainbows': 0.609,\n",
       " 'elegance': 0.609,\n",
       " 'generous': 0.609,\n",
       " 'playful': 0.609,\n",
       " 'christmas': 0.609,\n",
       " 'praiseworthy': 0.609,\n",
       " 'winnings': 0.609,\n",
       " 'independence': 0.607,\n",
       " 'amour': 0.607,\n",
       " 'wonder': 0.606,\n",
       " 'surprises': 0.606,\n",
       " 'onelove': 0.606,\n",
       " 'freely': 0.606,\n",
       " 'hilarity': 0.606,\n",
       " 'heheh': 0.606,\n",
       " 'inspired': 0.606,\n",
       " 'kindness': 0.606,\n",
       " 'successful': 0.606,\n",
       " 'whimsical': 0.603,\n",
       " 'entertainment': 0.603,\n",
       " 'passion': 0.603,\n",
       " 'beautify': 0.601,\n",
       " 'stressfree': 0.601,\n",
       " 'sunrise': 0.6,\n",
       " 'godisgood': 0.597,\n",
       " 'goodmusic': 0.594,\n",
       " 'revere': 0.594,\n",
       " 'whoo': 0.594,\n",
       " 'angel': 0.594,\n",
       " 'flirt': 0.594,\n",
       " 'fanfare': 0.594,\n",
       " 'snuggled': 0.594,\n",
       " 'goodies': 0.594,\n",
       " 'thankgod': 0.594,\n",
       " 'inspire': 0.594,\n",
       " 'accomplishment': 0.594,\n",
       " 'peacefully': 0.594,\n",
       " 'jesus': 0.594,\n",
       " 'friendship': 0.591,\n",
       " 'highest': 0.591,\n",
       " 'heroic': 0.591,\n",
       " 'singing': 0.591,\n",
       " 'exalted': 0.591,\n",
       " 'fortune': 0.591,\n",
       " 'summer': 0.591,\n",
       " 'overflowing': 0.588,\n",
       " 'woot': 0.588,\n",
       " 'rollicking': 0.588,\n",
       " 'contented': 0.588,\n",
       " 'accolade': 0.586,\n",
       " 'hope': 0.586,\n",
       " 'cozy': 0.583,\n",
       " 'delicious': 0.579,\n",
       " 'darling': 0.578,\n",
       " 'praise': 0.578,\n",
       " 'raving': 0.578,\n",
       " 'picturesque': 0.578,\n",
       " 'sensuous': 0.578,\n",
       " 'ambition': 0.578,\n",
       " 'everlasting': 0.578,\n",
       " 'thelife': 0.578,\n",
       " 'friendly': 0.578,\n",
       " 'sparkle': 0.577,\n",
       " 'peace': 0.576,\n",
       " 'luckygirl': 0.576,\n",
       " 'flattering': 0.576,\n",
       " 'heroism': 0.576,\n",
       " 'sensual': 0.576,\n",
       " 'grace': 0.576,\n",
       " 'succeeding': 0.576,\n",
       " 'yeahhh': 0.576,\n",
       " 'livelife': 0.574,\n",
       " 'special': 0.574,\n",
       " 'tantalizing': 0.572,\n",
       " 'pumped': 0.567,\n",
       " 'admirable': 0.562,\n",
       " 'relax': 0.562,\n",
       " 'prevail': 0.562,\n",
       " 'superstar': 0.562,\n",
       " 'yey': 0.562,\n",
       " 'prosper': 0.562,\n",
       " 'surprise': 0.562,\n",
       " 'revels': 0.562,\n",
       " 'sunny': 0.562,\n",
       " 'worthwhile': 0.562,\n",
       " 'humorous': 0.562,\n",
       " 'liking': 0.562,\n",
       " 'sweets': 0.562,\n",
       " 'hero': 0.562,\n",
       " 'hugs': 0.562,\n",
       " 'freedom': 0.561,\n",
       " 'tenderness': 0.561,\n",
       " 'favorable': 0.561,\n",
       " 'newyear': 0.561,\n",
       " 'masterpiece': 0.561,\n",
       " 'bless': 0.561,\n",
       " 'dreams': 0.559,\n",
       " 'home': 0.559,\n",
       " 'hopeful': 0.559,\n",
       " 'cruising': 0.556,\n",
       " 'gracias': 0.554,\n",
       " 'faithfulness': 0.553,\n",
       " 'eagerness': 0.552,\n",
       " 'closeness': 0.552,\n",
       " 'sunshine': 0.551,\n",
       " 'comfy': 0.551,\n",
       " 'gifts': 0.547,\n",
       " 'mistletoe': 0.547,\n",
       " 'confidence': 0.547,\n",
       " 'astonishment': 0.547,\n",
       " 'goodmorning': 0.547,\n",
       " 'daughter': 0.547,\n",
       " 'vacation': 0.547,\n",
       " 'bonus': 0.547,\n",
       " 'gift': 0.547,\n",
       " 'celestial': 0.547,\n",
       " 'heart': 0.547,\n",
       " 'illuminate': 0.547,\n",
       " 'elite': 0.547,\n",
       " 'completion': 0.547,\n",
       " 'lifted': 0.547,\n",
       " 'zeal': 0.547,\n",
       " 'good': 0.547,\n",
       " 'charmed': 0.546,\n",
       " 'dance': 0.545,\n",
       " 'sublime': 0.545,\n",
       " 'god': 0.545,\n",
       " 'gush': 0.545,\n",
       " 'recreation': 0.545,\n",
       " 'encouragement': 0.545,\n",
       " 'freshstart': 0.544,\n",
       " 'free': 0.544,\n",
       " 'savior': 0.543,\n",
       " 'sanctuary': 0.541,\n",
       " 'grandchildren': 0.54,\n",
       " 'wellness': 0.537,\n",
       " 'revel': 0.534,\n",
       " 'savor': 0.531,\n",
       " 'music': 0.531,\n",
       " 'confident': 0.531,\n",
       " 'money': 0.531,\n",
       " 'holiness': 0.531,\n",
       " 'liberation': 0.531,\n",
       " 'alive': 0.531,\n",
       " 'matrimony': 0.531,\n",
       " 'vitality': 0.531,\n",
       " 'firstborn': 0.531,\n",
       " 'rainbow': 0.531,\n",
       " 'serene': 0.531,\n",
       " 'inspirational': 0.531,\n",
       " 'soar': 0.531,\n",
       " 'soothing': 0.531,\n",
       " 'dayoff': 0.531,\n",
       " 'fab': 0.531,\n",
       " 'bridal': 0.531,\n",
       " 'welcomed': 0.53,\n",
       " 'mastery': 0.53,\n",
       " 'illumination': 0.53,\n",
       " 'warmth': 0.53,\n",
       " 'elegant': 0.53,\n",
       " 'blossom': 0.53,\n",
       " 'glimmer': 0.53,\n",
       " 'treat': 0.529,\n",
       " 'faithful': 0.529,\n",
       " 'snuggles': 0.522,\n",
       " 'laurels': 0.521,\n",
       " 'commendable': 0.519,\n",
       " 'silly': 0.516,\n",
       " 'remarkable': 0.516,\n",
       " 'jingle': 0.516,\n",
       " 'zest': 0.516,\n",
       " 'aspire': 0.516,\n",
       " 'noschool': 0.516,\n",
       " 'pride': 0.516,\n",
       " 'brotherly': 0.516,\n",
       " 'almighty': 0.516,\n",
       " 'resplendent': 0.516,\n",
       " 'fancy': 0.516,\n",
       " 'abundant': 0.516,\n",
       " 'succeed': 0.516,\n",
       " 'presents': 0.516,\n",
       " 'greeted': 0.516,\n",
       " 'powerful': 0.516,\n",
       " 'strengthening': 0.516,\n",
       " 'payday': 0.515,\n",
       " 'reunited': 0.515,\n",
       " 'comfort': 0.515,\n",
       " 'spirit': 0.515,\n",
       " 'princely': 0.515,\n",
       " 'coronation': 0.515,\n",
       " 'complete': 0.515,\n",
       " 'newme': 0.515,\n",
       " 'animated': 0.515,\n",
       " 'therapeutic': 0.515,\n",
       " 'leisure': 0.515,\n",
       " 'kid': 0.515,\n",
       " 'kudos': 0.515,\n",
       " 'shining': 0.515,\n",
       " 'zen': 0.515,\n",
       " 'vivid': 0.515,\n",
       " 'cutie': 0.515,\n",
       " 'thanking': 0.515,\n",
       " 'familytime': 0.515,\n",
       " 'godly': 0.514,\n",
       " 'marriage': 0.514,\n",
       " 'relationship': 0.514,\n",
       " 'daymade': 0.514,\n",
       " 'spouse': 0.507,\n",
       " 'intimately': 0.507,\n",
       " 'visionary': 0.5,\n",
       " 'respect': 0.5,\n",
       " 'nature': 0.5,\n",
       " 'holyspirit': 0.5,\n",
       " 'meritorious': 0.5,\n",
       " 'soulful': 0.5,\n",
       " 'refreshed': 0.5,\n",
       " 'motherhood': 0.5,\n",
       " 'family': 0.5,\n",
       " 'stressrelief': 0.5,\n",
       " 'achieved': 0.5,\n",
       " 'diamond': 0.5,\n",
       " 'teamjesus': 0.5,\n",
       " 'satisfied': 0.5,\n",
       " 'memorable': 0.5,\n",
       " 'encourage': 0.5,\n",
       " 'veracity': 0.5,\n",
       " 'gem': 0.5,\n",
       " 'baby': 0.5,\n",
       " 'dignity': 0.5,\n",
       " 'welcoming': 0.5,\n",
       " 'excel': 0.5,\n",
       " 'healthy': 0.5,\n",
       " 'beach': 0.5,\n",
       " 'charitable': 0.5,\n",
       " 'inviting': 0.5,\n",
       " 'erotic': 0.5,\n",
       " 'bloom': 0.5,\n",
       " 'christ': 0.5,\n",
       " 'accomplish': 0.5,\n",
       " 'carefree': 0.5,\n",
       " 'friends': 0.5,\n",
       " 'purr': 0.5,\n",
       " 'surreal': 0.5,\n",
       " 'health': 0.493,\n",
       " 'aura': 0.493,\n",
       " 'oasis': 0.486,\n",
       " 'approved': 0.486,\n",
       " 'liberty': 0.486,\n",
       " 'yehey': 0.486,\n",
       " 'prestige': 0.485,\n",
       " 'aspiration': 0.485,\n",
       " 'inseparable': 0.485,\n",
       " 'crescendo': 0.485,\n",
       " 'betrothed': 0.485,\n",
       " 'crowning': 0.485,\n",
       " 'loyal': 0.485,\n",
       " 'bounty': 0.485,\n",
       " 'privileged': 0.485,\n",
       " 'liberate': 0.485,\n",
       " 'rapture': 0.485,\n",
       " 'gentle': 0.485,\n",
       " 'engaging': 0.485,\n",
       " 'nocomplaints': 0.485,\n",
       " 'selfworth': 0.484,\n",
       " 'desire': 0.484,\n",
       " 'luck': 0.484,\n",
       " 'aloha': 0.484,\n",
       " 'trophy': 0.484,\n",
       " 'chocolate': 0.484,\n",
       " 'transcendence': 0.484,\n",
       " 'yummy': 0.484,\n",
       " 'datenight': 0.484,\n",
       " 'fete': 0.484,\n",
       " 'creativity': 0.484,\n",
       " 'heyday': 0.484,\n",
       " 'bouquet': 0.484,\n",
       " 'dream': 0.484,\n",
       " 'destiny': 0.484,\n",
       " 'boyfriend': 0.48,\n",
       " 'commemoration': 0.479,\n",
       " 'intelligence': 0.477,\n",
       " 'readiness': 0.473,\n",
       " 'bride': 0.471,\n",
       " 'friend': 0.471,\n",
       " 'enthusiast': 0.471,\n",
       " 'calming': 0.47,\n",
       " 'massage': 0.47,\n",
       " 'nostalgia': 0.47,\n",
       " 'adventure': 0.47,\n",
       " 'lush': 0.47,\n",
       " 'tickle': 0.47,\n",
       " 'inheritance': 0.47,\n",
       " 'kiddo': 0.47,\n",
       " 'soothe': 0.47,\n",
       " 'luster': 0.469,\n",
       " 'eternal': 0.469,\n",
       " 'purring': 0.469,\n",
       " 'heartily': 0.469,\n",
       " 'bonding': 0.469,\n",
       " 'princess': 0.469,\n",
       " 'rest': 0.469,\n",
       " 'humanitarian': 0.469,\n",
       " 'benevolence': 0.469,\n",
       " 'goals': 0.469,\n",
       " 'amicable': 0.469,\n",
       " 'bridegroom': 0.469,\n",
       " 'nurture': 0.469,\n",
       " 'pretty': 0.469,\n",
       " 'giving': 0.469,\n",
       " 'pray': 0.469,\n",
       " 'getaway': 0.469,\n",
       " 'child': 0.466,\n",
       " 'salutary': 0.465,\n",
       " 'invite': 0.457,\n",
       " 'beam': 0.456,\n",
       " 'reminiscing': 0.456,\n",
       " 'friday': 0.455,\n",
       " 'aesthetics': 0.455,\n",
       " 'hee': 0.455,\n",
       " 'ceremony': 0.455,\n",
       " 'scholarship': 0.455,\n",
       " 'befriend': 0.455,\n",
       " 'mindfulness': 0.455,\n",
       " 'elevation': 0.455,\n",
       " 'kindred': 0.455,\n",
       " 'freshair': 0.455,\n",
       " 'tropical': 0.455,\n",
       " 'sonice': 0.455,\n",
       " 'faith': 0.453,\n",
       " 'allure': 0.453,\n",
       " 'noworries': 0.453,\n",
       " 'commemorate': 0.453,\n",
       " 'vindication': 0.453,\n",
       " 'namaste': 0.453,\n",
       " 'forgiveness': 0.453,\n",
       " 'waterfall': 0.453,\n",
       " 'approve': 0.453,\n",
       " 'birth': 0.453,\n",
       " 'scenery': 0.453,\n",
       " 'journey': 0.447,\n",
       " 'meditation': 0.446,\n",
       " 'relaxed': 0.442,\n",
       " 'tender': 0.441,\n",
       " 'weekend': 0.441,\n",
       " 'tranquil': 0.441,\n",
       " 'present': 0.441,\n",
       " 'sharing': 0.439,\n",
       " 'lyrical': 0.439,\n",
       " 'righteousness': 0.439,\n",
       " 'esteem': 0.439,\n",
       " 'prayer': 0.439,\n",
       " 'nostalgic': 0.439,\n",
       " 'relief': 0.438,\n",
       " 'eager': 0.438,\n",
       " 'life': 0.438,\n",
       " 'husband': 0.438,\n",
       " 'mighty': 0.438,\n",
       " 'unbeaten': 0.438,\n",
       " 'meditate': 0.438,\n",
       " 'strength': 0.438,\n",
       " 'newday': 0.438,\n",
       " 'sonnet': 0.438,\n",
       " 'share': 0.438,\n",
       " 'warm': 0.429,\n",
       " 'winterbreak': 0.429,\n",
       " 'movingforward': 0.429,\n",
       " 'buddy': 0.427,\n",
       " 'oneness': 0.426,\n",
       " 'reverence': 0.424,\n",
       " 'ejaculation': 0.424,\n",
       " 'thelittlethings': 0.424,\n",
       " 'carols': 0.424,\n",
       " 'amen': 0.424,\n",
       " 'healthful': 0.424,\n",
       " 'medal': 0.424,\n",
       " 'unconstrained': 0.424,\n",
       " 'unsurpassed': 0.424,\n",
       " 'candlelight': 0.424,\n",
       " 'symphony': 0.422,\n",
       " 'calmness': 0.422,\n",
       " 'lml': 0.422,\n",
       " 'helpful': 0.422,\n",
       " 'graduation': 0.422,\n",
       " 'ease': 0.422,\n",
       " 'energy': 0.422,\n",
       " 'musical': 0.422,\n",
       " 'safe': 0.422,\n",
       " 'frisky': 0.422,\n",
       " 'sledding': 0.422,\n",
       " 'wealth': 0.422,\n",
       " 'glitter': 0.422,\n",
       " 'beginnings': 0.422,\n",
       " 'soundness': 0.421,\n",
       " 'nostress': 0.421,\n",
       " 'promise': 0.415,\n",
       " 'reunite': 0.414,\n",
       " 'salvation': 0.412,\n",
       " 'mother': 0.412,\n",
       " 'poems': 0.412,\n",
       " 'lighten': 0.409,\n",
       " 'lavender': 0.409,\n",
       " 'aromatherapy': 0.409,\n",
       " 'inauguration': 0.409,\n",
       " 'travel': 0.409,\n",
       " 'clown': 0.409,\n",
       " 'purify': 0.409,\n",
       " 'immaculate': 0.409,\n",
       " 'charity': 0.406,\n",
       " 'wishing': 0.406,\n",
       " 'heal': 0.406,\n",
       " 'live': 0.406,\n",
       " 'star': 0.406,\n",
       " 'companion': 0.406,\n",
       " 'flowers': 0.406,\n",
       " 'cash': 0.406,\n",
       " 'completing': 0.406,\n",
       " 'opportune': 0.406,\n",
       " 'income': 0.403,\n",
       " 'soul': 0.401,\n",
       " 'munchies': 0.4,\n",
       " 'christian': 0.397,\n",
       " 'indescribable': 0.397,\n",
       " 'progress': 0.397,\n",
       " 'emancipation': 0.397,\n",
       " 'calm': 0.394,\n",
       " 'picnic': 0.394,\n",
       " 'hammock': 0.394,\n",
       " 'rhythmical': 0.394,\n",
       " 'equality': 0.394,\n",
       " 'together': 0.394,\n",
       " 'childhood': 0.394,\n",
       " 'fullness': 0.394,\n",
       " 'zealous': 0.393,\n",
       " 'movies': 0.393,\n",
       " 'humanity': 0.391,\n",
       " 'playground': 0.391,\n",
       " 'starry': 0.391,\n",
       " 'affluence': 0.391,\n",
       " 'meaningful': 0.391,\n",
       " 'adventures': 0.391,\n",
       " 'choir': 0.391,\n",
       " 'warms': 0.391,\n",
       " 'littlethings': 0.391,\n",
       " 'auspicious': 0.391,\n",
       " 'goofy': 0.391,\n",
       " 'gesture': 0.387,\n",
       " 'shopping': 0.382,\n",
       " 'vow': 0.382,\n",
       " 'witty': 0.382,\n",
       " 'communion': 0.379,\n",
       " 'worship': 0.379,\n",
       " 'vibes': 0.379,\n",
       " 'jump': 0.379,\n",
       " 'reverend': 0.377,\n",
       " 'experience': 0.375,\n",
       " 'full': 0.375,\n",
       " 'reunion': 0.375,\n",
       " 'rising': 0.375,\n",
       " 'redeemed': 0.375,\n",
       " 'youth': 0.375,\n",
       " 'simplicity': 0.375,\n",
       " 'advance': 0.375,\n",
       " 'courtship': 0.375,\n",
       " 'scenic': 0.375,\n",
       " 'spirits': 0.375,\n",
       " 'beaches': 0.375,\n",
       " 'hymn': 0.375,\n",
       " 'sonorous': 0.375,\n",
       " 'mirth': 0.375,\n",
       " 'unique': 0.375,\n",
       " 'unforgettable': 0.375,\n",
       " 'baptismal': 0.368,\n",
       " 'alliance': 0.368,\n",
       " 'grant': 0.366,\n",
       " 'moonlight': 0.364,\n",
       " 'improve': 0.364,\n",
       " 'conciliation': 0.364,\n",
       " 'pure': 0.364,\n",
       " 'sanctification': 0.364,\n",
       " 'authentic': 0.364,\n",
       " 'kitten': 0.364,\n",
       " 'improves': 0.364,\n",
       " 'weightloss': 0.362,\n",
       " 'raspberries': 0.36,\n",
       " 'listenting': 0.359,\n",
       " 'proficiency': 0.359,\n",
       " 'revival': 0.359,\n",
       " 'sanctify': 0.359,\n",
       " 'fidelity': 0.359,\n",
       " 'jest': 0.359,\n",
       " 'tinsel': 0.359,\n",
       " 'feeling': 0.359,\n",
       " 'independent': 0.359,\n",
       " 'devotional': 0.359,\n",
       " 'giver': 0.353,\n",
       " 'cocoa': 0.353,\n",
       " 'romp': 0.348,\n",
       " 'melody': 0.348,\n",
       " 'choral': 0.348,\n",
       " 'unification': 0.348,\n",
       " 'dolphin': 0.348,\n",
       " 'favor': 0.348,\n",
       " 'roaring': 0.348,\n",
       " 'exceed': 0.348,\n",
       " 'purpose': 0.348,\n",
       " 'deliverance': 0.348,\n",
       " 'hotyoga': 0.347,\n",
       " 'thx': 0.344,\n",
       " 'roadtrip': 0.344,\n",
       " 'kiddos': 0.344,\n",
       " 'manicure': 0.344,\n",
       " 'newstart': 0.344,\n",
       " 'date': 0.344,\n",
       " 'voluptuous': 0.344,\n",
       " 'hedonism': 0.344,\n",
       " 'pledge': 0.344,\n",
       " 'cookies': 0.344,\n",
       " 'fruits': 0.344,\n",
       " 'electric': 0.344,\n",
       " 'nowork': 0.344,\n",
       " 'humble': 0.344,\n",
       " 'celebrity': 0.342,\n",
       " 'rhythm': 0.338,\n",
       " 'bridesmaid': 0.338,\n",
       " 'obliging': 0.333,\n",
       " 'dawn': 0.333,\n",
       " 'gazing': 0.333,\n",
       " 'snowday': 0.333,\n",
       " 'edification': 0.333,\n",
       " 'young': 0.333,\n",
       " 'connoisseur': 0.333,\n",
       " 'partner': 0.333,\n",
       " 'spa': 0.333,\n",
       " 'coffee': 0.333,\n",
       " 'renovation': 0.333,\n",
       " 'garden': 0.333,\n",
       " 'familiarity': 0.333,\n",
       " 'foodie': 0.331,\n",
       " 'synchronize': 0.329,\n",
       " 'pedicure': 0.328,\n",
       " 'noregrets': 0.328,\n",
       " 'hobby': 0.328,\n",
       " 'amnesty': 0.328,\n",
       " 'true': 0.328,\n",
       " 'chirping': 0.328,\n",
       " 'psalm': 0.328,\n",
       " 'saint': 0.328,\n",
       " 'healing': 0.328,\n",
       " 'tribulation': 0.328,\n",
       " 'carol': 0.328,\n",
       " 'respite': 0.324,\n",
       " 'restorative': 0.318,\n",
       " 'cousins': 0.318,\n",
       " 'recreational': 0.318,\n",
       " 'mellow': 0.318,\n",
       " 'lazyday': 0.318,\n",
       " 'classics': 0.318,\n",
       " 'reconciliation': 0.316,\n",
       " 'pony': 0.312,\n",
       " 'muchneeded': 0.312,\n",
       " 'recovery': 0.312,\n",
       " 'presto': 0.312,\n",
       " 'fitness': 0.312,\n",
       " 'relight': 0.312,\n",
       " 'progression': 0.312,\n",
       " 'crafts': 0.312,\n",
       " 'deal': 0.312,\n",
       " 'woods': 0.312,\n",
       " 'lord': 0.312,\n",
       " 'playhouse': 0.312,\n",
       " 'sterling': 0.312,\n",
       " 'sunset': 0.312,\n",
       " 'wisdom': 0.312,\n",
       " 'superman': 0.312,\n",
       " 'dove': 0.312,\n",
       " 'living': 0.312,\n",
       " 'simplify': 0.312,\n",
       " 'improvement': 0.309,\n",
       " 'infant': 0.309,\n",
       " 'absolution': 0.306,\n",
       " 'honest': 0.303,\n",
       " 'established': 0.303,\n",
       " 'banquet': 0.303,\n",
       " 'endless': 0.303,\n",
       " 'decorating': 0.303,\n",
       " 'gently': 0.303,\n",
       " 'providing': 0.3,\n",
       " 'breeze': 0.297,\n",
       " 'yearning': 0.297,\n",
       " 'joker': 0.297,\n",
       " ...}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_intensities = get_word_affect_intensity_dict(emotion)\n",
    "word_intensities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly_emo_int = PolynomialFeatures(10)\n",
    "\n",
    "def get_emo_int_vector(tweet):\n",
    "    score = 0.0\n",
    "    for word in word_intensities.keys():\n",
    "        if word in tweet:\n",
    "            score += tweet.count(word) * float(word_intensities[word])\n",
    "    return normalize(poly_emo_int.fit_transform(np.array([score]).reshape(1, -1))[0].reshape(1, -1))[0]\n",
    "    # return [score]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_emo_int_vector(\"furious\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3) SentiWordNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import sentiwordnet as swn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly_sentiwordnet = PolynomialFeatures(5)\n",
    "\n",
    "def get_sentiwordnetscore(tweet):\n",
    "    \n",
    "    score = np.zeros(2)\n",
    "    \n",
    "    for word in tweet.split():\n",
    "        synsetlist = list(swn.senti_synsets(word))\n",
    "        \n",
    "        if synsetlist:\n",
    "            score[0] += synsetlist[0].pos_score()\n",
    "            score[1] += synsetlist[0].neg_score()\n",
    "            \n",
    "#     return tweet_score.tolist()\n",
    "    return normalize(poly_sentiwordnet.fit_transform(np.array([score]).reshape(1, -1))[0].reshape(1, -1))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9.37500185e-01, 2.34375046e-01, 2.34375046e-01, 5.85937616e-02,\n",
       "       5.85937616e-02, 5.85937616e-02, 1.46484404e-02, 1.46484404e-02,\n",
       "       1.46484404e-02, 1.46484404e-02, 3.66211010e-03, 3.66211010e-03,\n",
       "       3.66211010e-03, 3.66211010e-03, 3.66211010e-03, 9.15527525e-04,\n",
       "       9.15527525e-04, 9.15527525e-04, 9.15527525e-04, 9.15527525e-04,\n",
       "       9.15527525e-04])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_sentiwordnetscore(\"furious\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4) Sentiment Emotion Presence Lexicon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_emotion_lex_file_path = ('%s%s/' %(lexicons_path, paths2[2])) + listdir('%s%s/' %(lexicons_path, paths2[2]))[0]\n",
    "\n",
    "def get_affect_presence_list(emotion):\n",
    "    word_list = list()\n",
    "    \n",
    "    with open(sentiment_emotion_lex_file_path) as sentiment_emotion_lex_file:\n",
    "        lines = sentiment_emotion_lex_file.readlines()[1:] \n",
    "        for line in lines:\n",
    "            word_array = line.replace(\"\\n\", \"\").split(\"\\t\")\n",
    "\n",
    "            if (word_array[1] == emotion and word_array[2] == '1'):\n",
    "                word_list.append(word_array[0])\n",
    "                \n",
    "    return word_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['absolution',\n",
       " 'abundance',\n",
       " 'abundant',\n",
       " 'accolade',\n",
       " 'accompaniment',\n",
       " 'accomplish',\n",
       " 'accomplished',\n",
       " 'achieve',\n",
       " 'achievement',\n",
       " 'acrobat',\n",
       " 'admirable',\n",
       " 'admiration',\n",
       " 'adorable',\n",
       " 'adoration',\n",
       " 'adore',\n",
       " 'advance',\n",
       " 'advent',\n",
       " 'advocacy',\n",
       " 'aesthetics',\n",
       " 'affection',\n",
       " 'affluence',\n",
       " 'alive',\n",
       " 'allure',\n",
       " 'aloha',\n",
       " 'amazingly',\n",
       " 'ambition',\n",
       " 'amen',\n",
       " 'amicable',\n",
       " 'amnesty',\n",
       " 'amour',\n",
       " 'amuse',\n",
       " 'amused',\n",
       " 'amusement',\n",
       " 'amusing',\n",
       " 'angel',\n",
       " 'angelic',\n",
       " 'animated',\n",
       " 'applause',\n",
       " 'appreciation',\n",
       " 'approve',\n",
       " 'ardent',\n",
       " 'art',\n",
       " 'aspiration',\n",
       " 'aspire',\n",
       " 'aspiring',\n",
       " 'astonishment',\n",
       " 'atone',\n",
       " 'auspicious',\n",
       " 'authentic',\n",
       " 'award',\n",
       " 'baby',\n",
       " 'balm',\n",
       " 'banquet',\n",
       " 'baptismal',\n",
       " 'basketball',\n",
       " 'beach',\n",
       " 'beam',\n",
       " 'beaming',\n",
       " 'beautification',\n",
       " 'beautiful',\n",
       " 'beautify',\n",
       " 'beauty',\n",
       " 'beer',\n",
       " 'befriend',\n",
       " 'benevolence',\n",
       " 'benign',\n",
       " 'betrothed',\n",
       " 'birth',\n",
       " 'birthday',\n",
       " 'bless',\n",
       " 'blessed',\n",
       " 'blessing',\n",
       " 'blessings',\n",
       " 'bliss',\n",
       " 'blissful',\n",
       " 'bloom',\n",
       " 'blossom',\n",
       " 'boisterous',\n",
       " 'bonanza',\n",
       " 'bonus',\n",
       " 'bountiful',\n",
       " 'bounty',\n",
       " 'bouquet',\n",
       " 'bridal',\n",
       " 'bride',\n",
       " 'bridegroom',\n",
       " 'bridesmaid',\n",
       " 'brighten',\n",
       " 'brilliant',\n",
       " 'brotherly',\n",
       " 'buddy',\n",
       " 'buss',\n",
       " 'calf',\n",
       " 'candid',\n",
       " 'captivate',\n",
       " 'carol',\n",
       " 'cash',\n",
       " 'cathedral',\n",
       " 'celebrated',\n",
       " 'celebrating',\n",
       " 'celebration',\n",
       " 'celebrity',\n",
       " 'celestial',\n",
       " 'ceremony',\n",
       " 'champion',\n",
       " 'chant',\n",
       " 'charitable',\n",
       " 'charity',\n",
       " 'charmed',\n",
       " 'cheer',\n",
       " 'cheerful',\n",
       " 'cheerfulness',\n",
       " 'cheering',\n",
       " 'cheery',\n",
       " 'cherish',\n",
       " 'child',\n",
       " 'childhood',\n",
       " 'chirp',\n",
       " 'chocolate',\n",
       " 'choir',\n",
       " 'choral',\n",
       " 'chuckle',\n",
       " 'church',\n",
       " 'civilized',\n",
       " 'clap',\n",
       " 'classics',\n",
       " 'clean',\n",
       " 'climax',\n",
       " 'closeness',\n",
       " 'closure',\n",
       " 'clown',\n",
       " 'comfort',\n",
       " 'commemorate',\n",
       " 'commemoration',\n",
       " 'commendable',\n",
       " 'communion',\n",
       " 'companion',\n",
       " 'compensate',\n",
       " 'complement',\n",
       " 'completing',\n",
       " 'completion',\n",
       " 'compliment',\n",
       " 'conciliation',\n",
       " 'confidence',\n",
       " 'confident',\n",
       " 'congratulatory',\n",
       " 'connoisseur',\n",
       " 'consecration',\n",
       " 'content',\n",
       " 'coronation',\n",
       " 'courtship',\n",
       " 'cove',\n",
       " 'cradle',\n",
       " 'cream',\n",
       " 'create',\n",
       " 'crescendo',\n",
       " 'crowning',\n",
       " 'cuddle',\n",
       " 'dance',\n",
       " 'darling',\n",
       " 'daughter',\n",
       " 'dawn',\n",
       " 'deal',\n",
       " 'delicious',\n",
       " 'delight',\n",
       " 'delighted',\n",
       " 'delightful',\n",
       " 'deliverance',\n",
       " 'demonstrative',\n",
       " 'destination',\n",
       " 'devout',\n",
       " 'diamond',\n",
       " 'diary',\n",
       " 'ditty',\n",
       " 'doll',\n",
       " 'dolphin',\n",
       " 'dove',\n",
       " 'eager',\n",
       " 'eagerness',\n",
       " 'ecstasy',\n",
       " 'ecstatic',\n",
       " 'edification',\n",
       " 'ejaculation',\n",
       " 'elated',\n",
       " 'electric',\n",
       " 'elegance',\n",
       " 'elegant',\n",
       " 'elevation',\n",
       " 'elite',\n",
       " 'emancipation',\n",
       " 'embrace',\n",
       " 'enchant',\n",
       " 'enchanted',\n",
       " 'enchanting',\n",
       " 'encourage',\n",
       " 'endless',\n",
       " 'engaged',\n",
       " 'engaging',\n",
       " 'enjoy',\n",
       " 'enjoying',\n",
       " 'enlighten',\n",
       " 'enlightenment',\n",
       " 'enliven',\n",
       " 'entertain',\n",
       " 'entertained',\n",
       " 'entertaining',\n",
       " 'entertainment',\n",
       " 'enthusiasm',\n",
       " 'enthusiast',\n",
       " 'equality',\n",
       " 'erotic',\n",
       " 'established',\n",
       " 'esteem',\n",
       " 'evergreen',\n",
       " 'exalt',\n",
       " 'exaltation',\n",
       " 'exalted',\n",
       " 'exceed',\n",
       " 'excel',\n",
       " 'excellence',\n",
       " 'excellent',\n",
       " 'excitation',\n",
       " 'excite',\n",
       " 'excited',\n",
       " 'excitement',\n",
       " 'exciting',\n",
       " 'exhilaration',\n",
       " 'expedient',\n",
       " 'exquisite',\n",
       " 'exuberance',\n",
       " 'fain',\n",
       " 'faith',\n",
       " 'familiarity',\n",
       " 'fancy',\n",
       " 'fanfare',\n",
       " 'favorable',\n",
       " 'favorite',\n",
       " 'feat',\n",
       " 'feeling',\n",
       " 'felicity',\n",
       " 'fervor',\n",
       " 'festival',\n",
       " 'festive',\n",
       " 'fete',\n",
       " 'fidelity',\n",
       " 'fiesta',\n",
       " 'finally',\n",
       " 'firstborn',\n",
       " 'fitting',\n",
       " 'flattering',\n",
       " 'flirt',\n",
       " 'fondness',\n",
       " 'food',\n",
       " 'football',\n",
       " 'forefathers',\n",
       " 'fortitude',\n",
       " 'fortune',\n",
       " 'found',\n",
       " 'fraternal',\n",
       " 'freedom',\n",
       " 'freely',\n",
       " 'friend',\n",
       " 'friendliness',\n",
       " 'friendly',\n",
       " 'friendship',\n",
       " 'frisky',\n",
       " 'frolic',\n",
       " 'fulfill',\n",
       " 'fulfillment',\n",
       " 'fun',\n",
       " 'gain',\n",
       " 'garden',\n",
       " 'gem',\n",
       " 'generosity',\n",
       " 'generous',\n",
       " 'genial',\n",
       " 'gift',\n",
       " 'giggle',\n",
       " 'glad',\n",
       " 'gladness',\n",
       " 'glee',\n",
       " 'glide',\n",
       " 'glimmer',\n",
       " 'glitter',\n",
       " 'glorification',\n",
       " 'glorify',\n",
       " 'glory',\n",
       " 'glow',\n",
       " 'god',\n",
       " 'godly',\n",
       " 'godsend',\n",
       " 'good',\n",
       " 'goodness',\n",
       " 'gorgeous',\n",
       " 'graduation',\n",
       " 'grandchildren',\n",
       " 'grant',\n",
       " 'gratify',\n",
       " 'gratitude',\n",
       " 'greatness',\n",
       " 'green',\n",
       " 'grin',\n",
       " 'grow',\n",
       " 'gush',\n",
       " 'happily',\n",
       " 'happiness',\n",
       " 'happy',\n",
       " 'hardy',\n",
       " 'harmoniously',\n",
       " 'harmony',\n",
       " 'harvest',\n",
       " 'heal',\n",
       " 'healing',\n",
       " 'healthful',\n",
       " 'heartfelt',\n",
       " 'heartily',\n",
       " 'heavenly',\n",
       " 'heavens',\n",
       " 'hedonism',\n",
       " 'helpful',\n",
       " 'hero',\n",
       " 'heroic',\n",
       " 'heroism',\n",
       " 'heyday',\n",
       " 'highest',\n",
       " 'hilarious',\n",
       " 'hilarity',\n",
       " 'hire',\n",
       " 'hobby',\n",
       " 'holiday',\n",
       " 'holiness',\n",
       " 'honest',\n",
       " 'honeymoon',\n",
       " 'hope',\n",
       " 'hopeful',\n",
       " 'hug',\n",
       " 'humanitarian',\n",
       " 'humanity',\n",
       " 'humorous',\n",
       " 'hurrah',\n",
       " 'hymn',\n",
       " 'illuminate',\n",
       " 'illumination',\n",
       " 'immaculate',\n",
       " 'immerse',\n",
       " 'improve',\n",
       " 'improvement',\n",
       " 'inauguration',\n",
       " 'income',\n",
       " 'independence',\n",
       " 'infant',\n",
       " 'infinity',\n",
       " 'inheritance',\n",
       " 'inseparable',\n",
       " 'inspiration',\n",
       " 'inspire',\n",
       " 'inspired',\n",
       " 'intelligence',\n",
       " 'intense',\n",
       " 'intimate',\n",
       " 'intimately',\n",
       " 'invite',\n",
       " 'inviting',\n",
       " 'jackpot',\n",
       " 'jest',\n",
       " 'joker',\n",
       " 'journey',\n",
       " 'jovial',\n",
       " 'joy',\n",
       " 'joyful',\n",
       " 'joyous',\n",
       " 'jubilant',\n",
       " 'jubilee',\n",
       " 'jump',\n",
       " 'kind',\n",
       " 'kindred',\n",
       " 'kiss',\n",
       " 'kitten',\n",
       " 'kudos',\n",
       " 'labor',\n",
       " 'lamb',\n",
       " 'laugh',\n",
       " 'laughing',\n",
       " 'laughter',\n",
       " 'laurels',\n",
       " 'legalized',\n",
       " 'leisure',\n",
       " 'liberate',\n",
       " 'liberation',\n",
       " 'liberty',\n",
       " 'liking',\n",
       " 'liquor',\n",
       " 'lovable',\n",
       " 'love',\n",
       " 'lovely',\n",
       " 'lovemaking',\n",
       " 'lover',\n",
       " 'loving',\n",
       " 'loyal',\n",
       " 'luck',\n",
       " 'lucky',\n",
       " 'luscious',\n",
       " 'luster',\n",
       " 'luxurious',\n",
       " 'luxury',\n",
       " 'lyre',\n",
       " 'lyrical',\n",
       " 'magical',\n",
       " 'magnificence',\n",
       " 'magnificent',\n",
       " 'majestic',\n",
       " 'majority',\n",
       " 'marriage',\n",
       " 'marrow',\n",
       " 'marry',\n",
       " 'marvelous',\n",
       " 'marvelously',\n",
       " 'massage',\n",
       " 'masterpiece',\n",
       " 'mastery',\n",
       " 'matrimony',\n",
       " 'medal',\n",
       " 'meditate',\n",
       " 'memorable',\n",
       " 'meritorious',\n",
       " 'merriment',\n",
       " 'merry',\n",
       " 'midwife',\n",
       " 'mighty',\n",
       " 'ministry',\n",
       " 'miracle',\n",
       " 'miraculous',\n",
       " 'mirth',\n",
       " 'money',\n",
       " 'morals',\n",
       " 'mother',\n",
       " 'motherhood',\n",
       " 'music',\n",
       " 'musical',\n",
       " 'nap',\n",
       " 'notable',\n",
       " 'nursery',\n",
       " 'nurture',\n",
       " 'oasis',\n",
       " 'obliging',\n",
       " 'obtainable',\n",
       " 'opera',\n",
       " 'opportune',\n",
       " 'optimism',\n",
       " 'orchestra',\n",
       " 'ordination',\n",
       " 'organ',\n",
       " 'organization',\n",
       " 'orgasm',\n",
       " 'outburst',\n",
       " 'outstanding',\n",
       " 'overjoyed',\n",
       " 'parade',\n",
       " 'paragon',\n",
       " 'passion',\n",
       " 'passionate',\n",
       " 'pastor',\n",
       " 'pastry',\n",
       " 'pay',\n",
       " 'peace',\n",
       " 'peaceful',\n",
       " 'perfect',\n",
       " 'perfection',\n",
       " 'picnic',\n",
       " 'picturesque',\n",
       " 'playful',\n",
       " 'playground',\n",
       " 'playhouse',\n",
       " 'pleasant',\n",
       " 'pleased',\n",
       " 'pleasurable',\n",
       " 'pledge',\n",
       " 'possess',\n",
       " 'powerful',\n",
       " 'practiced',\n",
       " 'praise',\n",
       " 'praised',\n",
       " 'praiseworthy',\n",
       " 'pray',\n",
       " 'precious',\n",
       " 'present',\n",
       " 'preservative',\n",
       " 'prestige',\n",
       " 'presto',\n",
       " 'pretty',\n",
       " 'prevail',\n",
       " 'pride',\n",
       " 'priesthood',\n",
       " 'princely',\n",
       " 'privileged',\n",
       " 'procession',\n",
       " 'proficiency',\n",
       " 'progress',\n",
       " 'progression',\n",
       " 'promise',\n",
       " 'prosper',\n",
       " 'prosperous',\n",
       " 'proud',\n",
       " 'providing',\n",
       " 'purify',\n",
       " 'purr',\n",
       " 'quaint',\n",
       " 'radiance',\n",
       " 'radiant',\n",
       " 'rapt',\n",
       " 'rapture',\n",
       " 'rave',\n",
       " 'raving',\n",
       " 'readiness',\n",
       " 'receiving',\n",
       " 'reconciliation',\n",
       " 'recreation',\n",
       " 'recreational',\n",
       " 'rejoice',\n",
       " 'rejoicing',\n",
       " 'rekindle',\n",
       " 'remarkable',\n",
       " 'remedy',\n",
       " 'renovation',\n",
       " 'repay',\n",
       " 'reproductive',\n",
       " 'rescue',\n",
       " 'resources',\n",
       " 'respect',\n",
       " 'respite',\n",
       " 'resplendent',\n",
       " 'restorative',\n",
       " 'retirement',\n",
       " 'revel',\n",
       " 'revels',\n",
       " 'revere',\n",
       " 'reverence',\n",
       " 'reverend',\n",
       " 'reverie',\n",
       " 'revival',\n",
       " 'reward',\n",
       " 'rhythmical',\n",
       " 'ribbon',\n",
       " 'rising',\n",
       " 'roadster',\n",
       " 'rollicking',\n",
       " 'romance',\n",
       " 'romantic',\n",
       " 'romanticism',\n",
       " 'romp',\n",
       " 'safe',\n",
       " 'saint',\n",
       " 'saintly',\n",
       " 'salary',\n",
       " 'salutary',\n",
       " 'salute',\n",
       " 'salvation',\n",
       " 'sanctification',\n",
       " 'sanctify',\n",
       " 'sanctuary',\n",
       " 'satisfied',\n",
       " 'save',\n",
       " 'savor',\n",
       " 'scholarship',\n",
       " 'score',\n",
       " 'sensational',\n",
       " 'sensual',\n",
       " 'sensuality',\n",
       " 'sensuous',\n",
       " 'serenity',\n",
       " 'sex',\n",
       " 'share',\n",
       " 'shining',\n",
       " 'shopping',\n",
       " 'silly',\n",
       " 'simplify',\n",
       " 'sing',\n",
       " 'smile',\n",
       " 'smiling',\n",
       " 'sonnet',\n",
       " 'sonorous',\n",
       " 'soothing',\n",
       " 'soundness',\n",
       " 'spa',\n",
       " 'spaniel',\n",
       " 'sparkle',\n",
       " 'special',\n",
       " 'spirits',\n",
       " 'splendid',\n",
       " 'splendor',\n",
       " 'spouse',\n",
       " 'star',\n",
       " 'starry',\n",
       " 'sterling',\n",
       " 'strengthening',\n",
       " 'sublimation',\n",
       " 'succeed',\n",
       " 'succeeding',\n",
       " 'success',\n",
       " 'successful',\n",
       " 'sun',\n",
       " 'sunny',\n",
       " 'sunshine',\n",
       " 'superman',\n",
       " 'superstar',\n",
       " 'supporter',\n",
       " 'supremacy',\n",
       " 'surprise',\n",
       " 'sweet',\n",
       " 'sweetheart',\n",
       " 'sweets',\n",
       " 'swim',\n",
       " 'symmetry',\n",
       " 'sympathetic',\n",
       " 'symphony',\n",
       " 'synchronize',\n",
       " 'tantalizing',\n",
       " 'teach',\n",
       " 'tender',\n",
       " 'tenderness',\n",
       " 'thankful',\n",
       " 'thanksgiving',\n",
       " 'therapeutic',\n",
       " 'thrill',\n",
       " 'thrilling',\n",
       " 'thriving',\n",
       " 'tickle',\n",
       " 'tinsel',\n",
       " 'toast',\n",
       " 'tranquil',\n",
       " 'tranquility',\n",
       " 'transcendence',\n",
       " 'treasure',\n",
       " 'treat',\n",
       " 'tree',\n",
       " 'triumph',\n",
       " 'triumphant',\n",
       " 'trophy',\n",
       " 'truce',\n",
       " 'true',\n",
       " 'twinkle',\n",
       " 'unbeaten',\n",
       " 'unconstrained',\n",
       " 'undying',\n",
       " 'unexpected',\n",
       " 'unification',\n",
       " 'unsurpassed',\n",
       " 'untie',\n",
       " 'uplift',\n",
       " 'utopian',\n",
       " 'vacation',\n",
       " 'venerable',\n",
       " 'veracity',\n",
       " 'vernal',\n",
       " 'victor',\n",
       " 'victorious',\n",
       " 'victory',\n",
       " 'vindication',\n",
       " 'virtuous',\n",
       " 'visionary',\n",
       " 'visitor',\n",
       " 'vitality',\n",
       " 'vivacious',\n",
       " 'vivid',\n",
       " 'volunteer',\n",
       " 'voluptuous',\n",
       " 'vote',\n",
       " 'vow',\n",
       " 'wages',\n",
       " 'wealth',\n",
       " 'weight',\n",
       " 'welcomed',\n",
       " 'whim',\n",
       " 'whimsical',\n",
       " 'white',\n",
       " 'whiteness',\n",
       " 'winner',\n",
       " 'winning',\n",
       " 'winnings',\n",
       " 'witty',\n",
       " 'wonderful',\n",
       " 'wonderfully',\n",
       " 'worship',\n",
       " 'yearning',\n",
       " 'young',\n",
       " 'youth',\n",
       " 'zeal',\n",
       " 'zealous',\n",
       " 'zest']"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_list = get_affect_presence_list(emotion)\n",
    "word_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentiment_emotion_feature(tweet):\n",
    "    \n",
    "    vector = np.zeros(1)\n",
    "    for word in word_list:\n",
    "        if word in tweet.split():\n",
    "            vector[0] = 1.0\n",
    "    \n",
    "    return vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_sentiment_emotion_feature(\"furious\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5) Hashtag Emotion Intensity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "hashtag_emotion_lex_file_path = ('%s%s/' %(lexicons_path, paths2[3])) + listdir('%s%s/' %(lexicons_path, paths2[3]))[0]\n",
    "    \n",
    "def get_hashtag_emotion_intensity(emotion):\n",
    "    hastag_intensities = dict()\n",
    "    \n",
    "    with open(hashtag_emotion_lex_file_path) as hashtag_emotion_lex_file:\n",
    "        for line in hashtag_emotion_lex_file:\n",
    "            word_array = line.replace(\"\\n\", \"\").split(\"\\t\")\n",
    "            \n",
    "            if (word_array[0] == emotion):\n",
    "                hastag_intensities[clean_str(word_array[1])] = float(word_array[2])\n",
    "\n",
    "    return hastag_intensities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "hashtag_emotion_intensities = get_hashtag_emotion_intensity(emotion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly_hashtag_emotion = PolynomialFeatures(10)\n",
    "\n",
    "def get_hashtag_emotion_vector(tweet):\n",
    "    score = 0.0\n",
    "    for word in hashtag_emotion_intensities.keys():\n",
    "        if word in tweet:\n",
    "            score += tweet.count(word) * float(hashtag_emotion_intensities[word])\n",
    "            \n",
    "#     return [score]\n",
    "    return normalize(poly_hashtag_emotion.fit_transform(np.array([score]).reshape(1, -1))[0].reshape(1, -1))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9.97519077e-01, 7.02220137e-02, 4.94339538e-03, 3.47998536e-04,\n",
       "       2.44979354e-05, 1.72457289e-06, 1.21404175e-07, 8.54644873e-09,\n",
       "       6.01641465e-10, 4.23535511e-11, 2.98154863e-12])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_hashtag_emotion_vector(\"furious\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6) Emoticon Sentiment Lexicon¬∂"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bigrams-pmilexicon.txt', 'pairs-pmilexicon.txt', 'unigrams-pmilexicon.txt']"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "listdir('%s%s/' %(lexicons_path, paths2[4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "emoticon_lexicon_unigrams_file_path = ('%s%s/' %(lexicons_path, paths2[4])) + listdir('%s%s/' %(lexicons_path, paths2[4]))[2]\n",
    "emoticon_lexicon_bigrams_file_path = ('%s%s/' %(lexicons_path, paths2[4])) + listdir('%s%s/' %(lexicons_path, paths2[4]))[0]\n",
    "emoticon_lexicon_pairs_file_path = ('%s%s/' %(lexicons_path, paths2[4])) + listdir('%s%s/' %(lexicons_path, paths2[4]))[1]\n",
    "pair_split_string = \"---\"\n",
    "    \n",
    "def get_emoticon_lexicon_unigram_dict():\n",
    "    emoticon_lexicon_unigrams = dict()\n",
    "    with open(emoticon_lexicon_unigrams_file_path, encoding = 'UTF-8') as emoticon_lexicon_file:\n",
    "        for line in emoticon_lexicon_file:\n",
    "            word_array = line.replace(\"\\n\", \"\").split(\"\\t\")\n",
    "            emoticon_lexicon_unigrams[word_array[0]] = np.array([float(val) for val in word_array[1:]])\n",
    "    \n",
    "    return emoticon_lexicon_unigrams\n",
    "\n",
    "def get_emoticon_lexicon_bigram_dict():\n",
    "    emoticon_lexicon_bigrams = dict()\n",
    "    with open(emoticon_lexicon_bigrams_file_path, encoding = 'UTF-8') as emoticon_lexicon_file:\n",
    "        for line in emoticon_lexicon_file:\n",
    "            word_array = line.replace(\"\\n\", \"\").split(\"\\t\")\n",
    "            emoticon_lexicon_bigrams[word_array[0]] = np.array([float(val) for val in word_array[1:]])\n",
    "    \n",
    "    return emoticon_lexicon_bigrams\n",
    "\n",
    "def get_emoticon_lexicon_pairs_dict():\n",
    "    emoticon_lexicon_pairs = dict()\n",
    "    with open(emoticon_lexicon_pairs_file_path, encoding = 'UTF-8') as emoticon_lexicon_file:\n",
    "        for line in emoticon_lexicon_file:\n",
    "            word_array = line.replace(\"\\n\", \"\").split(\"\\t\")\n",
    "            pair = word_array[0].split(pair_split_string)\n",
    "            token_1 = clean_str(pair[0])\n",
    "            token_2 = clean_str(pair[1])\n",
    "            if token_1 and token_2:\n",
    "                token_1_dict = None\n",
    "                if token_1 in emoticon_lexicon_pairs.keys():\n",
    "                    token_1_dict = emoticon_lexicon_pairs[token_1]\n",
    "                else:\n",
    "                    token_1_dict = dict()\n",
    "                    \n",
    "                token_1_dict[token_2] = np.array([float(val) for val in word_array[1:]])\n",
    "                emoticon_lexicon_pairs[token_1] = token_1_dict\n",
    "    \n",
    "    return emoticon_lexicon_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "emoticon_lexicon_unigram_dict = get_emoticon_lexicon_unigram_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "emoticon_lexicon_bigram_dict = get_emoticon_lexicon_bigram_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "emoticon_lexicon_pairs_dict = get_emoticon_lexicon_pairs_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly_emoticon_lexicon = PolynomialFeatures(5)\n",
    "\n",
    "def get_unigram_sentiment_emoticon_lexicon_vector(tokens):\n",
    "    vector_list = np.zeros(3)\n",
    "    counter = 0\n",
    "    for token in tokens:\n",
    "        word = clean_str(token)\n",
    "        if word in emoticon_lexicon_unigram_dict.keys():\n",
    "            vector_list += emoticon_lexicon_unigram_dict[word]\n",
    "            counter += 1\n",
    "    if counter > 0:\n",
    "        vector_list /= counter\n",
    "        \n",
    "#     return vector_list\n",
    "    return normalize(poly_emoticon_lexicon.fit_transform(vector_list.reshape(1, -1))[0].reshape(1, -1))[0]\n",
    "\n",
    "\n",
    "def get_bigram_sentiment_emoticon_lexicon_vector(tokens):\n",
    "    bi_tokens = bigrams(tokens)\n",
    "    vector_list = np.zeros(3)\n",
    "    counter = 0\n",
    "    for bi_token in bi_tokens:\n",
    "        word = clean_str(\" \".join(bi_token))\n",
    "        if word in emoticon_lexicon_bigram_dict.keys():\n",
    "            vector_list += emoticon_lexicon_bigram_dict[word]\n",
    "            counter += 1\n",
    "    if counter > 0:\n",
    "        vector_list /= counter\n",
    "        \n",
    "#     return vector_list\n",
    "    return normalize(poly_emoji_intensity.fit_transform(vector_list.reshape(1, -1))[0].reshape(1, -1))[0].tolist()\n",
    "\n",
    "def get_pair_sentiment_emoticon_lexicon_vector(tokens):\n",
    "    vector_list = np.zeros(3)\n",
    "    counter = 0\n",
    "    \n",
    "    for i in range(len(tokens)):\n",
    "        word_1 = clean_str(tokens[i])\n",
    "        if word_1 in emoticon_lexicon_pairs_dict.keys():\n",
    "            token_1_dict = emoticon_lexicon_pairs_dict[word_1]\n",
    "            for j in range(i, len(tokens)):\n",
    "                word_2 = clean_str(tokens[j])\n",
    "                if word_2 in token_1_dict.keys():\n",
    "                    vector_list += token_1_dict[word_2]\n",
    "                    counter += 1\n",
    "                    \n",
    "    if counter > 0:\n",
    "        vector_list /= counter\n",
    "        \n",
    "#     return vector_list\n",
    "    return normalize(poly_emoji_intensity.fit_transform(vector_list.reshape(1, -1))[0].reshape(1, -1))[0].tolist()\n",
    "\n",
    "def get_sentiment_emoticon_lexicon_vector(tweet):\n",
    "    \n",
    "    tokens = word_tokenize(tweet)\n",
    "    final_list = np.asarray([])\n",
    "    \n",
    "    # Adding unigram features\n",
    "    final_list = np.append(\n",
    "        final_list,\n",
    "        get_unigram_sentiment_emoticon_lexicon_vector(tokens)\n",
    "    )\n",
    "    \n",
    "    final_list = np.append(\n",
    "        final_list,\n",
    "        get_bigram_sentiment_emoticon_lexicon_vector(tokens)\n",
    "    )\n",
    "    \n",
    "    final_list = np.append(\n",
    "        final_list,\n",
    "        get_pair_sentiment_emoticon_lexicon_vector(tokens)\n",
    "    )\n",
    "   \n",
    "    return final_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5.21931637e-10, 1.32048704e-10, 3.39255564e-08, 2.76623768e-08,\n",
       "       3.34083222e-11, 8.58316578e-09, 6.99858133e-09, 2.20516117e-06,\n",
       "       1.79805449e-06, 1.46610597e-06, 8.45230551e-12, 2.17154094e-09,\n",
       "       1.77064108e-09, 5.57905775e-07, 4.54907786e-07, 3.70924810e-07,\n",
       "       1.43335476e-04, 1.16873542e-04, 9.52968880e-05, 7.77036164e-05,\n",
       "       2.13843329e-12, 5.49399858e-10, 4.47972192e-10, 1.41150161e-07,\n",
       "       1.15091670e-07, 9.38439770e-08, 3.62638754e-05, 2.95690061e-05,\n",
       "       2.41101127e-05, 1.96590149e-05, 9.31680593e-03, 7.59678022e-03,\n",
       "       6.19429772e-03, 5.05073506e-03, 4.11829167e-03, 5.41023623e-13,\n",
       "       1.38998164e-10, 1.13336965e-10, 3.57109908e-08, 2.91181925e-08,\n",
       "       2.37425262e-08, 9.17476048e-06, 7.48095854e-06, 6.09985850e-06,\n",
       "       4.97373078e-06, 2.35715190e-03, 1.92198540e-03, 1.56715732e-03,\n",
       "       1.27783597e-03, 1.04192779e-03, 6.05592386e-01, 4.93790715e-01,\n",
       "       4.02629352e-01, 3.28297779e-01, 2.67688958e-01, 2.18269458e-01,\n",
       "       1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_sentiment_emoticon_lexicon_vector(\"furious\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7) Emoticon Sentiment Aff-Neg Lexicon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Emoticon-AFFLEX-NEGLEX-bigrams.txt', 'Emoticon-AFFLEX-NEGLEX-unigrams.txt']"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "listdir('%s%s/' %(lexicons_path, paths2[5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "emoticon_afflex_unigrams_file_path = ('%s%s/' %(lexicons_path, paths2[5])) + listdir('%s%s/' %(lexicons_path, paths2[5]))[1]\n",
    "emoticon_afflex_bigrams_file_path = ('%s%s/' %(lexicons_path, paths2[5])) + listdir('%s%s/' %(lexicons_path, paths2[5]))[0]\n",
    "    \n",
    "def get_emoticon_afflex_unigram_dict():\n",
    "    emoticon_afflex_unigrams = dict()\n",
    "    with open(emoticon_afflex_unigrams_file_path, encoding = 'UTF-8') as emoticon_lexicon_file:\n",
    "        for line in emoticon_lexicon_file:\n",
    "            word_array = line.replace(\"\\n\", \"\").split(\"\\t\")\n",
    "            emoticon_afflex_unigrams[word_array[0]] = np.array([float(val) for val in word_array[1:]])\n",
    "    \n",
    "    return emoticon_afflex_unigrams\n",
    "\n",
    "def get_emoticon_afflex_bigram_dict():\n",
    "    emoticon_afflex_bigrams = dict()\n",
    "    with open(emoticon_afflex_bigrams_file_path, encoding = 'UTF-8') as emoticon_lexicon_file:\n",
    "        for line in emoticon_lexicon_file:\n",
    "            word_array = line.replace(\"\\n\", \"\").split(\"\\t\")\n",
    "            emoticon_afflex_bigrams[word_array[0]] = np.array([float(val) for val in word_array[1:]])\n",
    "    \n",
    "    return emoticon_afflex_bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "emoticon_afflex_unigram_dict = get_emoticon_afflex_unigram_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "emoticon_afflex_bigram_dict = get_emoticon_afflex_bigram_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly_emoticon_lexicon = PolynomialFeatures(5)\n",
    "# poly_emoticon_lexicon = PolynomialFeatures(1)\n",
    "\n",
    "def get_unigram_sentiment_emoticon_afflex_vector(tokens):\n",
    "    vector_list = np.zeros(3)\n",
    "    counter = 0\n",
    "    for token in tokens:\n",
    "        word = clean_str(token)\n",
    "        if word in emoticon_afflex_unigram_dict.keys():\n",
    "            vector_list += emoticon_afflex_unigram_dict[word]\n",
    "            counter += 1\n",
    "    if counter > 0:\n",
    "        vector_list /= counter\n",
    "        \n",
    "#     return vector_list\n",
    "    return normalize(poly_emoticon_lexicon.fit_transform(vector_list.reshape(1, -1))[0].reshape(1, -1))[0]\n",
    "\n",
    "\n",
    "def get_bigram_sentiment_emoticon_afflex_vector(tokens):\n",
    "    bi_tokens = bigrams(tokens)\n",
    "    vector_list = np.zeros(3)\n",
    "    counter = 0\n",
    "    for bi_token in bi_tokens:\n",
    "        word = clean_str(\" \".join(bi_token))\n",
    "        if word in emoticon_afflex_bigram_dict.keys():\n",
    "            vector_list += emoticon_afflex_bigram_dict[word]\n",
    "            counter += 1\n",
    "    if counter > 0:\n",
    "        vector_list /= counter\n",
    "        \n",
    "#     return vector_list\n",
    "    return normalize(poly_emoticon_lexicon.fit_transform(vector_list.reshape(1, -1))[0].reshape(1, -1))[0]\n",
    "\n",
    "def get_sentiment_emoticon_afflex_vector(tweet):\n",
    "    final_list = np.asarray([])\n",
    "    tokens = word_tokenize(tweet)\n",
    "    \n",
    "    # Adding unigram features\n",
    "    final_list = np.append(final_list, get_unigram_sentiment_emoticon_afflex_vector(tokens))\n",
    "    \n",
    "    # Adding bigram featunigram_list =ures\n",
    "    final_list = np.append(final_list, get_bigram_sentiment_emoticon_afflex_vector(tokens))\n",
    "\n",
    "    return final_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.95719929e-10, 1.33357616e-10, 2.77003950e-08, 2.09731562e-08,\n",
       "       4.49415166e-11, 9.33503312e-09, 7.06795365e-09, 1.93902765e-06,\n",
       "       1.46812094e-06, 1.11157728e-06, 1.51452911e-11, 3.14590616e-09,\n",
       "       2.38190038e-09, 6.53452318e-07, 4.94756755e-07, 3.74601543e-07,\n",
       "       1.35731936e-04, 1.02768466e-04, 7.78104096e-05, 5.89135958e-05,\n",
       "       5.10396310e-12, 1.06017038e-09, 8.02700428e-10, 2.20213431e-07,\n",
       "       1.66733027e-07, 1.26240720e-07, 4.57416623e-05, 3.46329729e-05,\n",
       "       2.62221080e-05, 1.98538818e-05, 9.50123549e-03, 7.19379259e-03,\n",
       "       5.44672867e-03, 4.12395171e-03, 3.12242058e-03, 1.72003556e-12,\n",
       "       3.57277417e-10, 2.70510044e-10, 7.42119264e-08, 5.61890300e-08,\n",
       "       4.25431227e-08, 1.54149402e-05, 1.16713119e-05, 8.83685041e-06,\n",
       "       6.69075817e-06, 3.20191636e-03, 2.42430810e-03, 1.83554756e-03,\n",
       "       1.38977173e-03, 1.05225574e-03, 6.65086484e-01, 5.03565481e-01,\n",
       "       3.81271007e-01, 2.88676620e-01, 2.18569441e-01, 1.65488291e-01,\n",
       "       1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_sentiment_emoticon_afflex_vector(\"furious\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8) Hashtag Sentiment Aff-Neg Lexicon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['HS-AFFLEX-NEGLEX-bigrams.txt', 'HS-AFFLEX-NEGLEX-unigrams.txt']"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "listdir('%s%s/' %(lexicons_path, paths2[6]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "hashtag_affneglex_unigrams_file_path = ('%s%s/' %(lexicons_path, paths2[6])) + listdir('%s%s/' %(lexicons_path, paths2[6]))[1]\n",
    "hashtag_affneglex_bigrams_file_path = ('%s%s/' %(lexicons_path, paths2[6])) + listdir('%s%s/' %(lexicons_path, paths2[6]))[0]\n",
    "    \n",
    "def get_hashtag_affneglex_unigram_dict():\n",
    "    hashtag_affneglex_unigrams = dict()\n",
    "    with open(hashtag_affneglex_unigrams_file_path) as hashtag_sent_lex_file:\n",
    "        for line in hashtag_sent_lex_file:\n",
    "            word_array = line.replace(\"\\n\", \"\").split(\"\\t\")\n",
    "            hashtag_affneglex_unigrams[clean_str(word_array[0])] = np.array([float(val) for val in word_array[1:]])\n",
    "    \n",
    "    return hashtag_affneglex_unigrams\n",
    "\n",
    "def get_hashtag_affneglex_bigram_dict():\n",
    "    hashtag_affneglex_bigrams = dict()\n",
    "    with open(hashtag_affneglex_bigrams_file_path) as hashtag_sent_lex_file:\n",
    "        for line in hashtag_sent_lex_file:\n",
    "            word_array = line.replace(\"\\n\", \"\").split(\"\\t\")\n",
    "            hashtag_affneglex_bigrams[clean_str(word_array[0])] = np.array([float(val) for val in word_array[1:]])\n",
    "\n",
    "    return hashtag_affneglex_bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "hashtag_affneglex_unigram_dict = get_hashtag_affneglex_unigram_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "hashtag_affneglex_bigram_dict = get_hashtag_affneglex_bigram_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly_hashtag_sent_affneglex = PolynomialFeatures(5)\n",
    "\n",
    "def get_unigram_sentiment_hashtag_affneglex_vector(tokens):\n",
    "    vector_list = np.zeros(3)\n",
    "    counter = 0\n",
    "    for token in tokens:\n",
    "        word = clean_str(token)\n",
    "        if word in hashtag_affneglex_unigram_dict.keys():\n",
    "            vector_list += hashtag_affneglex_unigram_dict[word]\n",
    "            counter += 1\n",
    "    if counter > 0:\n",
    "        vector_list /= counter\n",
    "        \n",
    "#     return vector_list\n",
    "    return normalize(poly_hashtag_sent_affneglex.fit_transform(vector_list.reshape(1, -1))[0].reshape(1, -1))[0]\n",
    "\n",
    "def get_bigram_sentiment_hashtag_affneglex_vector(tokens):\n",
    "    bi_tokens = bigrams(tokens)\n",
    "    vector_list = np.zeros(3)\n",
    "    counter = 0\n",
    "    for bi_token in bi_tokens:\n",
    "        word = clean_str(\" \".join(bi_token))\n",
    "        if word in hashtag_affneglex_bigram_dict.keys():\n",
    "            vector_list += hashtag_affneglex_bigram_dict[word]\n",
    "            counter += 1\n",
    "    if counter > 0:\n",
    "        vector_list /= counter\n",
    "        \n",
    "#     return vector_list\n",
    "    return normalize(poly_hashtag_sent_affneglex.fit_transform(vector_list.reshape(1, -1))[0].reshape(1, -1))[0]\n",
    "\n",
    "def get_sentiment_hashtag_affneglex_vector(tweet):\n",
    "    final_list = np.asarray([])\n",
    "    tokens = word_tokenize(tweet)\n",
    "    \n",
    "    # Adding unigram features\n",
    "    final_list = np.append(final_list, get_unigram_sentiment_hashtag_affneglex_vector(tokens))\n",
    "    # Adding bigram features\n",
    "    final_list = np.append(final_list, get_bigram_sentiment_hashtag_affneglex_vector(tokens))\n",
    "\n",
    "    return final_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.50661452e-05, -5.16768782e-06,  6.02645810e-05,  1.35595307e-04,\n",
       "        1.77251692e-06, -2.06707513e-05, -4.65091904e-05,  2.41058324e-04,\n",
       "        5.42381229e-04,  1.22035777e-03, -6.07973304e-07,  7.09006769e-06,\n",
       "        1.59526523e-05, -8.26830051e-05, -1.86036762e-04, -4.18582713e-04,\n",
       "        9.64233296e-04,  2.16952492e-03,  4.88143106e-03,  1.09832199e-02,\n",
       "        2.08534843e-07, -2.43189322e-06, -5.47175974e-06,  2.83602708e-05,\n",
       "        6.38106092e-05,  1.43573871e-04, -3.30732020e-04, -7.44147046e-04,\n",
       "       -1.67433085e-03, -3.76724442e-03,  3.85693318e-03,  8.67809966e-03,\n",
       "        1.95257242e-02,  4.39328795e-02,  9.88489790e-02, -7.15274513e-08,\n",
       "        8.34139374e-07,  1.87681359e-06, -9.72757287e-06, -2.18870390e-05,\n",
       "       -4.92458377e-05,  1.13441083e-04,  2.55242437e-04,  5.74295483e-04,\n",
       "        1.29216484e-03, -1.32292808e-03, -2.97658818e-03, -6.69732341e-03,\n",
       "       -1.50689777e-02, -3.39051998e-02,  1.54277327e-02,  3.47123987e-02,\n",
       "        7.81028970e-02,  1.75731518e-01,  3.95395916e-01,  8.89640811e-01,\n",
       "        1.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_sentiment_hashtag_affneglex_vector(\"furious\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9) Hashtag Sentiment Lexicon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['HS-bigrams.txt', 'HS-pairs.txt', 'HS-unigrams.txt']"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "listdir('%s%s/' %(lexicons_path, paths2[7]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "hash_sent_lex_unigrams_file_path = ('%s%s/' %(lexicons_path, paths2[7])) + listdir('%s%s/' %(lexicons_path, paths2[7]))[2]\n",
    "hash_sent_lex_bigrams_file_path = ('%s%s/' %(lexicons_path, paths2[7])) + listdir('%s%s/' %(lexicons_path, paths2[7]))[0]\n",
    "hash_sent_lex_pairs_file_path = ('%s%s/' %(lexicons_path, paths2[7])) + listdir('%s%s/' %(lexicons_path, paths2[7]))[1]\n",
    "pair_split_string = \"---\"\n",
    "\n",
    "\n",
    "def get_hash_sent_lex_unigram_dict():\n",
    "    hash_sent_lex_unigrams = dict()\n",
    "    with open(hash_sent_lex_unigrams_file_path) as hash_sent_lex_file:\n",
    "        for line in hash_sent_lex_file:\n",
    "            word_array = line.replace(\"\\n\", \"\").split(\"\\t\")\n",
    "            if clean_str(word_array[0]):\n",
    "                hash_sent_lex_unigrams[word_array[0]] = np.array([float(val) for val in word_array[1:]])\n",
    "    \n",
    "    return hash_sent_lex_unigrams\n",
    "\n",
    "def get_hash_sent_lex_bigram_dict():\n",
    "    hash_sent_lex_bigrams = dict()\n",
    "    with open(hash_sent_lex_bigrams_file_path) as hash_sent_lex_file:\n",
    "        for line in hash_sent_lex_file:\n",
    "            word_array = line.replace(\"\\n\", \"\").split(\"\\t\")\n",
    "            if clean_str(word_array[0]):\n",
    "                hash_sent_lex_bigrams[word_array[0]] = np.array([float(val) for val in word_array[1:]])\n",
    "    \n",
    "    return hash_sent_lex_bigrams\n",
    "\n",
    "def get_hash_sent_lex_pairs_dict():\n",
    "    hash_sent_lex_pairs = dict()\n",
    "    with open(hash_sent_lex_pairs_file_path) as hash_sent_lex_file:\n",
    "        for line in hash_sent_lex_file:\n",
    "            word_array = line.replace(\"\\n\", \"\").split(\"\\t\")\n",
    "            pair = word_array[0].split(pair_split_string)\n",
    "            token_1 = clean_str(pair[0])\n",
    "            token_2 = clean_str(pair[1])\n",
    "            if token_1 and token_2:\n",
    "                token_1_dict = None\n",
    "                if token_1 in hash_sent_lex_pairs.keys():\n",
    "                    token_1_dict = hash_sent_lex_pairs[token_1]\n",
    "                else:\n",
    "                    token_1_dict = dict()\n",
    "                    \n",
    "                token_1_dict[token_2] = np.array([float(val) for val in word_array[1:]])\n",
    "                hash_sent_lex_pairs[token_1] = token_1_dict\n",
    "    \n",
    "    return hash_sent_lex_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "hash_sent_lex_unigram_dict = get_hash_sent_lex_unigram_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "hash_sent_lex_bigram_dict = get_hash_sent_lex_bigram_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "hash_sent_lex_pairs_dict = get_hash_sent_lex_pairs_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly_hash_sent_lex = PolynomialFeatures(5)\n",
    "\n",
    "def get_unigram_sentiment_hash_sent_lex_vector(tokens):\n",
    "    vector_list = np.zeros(3)\n",
    "    counter = 0\n",
    "    \n",
    "    for token in tokens:\n",
    "        word = clean_str(token)\n",
    "        if word in hash_sent_lex_unigram_dict.keys():\n",
    "            vector_list += hash_sent_lex_unigram_dict[word]\n",
    "            counter += 1\n",
    "\n",
    "    if counter > 0:\n",
    "        vector_list /= counter\n",
    "    \n",
    "#     return vector_list\n",
    "    return normalize(poly_hash_sent_lex.fit_transform(vector_list.reshape(1, -1))[0].reshape(1, -1))[0]\n",
    "    \n",
    "def get_bigram_sentiment_hash_sent_lex_vector(tokens):\n",
    "    bi_tokens = bigrams(tokens)\n",
    "    vector_list = np.zeros(3)\n",
    "    counter = 0\n",
    "    for bi_token in bi_tokens:\n",
    "        word = clean_str(\" \".join(bi_token))\n",
    "        if word in hash_sent_lex_bigram_dict.keys():\n",
    "            vector_list += hash_sent_lex_bigram_dict[word]\n",
    "            counter += 1\n",
    "    if counter > 0:\n",
    "        vector_list /= counter\n",
    "    \n",
    "#     return vector_list\n",
    "    return normalize(poly_hash_sent_lex.fit_transform(vector_list.reshape(1, -1))[0].reshape(1, -1))[0]\n",
    "\n",
    "def get_pair_sentiment_hash_sent_lex_vector(tokens):\n",
    "    vector_list = np.zeros(3)\n",
    "    counter = 0\n",
    "    \n",
    "    for i in range(len(tokens)):\n",
    "        word_1 = clean_str(tokens[i])\n",
    "        if word_1 in hash_sent_lex_pairs_dict.keys():\n",
    "            token_1_dict = hash_sent_lex_pairs_dict[word_1]\n",
    "            for j in range(i, len(tokens)):\n",
    "                word_2 = clean_str(tokens[j])\n",
    "                if word_2 in token_1_dict.keys():\n",
    "                    vector_list += token_1_dict[word_2]\n",
    "                    counter += 1\n",
    "    if counter > 0:\n",
    "        vector_list /= counter\n",
    "        \n",
    "#     return vector_list\n",
    "    return normalize(poly_hash_sent_lex.fit_transform(vector_list.reshape(1, -1))[0].reshape(1, -1))[0]\n",
    "    \n",
    "def get_sentiment_hash_sent_lex_vector(tweet):\n",
    "    final_list = np.asarray([])\n",
    "    \n",
    "    tokens = word_tokenize(tweet)\n",
    "    \n",
    "    # Adding unigram features\n",
    "    final_list = np.append(final_list, get_unigram_sentiment_hash_sent_lex_vector(tokens))\n",
    "    # Adding bigram features\n",
    "    final_list = np.append(final_list, get_bigram_sentiment_hash_sent_lex_vector(tokens))\n",
    "    # Adding pair features\n",
    "    final_list = np.append(final_list, get_pair_sentiment_hash_sent_lex_vector(tokens))\n",
    "\n",
    "    return final_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5.09887390e-09, 3.39075115e-09, 2.09053830e-07, 1.73361713e-07,\n",
       "       2.25484951e-09, 1.39020797e-07, 1.15285539e-07, 8.57120703e-06,\n",
       "       7.10783022e-06, 5.89429823e-06, 1.49947493e-09, 9.24488300e-08,\n",
       "       7.66648834e-08, 5.69985268e-06, 4.72670710e-06, 3.91970833e-06,\n",
       "       3.51419488e-04, 2.91421039e-04, 2.41666228e-04, 2.00406140e-04,\n",
       "       9.97150826e-10, 6.14784720e-08, 5.09821475e-08, 3.79040203e-06,\n",
       "       3.14326022e-06, 2.60660604e-06, 2.33693960e-04, 1.93794991e-04,\n",
       "       1.60708041e-04, 1.33270083e-04, 1.44081990e-02, 1.19482626e-02,\n",
       "       9.90831533e-03, 8.21665174e-03, 6.81380876e-03, 6.63105299e-10,\n",
       "       4.08831839e-08, 3.39031281e-08, 2.52061735e-06, 2.09026805e-06,\n",
       "       1.73339301e-06, 1.55406483e-04, 1.28873669e-04, 1.06870848e-04,\n",
       "       8.86246052e-05, 9.58145235e-03, 7.94559463e-03, 6.58902970e-03,\n",
       "       5.46407341e-03, 4.53118282e-03, 5.90736160e-01, 4.89878767e-01,\n",
       "       4.06240929e-01, 3.36882721e-01, 2.79366159e-01, 2.31669498e-01,\n",
       "       1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_sentiment_hash_sent_lex_vector(\"furious\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10) Depeche Mood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "depeche_mood_file_path = ('%s%s/' %(lexicons_path, paths2[8])) + listdir('%s%s/' %(lexicons_path, paths2[8]))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_depeche_vector_dict():\n",
    "    depeche_vector_dict = dict()\n",
    "    with open(depeche_mood_file_path) as depeche_mood_file:\n",
    "        lines = depeche_mood_file.readlines()[1:] \n",
    "        for line in lines:\n",
    "            word_array = line.replace(\"\\n\", \"\").split(\"\\t\")\n",
    "            depeche_vector_dict[word_array[0].split(\"#\")[0]] = np.array([float(val) for val in word_array[1:]])\n",
    "    \n",
    "    return depeche_vector_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "depeche_vector_dict = get_depeche_vector_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "print(len(depeche_vector_dict[\"0\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly_depm = PolynomialFeatures(5)\n",
    "\n",
    "def get_depeche_mood_vector(tweet):\n",
    "    vector_list = np.zeros(8)\n",
    "    tokens = word_tokenize(tweet)\n",
    "    counter = 0\n",
    "    \n",
    "    for token in tokens:\n",
    "        if token in depeche_vector_dict.keys():\n",
    "            vector_list += np.array(depeche_vector_dict[token])\n",
    "            counter += 1\n",
    "    \n",
    "    if counter > 0:\n",
    "        vector_list /= counter\n",
    "        \n",
    "    return normalize(poly_depm.fit_transform(vector_list.reshape(1, -1))[0].reshape(1, -1))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9.34469068e-01, 5.98056709e-02, 1.49434297e-01, ...,\n",
       "       1.06644824e-05, 5.70178406e-06, 3.04846875e-06])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_depeche_mood_vector(\"i am so mad about power rangers. i am incensed. i am furious.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (3)  Prepare Sentence Vectors as Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_active_vector_method(string):\n",
    "    return int(string)\n",
    "\n",
    "\n",
    "def vectorize_tweets(tweet_list, bin_string, vector_dict):\n",
    "\n",
    "    vectors = list()\n",
    "    frames = list()\n",
    "\n",
    "    '''Pre-trained Word embeddings'''\n",
    "    index = 0\n",
    "    if is_active_vector_method(bin_string[index]):\n",
    "        if index not in vector_dict.keys():\n",
    "            tmp_vector = \\\n",
    "                pd.DataFrame(list(map(lambda x: get_averaged_embeddings(x, wv_model_g, w2v_dimensions_g), tweet_list)))\n",
    "            vector_dict[index] = tmp_vector\n",
    "        frames.append(vector_dict[index])\n",
    "\n",
    "    index = 1\n",
    "    if is_active_vector_method(bin_string[index]):\n",
    "        if index not in vector_dict.keys():\n",
    "            tmp_vector = \\\n",
    "                pd.DataFrame(list(map(lambda x: get_averaged_embeddings(x, wv_model_w, w2v_dimensions_w), tweet_list)))\n",
    "            vector_dict[index] = tmp_vector\n",
    "        frames.append(vector_dict[index])\n",
    "\n",
    "\n",
    "    '''NRC Emotion Intensity Lexicon'''\n",
    "    index = 2\n",
    "    if is_active_vector_method(bin_string[index]):\n",
    "        if index not in vector_dict.keys():\n",
    "            tmp_vector = pd.DataFrame(list(map(lambda x: get_emo_int_vector(x), tweet_list)))\n",
    "            vector_dict[index] = tmp_vector\n",
    "        frames.append(vector_dict[index])\n",
    "\n",
    "    '''WordNet'''\n",
    "    index = 3\n",
    "    if is_active_vector_method(bin_string[index]):\n",
    "        if index not in vector_dict.keys():\n",
    "            tmp_vector = pd.DataFrame(list(map(lambda x: get_sentiwordnetscore(x), tweet_list)))\n",
    "            vector_dict[index] = tmp_vector\n",
    "        frames.append(vector_dict[index])\n",
    "\n",
    "    '''NRC Sentiment Lexicon'''\n",
    "    index = 4\n",
    "    if is_active_vector_method(bin_string[index]):\n",
    "        if index not in vector_dict.keys():\n",
    "            tmp_vector = pd.DataFrame(list(map(lambda x: get_sentiment_emotion_feature(x), tweet_list)))\n",
    "            vector_dict[index] = tmp_vector\n",
    "        frames.append(vector_dict[index])\n",
    "\n",
    "    index = 5\n",
    "    if is_active_vector_method(bin_string[index]):\n",
    "        if index not in vector_dict.keys():\n",
    "            tmp_vector = pd.DataFrame(list(map(lambda x: get_sentiment_emoticon_lexicon_vector(x), tweet_list)))\n",
    "            vector_dict[index] = tmp_vector\n",
    "        frames.append(vector_dict[index])\n",
    "\n",
    "    index = 6\n",
    "    if is_active_vector_method(bin_string[index]):\n",
    "        if index not in vector_dict.keys():\n",
    "            tmp_vector = pd.DataFrame(list(map(lambda x: get_sentiment_emoticon_afflex_vector(x), tweet_list)))\n",
    "            vector_dict[index] = tmp_vector\n",
    "        frames.append(vector_dict[index])\n",
    "\n",
    "    '''NRC Hashtag Lexicon'''\n",
    "    index = 7\n",
    "    if is_active_vector_method(bin_string[index]):\n",
    "        if index not in vector_dict.keys():\n",
    "            tmp_vector = pd.DataFrame(list(map(lambda x: get_hashtag_emotion_vector(x), tweet_list)))\n",
    "            vector_dict[index] = tmp_vector\n",
    "        frames.append(vector_dict[index])\n",
    "\n",
    "    index = 8\n",
    "    if is_active_vector_method(bin_string[index]):\n",
    "        if index not in vector_dict.keys():\n",
    "            tmp_vector = pd.DataFrame(list(map(lambda x: get_sentiment_hash_sent_lex_vector(x), tweet_list)))\n",
    "            vector_dict[index] = tmp_vector\n",
    "        frames.append(vector_dict[index])\n",
    "\n",
    "    index = 9\n",
    "    if is_active_vector_method(bin_string[index]):\n",
    "        if index not in vector_dict.keys():\n",
    "            tmp_vector = pd.DataFrame(list(map(lambda x: get_sentiment_hashtag_affneglex_vector(x), tweet_list)))\n",
    "            vector_dict[index] = tmp_vector\n",
    "        frames.append(vector_dict[index])\n",
    "\n",
    "   \n",
    "    index = 10\n",
    "    if is_active_vector_method(bin_string[index]):\n",
    "        if index not in vector_dict.keys():\n",
    "            tmp_vector = pd.DataFrame(list(map(lambda x: get_emoji_intensity(x), tweet_list)))\n",
    "            vector_dict[index] = tmp_vector\n",
    "        frames.append(vector_dict[index])\n",
    "        \n",
    "    index = 11\n",
    "    if is_active_vector_method(bin_string[index]):\n",
    "        if index not in vector_dict.keys():\n",
    "            tmp_vector = pd.DataFrame(list(map(lambda x: get_depeche_mood_vector(x), tweet_list)))\n",
    "            vector_dict[index] = tmp_vector\n",
    "        frames.append(vector_dict[index])\n",
    "\n",
    "    vectors = pd.concat(frames, axis=1)\n",
    "\n",
    "    return vectors.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_index_mapping = \\\n",
    "    {\n",
    "        0: \"Glove[Twitter]\",\n",
    "        1: \"Word2Vec[Twitter]\",\n",
    "        2: \"NRC-Emotion Intensity Lexicon\",\n",
    "        3: \"Wordnet-Affect\",\n",
    "        4: \"NRC-Emotion-Lexicon\",\n",
    "        5: \"NRC-Emoticon-Lexicon\",\n",
    "        6: \"NRC-Emoticon-AffLexNegLex\",\n",
    "        7: \"NRC-Hashtag-Emotion\",\n",
    "        8: \"NRC-Hashtag-Sentiment-Lexicon\",\n",
    "        9: \"NRC-Hashtag-Sentiment-AffLexNegLex\",\n",
    "        10: \"Emoji Intensity\",\n",
    "        11: \"Depeche Mood\"\n",
    "    \n",
    "    }\n",
    "\n",
    "\n",
    "def get_features_from_identifier(bin_string):\n",
    "    features = list()\n",
    "    for i in range(len(bin_string)):\n",
    "        if int(bin_string[i]):\n",
    "            features.append(feature_index_mapping[i])\n",
    "\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Glove[Twitter]',\n",
       " 'Word2Vec[Twitter]',\n",
       " 'NRC-Emotion-Lexicon',\n",
       " 'NRC-Emoticon-Lexicon',\n",
       " 'NRC-Hashtag-Sentiment-Lexicon',\n",
       " 'Emoji Intensity']"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string1 = \"110011001010\"\n",
    "get_features_from_identifier(string1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vector_dict = dict()\n",
    "test_vector_dict = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = vectorize_tweets(train_tweets, string1, train_vector_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "902\n",
      "943\n"
     ]
    }
   ],
   "source": [
    "print(len(x_train))\n",
    "dimension = len(x_train[0])\n",
    "print(dimension)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.array(x_train)\n",
    "score_train = np.array(train_intensities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = vectorize_tweets(test_tweets, string1, test_vector_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "714\n",
      "943\n"
     ]
    }
   ],
   "source": [
    "print(len(x_test))\n",
    "print(len(x_test[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vectors_path = \"files/\" + emotion + \"_vectors/train_vectors.npy\"\n",
    "test_vectors_path = \"files/\" + emotion + \"_vectors/test_vectors.npy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save vectors_dict\n",
    "import pickle\n",
    "with open(train_vectors_path, 'wb') as train_vectors_file:\n",
    "    pickle.dump(train_vector_dict, train_vectors_file)\n",
    "\n",
    "with open(test_vectors_path, 'wb') as test_vectors_file:\n",
    "    pickle.dump(test_vector_dict, test_vectors_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Restore vectors_dict\n",
    "import pickle\n",
    "with open(train_vectors_path, 'rb') as train_vectors_file:\n",
    "    train_vector_dict = pickle.load(train_vectors_file)\n",
    "\n",
    "with open(test_vectors_path, 'rb') as test_vectors_file:\n",
    "    test_vector_dict = pickle.load(test_vectors_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_vectors_path = \"files/\" + emotion + \"_vectors/x_train.npy\"\n",
    "y_train_vectors_path = \"files/\" + emotion + \"_vectors/y_train.npy\"\n",
    "\n",
    "x_test_vectors_path = \"files/\" + emotion + \"_vectors/x_test.npy\"\n",
    "y_test_vectors_path = \"files/\" + emotion + \"_vectors/y_test.npy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save train_vectors\n",
    "import pickle\n",
    "with open(x_train_vectors_path, 'wb') as x_train_vectors_file:\n",
    "    x_train = pickle.dump(x_train, x_train_vectors_file)\n",
    "with open(y_train_vectors_path, 'wb') as y_train_vectors_file:\n",
    "    score_train = pickle.dump(score_train, y_train_vectors_file)\n",
    "\n",
    "with open(x_test_vectors_path, 'wb') as x_test_vectors_file:\n",
    "    x_test = pickle.dump(x_test, x_test_vectors_file)\n",
    "with open(y_test_vectors_path, 'wb') as y_test_vectors_file:\n",
    "    test_intensities = pickle.dump(test_intensities, y_test_vectors_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Restore vectors_dict\n",
    "with open(x_train_vectors_path, 'rb') as x_train_vectors_file:\n",
    "    x_train = pickle.load(x_train_vectors_file)\n",
    "with open(y_train_vectors_path, 'rb') as y_train_vectors_file:\n",
    "    score_train = pickle.load(y_train_vectors_file)\n",
    "\n",
    "with open(x_test_vectors_path, 'rb') as x_test_vectors_file:\n",
    "    x_test = pickle.load(x_test_vectors_file)\n",
    "with open(y_test_vectors_path, 'rb') as y_test_vectors_file:\n",
    "    test_intensities = pickle.load(y_test_vectors_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.array(x_train)\n",
    "score_train = np.array(score_train)\n",
    "\n",
    "x_test = np.array(x_test)\n",
    "test_intensities = np.array(test_intensities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(902, 943) \n",
      " (902,) \n",
      " (714, 943) \n",
      " (714,)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape,'\\n',score_train.shape,'\\n',x_test.shape, '\\n', test_intensities.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Train a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "import numpy as np\n",
    "import scipy\n",
    "\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_lists(pred, gold):\n",
    "    if len(pred) == len(gold):\n",
    "        gold_scores=gold\n",
    "        pred_scores=pred         \n",
    "        \n",
    "        # lists storing gold and prediction scores where gold score >= 0.5\n",
    "        gold_scores_range_05_1=[]\n",
    "        pred_scores_range_05_1=[]\n",
    "         \n",
    "            \n",
    "        for i in range(len(gold_scores)):\n",
    "            if(gold_scores[i]>=0.5):\n",
    "                gold_scores_range_05_1.append(gold_scores[i])\n",
    "                pred_scores_range_05_1.append(pred_scores[i])\n",
    "                \n",
    "        # return zero correlation if predictions are constant\n",
    "        if np.std(pred_scores)==0 or np.std(gold_scores)==0:\n",
    "            return (0,0,0,0)\n",
    "        \n",
    "        pears_corr=scipy.stats.pearsonr(pred_scores,gold_scores)[0]                                    \n",
    "        spear_corr=scipy.stats.spearmanr(pred_scores,gold_scores)[0]   \n",
    "\n",
    "\n",
    "        pears_corr_range_05_1=scipy.stats.pearsonr(pred_scores_range_05_1,gold_scores_range_05_1)[0]                                    \n",
    "        spear_corr_range_05_1=scipy.stats.spearmanr(pred_scores_range_05_1,gold_scores_range_05_1)[0]           \n",
    "        \n",
    "      \n",
    "        return np.array([pears_corr,spear_corr,pears_corr_range_05_1,spear_corr_range_05_1])\n",
    "    else:\n",
    "        raise ValueError('Predictions and gold data have different number of lines.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1) XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from sklearn.metrics import make_scorer\n",
    "import scipy\n",
    "def pearson_score(ground_truth, predictions):\n",
    "    score = scipy.stats.pearsonr(predictions,ground_truth)[0]\n",
    "    return score\n",
    "PS = make_scorer(pearson_score, greater_is_better=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "ml_model = XGBRegressor(objective=\"reg:squarederror\",seed=0)\n",
    "\n",
    "# specify parameters and distributions to sample from\n",
    "param_dist = {\n",
    "     \"max_depth\": range(3, 11),\n",
    "     \"n_estimators\": [100,300,500,700,900,1000,3000]\n",
    " }\n",
    "\n",
    "\n",
    "# run randomized search\n",
    "grid_search = GridSearchCV(ml_model,param_grid=param_dist, cv=5, n_jobs=-1,return_train_score=True)\n",
    "\n",
    "trainingtime = pd.DataFrame(columns = [\"Model\", \"Training Time(Seconds)\"])\n",
    "start_time_XG =time.time()\n",
    "\n",
    "grid_search.fit(x_train, score_train)\n",
    "trainingtime.loc[0] = [\"XGBoost\", round((time.time()-start_time_XG), 2)] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-9.681875256265263"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "             colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "             importance_type='gain', interaction_constraints='',\n",
       "             learning_rate=0.300000012, max_delta_step=0, max_depth=3,\n",
       "             min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "             n_estimators=100, n_jobs=0, num_parallel_tree=1,\n",
       "             objective='reg:squarederror', random_state=0, reg_alpha=0,\n",
       "             reg_lambda=1, scale_pos_weight=1, seed=0, subsample=1,\n",
       "             tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9849803268862722"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_estimator_.score(x_train, score_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.631767</td>\n",
       "      <td>0.130167</td>\n",
       "      <td>0.009375</td>\n",
       "      <td>4.886361e-04</td>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_depth': 3, 'n_estimators': 100}</td>\n",
       "      <td>-12.060514</td>\n",
       "      <td>-9.430328</td>\n",
       "      <td>-11.387660</td>\n",
       "      <td>...</td>\n",
       "      <td>-9.681875</td>\n",
       "      <td>5.049857</td>\n",
       "      <td>1</td>\n",
       "      <td>0.983614</td>\n",
       "      <td>0.992757</td>\n",
       "      <td>0.992430</td>\n",
       "      <td>0.990681</td>\n",
       "      <td>0.984764</td>\n",
       "      <td>0.988849</td>\n",
       "      <td>0.003887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>27.925318</td>\n",
       "      <td>0.975380</td>\n",
       "      <td>0.010372</td>\n",
       "      <td>4.883635e-04</td>\n",
       "      <td>3</td>\n",
       "      <td>300</td>\n",
       "      <td>{'max_depth': 3, 'n_estimators': 300}</td>\n",
       "      <td>-12.129118</td>\n",
       "      <td>-9.558391</td>\n",
       "      <td>-11.443485</td>\n",
       "      <td>...</td>\n",
       "      <td>-9.736813</td>\n",
       "      <td>5.063923</td>\n",
       "      <td>7</td>\n",
       "      <td>0.987425</td>\n",
       "      <td>0.996604</td>\n",
       "      <td>0.996170</td>\n",
       "      <td>0.993850</td>\n",
       "      <td>0.989335</td>\n",
       "      <td>0.992677</td>\n",
       "      <td>0.003681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>33.095691</td>\n",
       "      <td>1.183824</td>\n",
       "      <td>0.010771</td>\n",
       "      <td>3.989697e-04</td>\n",
       "      <td>3</td>\n",
       "      <td>500</td>\n",
       "      <td>{'max_depth': 3, 'n_estimators': 500}</td>\n",
       "      <td>-12.129148</td>\n",
       "      <td>-9.555392</td>\n",
       "      <td>-11.443451</td>\n",
       "      <td>...</td>\n",
       "      <td>-9.736227</td>\n",
       "      <td>5.063952</td>\n",
       "      <td>2</td>\n",
       "      <td>0.987425</td>\n",
       "      <td>0.996605</td>\n",
       "      <td>0.996170</td>\n",
       "      <td>0.993850</td>\n",
       "      <td>0.989335</td>\n",
       "      <td>0.992677</td>\n",
       "      <td>0.003681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>39.633008</td>\n",
       "      <td>1.296226</td>\n",
       "      <td>0.012167</td>\n",
       "      <td>2.917996e-03</td>\n",
       "      <td>3</td>\n",
       "      <td>700</td>\n",
       "      <td>{'max_depth': 3, 'n_estimators': 700}</td>\n",
       "      <td>-12.129156</td>\n",
       "      <td>-9.555402</td>\n",
       "      <td>-11.443448</td>\n",
       "      <td>...</td>\n",
       "      <td>-9.736234</td>\n",
       "      <td>5.063951</td>\n",
       "      <td>3</td>\n",
       "      <td>0.987425</td>\n",
       "      <td>0.996605</td>\n",
       "      <td>0.996170</td>\n",
       "      <td>0.993850</td>\n",
       "      <td>0.989335</td>\n",
       "      <td>0.992677</td>\n",
       "      <td>0.003681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>46.055831</td>\n",
       "      <td>1.254065</td>\n",
       "      <td>0.011769</td>\n",
       "      <td>3.989459e-04</td>\n",
       "      <td>3</td>\n",
       "      <td>900</td>\n",
       "      <td>{'max_depth': 3, 'n_estimators': 900}</td>\n",
       "      <td>-12.129163</td>\n",
       "      <td>-9.555409</td>\n",
       "      <td>-11.443447</td>\n",
       "      <td>...</td>\n",
       "      <td>-9.736240</td>\n",
       "      <td>5.063950</td>\n",
       "      <td>4</td>\n",
       "      <td>0.987425</td>\n",
       "      <td>0.996605</td>\n",
       "      <td>0.996170</td>\n",
       "      <td>0.993850</td>\n",
       "      <td>0.989335</td>\n",
       "      <td>0.992677</td>\n",
       "      <td>0.003681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>49.401683</td>\n",
       "      <td>1.357552</td>\n",
       "      <td>0.011370</td>\n",
       "      <td>4.885777e-04</td>\n",
       "      <td>3</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'max_depth': 3, 'n_estimators': 1000}</td>\n",
       "      <td>-12.129166</td>\n",
       "      <td>-9.555413</td>\n",
       "      <td>-11.443446</td>\n",
       "      <td>...</td>\n",
       "      <td>-9.736242</td>\n",
       "      <td>5.063950</td>\n",
       "      <td>5</td>\n",
       "      <td>0.987425</td>\n",
       "      <td>0.996605</td>\n",
       "      <td>0.996170</td>\n",
       "      <td>0.993850</td>\n",
       "      <td>0.989335</td>\n",
       "      <td>0.992677</td>\n",
       "      <td>0.003681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>117.403622</td>\n",
       "      <td>1.924388</td>\n",
       "      <td>0.016567</td>\n",
       "      <td>2.071911e-03</td>\n",
       "      <td>3</td>\n",
       "      <td>3000</td>\n",
       "      <td>{'max_depth': 3, 'n_estimators': 3000}</td>\n",
       "      <td>-12.129193</td>\n",
       "      <td>-9.555431</td>\n",
       "      <td>-11.443442</td>\n",
       "      <td>...</td>\n",
       "      <td>-9.736274</td>\n",
       "      <td>5.063925</td>\n",
       "      <td>6</td>\n",
       "      <td>0.987425</td>\n",
       "      <td>0.996605</td>\n",
       "      <td>0.996170</td>\n",
       "      <td>0.993850</td>\n",
       "      <td>0.989335</td>\n",
       "      <td>0.992677</td>\n",
       "      <td>0.003681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>12.488202</td>\n",
       "      <td>0.131866</td>\n",
       "      <td>0.008976</td>\n",
       "      <td>6.309019e-04</td>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_depth': 4, 'n_estimators': 100}</td>\n",
       "      <td>-12.747214</td>\n",
       "      <td>-11.731895</td>\n",
       "      <td>-12.204623</td>\n",
       "      <td>...</td>\n",
       "      <td>-10.251003</td>\n",
       "      <td>5.031153</td>\n",
       "      <td>15</td>\n",
       "      <td>0.987327</td>\n",
       "      <td>0.996486</td>\n",
       "      <td>0.996082</td>\n",
       "      <td>0.993747</td>\n",
       "      <td>0.989190</td>\n",
       "      <td>0.992567</td>\n",
       "      <td>0.003687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>23.503544</td>\n",
       "      <td>0.735191</td>\n",
       "      <td>0.009774</td>\n",
       "      <td>3.989220e-04</td>\n",
       "      <td>4</td>\n",
       "      <td>300</td>\n",
       "      <td>{'max_depth': 4, 'n_estimators': 300}</td>\n",
       "      <td>-12.749460</td>\n",
       "      <td>-11.721330</td>\n",
       "      <td>-12.207308</td>\n",
       "      <td>...</td>\n",
       "      <td>-10.253517</td>\n",
       "      <td>5.033427</td>\n",
       "      <td>21</td>\n",
       "      <td>0.987427</td>\n",
       "      <td>0.996606</td>\n",
       "      <td>0.996170</td>\n",
       "      <td>0.993851</td>\n",
       "      <td>0.989336</td>\n",
       "      <td>0.992678</td>\n",
       "      <td>0.003681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>30.076365</td>\n",
       "      <td>0.857744</td>\n",
       "      <td>0.010173</td>\n",
       "      <td>3.988983e-04</td>\n",
       "      <td>4</td>\n",
       "      <td>500</td>\n",
       "      <td>{'max_depth': 4, 'n_estimators': 500}</td>\n",
       "      <td>-12.749446</td>\n",
       "      <td>-11.721316</td>\n",
       "      <td>-12.207300</td>\n",
       "      <td>...</td>\n",
       "      <td>-10.253508</td>\n",
       "      <td>5.033417</td>\n",
       "      <td>20</td>\n",
       "      <td>0.987427</td>\n",
       "      <td>0.996606</td>\n",
       "      <td>0.996170</td>\n",
       "      <td>0.993851</td>\n",
       "      <td>0.989336</td>\n",
       "      <td>0.992678</td>\n",
       "      <td>0.003681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>38.301072</td>\n",
       "      <td>0.662623</td>\n",
       "      <td>0.010771</td>\n",
       "      <td>3.990412e-04</td>\n",
       "      <td>4</td>\n",
       "      <td>700</td>\n",
       "      <td>{'max_depth': 4, 'n_estimators': 700}</td>\n",
       "      <td>-12.749437</td>\n",
       "      <td>-11.721309</td>\n",
       "      <td>-12.207298</td>\n",
       "      <td>...</td>\n",
       "      <td>-10.253504</td>\n",
       "      <td>5.033411</td>\n",
       "      <td>18</td>\n",
       "      <td>0.987427</td>\n",
       "      <td>0.996606</td>\n",
       "      <td>0.996170</td>\n",
       "      <td>0.993851</td>\n",
       "      <td>0.989336</td>\n",
       "      <td>0.992678</td>\n",
       "      <td>0.003681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>44.464900</td>\n",
       "      <td>1.464862</td>\n",
       "      <td>0.010970</td>\n",
       "      <td>3.234067e-07</td>\n",
       "      <td>4</td>\n",
       "      <td>900</td>\n",
       "      <td>{'max_depth': 4, 'n_estimators': 900}</td>\n",
       "      <td>-12.749429</td>\n",
       "      <td>-11.721303</td>\n",
       "      <td>-12.207295</td>\n",
       "      <td>...</td>\n",
       "      <td>-10.253500</td>\n",
       "      <td>5.033404</td>\n",
       "      <td>17</td>\n",
       "      <td>0.987427</td>\n",
       "      <td>0.996606</td>\n",
       "      <td>0.996170</td>\n",
       "      <td>0.993851</td>\n",
       "      <td>0.989336</td>\n",
       "      <td>0.992678</td>\n",
       "      <td>0.003681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>46.691145</td>\n",
       "      <td>0.924734</td>\n",
       "      <td>0.011567</td>\n",
       "      <td>4.868595e-04</td>\n",
       "      <td>4</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'max_depth': 4, 'n_estimators': 1000}</td>\n",
       "      <td>-12.749427</td>\n",
       "      <td>-11.721301</td>\n",
       "      <td>-12.207295</td>\n",
       "      <td>...</td>\n",
       "      <td>-10.253500</td>\n",
       "      <td>5.033402</td>\n",
       "      <td>16</td>\n",
       "      <td>0.987427</td>\n",
       "      <td>0.996606</td>\n",
       "      <td>0.996170</td>\n",
       "      <td>0.993851</td>\n",
       "      <td>0.989336</td>\n",
       "      <td>0.992678</td>\n",
       "      <td>0.003681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>110.851647</td>\n",
       "      <td>1.609430</td>\n",
       "      <td>0.014162</td>\n",
       "      <td>7.464678e-04</td>\n",
       "      <td>4</td>\n",
       "      <td>3000</td>\n",
       "      <td>{'max_depth': 4, 'n_estimators': 3000}</td>\n",
       "      <td>-12.749409</td>\n",
       "      <td>-11.721294</td>\n",
       "      <td>-12.207287</td>\n",
       "      <td>...</td>\n",
       "      <td>-10.253506</td>\n",
       "      <td>5.033361</td>\n",
       "      <td>19</td>\n",
       "      <td>0.987427</td>\n",
       "      <td>0.996606</td>\n",
       "      <td>0.996170</td>\n",
       "      <td>0.993851</td>\n",
       "      <td>0.989336</td>\n",
       "      <td>0.992678</td>\n",
       "      <td>0.003681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14.070171</td>\n",
       "      <td>0.716075</td>\n",
       "      <td>0.008976</td>\n",
       "      <td>2.336015e-07</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_depth': 5, 'n_estimators': 100}</td>\n",
       "      <td>-12.640541</td>\n",
       "      <td>-11.028482</td>\n",
       "      <td>-11.472273</td>\n",
       "      <td>...</td>\n",
       "      <td>-10.236817</td>\n",
       "      <td>5.172117</td>\n",
       "      <td>14</td>\n",
       "      <td>0.987428</td>\n",
       "      <td>0.996607</td>\n",
       "      <td>0.996171</td>\n",
       "      <td>0.993851</td>\n",
       "      <td>0.989337</td>\n",
       "      <td>0.992679</td>\n",
       "      <td>0.003681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>20.509750</td>\n",
       "      <td>0.733134</td>\n",
       "      <td>0.010173</td>\n",
       "      <td>7.464803e-04</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>{'max_depth': 5, 'n_estimators': 300}</td>\n",
       "      <td>-12.640504</td>\n",
       "      <td>-11.028430</td>\n",
       "      <td>-11.472246</td>\n",
       "      <td>...</td>\n",
       "      <td>-10.236783</td>\n",
       "      <td>5.172092</td>\n",
       "      <td>13</td>\n",
       "      <td>0.987428</td>\n",
       "      <td>0.996607</td>\n",
       "      <td>0.996171</td>\n",
       "      <td>0.993851</td>\n",
       "      <td>0.989337</td>\n",
       "      <td>0.992679</td>\n",
       "      <td>0.003681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>26.830646</td>\n",
       "      <td>0.720175</td>\n",
       "      <td>0.010173</td>\n",
       "      <td>3.990889e-04</td>\n",
       "      <td>5</td>\n",
       "      <td>500</td>\n",
       "      <td>{'max_depth': 5, 'n_estimators': 500}</td>\n",
       "      <td>-12.640495</td>\n",
       "      <td>-11.028420</td>\n",
       "      <td>-11.472244</td>\n",
       "      <td>...</td>\n",
       "      <td>-10.236777</td>\n",
       "      <td>5.172084</td>\n",
       "      <td>12</td>\n",
       "      <td>0.987428</td>\n",
       "      <td>0.996607</td>\n",
       "      <td>0.996171</td>\n",
       "      <td>0.993851</td>\n",
       "      <td>0.989337</td>\n",
       "      <td>0.992679</td>\n",
       "      <td>0.003681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>33.190039</td>\n",
       "      <td>0.768244</td>\n",
       "      <td>0.010372</td>\n",
       "      <td>4.885971e-04</td>\n",
       "      <td>5</td>\n",
       "      <td>700</td>\n",
       "      <td>{'max_depth': 5, 'n_estimators': 700}</td>\n",
       "      <td>-12.640487</td>\n",
       "      <td>-11.028411</td>\n",
       "      <td>-11.472243</td>\n",
       "      <td>...</td>\n",
       "      <td>-10.236773</td>\n",
       "      <td>5.172076</td>\n",
       "      <td>11</td>\n",
       "      <td>0.987428</td>\n",
       "      <td>0.996607</td>\n",
       "      <td>0.996171</td>\n",
       "      <td>0.993851</td>\n",
       "      <td>0.989337</td>\n",
       "      <td>0.992679</td>\n",
       "      <td>0.003681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>40.488919</td>\n",
       "      <td>0.986284</td>\n",
       "      <td>0.010971</td>\n",
       "      <td>6.306002e-04</td>\n",
       "      <td>5</td>\n",
       "      <td>900</td>\n",
       "      <td>{'max_depth': 5, 'n_estimators': 900}</td>\n",
       "      <td>-12.640480</td>\n",
       "      <td>-11.028403</td>\n",
       "      <td>-11.472241</td>\n",
       "      <td>...</td>\n",
       "      <td>-10.236769</td>\n",
       "      <td>5.172070</td>\n",
       "      <td>9</td>\n",
       "      <td>0.987428</td>\n",
       "      <td>0.996607</td>\n",
       "      <td>0.996171</td>\n",
       "      <td>0.993851</td>\n",
       "      <td>0.989337</td>\n",
       "      <td>0.992679</td>\n",
       "      <td>0.003681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>43.756181</td>\n",
       "      <td>1.684105</td>\n",
       "      <td>0.012367</td>\n",
       "      <td>2.792549e-03</td>\n",
       "      <td>5</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'max_depth': 5, 'n_estimators': 1000}</td>\n",
       "      <td>-12.640479</td>\n",
       "      <td>-11.028401</td>\n",
       "      <td>-11.472241</td>\n",
       "      <td>...</td>\n",
       "      <td>-10.236769</td>\n",
       "      <td>5.172067</td>\n",
       "      <td>8</td>\n",
       "      <td>0.987428</td>\n",
       "      <td>0.996607</td>\n",
       "      <td>0.996171</td>\n",
       "      <td>0.993851</td>\n",
       "      <td>0.989337</td>\n",
       "      <td>0.992679</td>\n",
       "      <td>0.003681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>111.961578</td>\n",
       "      <td>1.711697</td>\n",
       "      <td>0.014362</td>\n",
       "      <td>1.352747e-03</td>\n",
       "      <td>5</td>\n",
       "      <td>3000</td>\n",
       "      <td>{'max_depth': 5, 'n_estimators': 3000}</td>\n",
       "      <td>-12.640455</td>\n",
       "      <td>-11.028384</td>\n",
       "      <td>-11.472234</td>\n",
       "      <td>...</td>\n",
       "      <td>-10.236770</td>\n",
       "      <td>5.172021</td>\n",
       "      <td>10</td>\n",
       "      <td>0.987428</td>\n",
       "      <td>0.996607</td>\n",
       "      <td>0.996171</td>\n",
       "      <td>0.993851</td>\n",
       "      <td>0.989337</td>\n",
       "      <td>0.992679</td>\n",
       "      <td>0.003681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>12.261210</td>\n",
       "      <td>0.391740</td>\n",
       "      <td>0.009175</td>\n",
       "      <td>3.988982e-04</td>\n",
       "      <td>6</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_depth': 6, 'n_estimators': 100}</td>\n",
       "      <td>-12.306088</td>\n",
       "      <td>-10.886131</td>\n",
       "      <td>-11.485530</td>\n",
       "      <td>...</td>\n",
       "      <td>-10.369334</td>\n",
       "      <td>5.362468</td>\n",
       "      <td>22</td>\n",
       "      <td>0.987428</td>\n",
       "      <td>0.996607</td>\n",
       "      <td>0.996171</td>\n",
       "      <td>0.993852</td>\n",
       "      <td>0.989338</td>\n",
       "      <td>0.992679</td>\n",
       "      <td>0.003680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>18.993406</td>\n",
       "      <td>0.374856</td>\n",
       "      <td>0.010971</td>\n",
       "      <td>2.522910e-03</td>\n",
       "      <td>6</td>\n",
       "      <td>300</td>\n",
       "      <td>{'max_depth': 6, 'n_estimators': 300}</td>\n",
       "      <td>-12.306057</td>\n",
       "      <td>-10.886095</td>\n",
       "      <td>-11.485557</td>\n",
       "      <td>...</td>\n",
       "      <td>-10.369338</td>\n",
       "      <td>5.362474</td>\n",
       "      <td>23</td>\n",
       "      <td>0.987428</td>\n",
       "      <td>0.996607</td>\n",
       "      <td>0.996171</td>\n",
       "      <td>0.993852</td>\n",
       "      <td>0.989338</td>\n",
       "      <td>0.992679</td>\n",
       "      <td>0.003680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>25.450936</td>\n",
       "      <td>0.777757</td>\n",
       "      <td>0.010971</td>\n",
       "      <td>1.544957e-03</td>\n",
       "      <td>6</td>\n",
       "      <td>500</td>\n",
       "      <td>{'max_depth': 6, 'n_estimators': 500}</td>\n",
       "      <td>-12.306047</td>\n",
       "      <td>-10.886087</td>\n",
       "      <td>-11.485561</td>\n",
       "      <td>...</td>\n",
       "      <td>-10.369340</td>\n",
       "      <td>5.362473</td>\n",
       "      <td>24</td>\n",
       "      <td>0.987428</td>\n",
       "      <td>0.996607</td>\n",
       "      <td>0.996171</td>\n",
       "      <td>0.993852</td>\n",
       "      <td>0.989338</td>\n",
       "      <td>0.992679</td>\n",
       "      <td>0.003680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>33.455329</td>\n",
       "      <td>1.301512</td>\n",
       "      <td>0.011370</td>\n",
       "      <td>1.353907e-03</td>\n",
       "      <td>6</td>\n",
       "      <td>700</td>\n",
       "      <td>{'max_depth': 6, 'n_estimators': 700}</td>\n",
       "      <td>-12.306039</td>\n",
       "      <td>-10.886081</td>\n",
       "      <td>-11.485563</td>\n",
       "      <td>...</td>\n",
       "      <td>-10.369343</td>\n",
       "      <td>5.362472</td>\n",
       "      <td>25</td>\n",
       "      <td>0.987428</td>\n",
       "      <td>0.996607</td>\n",
       "      <td>0.996171</td>\n",
       "      <td>0.993852</td>\n",
       "      <td>0.989338</td>\n",
       "      <td>0.992679</td>\n",
       "      <td>0.003680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>40.003218</td>\n",
       "      <td>0.375416</td>\n",
       "      <td>0.010572</td>\n",
       "      <td>4.884608e-04</td>\n",
       "      <td>6</td>\n",
       "      <td>900</td>\n",
       "      <td>{'max_depth': 6, 'n_estimators': 900}</td>\n",
       "      <td>-12.306032</td>\n",
       "      <td>-10.886075</td>\n",
       "      <td>-11.485565</td>\n",
       "      <td>...</td>\n",
       "      <td>-10.369345</td>\n",
       "      <td>5.362471</td>\n",
       "      <td>26</td>\n",
       "      <td>0.987428</td>\n",
       "      <td>0.996607</td>\n",
       "      <td>0.996171</td>\n",
       "      <td>0.993852</td>\n",
       "      <td>0.989338</td>\n",
       "      <td>0.992679</td>\n",
       "      <td>0.003680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>42.420752</td>\n",
       "      <td>1.063448</td>\n",
       "      <td>0.012367</td>\n",
       "      <td>1.850270e-03</td>\n",
       "      <td>6</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'max_depth': 6, 'n_estimators': 1000}</td>\n",
       "      <td>-12.306030</td>\n",
       "      <td>-10.886074</td>\n",
       "      <td>-11.485566</td>\n",
       "      <td>...</td>\n",
       "      <td>-10.369346</td>\n",
       "      <td>5.362470</td>\n",
       "      <td>27</td>\n",
       "      <td>0.987428</td>\n",
       "      <td>0.996607</td>\n",
       "      <td>0.996171</td>\n",
       "      <td>0.993852</td>\n",
       "      <td>0.989338</td>\n",
       "      <td>0.992679</td>\n",
       "      <td>0.003680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>110.845163</td>\n",
       "      <td>1.333344</td>\n",
       "      <td>0.013963</td>\n",
       "      <td>1.092406e-03</td>\n",
       "      <td>6</td>\n",
       "      <td>3000</td>\n",
       "      <td>{'max_depth': 6, 'n_estimators': 3000}</td>\n",
       "      <td>-12.306007</td>\n",
       "      <td>-10.886060</td>\n",
       "      <td>-11.485574</td>\n",
       "      <td>...</td>\n",
       "      <td>-10.369369</td>\n",
       "      <td>5.362443</td>\n",
       "      <td>28</td>\n",
       "      <td>0.987428</td>\n",
       "      <td>0.996607</td>\n",
       "      <td>0.996171</td>\n",
       "      <td>0.993852</td>\n",
       "      <td>0.989338</td>\n",
       "      <td>0.992679</td>\n",
       "      <td>0.003680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>11.682557</td>\n",
       "      <td>0.809144</td>\n",
       "      <td>0.009375</td>\n",
       "      <td>4.889087e-04</td>\n",
       "      <td>7</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_depth': 7, 'n_estimators': 100}</td>\n",
       "      <td>-12.625192</td>\n",
       "      <td>-12.221411</td>\n",
       "      <td>-11.048660</td>\n",
       "      <td>...</td>\n",
       "      <td>-10.774121</td>\n",
       "      <td>5.556254</td>\n",
       "      <td>33</td>\n",
       "      <td>0.987429</td>\n",
       "      <td>0.996606</td>\n",
       "      <td>0.996172</td>\n",
       "      <td>0.993853</td>\n",
       "      <td>0.989339</td>\n",
       "      <td>0.992680</td>\n",
       "      <td>0.003680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>18.757636</td>\n",
       "      <td>0.367971</td>\n",
       "      <td>0.011170</td>\n",
       "      <td>1.595873e-03</td>\n",
       "      <td>7</td>\n",
       "      <td>300</td>\n",
       "      <td>{'max_depth': 7, 'n_estimators': 300}</td>\n",
       "      <td>-12.625165</td>\n",
       "      <td>-12.221386</td>\n",
       "      <td>-11.048682</td>\n",
       "      <td>...</td>\n",
       "      <td>-10.774122</td>\n",
       "      <td>5.556267</td>\n",
       "      <td>35</td>\n",
       "      <td>0.987429</td>\n",
       "      <td>0.996606</td>\n",
       "      <td>0.996172</td>\n",
       "      <td>0.993853</td>\n",
       "      <td>0.989339</td>\n",
       "      <td>0.992680</td>\n",
       "      <td>0.003680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>25.345219</td>\n",
       "      <td>0.993689</td>\n",
       "      <td>0.009972</td>\n",
       "      <td>1.548069e-06</td>\n",
       "      <td>7</td>\n",
       "      <td>500</td>\n",
       "      <td>{'max_depth': 7, 'n_estimators': 500}</td>\n",
       "      <td>-12.625156</td>\n",
       "      <td>-12.221378</td>\n",
       "      <td>-11.048686</td>\n",
       "      <td>...</td>\n",
       "      <td>-10.774121</td>\n",
       "      <td>5.556274</td>\n",
       "      <td>34</td>\n",
       "      <td>0.987429</td>\n",
       "      <td>0.996606</td>\n",
       "      <td>0.996172</td>\n",
       "      <td>0.993853</td>\n",
       "      <td>0.989339</td>\n",
       "      <td>0.992680</td>\n",
       "      <td>0.003680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>31.924623</td>\n",
       "      <td>0.636841</td>\n",
       "      <td>0.010372</td>\n",
       "      <td>4.885582e-04</td>\n",
       "      <td>7</td>\n",
       "      <td>700</td>\n",
       "      <td>{'max_depth': 7, 'n_estimators': 700}</td>\n",
       "      <td>-12.625148</td>\n",
       "      <td>-12.221372</td>\n",
       "      <td>-11.048689</td>\n",
       "      <td>...</td>\n",
       "      <td>-10.774120</td>\n",
       "      <td>5.556281</td>\n",
       "      <td>32</td>\n",
       "      <td>0.987429</td>\n",
       "      <td>0.996606</td>\n",
       "      <td>0.996172</td>\n",
       "      <td>0.993853</td>\n",
       "      <td>0.989339</td>\n",
       "      <td>0.992680</td>\n",
       "      <td>0.003680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>37.566335</td>\n",
       "      <td>0.402002</td>\n",
       "      <td>0.010372</td>\n",
       "      <td>4.884998e-04</td>\n",
       "      <td>7</td>\n",
       "      <td>900</td>\n",
       "      <td>{'max_depth': 7, 'n_estimators': 900}</td>\n",
       "      <td>-12.625142</td>\n",
       "      <td>-12.221367</td>\n",
       "      <td>-11.048691</td>\n",
       "      <td>...</td>\n",
       "      <td>-10.774118</td>\n",
       "      <td>5.556287</td>\n",
       "      <td>31</td>\n",
       "      <td>0.987429</td>\n",
       "      <td>0.996606</td>\n",
       "      <td>0.996172</td>\n",
       "      <td>0.993853</td>\n",
       "      <td>0.989339</td>\n",
       "      <td>0.992680</td>\n",
       "      <td>0.003680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>40.729875</td>\n",
       "      <td>0.483288</td>\n",
       "      <td>0.010771</td>\n",
       "      <td>3.992081e-04</td>\n",
       "      <td>7</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'max_depth': 7, 'n_estimators': 1000}</td>\n",
       "      <td>-12.625141</td>\n",
       "      <td>-12.221366</td>\n",
       "      <td>-11.048692</td>\n",
       "      <td>...</td>\n",
       "      <td>-10.774117</td>\n",
       "      <td>5.556289</td>\n",
       "      <td>30</td>\n",
       "      <td>0.987429</td>\n",
       "      <td>0.996606</td>\n",
       "      <td>0.996172</td>\n",
       "      <td>0.993853</td>\n",
       "      <td>0.989339</td>\n",
       "      <td>0.992680</td>\n",
       "      <td>0.003680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>105.202853</td>\n",
       "      <td>1.006295</td>\n",
       "      <td>0.013364</td>\n",
       "      <td>4.888698e-04</td>\n",
       "      <td>7</td>\n",
       "      <td>3000</td>\n",
       "      <td>{'max_depth': 7, 'n_estimators': 3000}</td>\n",
       "      <td>-12.625121</td>\n",
       "      <td>-12.221349</td>\n",
       "      <td>-11.048703</td>\n",
       "      <td>...</td>\n",
       "      <td>-10.774102</td>\n",
       "      <td>5.556336</td>\n",
       "      <td>29</td>\n",
       "      <td>0.987429</td>\n",
       "      <td>0.996606</td>\n",
       "      <td>0.996172</td>\n",
       "      <td>0.993853</td>\n",
       "      <td>0.989339</td>\n",
       "      <td>0.992680</td>\n",
       "      <td>0.003680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>10.866739</td>\n",
       "      <td>0.280806</td>\n",
       "      <td>0.008976</td>\n",
       "      <td>2.132481e-07</td>\n",
       "      <td>8</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_depth': 8, 'n_estimators': 100}</td>\n",
       "      <td>-12.887637</td>\n",
       "      <td>-13.645282</td>\n",
       "      <td>-13.149483</td>\n",
       "      <td>...</td>\n",
       "      <td>-11.810501</td>\n",
       "      <td>6.106056</td>\n",
       "      <td>36</td>\n",
       "      <td>0.987429</td>\n",
       "      <td>0.996607</td>\n",
       "      <td>0.996172</td>\n",
       "      <td>0.993853</td>\n",
       "      <td>0.989339</td>\n",
       "      <td>0.992680</td>\n",
       "      <td>0.003681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>17.533709</td>\n",
       "      <td>0.455182</td>\n",
       "      <td>0.009973</td>\n",
       "      <td>1.092710e-03</td>\n",
       "      <td>8</td>\n",
       "      <td>300</td>\n",
       "      <td>{'max_depth': 8, 'n_estimators': 300}</td>\n",
       "      <td>-12.887608</td>\n",
       "      <td>-13.645256</td>\n",
       "      <td>-13.149504</td>\n",
       "      <td>...</td>\n",
       "      <td>-11.810505</td>\n",
       "      <td>6.106058</td>\n",
       "      <td>37</td>\n",
       "      <td>0.987429</td>\n",
       "      <td>0.996607</td>\n",
       "      <td>0.996172</td>\n",
       "      <td>0.993853</td>\n",
       "      <td>0.989339</td>\n",
       "      <td>0.992680</td>\n",
       "      <td>0.003681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>24.051678</td>\n",
       "      <td>0.313567</td>\n",
       "      <td>0.009973</td>\n",
       "      <td>6.309018e-04</td>\n",
       "      <td>8</td>\n",
       "      <td>500</td>\n",
       "      <td>{'max_depth': 8, 'n_estimators': 500}</td>\n",
       "      <td>-12.887598</td>\n",
       "      <td>-13.645248</td>\n",
       "      <td>-13.149507</td>\n",
       "      <td>...</td>\n",
       "      <td>-11.810507</td>\n",
       "      <td>6.106057</td>\n",
       "      <td>38</td>\n",
       "      <td>0.987429</td>\n",
       "      <td>0.996607</td>\n",
       "      <td>0.996172</td>\n",
       "      <td>0.993853</td>\n",
       "      <td>0.989339</td>\n",
       "      <td>0.992680</td>\n",
       "      <td>0.003681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>30.463131</td>\n",
       "      <td>0.739417</td>\n",
       "      <td>0.009973</td>\n",
       "      <td>1.784161e-07</td>\n",
       "      <td>8</td>\n",
       "      <td>700</td>\n",
       "      <td>{'max_depth': 8, 'n_estimators': 700}</td>\n",
       "      <td>-12.887590</td>\n",
       "      <td>-13.645240</td>\n",
       "      <td>-13.149510</td>\n",
       "      <td>...</td>\n",
       "      <td>-11.810508</td>\n",
       "      <td>6.106056</td>\n",
       "      <td>39</td>\n",
       "      <td>0.987429</td>\n",
       "      <td>0.996607</td>\n",
       "      <td>0.996172</td>\n",
       "      <td>0.993853</td>\n",
       "      <td>0.989339</td>\n",
       "      <td>0.992680</td>\n",
       "      <td>0.003681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>37.077642</td>\n",
       "      <td>0.796411</td>\n",
       "      <td>0.010173</td>\n",
       "      <td>3.989697e-04</td>\n",
       "      <td>8</td>\n",
       "      <td>900</td>\n",
       "      <td>{'max_depth': 8, 'n_estimators': 900}</td>\n",
       "      <td>-12.887583</td>\n",
       "      <td>-13.645233</td>\n",
       "      <td>-13.149512</td>\n",
       "      <td>...</td>\n",
       "      <td>-11.810510</td>\n",
       "      <td>6.106054</td>\n",
       "      <td>40</td>\n",
       "      <td>0.987429</td>\n",
       "      <td>0.996607</td>\n",
       "      <td>0.996172</td>\n",
       "      <td>0.993853</td>\n",
       "      <td>0.989339</td>\n",
       "      <td>0.992680</td>\n",
       "      <td>0.003681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>40.183137</td>\n",
       "      <td>0.391922</td>\n",
       "      <td>0.011170</td>\n",
       "      <td>3.988982e-04</td>\n",
       "      <td>8</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'max_depth': 8, 'n_estimators': 1000}</td>\n",
       "      <td>-12.887581</td>\n",
       "      <td>-13.645233</td>\n",
       "      <td>-13.149512</td>\n",
       "      <td>...</td>\n",
       "      <td>-11.810511</td>\n",
       "      <td>6.106052</td>\n",
       "      <td>41</td>\n",
       "      <td>0.987429</td>\n",
       "      <td>0.996607</td>\n",
       "      <td>0.996172</td>\n",
       "      <td>0.993853</td>\n",
       "      <td>0.989339</td>\n",
       "      <td>0.992680</td>\n",
       "      <td>0.003681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>105.656440</td>\n",
       "      <td>1.001348</td>\n",
       "      <td>0.013763</td>\n",
       "      <td>7.462000e-04</td>\n",
       "      <td>8</td>\n",
       "      <td>3000</td>\n",
       "      <td>{'max_depth': 8, 'n_estimators': 3000}</td>\n",
       "      <td>-12.887561</td>\n",
       "      <td>-13.645216</td>\n",
       "      <td>-13.149520</td>\n",
       "      <td>...</td>\n",
       "      <td>-11.810531</td>\n",
       "      <td>6.106022</td>\n",
       "      <td>42</td>\n",
       "      <td>0.987429</td>\n",
       "      <td>0.996607</td>\n",
       "      <td>0.996172</td>\n",
       "      <td>0.993853</td>\n",
       "      <td>0.989339</td>\n",
       "      <td>0.992680</td>\n",
       "      <td>0.003681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>11.509819</td>\n",
       "      <td>0.126400</td>\n",
       "      <td>0.008976</td>\n",
       "      <td>1.784161e-07</td>\n",
       "      <td>9</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_depth': 9, 'n_estimators': 100}</td>\n",
       "      <td>-13.690637</td>\n",
       "      <td>-13.878027</td>\n",
       "      <td>-14.676673</td>\n",
       "      <td>...</td>\n",
       "      <td>-12.219098</td>\n",
       "      <td>6.059787</td>\n",
       "      <td>43</td>\n",
       "      <td>0.987430</td>\n",
       "      <td>0.996608</td>\n",
       "      <td>0.996173</td>\n",
       "      <td>0.993854</td>\n",
       "      <td>0.989339</td>\n",
       "      <td>0.992681</td>\n",
       "      <td>0.003680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>18.018014</td>\n",
       "      <td>0.247704</td>\n",
       "      <td>0.010173</td>\n",
       "      <td>9.770677e-04</td>\n",
       "      <td>9</td>\n",
       "      <td>300</td>\n",
       "      <td>{'max_depth': 9, 'n_estimators': 300}</td>\n",
       "      <td>-13.690610</td>\n",
       "      <td>-13.878053</td>\n",
       "      <td>-14.676693</td>\n",
       "      <td>...</td>\n",
       "      <td>-12.219114</td>\n",
       "      <td>6.059791</td>\n",
       "      <td>44</td>\n",
       "      <td>0.987430</td>\n",
       "      <td>0.996608</td>\n",
       "      <td>0.996173</td>\n",
       "      <td>0.993854</td>\n",
       "      <td>0.989339</td>\n",
       "      <td>0.992681</td>\n",
       "      <td>0.003680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>24.564506</td>\n",
       "      <td>0.125514</td>\n",
       "      <td>0.009973</td>\n",
       "      <td>1.168008e-07</td>\n",
       "      <td>9</td>\n",
       "      <td>500</td>\n",
       "      <td>{'max_depth': 9, 'n_estimators': 500}</td>\n",
       "      <td>-13.690600</td>\n",
       "      <td>-13.878061</td>\n",
       "      <td>-14.676696</td>\n",
       "      <td>...</td>\n",
       "      <td>-12.219119</td>\n",
       "      <td>6.059790</td>\n",
       "      <td>45</td>\n",
       "      <td>0.987430</td>\n",
       "      <td>0.996608</td>\n",
       "      <td>0.996173</td>\n",
       "      <td>0.993854</td>\n",
       "      <td>0.989339</td>\n",
       "      <td>0.992681</td>\n",
       "      <td>0.003680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>31.109403</td>\n",
       "      <td>0.204871</td>\n",
       "      <td>0.010572</td>\n",
       "      <td>4.886167e-04</td>\n",
       "      <td>9</td>\n",
       "      <td>700</td>\n",
       "      <td>{'max_depth': 9, 'n_estimators': 700}</td>\n",
       "      <td>-13.690592</td>\n",
       "      <td>-13.878068</td>\n",
       "      <td>-14.676698</td>\n",
       "      <td>...</td>\n",
       "      <td>-12.219124</td>\n",
       "      <td>6.059789</td>\n",
       "      <td>46</td>\n",
       "      <td>0.987430</td>\n",
       "      <td>0.996608</td>\n",
       "      <td>0.996173</td>\n",
       "      <td>0.993854</td>\n",
       "      <td>0.989339</td>\n",
       "      <td>0.992681</td>\n",
       "      <td>0.003680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>37.902436</td>\n",
       "      <td>0.228725</td>\n",
       "      <td>0.010173</td>\n",
       "      <td>3.991843e-04</td>\n",
       "      <td>9</td>\n",
       "      <td>900</td>\n",
       "      <td>{'max_depth': 9, 'n_estimators': 900}</td>\n",
       "      <td>-13.690586</td>\n",
       "      <td>-13.878073</td>\n",
       "      <td>-14.676699</td>\n",
       "      <td>...</td>\n",
       "      <td>-12.219129</td>\n",
       "      <td>6.059788</td>\n",
       "      <td>47</td>\n",
       "      <td>0.987430</td>\n",
       "      <td>0.996608</td>\n",
       "      <td>0.996173</td>\n",
       "      <td>0.993854</td>\n",
       "      <td>0.989339</td>\n",
       "      <td>0.992681</td>\n",
       "      <td>0.003680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>41.645825</td>\n",
       "      <td>0.720050</td>\n",
       "      <td>0.011569</td>\n",
       "      <td>2.239003e-03</td>\n",
       "      <td>9</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'max_depth': 9, 'n_estimators': 1000}</td>\n",
       "      <td>-13.690584</td>\n",
       "      <td>-13.878074</td>\n",
       "      <td>-14.676700</td>\n",
       "      <td>...</td>\n",
       "      <td>-12.219130</td>\n",
       "      <td>6.059786</td>\n",
       "      <td>48</td>\n",
       "      <td>0.987430</td>\n",
       "      <td>0.996608</td>\n",
       "      <td>0.996173</td>\n",
       "      <td>0.993854</td>\n",
       "      <td>0.989339</td>\n",
       "      <td>0.992681</td>\n",
       "      <td>0.003680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>106.712416</td>\n",
       "      <td>2.460531</td>\n",
       "      <td>0.013564</td>\n",
       "      <td>4.884609e-04</td>\n",
       "      <td>9</td>\n",
       "      <td>3000</td>\n",
       "      <td>{'max_depth': 9, 'n_estimators': 3000}</td>\n",
       "      <td>-13.690556</td>\n",
       "      <td>-13.878090</td>\n",
       "      <td>-14.676705</td>\n",
       "      <td>...</td>\n",
       "      <td>-12.219154</td>\n",
       "      <td>6.059754</td>\n",
       "      <td>49</td>\n",
       "      <td>0.987430</td>\n",
       "      <td>0.996608</td>\n",
       "      <td>0.996173</td>\n",
       "      <td>0.993854</td>\n",
       "      <td>0.989339</td>\n",
       "      <td>0.992681</td>\n",
       "      <td>0.003680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>12.409413</td>\n",
       "      <td>0.907695</td>\n",
       "      <td>0.009574</td>\n",
       "      <td>4.887140e-04</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_depth': 10, 'n_estimators': 100}</td>\n",
       "      <td>-13.546094</td>\n",
       "      <td>-14.276357</td>\n",
       "      <td>-13.114333</td>\n",
       "      <td>...</td>\n",
       "      <td>-12.256919</td>\n",
       "      <td>6.342889</td>\n",
       "      <td>50</td>\n",
       "      <td>0.987430</td>\n",
       "      <td>0.996608</td>\n",
       "      <td>0.996173</td>\n",
       "      <td>0.993854</td>\n",
       "      <td>0.989340</td>\n",
       "      <td>0.992681</td>\n",
       "      <td>0.003680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>18.350923</td>\n",
       "      <td>0.252005</td>\n",
       "      <td>0.009375</td>\n",
       "      <td>4.886361e-04</td>\n",
       "      <td>10</td>\n",
       "      <td>300</td>\n",
       "      <td>{'max_depth': 10, 'n_estimators': 300}</td>\n",
       "      <td>-13.546122</td>\n",
       "      <td>-14.276333</td>\n",
       "      <td>-13.114307</td>\n",
       "      <td>...</td>\n",
       "      <td>-12.256924</td>\n",
       "      <td>6.342891</td>\n",
       "      <td>51</td>\n",
       "      <td>0.987430</td>\n",
       "      <td>0.996608</td>\n",
       "      <td>0.996173</td>\n",
       "      <td>0.993854</td>\n",
       "      <td>0.989340</td>\n",
       "      <td>0.992681</td>\n",
       "      <td>0.003680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>24.836181</td>\n",
       "      <td>0.255396</td>\n",
       "      <td>0.009972</td>\n",
       "      <td>3.553637e-06</td>\n",
       "      <td>10</td>\n",
       "      <td>500</td>\n",
       "      <td>{'max_depth': 10, 'n_estimators': 500}</td>\n",
       "      <td>-13.546132</td>\n",
       "      <td>-14.276327</td>\n",
       "      <td>-13.114301</td>\n",
       "      <td>...</td>\n",
       "      <td>-12.256929</td>\n",
       "      <td>6.342891</td>\n",
       "      <td>52</td>\n",
       "      <td>0.987430</td>\n",
       "      <td>0.996608</td>\n",
       "      <td>0.996173</td>\n",
       "      <td>0.993854</td>\n",
       "      <td>0.989340</td>\n",
       "      <td>0.992681</td>\n",
       "      <td>0.003680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>31.451688</td>\n",
       "      <td>0.382398</td>\n",
       "      <td>0.010173</td>\n",
       "      <td>3.992796e-04</td>\n",
       "      <td>10</td>\n",
       "      <td>700</td>\n",
       "      <td>{'max_depth': 10, 'n_estimators': 700}</td>\n",
       "      <td>-13.546140</td>\n",
       "      <td>-14.276321</td>\n",
       "      <td>-13.114295</td>\n",
       "      <td>...</td>\n",
       "      <td>-12.256933</td>\n",
       "      <td>6.342890</td>\n",
       "      <td>53</td>\n",
       "      <td>0.987430</td>\n",
       "      <td>0.996608</td>\n",
       "      <td>0.996173</td>\n",
       "      <td>0.993854</td>\n",
       "      <td>0.989340</td>\n",
       "      <td>0.992681</td>\n",
       "      <td>0.003680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>37.880694</td>\n",
       "      <td>0.466141</td>\n",
       "      <td>0.010572</td>\n",
       "      <td>4.887723e-04</td>\n",
       "      <td>10</td>\n",
       "      <td>900</td>\n",
       "      <td>{'max_depth': 10, 'n_estimators': 900}</td>\n",
       "      <td>-13.546147</td>\n",
       "      <td>-14.276316</td>\n",
       "      <td>-13.114291</td>\n",
       "      <td>...</td>\n",
       "      <td>-12.256937</td>\n",
       "      <td>6.342889</td>\n",
       "      <td>54</td>\n",
       "      <td>0.987430</td>\n",
       "      <td>0.996608</td>\n",
       "      <td>0.996173</td>\n",
       "      <td>0.993854</td>\n",
       "      <td>0.989340</td>\n",
       "      <td>0.992681</td>\n",
       "      <td>0.003680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>38.354228</td>\n",
       "      <td>1.585269</td>\n",
       "      <td>0.008976</td>\n",
       "      <td>1.261389e-03</td>\n",
       "      <td>10</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'max_depth': 10, 'n_estimators': 1000}</td>\n",
       "      <td>-13.546148</td>\n",
       "      <td>-14.276316</td>\n",
       "      <td>-13.114290</td>\n",
       "      <td>...</td>\n",
       "      <td>-12.256938</td>\n",
       "      <td>6.342887</td>\n",
       "      <td>55</td>\n",
       "      <td>0.987430</td>\n",
       "      <td>0.996608</td>\n",
       "      <td>0.996173</td>\n",
       "      <td>0.993854</td>\n",
       "      <td>0.989340</td>\n",
       "      <td>0.992681</td>\n",
       "      <td>0.003680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>65.544911</td>\n",
       "      <td>2.618767</td>\n",
       "      <td>0.008178</td>\n",
       "      <td>7.464294e-04</td>\n",
       "      <td>10</td>\n",
       "      <td>3000</td>\n",
       "      <td>{'max_depth': 10, 'n_estimators': 3000}</td>\n",
       "      <td>-13.546179</td>\n",
       "      <td>-14.276306</td>\n",
       "      <td>-13.114277</td>\n",
       "      <td>...</td>\n",
       "      <td>-12.256968</td>\n",
       "      <td>6.342859</td>\n",
       "      <td>56</td>\n",
       "      <td>0.987430</td>\n",
       "      <td>0.996608</td>\n",
       "      <td>0.996173</td>\n",
       "      <td>0.993854</td>\n",
       "      <td>0.989340</td>\n",
       "      <td>0.992681</td>\n",
       "      <td>0.003680</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>56 rows √ó 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0       10.631767      0.130167         0.009375    4.886361e-04   \n",
       "1       27.925318      0.975380         0.010372    4.883635e-04   \n",
       "2       33.095691      1.183824         0.010771    3.989697e-04   \n",
       "3       39.633008      1.296226         0.012167    2.917996e-03   \n",
       "4       46.055831      1.254065         0.011769    3.989459e-04   \n",
       "5       49.401683      1.357552         0.011370    4.885777e-04   \n",
       "6      117.403622      1.924388         0.016567    2.071911e-03   \n",
       "7       12.488202      0.131866         0.008976    6.309019e-04   \n",
       "8       23.503544      0.735191         0.009774    3.989220e-04   \n",
       "9       30.076365      0.857744         0.010173    3.988983e-04   \n",
       "10      38.301072      0.662623         0.010771    3.990412e-04   \n",
       "11      44.464900      1.464862         0.010970    3.234067e-07   \n",
       "12      46.691145      0.924734         0.011567    4.868595e-04   \n",
       "13     110.851647      1.609430         0.014162    7.464678e-04   \n",
       "14      14.070171      0.716075         0.008976    2.336015e-07   \n",
       "15      20.509750      0.733134         0.010173    7.464803e-04   \n",
       "16      26.830646      0.720175         0.010173    3.990889e-04   \n",
       "17      33.190039      0.768244         0.010372    4.885971e-04   \n",
       "18      40.488919      0.986284         0.010971    6.306002e-04   \n",
       "19      43.756181      1.684105         0.012367    2.792549e-03   \n",
       "20     111.961578      1.711697         0.014362    1.352747e-03   \n",
       "21      12.261210      0.391740         0.009175    3.988982e-04   \n",
       "22      18.993406      0.374856         0.010971    2.522910e-03   \n",
       "23      25.450936      0.777757         0.010971    1.544957e-03   \n",
       "24      33.455329      1.301512         0.011370    1.353907e-03   \n",
       "25      40.003218      0.375416         0.010572    4.884608e-04   \n",
       "26      42.420752      1.063448         0.012367    1.850270e-03   \n",
       "27     110.845163      1.333344         0.013963    1.092406e-03   \n",
       "28      11.682557      0.809144         0.009375    4.889087e-04   \n",
       "29      18.757636      0.367971         0.011170    1.595873e-03   \n",
       "30      25.345219      0.993689         0.009972    1.548069e-06   \n",
       "31      31.924623      0.636841         0.010372    4.885582e-04   \n",
       "32      37.566335      0.402002         0.010372    4.884998e-04   \n",
       "33      40.729875      0.483288         0.010771    3.992081e-04   \n",
       "34     105.202853      1.006295         0.013364    4.888698e-04   \n",
       "35      10.866739      0.280806         0.008976    2.132481e-07   \n",
       "36      17.533709      0.455182         0.009973    1.092710e-03   \n",
       "37      24.051678      0.313567         0.009973    6.309018e-04   \n",
       "38      30.463131      0.739417         0.009973    1.784161e-07   \n",
       "39      37.077642      0.796411         0.010173    3.989697e-04   \n",
       "40      40.183137      0.391922         0.011170    3.988982e-04   \n",
       "41     105.656440      1.001348         0.013763    7.462000e-04   \n",
       "42      11.509819      0.126400         0.008976    1.784161e-07   \n",
       "43      18.018014      0.247704         0.010173    9.770677e-04   \n",
       "44      24.564506      0.125514         0.009973    1.168008e-07   \n",
       "45      31.109403      0.204871         0.010572    4.886167e-04   \n",
       "46      37.902436      0.228725         0.010173    3.991843e-04   \n",
       "47      41.645825      0.720050         0.011569    2.239003e-03   \n",
       "48     106.712416      2.460531         0.013564    4.884609e-04   \n",
       "49      12.409413      0.907695         0.009574    4.887140e-04   \n",
       "50      18.350923      0.252005         0.009375    4.886361e-04   \n",
       "51      24.836181      0.255396         0.009972    3.553637e-06   \n",
       "52      31.451688      0.382398         0.010173    3.992796e-04   \n",
       "53      37.880694      0.466141         0.010572    4.887723e-04   \n",
       "54      38.354228      1.585269         0.008976    1.261389e-03   \n",
       "55      65.544911      2.618767         0.008178    7.464294e-04   \n",
       "\n",
       "   param_max_depth param_n_estimators  \\\n",
       "0                3                100   \n",
       "1                3                300   \n",
       "2                3                500   \n",
       "3                3                700   \n",
       "4                3                900   \n",
       "5                3               1000   \n",
       "6                3               3000   \n",
       "7                4                100   \n",
       "8                4                300   \n",
       "9                4                500   \n",
       "10               4                700   \n",
       "11               4                900   \n",
       "12               4               1000   \n",
       "13               4               3000   \n",
       "14               5                100   \n",
       "15               5                300   \n",
       "16               5                500   \n",
       "17               5                700   \n",
       "18               5                900   \n",
       "19               5               1000   \n",
       "20               5               3000   \n",
       "21               6                100   \n",
       "22               6                300   \n",
       "23               6                500   \n",
       "24               6                700   \n",
       "25               6                900   \n",
       "26               6               1000   \n",
       "27               6               3000   \n",
       "28               7                100   \n",
       "29               7                300   \n",
       "30               7                500   \n",
       "31               7                700   \n",
       "32               7                900   \n",
       "33               7               1000   \n",
       "34               7               3000   \n",
       "35               8                100   \n",
       "36               8                300   \n",
       "37               8                500   \n",
       "38               8                700   \n",
       "39               8                900   \n",
       "40               8               1000   \n",
       "41               8               3000   \n",
       "42               9                100   \n",
       "43               9                300   \n",
       "44               9                500   \n",
       "45               9                700   \n",
       "46               9                900   \n",
       "47               9               1000   \n",
       "48               9               3000   \n",
       "49              10                100   \n",
       "50              10                300   \n",
       "51              10                500   \n",
       "52              10                700   \n",
       "53              10                900   \n",
       "54              10               1000   \n",
       "55              10               3000   \n",
       "\n",
       "                                     params  split0_test_score  \\\n",
       "0     {'max_depth': 3, 'n_estimators': 100}         -12.060514   \n",
       "1     {'max_depth': 3, 'n_estimators': 300}         -12.129118   \n",
       "2     {'max_depth': 3, 'n_estimators': 500}         -12.129148   \n",
       "3     {'max_depth': 3, 'n_estimators': 700}         -12.129156   \n",
       "4     {'max_depth': 3, 'n_estimators': 900}         -12.129163   \n",
       "5    {'max_depth': 3, 'n_estimators': 1000}         -12.129166   \n",
       "6    {'max_depth': 3, 'n_estimators': 3000}         -12.129193   \n",
       "7     {'max_depth': 4, 'n_estimators': 100}         -12.747214   \n",
       "8     {'max_depth': 4, 'n_estimators': 300}         -12.749460   \n",
       "9     {'max_depth': 4, 'n_estimators': 500}         -12.749446   \n",
       "10    {'max_depth': 4, 'n_estimators': 700}         -12.749437   \n",
       "11    {'max_depth': 4, 'n_estimators': 900}         -12.749429   \n",
       "12   {'max_depth': 4, 'n_estimators': 1000}         -12.749427   \n",
       "13   {'max_depth': 4, 'n_estimators': 3000}         -12.749409   \n",
       "14    {'max_depth': 5, 'n_estimators': 100}         -12.640541   \n",
       "15    {'max_depth': 5, 'n_estimators': 300}         -12.640504   \n",
       "16    {'max_depth': 5, 'n_estimators': 500}         -12.640495   \n",
       "17    {'max_depth': 5, 'n_estimators': 700}         -12.640487   \n",
       "18    {'max_depth': 5, 'n_estimators': 900}         -12.640480   \n",
       "19   {'max_depth': 5, 'n_estimators': 1000}         -12.640479   \n",
       "20   {'max_depth': 5, 'n_estimators': 3000}         -12.640455   \n",
       "21    {'max_depth': 6, 'n_estimators': 100}         -12.306088   \n",
       "22    {'max_depth': 6, 'n_estimators': 300}         -12.306057   \n",
       "23    {'max_depth': 6, 'n_estimators': 500}         -12.306047   \n",
       "24    {'max_depth': 6, 'n_estimators': 700}         -12.306039   \n",
       "25    {'max_depth': 6, 'n_estimators': 900}         -12.306032   \n",
       "26   {'max_depth': 6, 'n_estimators': 1000}         -12.306030   \n",
       "27   {'max_depth': 6, 'n_estimators': 3000}         -12.306007   \n",
       "28    {'max_depth': 7, 'n_estimators': 100}         -12.625192   \n",
       "29    {'max_depth': 7, 'n_estimators': 300}         -12.625165   \n",
       "30    {'max_depth': 7, 'n_estimators': 500}         -12.625156   \n",
       "31    {'max_depth': 7, 'n_estimators': 700}         -12.625148   \n",
       "32    {'max_depth': 7, 'n_estimators': 900}         -12.625142   \n",
       "33   {'max_depth': 7, 'n_estimators': 1000}         -12.625141   \n",
       "34   {'max_depth': 7, 'n_estimators': 3000}         -12.625121   \n",
       "35    {'max_depth': 8, 'n_estimators': 100}         -12.887637   \n",
       "36    {'max_depth': 8, 'n_estimators': 300}         -12.887608   \n",
       "37    {'max_depth': 8, 'n_estimators': 500}         -12.887598   \n",
       "38    {'max_depth': 8, 'n_estimators': 700}         -12.887590   \n",
       "39    {'max_depth': 8, 'n_estimators': 900}         -12.887583   \n",
       "40   {'max_depth': 8, 'n_estimators': 1000}         -12.887581   \n",
       "41   {'max_depth': 8, 'n_estimators': 3000}         -12.887561   \n",
       "42    {'max_depth': 9, 'n_estimators': 100}         -13.690637   \n",
       "43    {'max_depth': 9, 'n_estimators': 300}         -13.690610   \n",
       "44    {'max_depth': 9, 'n_estimators': 500}         -13.690600   \n",
       "45    {'max_depth': 9, 'n_estimators': 700}         -13.690592   \n",
       "46    {'max_depth': 9, 'n_estimators': 900}         -13.690586   \n",
       "47   {'max_depth': 9, 'n_estimators': 1000}         -13.690584   \n",
       "48   {'max_depth': 9, 'n_estimators': 3000}         -13.690556   \n",
       "49   {'max_depth': 10, 'n_estimators': 100}         -13.546094   \n",
       "50   {'max_depth': 10, 'n_estimators': 300}         -13.546122   \n",
       "51   {'max_depth': 10, 'n_estimators': 500}         -13.546132   \n",
       "52   {'max_depth': 10, 'n_estimators': 700}         -13.546140   \n",
       "53   {'max_depth': 10, 'n_estimators': 900}         -13.546147   \n",
       "54  {'max_depth': 10, 'n_estimators': 1000}         -13.546148   \n",
       "55  {'max_depth': 10, 'n_estimators': 3000}         -13.546179   \n",
       "\n",
       "    split1_test_score  split2_test_score  ...  mean_test_score  \\\n",
       "0           -9.430328         -11.387660  ...        -9.681875   \n",
       "1           -9.558391         -11.443485  ...        -9.736813   \n",
       "2           -9.555392         -11.443451  ...        -9.736227   \n",
       "3           -9.555402         -11.443448  ...        -9.736234   \n",
       "4           -9.555409         -11.443447  ...        -9.736240   \n",
       "5           -9.555413         -11.443446  ...        -9.736242   \n",
       "6           -9.555431         -11.443442  ...        -9.736274   \n",
       "7          -11.731895         -12.204623  ...       -10.251003   \n",
       "8          -11.721330         -12.207308  ...       -10.253517   \n",
       "9          -11.721316         -12.207300  ...       -10.253508   \n",
       "10         -11.721309         -12.207298  ...       -10.253504   \n",
       "11         -11.721303         -12.207295  ...       -10.253500   \n",
       "12         -11.721301         -12.207295  ...       -10.253500   \n",
       "13         -11.721294         -12.207287  ...       -10.253506   \n",
       "14         -11.028482         -11.472273  ...       -10.236817   \n",
       "15         -11.028430         -11.472246  ...       -10.236783   \n",
       "16         -11.028420         -11.472244  ...       -10.236777   \n",
       "17         -11.028411         -11.472243  ...       -10.236773   \n",
       "18         -11.028403         -11.472241  ...       -10.236769   \n",
       "19         -11.028401         -11.472241  ...       -10.236769   \n",
       "20         -11.028384         -11.472234  ...       -10.236770   \n",
       "21         -10.886131         -11.485530  ...       -10.369334   \n",
       "22         -10.886095         -11.485557  ...       -10.369338   \n",
       "23         -10.886087         -11.485561  ...       -10.369340   \n",
       "24         -10.886081         -11.485563  ...       -10.369343   \n",
       "25         -10.886075         -11.485565  ...       -10.369345   \n",
       "26         -10.886074         -11.485566  ...       -10.369346   \n",
       "27         -10.886060         -11.485574  ...       -10.369369   \n",
       "28         -12.221411         -11.048660  ...       -10.774121   \n",
       "29         -12.221386         -11.048682  ...       -10.774122   \n",
       "30         -12.221378         -11.048686  ...       -10.774121   \n",
       "31         -12.221372         -11.048689  ...       -10.774120   \n",
       "32         -12.221367         -11.048691  ...       -10.774118   \n",
       "33         -12.221366         -11.048692  ...       -10.774117   \n",
       "34         -12.221349         -11.048703  ...       -10.774102   \n",
       "35         -13.645282         -13.149483  ...       -11.810501   \n",
       "36         -13.645256         -13.149504  ...       -11.810505   \n",
       "37         -13.645248         -13.149507  ...       -11.810507   \n",
       "38         -13.645240         -13.149510  ...       -11.810508   \n",
       "39         -13.645233         -13.149512  ...       -11.810510   \n",
       "40         -13.645233         -13.149512  ...       -11.810511   \n",
       "41         -13.645216         -13.149520  ...       -11.810531   \n",
       "42         -13.878027         -14.676673  ...       -12.219098   \n",
       "43         -13.878053         -14.676693  ...       -12.219114   \n",
       "44         -13.878061         -14.676696  ...       -12.219119   \n",
       "45         -13.878068         -14.676698  ...       -12.219124   \n",
       "46         -13.878073         -14.676699  ...       -12.219129   \n",
       "47         -13.878074         -14.676700  ...       -12.219130   \n",
       "48         -13.878090         -14.676705  ...       -12.219154   \n",
       "49         -14.276357         -13.114333  ...       -12.256919   \n",
       "50         -14.276333         -13.114307  ...       -12.256924   \n",
       "51         -14.276327         -13.114301  ...       -12.256929   \n",
       "52         -14.276321         -13.114295  ...       -12.256933   \n",
       "53         -14.276316         -13.114291  ...       -12.256937   \n",
       "54         -14.276316         -13.114290  ...       -12.256938   \n",
       "55         -14.276306         -13.114277  ...       -12.256968   \n",
       "\n",
       "    std_test_score  rank_test_score  split0_train_score  split1_train_score  \\\n",
       "0         5.049857                1            0.983614            0.992757   \n",
       "1         5.063923                7            0.987425            0.996604   \n",
       "2         5.063952                2            0.987425            0.996605   \n",
       "3         5.063951                3            0.987425            0.996605   \n",
       "4         5.063950                4            0.987425            0.996605   \n",
       "5         5.063950                5            0.987425            0.996605   \n",
       "6         5.063925                6            0.987425            0.996605   \n",
       "7         5.031153               15            0.987327            0.996486   \n",
       "8         5.033427               21            0.987427            0.996606   \n",
       "9         5.033417               20            0.987427            0.996606   \n",
       "10        5.033411               18            0.987427            0.996606   \n",
       "11        5.033404               17            0.987427            0.996606   \n",
       "12        5.033402               16            0.987427            0.996606   \n",
       "13        5.033361               19            0.987427            0.996606   \n",
       "14        5.172117               14            0.987428            0.996607   \n",
       "15        5.172092               13            0.987428            0.996607   \n",
       "16        5.172084               12            0.987428            0.996607   \n",
       "17        5.172076               11            0.987428            0.996607   \n",
       "18        5.172070                9            0.987428            0.996607   \n",
       "19        5.172067                8            0.987428            0.996607   \n",
       "20        5.172021               10            0.987428            0.996607   \n",
       "21        5.362468               22            0.987428            0.996607   \n",
       "22        5.362474               23            0.987428            0.996607   \n",
       "23        5.362473               24            0.987428            0.996607   \n",
       "24        5.362472               25            0.987428            0.996607   \n",
       "25        5.362471               26            0.987428            0.996607   \n",
       "26        5.362470               27            0.987428            0.996607   \n",
       "27        5.362443               28            0.987428            0.996607   \n",
       "28        5.556254               33            0.987429            0.996606   \n",
       "29        5.556267               35            0.987429            0.996606   \n",
       "30        5.556274               34            0.987429            0.996606   \n",
       "31        5.556281               32            0.987429            0.996606   \n",
       "32        5.556287               31            0.987429            0.996606   \n",
       "33        5.556289               30            0.987429            0.996606   \n",
       "34        5.556336               29            0.987429            0.996606   \n",
       "35        6.106056               36            0.987429            0.996607   \n",
       "36        6.106058               37            0.987429            0.996607   \n",
       "37        6.106057               38            0.987429            0.996607   \n",
       "38        6.106056               39            0.987429            0.996607   \n",
       "39        6.106054               40            0.987429            0.996607   \n",
       "40        6.106052               41            0.987429            0.996607   \n",
       "41        6.106022               42            0.987429            0.996607   \n",
       "42        6.059787               43            0.987430            0.996608   \n",
       "43        6.059791               44            0.987430            0.996608   \n",
       "44        6.059790               45            0.987430            0.996608   \n",
       "45        6.059789               46            0.987430            0.996608   \n",
       "46        6.059788               47            0.987430            0.996608   \n",
       "47        6.059786               48            0.987430            0.996608   \n",
       "48        6.059754               49            0.987430            0.996608   \n",
       "49        6.342889               50            0.987430            0.996608   \n",
       "50        6.342891               51            0.987430            0.996608   \n",
       "51        6.342891               52            0.987430            0.996608   \n",
       "52        6.342890               53            0.987430            0.996608   \n",
       "53        6.342889               54            0.987430            0.996608   \n",
       "54        6.342887               55            0.987430            0.996608   \n",
       "55        6.342859               56            0.987430            0.996608   \n",
       "\n",
       "    split2_train_score  split3_train_score  split4_train_score  \\\n",
       "0             0.992430            0.990681            0.984764   \n",
       "1             0.996170            0.993850            0.989335   \n",
       "2             0.996170            0.993850            0.989335   \n",
       "3             0.996170            0.993850            0.989335   \n",
       "4             0.996170            0.993850            0.989335   \n",
       "5             0.996170            0.993850            0.989335   \n",
       "6             0.996170            0.993850            0.989335   \n",
       "7             0.996082            0.993747            0.989190   \n",
       "8             0.996170            0.993851            0.989336   \n",
       "9             0.996170            0.993851            0.989336   \n",
       "10            0.996170            0.993851            0.989336   \n",
       "11            0.996170            0.993851            0.989336   \n",
       "12            0.996170            0.993851            0.989336   \n",
       "13            0.996170            0.993851            0.989336   \n",
       "14            0.996171            0.993851            0.989337   \n",
       "15            0.996171            0.993851            0.989337   \n",
       "16            0.996171            0.993851            0.989337   \n",
       "17            0.996171            0.993851            0.989337   \n",
       "18            0.996171            0.993851            0.989337   \n",
       "19            0.996171            0.993851            0.989337   \n",
       "20            0.996171            0.993851            0.989337   \n",
       "21            0.996171            0.993852            0.989338   \n",
       "22            0.996171            0.993852            0.989338   \n",
       "23            0.996171            0.993852            0.989338   \n",
       "24            0.996171            0.993852            0.989338   \n",
       "25            0.996171            0.993852            0.989338   \n",
       "26            0.996171            0.993852            0.989338   \n",
       "27            0.996171            0.993852            0.989338   \n",
       "28            0.996172            0.993853            0.989339   \n",
       "29            0.996172            0.993853            0.989339   \n",
       "30            0.996172            0.993853            0.989339   \n",
       "31            0.996172            0.993853            0.989339   \n",
       "32            0.996172            0.993853            0.989339   \n",
       "33            0.996172            0.993853            0.989339   \n",
       "34            0.996172            0.993853            0.989339   \n",
       "35            0.996172            0.993853            0.989339   \n",
       "36            0.996172            0.993853            0.989339   \n",
       "37            0.996172            0.993853            0.989339   \n",
       "38            0.996172            0.993853            0.989339   \n",
       "39            0.996172            0.993853            0.989339   \n",
       "40            0.996172            0.993853            0.989339   \n",
       "41            0.996172            0.993853            0.989339   \n",
       "42            0.996173            0.993854            0.989339   \n",
       "43            0.996173            0.993854            0.989339   \n",
       "44            0.996173            0.993854            0.989339   \n",
       "45            0.996173            0.993854            0.989339   \n",
       "46            0.996173            0.993854            0.989339   \n",
       "47            0.996173            0.993854            0.989339   \n",
       "48            0.996173            0.993854            0.989339   \n",
       "49            0.996173            0.993854            0.989340   \n",
       "50            0.996173            0.993854            0.989340   \n",
       "51            0.996173            0.993854            0.989340   \n",
       "52            0.996173            0.993854            0.989340   \n",
       "53            0.996173            0.993854            0.989340   \n",
       "54            0.996173            0.993854            0.989340   \n",
       "55            0.996173            0.993854            0.989340   \n",
       "\n",
       "    mean_train_score  std_train_score  \n",
       "0           0.988849         0.003887  \n",
       "1           0.992677         0.003681  \n",
       "2           0.992677         0.003681  \n",
       "3           0.992677         0.003681  \n",
       "4           0.992677         0.003681  \n",
       "5           0.992677         0.003681  \n",
       "6           0.992677         0.003681  \n",
       "7           0.992567         0.003687  \n",
       "8           0.992678         0.003681  \n",
       "9           0.992678         0.003681  \n",
       "10          0.992678         0.003681  \n",
       "11          0.992678         0.003681  \n",
       "12          0.992678         0.003681  \n",
       "13          0.992678         0.003681  \n",
       "14          0.992679         0.003681  \n",
       "15          0.992679         0.003681  \n",
       "16          0.992679         0.003681  \n",
       "17          0.992679         0.003681  \n",
       "18          0.992679         0.003681  \n",
       "19          0.992679         0.003681  \n",
       "20          0.992679         0.003681  \n",
       "21          0.992679         0.003680  \n",
       "22          0.992679         0.003680  \n",
       "23          0.992679         0.003680  \n",
       "24          0.992679         0.003680  \n",
       "25          0.992679         0.003680  \n",
       "26          0.992679         0.003680  \n",
       "27          0.992679         0.003680  \n",
       "28          0.992680         0.003680  \n",
       "29          0.992680         0.003680  \n",
       "30          0.992680         0.003680  \n",
       "31          0.992680         0.003680  \n",
       "32          0.992680         0.003680  \n",
       "33          0.992680         0.003680  \n",
       "34          0.992680         0.003680  \n",
       "35          0.992680         0.003681  \n",
       "36          0.992680         0.003681  \n",
       "37          0.992680         0.003681  \n",
       "38          0.992680         0.003681  \n",
       "39          0.992680         0.003681  \n",
       "40          0.992680         0.003681  \n",
       "41          0.992680         0.003681  \n",
       "42          0.992681         0.003680  \n",
       "43          0.992681         0.003680  \n",
       "44          0.992681         0.003680  \n",
       "45          0.992681         0.003680  \n",
       "46          0.992681         0.003680  \n",
       "47          0.992681         0.003680  \n",
       "48          0.992681         0.003680  \n",
       "49          0.992681         0.003680  \n",
       "50          0.992681         0.003680  \n",
       "51          0.992681         0.003680  \n",
       "52          0.992681         0.003680  \n",
       "53          0.992681         0.003680  \n",
       "54          0.992681         0.003680  \n",
       "55          0.992681         0.003680  \n",
       "\n",
       "[56 rows x 22 columns]"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(grid_search.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 3, 'n_estimators': 100}"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "             colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "             importance_type='gain', interaction_constraints='',\n",
       "             learning_rate=0.300000012, max_delta_step=0, max_depth=3,\n",
       "             min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "             n_estimators=100, n_jobs=0, num_parallel_tree=1,\n",
       "             objective='reg:squarederror', random_state=0, reg_alpha=0,\n",
       "             reg_lambda=1, scale_pos_weight=1, seed=0, subsample=1,\n",
       "             tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ml_model_best = grid_search.best_estimator_\n",
    "\n",
    "ml_model_best.fit(x_train, score_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import learning_curve\n",
    "def plot_learningcurve(classifier, X, y, plt_titile):\n",
    "    # check whether there is overfitting or underfitting by learning_curve\n",
    "    # choose five kinds of fraction of the maximum size of the training set: np.linspace(0.1,1.0,5)\n",
    "    train_size, train_score, test_score = learning_curve(classifier, X, y, cv=5, train_sizes=np.linspace(0.1,1.0,5))\n",
    "    train_scores_mean = np.mean(train_score, axis=1)\n",
    "    train_scores_std = np.std(train_score, axis=1)\n",
    "    test_scores_mean = np.mean(test_score, axis=1)\n",
    "    test_scores_std = np.std(test_score, axis=1)\n",
    "    plt.fill_between(train_size, train_scores_mean - train_scores_std, train_scores_mean + train_scores_std, alpha=0.1, color=\"r\")\n",
    "    plt.fill_between(train_size, test_scores_mean - test_scores_std, test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n",
    "    plt.plot(train_size, train_scores_mean,'o--', color=\"r\",label=\"Training score\")\n",
    "    plt.plot(train_size, test_scores_mean,'o-', color=\"g\",label=\"Testing score\")\n",
    "    plt.grid()\n",
    "    plt.title(plt_titile)\n",
    "    plt.legend(loc=\"best\")\n",
    "    return plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_learningcurve(grid_search.best_estimator_, x_train, score_train, 'Learning Curve (XGBoost)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.56042458, 0.55124542, 0.34330915, 0.32848225])"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = ml_model_best.predict(x_test)\n",
    "\n",
    "score1 = evaluate_lists(y_pred, test_intensities)\n",
    "score1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgboost_path = \"files/final_models/\" + \"xgboost_\"+ emotion + \".dat\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(xgboost_path, 'wb') as xgboost_file:\n",
    "    pickle.dump(grid_search.best_estimator_, xgboost_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = pickle.load(open(xgboost_path,'rb'))\n",
    "#model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2) Feedfoward Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "class LinearModel(torch.nn.Module):\n",
    "    def __init__(self,n_feature,n_hidden,n_output):\n",
    "        super(LinearModel,self).__init__() \n",
    "        self.hidden = torch.nn.Linear(n_feature,n_hidden)\n",
    "        self.hidden.weight = torch.nn.init.xavier_normal(self.hidden.weight)\n",
    "        self.dropout = torch.nn.Dropout(p=0.25)\n",
    "        self.predict = torch.nn.Linear(n_hidden,n_output)\n",
    "    def forward(self,x):\n",
    "        out=F.relu(self.hidden(x))\n",
    "        out=self.dropout(out)\n",
    "        out=F.sigmoid(self.predict(out))\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.2238, -0.0329, -0.0837,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.2286, -0.0026,  0.1201,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.1415,  0.2089,  0.0201,  ...,  0.2165,  0.4331,  0.8661],\n",
      "        ...,\n",
      "        [ 0.0991, -0.1625, -0.0073,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [-0.1162, -0.0071,  0.1261,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.2552,  0.0932, -0.1217,  ...,  0.0000,  0.0000,  0.0000]]) \n",
      " tensor([0.4580, 0.5000, 0.7710, 0.7710, 0.2290, 0.4380, 0.6940, 0.4380, 0.4000,\n",
      "        0.5000, 0.3120, 0.7600, 0.9400, 0.4330, 0.8200, 0.5210, 0.3960, 0.7290,\n",
      "        0.1540, 0.9380, 0.3200, 0.7200, 0.7080, 0.7080, 0.1610, 0.8540, 0.4580,\n",
      "        0.4170, 0.8460, 0.6800, 0.2500, 0.6880, 0.3830, 0.6670, 0.5600, 0.5000,\n",
      "        0.2450, 0.5800, 0.5620, 0.0600, 0.5000, 0.7400, 0.6600, 0.3600, 0.2370,\n",
      "        0.4790, 0.3120, 0.4400, 0.5620, 0.5000, 0.7690, 0.0620, 0.8790, 0.4580,\n",
      "        0.6040, 0.5000, 0.8770, 0.4380, 0.1000, 0.8540, 0.5600, 0.4400, 0.2800,\n",
      "        0.3400, 0.2270, 0.8330, 0.7600, 0.4810, 0.3520, 0.7290, 0.1560, 0.5830,\n",
      "        0.7080, 0.4170, 0.3750, 0.3800, 0.3330, 0.4590, 0.6800, 0.4490, 0.4230,\n",
      "        0.8600, 0.3960, 0.7000, 0.6000, 0.3600, 0.4440, 0.8080, 0.4380, 0.4580,\n",
      "        0.3120, 0.6040, 0.8600, 0.4000, 0.6670, 0.5210, 0.4800, 0.3110, 0.3750,\n",
      "        0.6200, 0.3800, 0.6560, 0.3750, 0.8330, 0.6460, 0.3540, 0.5770, 0.1880,\n",
      "        0.1000, 0.9170, 0.5600, 0.1310, 0.6250, 0.6560, 0.7920, 0.5600, 0.5620,\n",
      "        0.2710, 0.4600, 0.2120, 0.3000, 0.2920, 0.9200, 0.7080, 0.7000, 0.4800,\n",
      "        0.5620, 0.5000])\n"
     ]
    }
   ],
   "source": [
    "import torch.utils.data as Data\n",
    "batch_size = 128\n",
    "dataset = Data.TensorDataset(torch.tensor(x_train.astype(np.float32)), torch.tensor(score_train.astype(np.float32)))\n",
    "data_iter = Data.DataLoader(dataset = dataset,batch_size = batch_size, shuffle = True, num_workers = 2)\n",
    "\n",
    "for X,y in data_iter:\n",
    "    print(X, '\\n', y)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearModel(\n",
      "  (hidden): Linear(in_features=943, out_features=10000, bias=True)\n",
      "  (dropout): Dropout(p=0.25, inplace=False)\n",
      "  (predict): Linear(in_features=10000, out_features=1, bias=True)\n",
      ")\n",
      "<generator object Module.parameters at 0x0000026D01484A40>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dell\\Anaconda3\\envs\\tf2\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: nn.init.xavier_normal is now deprecated in favor of nn.init.xavier_normal_.\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "# architecure: 1‚Üí10000‚Üí1\n",
    "net = LinearModel(x_train.shape[1],10000,1)\n",
    "print(net)\n",
    "print(net.parameters())    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Parameter containing:\n",
      "tensor([[-0.0124, -0.0004, -0.0055,  ...,  0.0114,  0.0158,  0.0208],\n",
      "        [ 0.0026, -0.0082,  0.0216,  ...,  0.0014, -0.0020, -0.0046],\n",
      "        [ 0.0137,  0.0031,  0.0072,  ..., -0.0181,  0.0037,  0.0043],\n",
      "        ...,\n",
      "        [-0.0009,  0.0039,  0.0182,  ...,  0.0023,  0.0026,  0.0068],\n",
      "        [ 0.0041, -0.0129, -0.0045,  ...,  0.0096,  0.0185, -0.0119],\n",
      "        [ 0.0206,  0.0004, -0.0027,  ...,  0.0125, -0.0223, -0.0132]],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([-0.0047,  0.0255,  0.0287,  ..., -0.0296, -0.0315,  0.0262],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([[ 0.0046,  0.0086, -0.0054,  ...,  0.0085, -0.0002, -0.0047]],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([-0.0023], requires_grad=True)]\n"
     ]
    }
   ],
   "source": [
    "para = list(net.parameters())\n",
    "print(para)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    lr: 0.001\n",
      "    weight_decay: 0\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(net.parameters())\n",
    "print(optimizer)\n",
    "\n",
    "loss_func = torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_test = Data.TensorDataset(torch.tensor(x_test.astype(np.float32)), torch.tensor(test_intensities.astype(np.float32)))\n",
    "data_iter_test = Data.DataLoader(dataset = dataset_test,batch_size = batch_size, num_workers = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dell\\Anaconda3\\envs\\tf2\\lib\\site-packages\\torch\\nn\\functional.py:1351: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch10,train_loss0.012203278951346874\n",
      "epoch10,test_loss0.023369688540697098\n",
      "epoch20,train_loss0.030744269490242004\n",
      "epoch20,test_loss0.03076244704425335\n",
      "epoch30,train_loss0.008862434886395931\n",
      "epoch30,test_loss0.02663676254451275\n",
      "epoch40,train_loss0.0018539306474849582\n",
      "epoch40,test_loss0.027748513966798782\n",
      "epoch50,train_loss0.008165162988007069\n",
      "epoch50,test_loss0.026108896359801292\n",
      "epoch60,train_loss0.0013414219720289111\n",
      "epoch60,test_loss0.030431730672717094\n",
      "epoch70,train_loss0.00042263581417500973\n",
      "epoch70,test_loss0.03291649371385574\n",
      "epoch80,train_loss0.0015824190340936184\n",
      "epoch80,test_loss0.03241726756095886\n",
      "epoch90,train_loss0.0024495406541973352\n",
      "epoch90,test_loss0.026442667469382286\n",
      "epoch100,train_loss0.004609646741300821\n",
      "epoch100,test_loss0.02745015174150467\n",
      "epoch110,train_loss0.003698916407302022\n",
      "epoch110,test_loss0.028895974159240723\n",
      "epoch120,train_loss0.004729819018393755\n",
      "epoch120,test_loss0.030528442934155464\n",
      "epoch130,train_loss0.0011265017092227936\n",
      "epoch130,test_loss0.030046679079532623\n",
      "epoch140,train_loss0.00018351756443735212\n",
      "epoch140,test_loss0.028250884264707565\n",
      "epoch150,train_loss0.001421242137439549\n",
      "epoch150,test_loss0.029328638687729836\n",
      "epoch160,train_loss0.0016352636739611626\n",
      "epoch160,test_loss0.030241282656788826\n",
      "epoch170,train_loss0.000528784585185349\n",
      "epoch170,test_loss0.02779300883412361\n",
      "epoch180,train_loss0.0008386788540519774\n",
      "epoch180,test_loss0.028489090502262115\n",
      "epoch190,train_loss0.002141455886885524\n",
      "epoch190,test_loss0.030625468119978905\n",
      "epoch200,train_loss0.0012641941430047154\n",
      "epoch200,test_loss0.03183932974934578\n",
      "epoch210,train_loss0.00048664642963558435\n",
      "epoch210,test_loss0.031054912135004997\n",
      "epoch220,train_loss0.0014182046288624406\n",
      "epoch220,test_loss0.03106948547065258\n",
      "epoch230,train_loss0.0007109108846634626\n",
      "epoch230,test_loss0.03223457187414169\n",
      "epoch240,train_loss0.0008201517630368471\n",
      "epoch240,test_loss0.030509835109114647\n",
      "epoch250,train_loss0.001761069055646658\n",
      "epoch250,test_loss0.03411494195461273\n",
      "epoch260,train_loss0.001864540739916265\n",
      "epoch260,test_loss0.03284774348139763\n",
      "epoch270,train_loss0.0015276820631697774\n",
      "epoch270,test_loss0.0313226692378521\n",
      "epoch280,train_loss0.000580495223402977\n",
      "epoch280,test_loss0.0338631346821785\n",
      "epoch290,train_loss7.529970025643706e-05\n",
      "epoch290,test_loss0.03131021186709404\n",
      "epoch300,train_loss0.00017682461475487798\n",
      "epoch300,test_loss0.03077189065515995\n",
      "epoch310,train_loss0.005218548234552145\n",
      "epoch310,test_loss0.031825192272663116\n",
      "epoch320,train_loss0.0002934449876192957\n",
      "epoch320,test_loss0.03157874196767807\n",
      "epoch330,train_loss0.0013130047591403127\n",
      "epoch330,test_loss0.03232373297214508\n",
      "epoch340,train_loss0.0016477134777233005\n",
      "epoch340,test_loss0.03586934134364128\n",
      "epoch350,train_loss0.0019113806774839759\n",
      "epoch350,test_loss0.03126208484172821\n",
      "epoch360,train_loss0.0002765764365904033\n",
      "epoch360,test_loss0.03289863094687462\n",
      "epoch370,train_loss0.0007728760247118771\n",
      "epoch370,test_loss0.03227252513170242\n",
      "epoch380,train_loss0.0011046893196180463\n",
      "epoch380,test_loss0.033335842192173004\n",
      "epoch390,train_loss0.0014858772046864033\n",
      "epoch390,test_loss0.03262363746762276\n",
      "epoch400,train_loss0.00043016570270992815\n",
      "epoch400,test_loss0.03474767506122589\n",
      "epoch410,train_loss0.001036546309478581\n",
      "epoch410,test_loss0.03055601194500923\n",
      "epoch420,train_loss0.0003728960582520813\n",
      "epoch420,test_loss0.03281231224536896\n",
      "epoch430,train_loss0.0002340978680877015\n",
      "epoch430,test_loss0.03151945024728775\n",
      "epoch440,train_loss0.00021142679906915873\n",
      "epoch440,test_loss0.03185359761118889\n",
      "epoch450,train_loss0.0004016839375253767\n",
      "epoch450,test_loss0.03155726194381714\n",
      "epoch460,train_loss4.3097006710013375e-05\n",
      "epoch460,test_loss0.03234843164682388\n",
      "epoch470,train_loss0.0014573646476492286\n",
      "epoch470,test_loss0.03193025663495064\n",
      "epoch480,train_loss0.0028227949514985085\n",
      "epoch480,test_loss0.0322285033762455\n",
      "epoch490,train_loss0.0034163359086960554\n",
      "epoch490,test_loss0.033493489027023315\n",
      "epoch500,train_loss0.00015357640222646296\n",
      "epoch500,test_loss0.030990120023489\n",
      "epoch510,train_loss0.00044718640856444836\n",
      "epoch510,test_loss0.031741488724946976\n",
      "epoch520,train_loss0.00047233785153366625\n",
      "epoch520,test_loss0.032282181084156036\n",
      "epoch530,train_loss0.0004144791455473751\n",
      "epoch530,test_loss0.031500060111284256\n",
      "epoch540,train_loss0.0055335215292871\n",
      "epoch540,test_loss0.031765956431627274\n",
      "epoch550,train_loss0.002279645996168256\n",
      "epoch550,test_loss0.030616693198680878\n",
      "epoch560,train_loss0.0004383083723951131\n",
      "epoch560,test_loss0.030734680593013763\n",
      "epoch570,train_loss0.00021390894835349172\n",
      "epoch570,test_loss0.030487656593322754\n",
      "epoch580,train_loss0.0002514563675504178\n",
      "epoch580,test_loss0.031145356595516205\n",
      "epoch590,train_loss0.0079971794039011\n",
      "epoch590,test_loss0.032639943063259125\n",
      "epoch600,train_loss0.0017482434632256627\n",
      "epoch600,test_loss0.03162575885653496\n",
      "epoch610,train_loss3.5235858376836404e-05\n",
      "epoch610,test_loss0.03208175674080849\n",
      "epoch620,train_loss0.0012456481344997883\n",
      "epoch620,test_loss0.03222315385937691\n",
      "epoch630,train_loss0.0022666200529783964\n",
      "epoch630,test_loss0.031254205852746964\n",
      "epoch640,train_loss0.0032185062300413847\n",
      "epoch640,test_loss0.032837044447660446\n",
      "epoch650,train_loss0.0005688501987606287\n",
      "epoch650,test_loss0.029960835352540016\n",
      "epoch660,train_loss0.0003786875167861581\n",
      "epoch660,test_loss0.031993791460990906\n",
      "epoch670,train_loss0.0011300320038571954\n",
      "epoch670,test_loss0.033380307257175446\n",
      "epoch680,train_loss0.0007798740989528596\n",
      "epoch680,test_loss0.032619163393974304\n",
      "epoch690,train_loss0.00012460742436815053\n",
      "epoch690,test_loss0.03273802250623703\n",
      "epoch700,train_loss0.0009103250340558589\n",
      "epoch700,test_loss0.03252198547124863\n",
      "epoch710,train_loss0.0006935869459994137\n",
      "epoch710,test_loss0.03288017585873604\n",
      "epoch720,train_loss0.0006643037195317447\n",
      "epoch720,test_loss0.0305621437728405\n",
      "epoch730,train_loss0.0011054844362661242\n",
      "epoch730,test_loss0.03155791386961937\n",
      "epoch740,train_loss0.0011741373455151916\n",
      "epoch740,test_loss0.03360944613814354\n",
      "epoch750,train_loss0.00035295853740535676\n",
      "epoch750,test_loss0.030898135155439377\n",
      "epoch760,train_loss9.662865340942517e-05\n",
      "epoch760,test_loss0.03076634183526039\n",
      "epoch770,train_loss0.0003802726569119841\n",
      "epoch770,test_loss0.031285472214221954\n",
      "epoch780,train_loss0.0003078867739532143\n",
      "epoch780,test_loss0.03278132900595665\n",
      "epoch790,train_loss0.00032889540307223797\n",
      "epoch790,test_loss0.0334954634308815\n",
      "epoch800,train_loss0.00016945078095886856\n",
      "epoch800,test_loss0.03248172998428345\n",
      "epoch810,train_loss0.00022427145449910313\n",
      "epoch810,test_loss0.03400378301739693\n",
      "epoch820,train_loss0.0033535270486027002\n",
      "epoch820,test_loss0.03240157663822174\n",
      "epoch830,train_loss0.0019920500926673412\n",
      "epoch830,test_loss0.033435262739658356\n",
      "epoch840,train_loss0.0007575508207082748\n",
      "epoch840,test_loss0.03223380818963051\n",
      "epoch850,train_loss0.0006064744084142148\n",
      "epoch850,test_loss0.03282409906387329\n",
      "epoch860,train_loss0.000645624881144613\n",
      "epoch860,test_loss0.03178412839770317\n",
      "epoch870,train_loss0.0019056395394727588\n",
      "epoch870,test_loss0.031144309788942337\n",
      "epoch880,train_loss0.0016199047677218914\n",
      "epoch880,test_loss0.03192847967147827\n",
      "epoch890,train_loss0.00019527215044945478\n",
      "epoch890,test_loss0.03128049895167351\n",
      "epoch900,train_loss0.0005739996558986604\n",
      "epoch900,test_loss0.03256144002079964\n",
      "epoch910,train_loss0.00040711218025535345\n",
      "epoch910,test_loss0.03472701087594032\n",
      "epoch920,train_loss0.0002543324662838131\n",
      "epoch920,test_loss0.033038415014743805\n",
      "epoch930,train_loss0.00048817016067914665\n",
      "epoch930,test_loss0.032923340797424316\n",
      "epoch940,train_loss0.0003862436569761485\n",
      "epoch940,test_loss0.03278466314077377\n",
      "epoch950,train_loss0.0002708780812099576\n",
      "epoch950,test_loss0.03312159702181816\n",
      "epoch960,train_loss0.00032310702954418957\n",
      "epoch960,test_loss0.03401480242609978\n",
      "epoch970,train_loss8.185006299754605e-05\n",
      "epoch970,test_loss0.03361590579152107\n",
      "epoch980,train_loss0.0023726169019937515\n",
      "epoch980,test_loss0.032854415476322174\n",
      "epoch990,train_loss0.0006274948245845735\n",
      "epoch990,test_loss0.03363291174173355\n",
      "epoch1000,train_loss0.0003862458106596023\n",
      "epoch1000,test_loss0.033042583614587784\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "\n",
    "\n",
    "start_time_NN =time.time()\n",
    "\n",
    "train_losses = []\n",
    "\n",
    "test_losses = []\n",
    "\n",
    "num_epochs = 1000\n",
    "train_interval = 10\n",
    "test_interval = 10\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    net.train()\n",
    "    for X,y in data_iter:\n",
    "        prediction = net(X)\n",
    "        loss = loss_func(prediction,y.view(-1,1))\n",
    "    \n",
    "    # reset gradient, equal to net.zero_grad()\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward() \n",
    "        optimizer.step()\n",
    "        \n",
    "        \n",
    "\n",
    "    if((epoch+1)%train_interval==0):\n",
    "        print(\"epoch{},train_loss{}\".format(epoch+1,loss.data))\n",
    "        train_losses.append(loss.item())\n",
    "   \n",
    "\n",
    "      \n",
    "    net.eval()\n",
    "    with torch.no_grad():\n",
    "        \n",
    "        for X_test, y_test in data_iter_test:\n",
    "            \n",
    "            prediction1 = net(X_test)\n",
    "            loss1 = loss_func(prediction1, y_test.view(-1,1))\n",
    "            \n",
    "    if ((epoch+1) % test_interval == 0):       \n",
    "        print(\"epoch{},test_loss{}\".format(epoch+1,loss1.data))\n",
    "        #test_loss += float(loss1.item())\n",
    "        test_losses.append(loss1.item())\n",
    "        \n",
    "trainingtime.loc[1] = [\"Simple Neural Network\", round((time.time()-start_time_NN), 2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = range(len(train_losses))\n",
    "train_y = train_losses\n",
    "\n",
    "train_iters = len(data_iter)\n",
    "#test_x = np.arange(1, len(test_losses)+1) * train_iters*test_interval \n",
    "test_x = range(len(test_losses))\n",
    "test_y = test_losses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8,8))\n",
    "plt.plot(train_x, train_y, label='Train')\n",
    "plt.plot(test_x, test_y, label='Test')\n",
    "plt.legend(loc='lower right')\n",
    "plt.ylabel('loss value')\n",
    "plt.xlabel('Iteration')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(714,)"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_tensor = net(torch.tensor(x_test.astype(np.float32)))\n",
    "# len(y_pred)\n",
    "y_pred_array = y_pred_tensor.detach().numpy()\n",
    "y_pred_a = np.concatenate((y_pred_array), axis=None)\n",
    "y_pred_a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.62126934, 0.62443188, 0.38150131, 0.38299049])"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score2 = evaluate_lists(y_pred_a, test_intensities)\n",
    "score2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'files/final_models/simpleNN_joy.pkl.tar'"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_neural_network_path = \"files/final_models/\" + \"simpleNN_\"+ emotion + \".pkl.tar\"\n",
    "simple_neural_network_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.save(net, simple_neural_network_path) \n",
    "torch.save({'state_dict': net.state_dict()}, simple_neural_network_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Compare the Performance and Training Time Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Training Time(Seconds)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>967.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Simple Neural Network</td>\n",
       "      <td>2671.59</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Model  Training Time(Seconds)\n",
       "0                XGBoost                  967.90\n",
       "1  Simple Neural Network                 2671.59"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainingtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingtime.to_csv(\"training_time_\"+emotion+\".csv\",mode='w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pears-corr</th>\n",
       "      <th>spear-corr</th>\n",
       "      <th>pears-corr-range-05-1</th>\n",
       "      <th>spear-corr-range-05-1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>xgboost</th>\n",
       "      <td>0.560425</td>\n",
       "      <td>0.551245</td>\n",
       "      <td>0.343309</td>\n",
       "      <td>0.328482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>simpleNN</th>\n",
       "      <td>0.621269</td>\n",
       "      <td>0.624432</td>\n",
       "      <td>0.381501</td>\n",
       "      <td>0.382990</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          pears-corr  spear-corr  pears-corr-range-05-1  spear-corr-range-05-1\n",
       "xgboost     0.560425    0.551245               0.343309               0.328482\n",
       "simpleNN    0.621269    0.624432               0.381501               0.382990"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_score = pd.DataFrame(data = [score1,score2], columns = ['pears-corr','spear-corr','pears-corr-range-05-1','spear-corr-range-05-1'],\\\n",
    "             index = ['xgboost','simpleNN'])\n",
    "all_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_score.to_csv('score_'+emotion+'.csv',mode='w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
