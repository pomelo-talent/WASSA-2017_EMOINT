{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating correlation scores\n",
    "\n",
    "import scipy.stats\n",
    "\n",
    "\n",
    "def evaluate_lists(pred, gold):\n",
    "    if len(pred) == len(gold):\n",
    "        gold_scores=gold\n",
    "        pred_scores=pred         \n",
    "        \n",
    "        # lists storing gold and prediction scores where gold score >= 0.5\n",
    "        gold_scores_range_05_1=[]\n",
    "        pred_scores_range_05_1=[]\n",
    "         \n",
    "            \n",
    "        for i in range(len(gold_scores)):\n",
    "            if(gold_scores[i]>=0.5):\n",
    "                gold_scores_range_05_1.append(gold_scores[i])\n",
    "                pred_scores_range_05_1.append(pred_scores[i])\n",
    "                \n",
    "        # return zero correlation if predictions are constant\n",
    "        if np.std(pred_scores)==0 or np.std(gold_scores)==0:\n",
    "            return (0,0,0,0)\n",
    "        \n",
    "        pears_corr=scipy.stats.pearsonr(pred_scores,gold_scores)[0]                                    \n",
    "        spear_corr=scipy.stats.spearmanr(pred_scores,gold_scores)[0]   \n",
    "\n",
    "\n",
    "        pears_corr_range_05_1=scipy.stats.pearsonr(pred_scores_range_05_1,gold_scores_range_05_1)[0]                                    \n",
    "        spear_corr_range_05_1=scipy.stats.spearmanr(pred_scores_range_05_1,gold_scores_range_05_1)[0]           \n",
    "        \n",
    "      \n",
    "        return np.array([pears_corr,spear_corr,pears_corr_range_05_1,spear_corr_range_05_1])\n",
    "    else:\n",
    "        raise ValueError('Predictions and gold data have different number of lines.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model based on Anger's training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras_self_attention import SeqSelfAttention, SeqWeightedAttention\n",
    "from keras.models import load_model\n",
    "emotion = \"anger\"\n",
    "neural_network_path = \"files/final_models/\" + \"lstmatt_\"+ emotion + \".h5\"\n",
    "\n",
    "model_a = load_model(neural_network_path, custom_objects=SeqWeightedAttention.get_custom_objects())\n",
    "\n",
    "# model_a's input length is 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (1) Evaluate on Fear's testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_path_f = \"files/fear_vectors/x_test_lstmatt.npy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "# restore vectors\n",
    "with open(x_test_path_f, 'rb') as x_test_file_f:\n",
    "    x_test_f = pickle.load(x_test_file_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(995, 27)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test_f.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3837,  118,  118, ...,    0,    0,    0],\n",
       "       [  29,   29, 1154, ...,    0,    0,    0],\n",
       "       [ 621,  323, 3842, ...,    0,    0,    0],\n",
       "       ...,\n",
       "       [ 706, 2321,  963, ...,    0,    0,    0],\n",
       "       [ 553,  592, 5076, ...,    0,    0,    0],\n",
       "       [5402,  874,  398, ...,    0,    0,    0]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(995, 25)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i_list = []\n",
    "for i in x_test_f.tolist():\n",
    "    i = i[:25]\n",
    "    i_list.append(i)\n",
    "x_test_f_1 = np.array(i_list)\n",
    "x_test_f_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_path_f = \"files/fear_vectors/y_test_lstmatt.npy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "# restore vectors\n",
    "with open(y_test_path_f, 'rb') as y_test_file_f:\n",
    "    y_gold_f = pickle.load(y_test_file_f)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_f = model_a.predict(x_test_f_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.14427986, 0.14175294, 0.10240098, 0.07846169])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score1_af = evaluate_lists(np.concatenate(y_pred_f), y_gold_f)\n",
    "score1_af"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.2850225721957258"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score2_af = r2_score( y_gold_f, np.concatenate(y_pred_f,axis=0))\n",
    "score2_af"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (2) Evaluate on Joy's testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_path_j = \"files/joy_vectors/x_test_lstmatt.npy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "# restore vectors\n",
    "with open(x_test_path_j, 'rb') as x_test_file_j:\n",
    "    x_test_j = pickle.load(x_test_file_j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(714, 29)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test_j.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(714, 25)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i_list = []\n",
    "for i in x_test_j.tolist():\n",
    "    i = i[:25]\n",
    "    i_list.append(i)\n",
    "x_test_j_1 = np.array(i_list)\n",
    "x_test_j_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_path_j = \"files/joy_vectors/y_test_lstmatt.npy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "# restore vectors\n",
    "with open(y_test_path_j, 'rb') as y_test_file_j:\n",
    "    y_gold_j = pickle.load(y_test_file_j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_j = model_a.predict(x_test_j_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.13757419, 0.13776679, 0.05859923, 0.06599017])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score1_aj = evaluate_lists(np.concatenate(y_pred_j), y_gold_j)\n",
    "score1_aj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.18889521454415314"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score2_aj = r2_score( y_gold_j, np.concatenate(y_pred_j, axis=0))\n",
    "score2_aj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (3)  Evaluate on Sadness's testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_path_s = \"files/sadness_vectors/x_test_lstmatt.npy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "# restore vectors\n",
    "with open(x_test_path_s, 'rb') as x_test_file_s:\n",
    "    x_test_s = pickle.load(x_test_file_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(673, 32)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test_s.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(673, 25)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i_list = []\n",
    "for i in x_test_s.tolist():\n",
    "    i = i[:25]\n",
    "    i_list.append(i)\n",
    "x_test_s_1 = np.array(i_list)\n",
    "x_test_s_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_path_s = \"files/sadness_vectors/y_test_lstmatt.npy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "# restore vectors\n",
    "with open(y_test_path_s, 'rb') as y_test_file_s:\n",
    "    y_gold_s = pickle.load(y_test_file_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_s = model_a.predict(x_test_s_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.02880648, 0.01966332, 0.12801944, 0.10889506])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score1_as = evaluate_lists(np.concatenate(y_pred_s), y_gold_s)\n",
    "score1_as"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.441341718287555"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score2_as = r2_score( y_gold_s, np.concatenate(y_pred_s, axis=0))\n",
    "score2_as"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model based on Fear's training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_self_attention import SeqSelfAttention, SeqWeightedAttention\n",
    "from keras.models import load_model\n",
    "emotion = \"fear\"\n",
    "neural_network_path = \"files/final_models/\" + \"lstmatt_\"+ emotion + \".h5\"\n",
    "\n",
    "model_f = load_model(neural_network_path, custom_objects=SeqWeightedAttention.get_custom_objects())\n",
    "\n",
    "# model_f's input length is 27"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (1) Evaluate on Anger's testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_path_a = \"files/anger_vectors/x_test_lstmatt.npy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "# restore vectors\n",
    "with open(x_test_path_a, 'rb') as x_test_file_a:\n",
    "    x_test_a = pickle.load(x_test_file_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(760, 25)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test_a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "pad_a = np.zeros((760,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(760, 27)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test_a_1 = np.concatenate((x_test_a, pad_a), axis=1)\n",
    "x_test_a_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_path_a = \"files/anger_vectors/y_test_lstmatt.npy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "# restore vectors\n",
    "with open(y_test_path_a, 'rb') as y_test_file_a:\n",
    "    y_gold_a = pickle.load(y_test_file_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_a = model_f.predict(x_test_a_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.17607785, 0.1633526 , 0.17587928, 0.15494419])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score1_fa = evaluate_lists(np.concatenate(y_pred_a), y_gold_a)\n",
    "score1_fa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.5848817192637823"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score2_fa = r2_score( y_gold_a, np.concatenate(y_pred_a, axis=0))\n",
    "score2_fa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (2) Evaluate on Joy's testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(714, 29)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test_j.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(714, 27)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i_list = []\n",
    "for i in x_test_j.tolist():\n",
    "    i = i[:27]\n",
    "    i_list.append(i)\n",
    "x_test_j_2 = np.array(i_list)\n",
    "x_test_j_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_j = model_f.predict(x_test_j_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.12795177, 0.13632302, 0.12148089, 0.12208705])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score1_fj = evaluate_lists(np.concatenate(y_pred_j), y_gold_j)\n",
    "score1_fj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.6902312647159303"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score2_fj = r2_score( y_gold_j, np.concatenate(y_pred_j, axis=0))\n",
    "score2_fj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (3) Evaluate on Sadness's testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_path_s = \"files/sadness_vectors/x_test_lstmatt.npy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "# restore vectors\n",
    "with open(x_test_path_s, 'rb') as x_test_file_s:\n",
    "    x_test_s = pickle.load(x_test_file_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(673, 32)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test_s.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(673, 27)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i_list = []\n",
    "for i in x_test_s.tolist():\n",
    "    i = i[:27]\n",
    "    i_list.append(i)\n",
    "x_test_s_2 = np.array(i_list)\n",
    "x_test_s_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_path_s = \"files/sadness_vectors/y_test_lstmatt.npy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "# restore vectors\n",
    "with open(y_test_path_s, 'rb') as y_test_file_s:\n",
    "    y_gold_s = pickle.load(y_test_file_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_s = model_f.predict(x_test_s_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.16275533, 0.15195597, 0.17263346, 0.16773367])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score1_fs = evaluate_lists(np.concatenate(y_pred_s), y_gold_s)\n",
    "score1_fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.3448358511186216"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score2_fs = r2_score( y_gold_s, np.concatenate(y_pred_s,axis=0))\n",
    "score2_fs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model based on Joy's training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_self_attention import SeqSelfAttention, SeqWeightedAttention\n",
    "from keras.models import load_model\n",
    "emotion = \"joy\"\n",
    "neural_network_path = \"files/final_models/\" + \"lstmatt_\"+ emotion + \".h5\"\n",
    "\n",
    "model_j = load_model(neural_network_path, custom_objects=SeqWeightedAttention.get_custom_objects())\n",
    "\n",
    "# model_j's input length is 29"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (1) Evaluate on Anger's testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(760, 25)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test_a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(760, 29)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pad_a = np.zeros((760,4))\n",
    "\n",
    "x_test_a_2 = np.concatenate((x_test_a, pad_a), axis=1)\n",
    "x_test_a_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_a = model_j.predict(x_test_a_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.20528835, 0.21191954, 0.14401007, 0.15577089])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score1_ja = evaluate_lists(np.concatenate(y_pred_a), y_gold_a)\n",
    "score1_ja"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.4849602699693303"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score2_ja = r2_score( y_gold_a, np.concatenate(y_pred_a,axis=0))\n",
    "score2_ja"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (2) Evaluate on Fear's testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(995, 27)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test_f.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(995, 29)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pad_f = np.zeros((995,2))\n",
    "\n",
    "x_test_f_2 = np.concatenate((x_test_f, pad_f), axis=1)\n",
    "x_test_f_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_f = model_j.predict(x_test_f_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(995, 1)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_f.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "995"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_gold_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.15833263, 0.14516126, 0.14015935, 0.11749486])"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score1_jf = evaluate_lists(np.concatenate(y_pred_f), y_gold_f)\n",
    "score1_jf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.4634936984201783"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score2_fs = r2_score( y_gold_f, np.concatenate(y_pred_f,axis=0))\n",
    "score2_fs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (3) Evaluate on Sadness's testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(673, 32)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test_s.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(673, 29)"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i_list = []\n",
    "for i in x_test_s.tolist():\n",
    "    i = i[:29]\n",
    "    i_list.append(i)\n",
    "x_test_s_3 = np.array(i_list)\n",
    "x_test_s_3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_s = model_j.predict(x_test_s_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.13510827, 0.1260913 , 0.2544796 , 0.24690998])"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score1_js = evaluate_lists(np.concatenate(y_pred_s), y_gold_s)\n",
    "score1_js"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.39528257841000225"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score2_js = r2_score( y_gold_s, np.concatenate(y_pred_s,axis=0))\n",
    "score2_js"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model based on Sadness's training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_self_attention import SeqSelfAttention, SeqWeightedAttention\n",
    "from keras.models import load_model\n",
    "emotion = \"sadness\"\n",
    "neural_network_path = \"files/final_models/\" + \"lstmatt_\"+ emotion + \".h5\"\n",
    "\n",
    "model_s = load_model(neural_network_path, custom_objects=SeqWeightedAttention.get_custom_objects())\n",
    "\n",
    "# model_s's input length is 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (1) Evaluate on Anger's testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(760, 25)"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test_a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(760, 32)"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pad_a = np.zeros((760,7))\n",
    "\n",
    "x_test_a_3 = np.concatenate((x_test_a, pad_a), axis=1)\n",
    "x_test_a_3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_a = model_s.predict(x_test_a_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.161729  , 0.16603149, 0.12425336, 0.14461773])"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score1_sa = evaluate_lists(np.concatenate(y_pred_a), y_gold_a)\n",
    "score1_sa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.4756695404539999"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score2_sa = r2_score( y_gold_a, np.concatenate(y_pred_a,axis=0))\n",
    "score2_sa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (2) Evaluate on Fear's testing data¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(995, 27)"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test_f.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(995, 32)"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pad_f = np.zeros((995,5))\n",
    "\n",
    "x_test_f_3 = np.concatenate((x_test_f, pad_f), axis=1)\n",
    "x_test_f_3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_f = model_s.predict(x_test_f_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.08482501, 0.06905951, 0.07885919, 0.04707761])"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score1_sf = evaluate_lists(np.concatenate(y_pred_f), y_gold_f)\n",
    "score1_sf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.7803125186933557"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score2_sf = r2_score( y_gold_f, np.concatenate(y_pred_f,axis=0))\n",
    "score2_sf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (3) Evaluate on Joy's testing data¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(714, 29)"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test_j.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(714, 32)"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pad_j = np.zeros((714,3))\n",
    "\n",
    "x_test_j_3 = np.concatenate((x_test_j, pad_j), axis=1)\n",
    "x_test_j_3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_j = model_s.predict(x_test_j_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.2104644 , 0.208948  , 0.11231986, 0.09934117])"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score1_sj = evaluate_lists(np.concatenate(y_pred_j), y_gold_j)\n",
    "score1_sj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.21042270379050354"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score2_sj = r2_score( y_gold_j, np.concatenate(y_pred_j,axis=0))\n",
    "score2_sj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
