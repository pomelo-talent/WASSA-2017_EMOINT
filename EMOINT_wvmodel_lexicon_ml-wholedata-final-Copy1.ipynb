{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (1) Reading the Training, the Development and the Testing Datasets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from os import listdir\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['anger-ratings-0to1.train.txt',\n",
       " 'fear-ratings-0to1.train.txt',\n",
       " 'joy-ratings-0to1.train.txt',\n",
       " 'sadness-ratings-0to1.train.txt']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "directory1 = 'data/train'\n",
    "paths1 = listdir(directory1)\n",
    "paths1.sort()\n",
    "paths1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotion = 'whole'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10000</td>\n",
       "      <td>How the fu*k! Who the heck! moved my fridge!.....</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10001</td>\n",
       "      <td>So my Indian Uber driver just called someone t...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10002</td>\n",
       "      <td>@DPD_UK I asked for my parcel to be delivered ...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10003</td>\n",
       "      <td>so ef whichever butt wipe pulled the fire alar...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10004</td>\n",
       "      <td>Don't join @BTCare they put the phone down on ...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.896</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0                                                  1      2      3\n",
       "0  10000  How the fu*k! Who the heck! moved my fridge!.....  anger  0.938\n",
       "1  10001  So my Indian Uber driver just called someone t...  anger  0.896\n",
       "2  10002  @DPD_UK I asked for my parcel to be delivered ...  anger  0.896\n",
       "3  10003  so ef whichever butt wipe pulled the fire alar...  anger  0.896\n",
       "4  10004  Don't join @BTCare they put the phone down on ...  anger  0.896"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_anger = pd.read_csv('%s/%s' %(directory1,paths1[0]), delimiter='\\t',header=None)\n",
    "train_anger.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SentID</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Emotion</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10000</td>\n",
       "      <td>How the fu*k! Who the heck! moved my fridge!.....</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10001</td>\n",
       "      <td>So my Indian Uber driver just called someone t...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10002</td>\n",
       "      <td>@DPD_UK I asked for my parcel to be delivered ...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10003</td>\n",
       "      <td>so ef whichever butt wipe pulled the fire alar...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10004</td>\n",
       "      <td>Don't join @BTCare they put the phone down on ...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10005</td>\n",
       "      <td>My blood is boiling</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10006</td>\n",
       "      <td>When you've still got a whole season of Wentwo...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10007</td>\n",
       "      <td>@bt_uk why does tracking show my equipment del...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10008</td>\n",
       "      <td>@TeamShanny legit why i am so furious with him...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10009</td>\n",
       "      <td>How is it suppose to work if you do that? Wtf ...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.875</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SentID                                              Tweet Emotion  Rating\n",
       "0   10000  How the fu*k! Who the heck! moved my fridge!.....   anger   0.938\n",
       "1   10001  So my Indian Uber driver just called someone t...   anger   0.896\n",
       "2   10002  @DPD_UK I asked for my parcel to be delivered ...   anger   0.896\n",
       "3   10003  so ef whichever butt wipe pulled the fire alar...   anger   0.896\n",
       "4   10004  Don't join @BTCare they put the phone down on ...   anger   0.896\n",
       "5   10005                                My blood is boiling   anger   0.875\n",
       "6   10006  When you've still got a whole season of Wentwo...   anger   0.875\n",
       "7   10007  @bt_uk why does tracking show my equipment del...   anger   0.875\n",
       "8   10008  @TeamShanny legit why i am so furious with him...   anger   0.875\n",
       "9   10009  How is it suppose to work if you do that? Wtf ...   anger   0.875"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_anger.columns = ['SentID', 'Tweet', 'Emotion', 'Rating']\n",
    "train_anger[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_fear = pd.read_csv('%s/%s' %(directory1,paths1[1]), delimiter='\\t',header=None)\n",
    "train_fear.columns = train_anger.columns\n",
    "\n",
    "train_joy = pd.read_csv('%s/%s' %(directory1,paths1[2]), delimiter='\\t',header=None) \n",
    "train_joy.columns = train_anger.columns\n",
    "\n",
    "train_sadness = pd.read_csv('%s/%s' %(directory1,paths1[3]), delimiter='\\t',header=None) \n",
    "train_sadness.columns = train_anger.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if there are any duplicates(subset = all of the columns)\n",
    "\n",
    "assert train_fear.duplicated().sum() == 0\n",
    "assert train_anger.duplicated().sum() == 0\n",
    "assert train_joy.duplicated().sum() == 0\n",
    "assert train_sadness.duplicated().sum() == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 857 entries, 0 to 856\n",
      "Data columns (total 4 columns):\n",
      " #   Column   Non-Null Count  Dtype  \n",
      "---  ------   --------------  -----  \n",
      " 0   SentID   857 non-null    int64  \n",
      " 1   Tweet    857 non-null    object \n",
      " 2   Emotion  857 non-null    object \n",
      " 3   Rating   857 non-null    float64\n",
      "dtypes: float64(1), int64(1), object(2)\n",
      "memory usage: 26.9+ KB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1147 entries, 0 to 1146\n",
      "Data columns (total 4 columns):\n",
      " #   Column   Non-Null Count  Dtype  \n",
      "---  ------   --------------  -----  \n",
      " 0   SentID   1147 non-null   int64  \n",
      " 1   Tweet    1147 non-null   object \n",
      " 2   Emotion  1147 non-null   object \n",
      " 3   Rating   1147 non-null   float64\n",
      "dtypes: float64(1), int64(1), object(2)\n",
      "memory usage: 36.0+ KB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 823 entries, 0 to 822\n",
      "Data columns (total 4 columns):\n",
      " #   Column   Non-Null Count  Dtype  \n",
      "---  ------   --------------  -----  \n",
      " 0   SentID   823 non-null    int64  \n",
      " 1   Tweet    823 non-null    object \n",
      " 2   Emotion  823 non-null    object \n",
      " 3   Rating   823 non-null    float64\n",
      "dtypes: float64(1), int64(1), object(2)\n",
      "memory usage: 25.8+ KB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 786 entries, 0 to 785\n",
      "Data columns (total 4 columns):\n",
      " #   Column   Non-Null Count  Dtype  \n",
      "---  ------   --------------  -----  \n",
      " 0   SentID   786 non-null    int64  \n",
      " 1   Tweet    786 non-null    object \n",
      " 2   Emotion  786 non-null    object \n",
      " 3   Rating   786 non-null    float64\n",
      "dtypes: float64(1), int64(1), object(2)\n",
      "memory usage: 24.7+ KB\n",
      "None None None None\n"
     ]
    }
   ],
   "source": [
    "# checking missing data & len(train),len(test)\n",
    "print(train_anger.info(), train_fear.info(), train_joy.info(), train_sadness.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             SentID      Rating\n",
      "count    857.000000  857.000000\n",
      "mean   10428.000000    0.496475\n",
      "std      247.538886    0.169169\n",
      "min    10000.000000    0.067000\n",
      "25%    10214.000000    0.375000\n",
      "50%    10428.000000    0.479000\n",
      "75%    10642.000000    0.604000\n",
      "max    10856.000000    0.938000 \n",
      "              SentID       Rating\n",
      "count   1147.000000  1147.000000\n",
      "mean   20573.000000     0.495579\n",
      "std      331.254686     0.194792\n",
      "min    20000.000000     0.062000\n",
      "25%    20286.500000     0.354000\n",
      "50%    20573.000000     0.479000\n",
      "75%    20859.500000     0.625000\n",
      "max    21146.000000     0.979000 \n",
      "             SentID      Rating\n",
      "count    823.00000  823.000000\n",
      "mean   30411.00000    0.492618\n",
      "std      237.72393    0.204334\n",
      "min    30000.00000    0.019000\n",
      "25%    30205.50000    0.340000\n",
      "50%    30411.00000    0.480000\n",
      "75%    30616.50000    0.646000\n",
      "max    30822.00000    0.980000 \n",
      "              SentID      Rating\n",
      "count    786.000000  786.000000\n",
      "mean   40392.500000    0.495957\n",
      "std      227.042947    0.190841\n",
      "min    40000.000000    0.083000\n",
      "25%    40196.250000    0.351750\n",
      "50%    40392.500000    0.479000\n",
      "75%    40588.750000    0.646000\n",
      "max    40785.000000    0.958000\n"
     ]
    }
   ],
   "source": [
    "print(train_anger.describe(), \"\\n\", train_fear.describe(), \"\\n\", train_joy.describe(), \"\\n\", train_sadness.describe() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# check the counts of observations in each categorical bin using bars (to see if we need data balance.)\n",
    "d_train = [train_anger.shape[0], train_fear.shape[0], train_joy.shape[0], train_sadness.shape[0]]\n",
    "labels= [\"anger\", \"fear\", \"joy\", \"sadness\"]\n",
    "plt.bar(labels, d_train,tick_label=labels)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SentID</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Emotion</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10857</td>\n",
       "      <td>@ZubairSabirPTI  pls dont insult the word 'Molna'</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10858</td>\n",
       "      <td>@ArcticFantasy I would have almost took offens...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10859</td>\n",
       "      <td>@IllinoisLoyalty that Rutgers game was an abom...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10860</td>\n",
       "      <td>@CozanGaming that's what lisa asked before she...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10861</td>\n",
       "      <td>Sometimes I get mad over something so minuscul...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10862</td>\n",
       "      <td>Sometimes I get mad over something so minuscul...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10863</td>\n",
       "      <td>I think @Sam_Canaday &amp;amp; @KYLEJDOWSON must a...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10864</td>\n",
       "      <td>My eyes have been dilated. I hate the world ri...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10865</td>\n",
       "      <td>@huwellwell One chosen by the CLP members! MP ...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10866</td>\n",
       "      <td>@huwellwell One chosen by the CLP members! MP ...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.438</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SentID                                              Tweet Emotion  Rating\n",
       "0   10857  @ZubairSabirPTI  pls dont insult the word 'Molna'   anger   0.479\n",
       "1   10858  @ArcticFantasy I would have almost took offens...   anger   0.458\n",
       "2   10859  @IllinoisLoyalty that Rutgers game was an abom...   anger   0.562\n",
       "3   10860  @CozanGaming that's what lisa asked before she...   anger   0.500\n",
       "4   10861  Sometimes I get mad over something so minuscul...   anger   0.708\n",
       "5   10862  Sometimes I get mad over something so minuscul...   anger   0.646\n",
       "6   10863  I think @Sam_Canaday &amp; @KYLEJDOWSON must a...   anger   0.250\n",
       "7   10864  My eyes have been dilated. I hate the world ri...   anger   0.812\n",
       "8   10865  @huwellwell One chosen by the CLP members! MP ...   anger   0.682\n",
       "9   10866  @huwellwell One chosen by the CLP members! MP ...   anger   0.438"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "directory2 = 'data/dev'\n",
    "paths2 = listdir(directory2)\n",
    "paths2.sort()\n",
    "paths2\n",
    "\n",
    "dev_anger = pd.read_csv('%s/%s' %(directory2,paths2[0]), delimiter='\\t',header=None)\n",
    "dev_anger.columns = train_anger.columns\n",
    "dev_anger[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_fear = pd.read_csv('%s/%s' %(directory2,paths2[1]), delimiter='\\t',header=None)\n",
    "dev_fear.columns = train_anger.columns\n",
    "\n",
    "dev_joy = pd.read_csv('%s/%s' %(directory2,paths2[2]), delimiter='\\t',header=None) \n",
    "dev_joy.columns = train_anger.columns\n",
    "\n",
    "dev_sadness = pd.read_csv('%s/%s' %(directory2,paths2[3]), delimiter='\\t',header=None) \n",
    "dev_sadness.columns = train_anger.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if there are any duplicates(subset = all of the columns)\n",
    "\n",
    "assert dev_fear.duplicated().sum() == 0\n",
    "assert dev_anger.duplicated().sum() == 0\n",
    "assert dev_joy.duplicated().sum() == 0\n",
    "assert dev_sadness.duplicated().sum() == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 110 entries, 0 to 109\n",
      "Data columns (total 4 columns):\n",
      " #   Column   Non-Null Count  Dtype  \n",
      "---  ------   --------------  -----  \n",
      " 0   SentID   110 non-null    int64  \n",
      " 1   Tweet    110 non-null    object \n",
      " 2   Emotion  110 non-null    object \n",
      " 3   Rating   110 non-null    float64\n",
      "dtypes: float64(1), int64(1), object(2)\n",
      "memory usage: 3.6+ KB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 110 entries, 0 to 109\n",
      "Data columns (total 4 columns):\n",
      " #   Column   Non-Null Count  Dtype  \n",
      "---  ------   --------------  -----  \n",
      " 0   SentID   110 non-null    int64  \n",
      " 1   Tweet    110 non-null    object \n",
      " 2   Emotion  110 non-null    object \n",
      " 3   Rating   110 non-null    float64\n",
      "dtypes: float64(1), int64(1), object(2)\n",
      "memory usage: 3.6+ KB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 79 entries, 0 to 78\n",
      "Data columns (total 4 columns):\n",
      " #   Column   Non-Null Count  Dtype  \n",
      "---  ------   --------------  -----  \n",
      " 0   SentID   79 non-null     int64  \n",
      " 1   Tweet    79 non-null     object \n",
      " 2   Emotion  79 non-null     object \n",
      " 3   Rating   79 non-null     float64\n",
      "dtypes: float64(1), int64(1), object(2)\n",
      "memory usage: 2.6+ KB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 74 entries, 0 to 73\n",
      "Data columns (total 4 columns):\n",
      " #   Column   Non-Null Count  Dtype  \n",
      "---  ------   --------------  -----  \n",
      " 0   SentID   74 non-null     int64  \n",
      " 1   Tweet    74 non-null     object \n",
      " 2   Emotion  74 non-null     object \n",
      " 3   Rating   74 non-null     float64\n",
      "dtypes: float64(1), int64(1), object(2)\n",
      "memory usage: 2.4+ KB\n",
      "None None None None\n"
     ]
    }
   ],
   "source": [
    "# checking missing data & len(train),len(test)\n",
    "print(dev_fear.info(), dev_fear.info(), dev_joy.info(), dev_sadness.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             SentID     Rating\n",
      "count     84.000000  84.000000\n",
      "mean   10898.500000   0.489607\n",
      "std       24.392622   0.156768\n",
      "min    10857.000000   0.125000\n",
      "25%    10877.750000   0.410250\n",
      "50%    10898.500000   0.500000\n",
      "75%    10919.250000   0.590500\n",
      "max    10940.000000   0.860000 \n",
      "              SentID      Rating\n",
      "count    110.000000  110.000000\n",
      "mean   21201.500000    0.489309\n",
      "std       31.898276    0.185675\n",
      "min    21147.000000    0.060000\n",
      "25%    21174.250000    0.354000\n",
      "50%    21201.500000    0.466500\n",
      "75%    21228.750000    0.632500\n",
      "max    21256.000000    0.896000 \n",
      "              SentID     Rating\n",
      "count     79.000000  79.000000\n",
      "mean   30862.000000   0.483392\n",
      "std       22.949219   0.219682\n",
      "min    30823.000000   0.038000\n",
      "25%    30842.500000   0.312000\n",
      "50%    30862.000000   0.479000\n",
      "75%    30881.500000   0.653000\n",
      "max    30901.000000   0.936000 \n",
      "              SentID     Rating\n",
      "count     74.000000  74.000000\n",
      "mean   40822.500000   0.475743\n",
      "std       21.505813   0.178436\n",
      "min    40786.000000   0.125000\n",
      "25%    40804.250000   0.340750\n",
      "50%    40822.500000   0.458000\n",
      "75%    40840.750000   0.625000\n",
      "max    40859.000000   0.875000\n"
     ]
    }
   ],
   "source": [
    "print(dev_anger.describe(), \"\\n\", dev_fear.describe(), \"\\n\", dev_joy.describe(), \"\\n\", dev_sadness.describe() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# check the counts of observations in each categorical bin using bars (to see if we need data balance.)\n",
    "d_dev = [dev_anger.shape[0], dev_fear.shape[0], dev_joy.shape[0], dev_sadness.shape[0]]\n",
    "labels= [\"anger\", \"fear\", \"joy\", \"sadness\"]\n",
    "plt.bar(labels, d_dev,tick_label=labels)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SentID</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Emotion</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10941</td>\n",
       "      <td>At the point today where if someone says somet...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10942</td>\n",
       "      <td>@CorningFootball  IT'S GAME DAY!!!!      T MIN...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10943</td>\n",
       "      <td>This game has pissed me off more than any othe...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10944</td>\n",
       "      <td>@spamvicious I've just found out it's Candice ...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10945</td>\n",
       "      <td>@moocowward @mrsajhargreaves @Melly77 @GaryBar...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10946</td>\n",
       "      <td>@moocowward @mrsajhargreaves @Melly77 @GaryBar...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10947</td>\n",
       "      <td>wanna go home and focus up on this game . Don'...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10948</td>\n",
       "      <td>@virginmedia I've been disconnected whilst on ...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10949</td>\n",
       "      <td>@virginmedia I've been disconnected whilst on ...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10950</td>\n",
       "      <td>I wanna see you smile I don't wanna see you ma...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.250</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SentID                                              Tweet Emotion  Rating\n",
       "0   10941  At the point today where if someone says somet...   anger   0.319\n",
       "1   10942  @CorningFootball  IT'S GAME DAY!!!!      T MIN...   anger   0.144\n",
       "2   10943  This game has pissed me off more than any othe...   anger   0.898\n",
       "3   10944  @spamvicious I've just found out it's Candice ...   anger   0.271\n",
       "4   10945  @moocowward @mrsajhargreaves @Melly77 @GaryBar...   anger   0.646\n",
       "5   10946  @moocowward @mrsajhargreaves @Melly77 @GaryBar...   anger   0.583\n",
       "6   10947  wanna go home and focus up on this game . Don'...   anger   0.375\n",
       "7   10948  @virginmedia I've been disconnected whilst on ...   anger   0.625\n",
       "8   10949  @virginmedia I've been disconnected whilst on ...   anger   0.396\n",
       "9   10950  I wanna see you smile I don't wanna see you ma...   anger   0.250"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "directory3 = 'data/test'\n",
    "paths3 = listdir(directory3)\n",
    "paths3.sort()\n",
    "paths3\n",
    "\n",
    "test_anger = pd.read_csv('%s/%s' %(directory3,paths3[0]), delimiter='\\t',header=None)\n",
    "test_anger.columns = train_anger.columns\n",
    "\n",
    "test_anger[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_fear = pd.read_csv('%s/%s' %(directory3,paths3[1]), delimiter='\\t',header=None)\n",
    "test_fear.columns = train_anger.columns\n",
    "\n",
    "test_joy = pd.read_csv('%s/%s' %(directory3,paths3[2]), delimiter='\\t',header=None) \n",
    "test_joy.columns = train_anger.columns\n",
    "\n",
    "test_sadness = pd.read_csv('%s/%s' %(directory3,paths3[3]), delimiter='\\t',header=None) \n",
    "test_sadness.columns = train_anger.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if there are any duplicates(subset = all of the columns)\n",
    "\n",
    "assert test_fear.duplicated().sum() == 0\n",
    "assert test_anger.duplicated().sum() == 0\n",
    "assert test_joy.duplicated().sum() == 0\n",
    "assert test_sadness.duplicated().sum() == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             SentID      Rating\n",
      "count    760.000000  760.000000\n",
      "mean   11320.500000    0.502149\n",
      "std      219.537392    0.171886\n",
      "min    10941.000000    0.032000\n",
      "25%    11130.750000    0.375000\n",
      "50%    11320.500000    0.496000\n",
      "75%    11510.250000    0.625000\n",
      "max    11700.000000    0.976000 \n",
      "             SentID     Rating\n",
      "count    995.00000  995.00000\n",
      "mean   21754.00000    0.50247\n",
      "std      287.37606    0.20094\n",
      "min    21257.00000    0.06200\n",
      "25%    21505.50000    0.35400\n",
      "50%    21754.00000    0.50000\n",
      "75%    22002.50000    0.64600\n",
      "max    22251.00000    1.00000 \n",
      "              SentID      Rating\n",
      "count    714.000000  714.000000\n",
      "mean   31258.500000    0.508958\n",
      "std      206.258333    0.217295\n",
      "min    30902.000000    0.000000\n",
      "25%    31080.250000    0.340000\n",
      "50%    31258.500000    0.500000\n",
      "75%    31436.750000    0.673000\n",
      "max    31615.000000    0.980000 \n",
      "             SentID      Rating\n",
      "count    673.00000  673.000000\n",
      "mean   41196.00000    0.511272\n",
      "std      194.42265    0.202737\n",
      "min    40860.00000    0.083000\n",
      "25%    41028.00000    0.354000\n",
      "50%    41196.00000    0.500000\n",
      "75%    41364.00000    0.667000\n",
      "max    41532.00000    1.000000\n"
     ]
    }
   ],
   "source": [
    "print(test_anger.describe(), \"\\n\", test_fear.describe(), \"\\n\", test_joy.describe(), \"\\n\", test_sadness.describe() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# check the counts of observations in each categorical bin using bars (to see if we need data balance.)\n",
    "d_test = [test_anger.shape[0], test_fear.shape[0], test_joy.shape[0], test_sadness.shape[0]]\n",
    "labels= [\"anger\", \"fear\", \"joy\", \"sadness\"]\n",
    "plt.bar(labels, d_test,tick_label=labels)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Train</th>\n",
       "      <th>Dev.</th>\n",
       "      <th>Test</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>anger</th>\n",
       "      <td>857</td>\n",
       "      <td>84</td>\n",
       "      <td>760</td>\n",
       "      <td>1701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fear</th>\n",
       "      <td>1147</td>\n",
       "      <td>110</td>\n",
       "      <td>995</td>\n",
       "      <td>2252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>joy</th>\n",
       "      <td>823</td>\n",
       "      <td>79</td>\n",
       "      <td>714</td>\n",
       "      <td>1616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sadness</th>\n",
       "      <td>786</td>\n",
       "      <td>74</td>\n",
       "      <td>673</td>\n",
       "      <td>1533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>3613</td>\n",
       "      <td>347</td>\n",
       "      <td>3142</td>\n",
       "      <td>7102</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Train  Dev.  Test   All\n",
       "anger      857    84   760  1701\n",
       "fear      1147   110   995  2252\n",
       "joy        823    79   714  1616\n",
       "sadness    786    74   673  1533\n",
       "All       3613   347  3142  7102"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show the number of instances in the Tweet Emotion Intensity dataset.\n",
    "\n",
    "Table_1 = pd.DataFrame(np.array([(d_train), (d_dev), (d_test)])).T\n",
    "Table_1.columns = ['Train', 'Dev.', 'Test']\n",
    "Table_1.index = ['anger', 'fear', 'joy', 'sadness']\n",
    "Table_1['All'] = Table_1.apply(lambda x: x.sum(), axis=1)\n",
    "Table_1.loc['All'] = Table_1.apply(lambda x: x.sum())\n",
    "\n",
    "Table_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SentID</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Emotion</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10000</td>\n",
       "      <td>How the fu*k! Who the heck! moved my fridge!.....</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10001</td>\n",
       "      <td>So my Indian Uber driver just called someone t...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10002</td>\n",
       "      <td>@DPD_UK I asked for my parcel to be delivered ...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10003</td>\n",
       "      <td>so ef whichever butt wipe pulled the fire alar...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10004</td>\n",
       "      <td>Don't join @BTCare they put the phone down on ...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3955</th>\n",
       "      <td>40855</td>\n",
       "      <td>Common app just randomly logged me out as I wa...</td>\n",
       "      <td>sadness</td>\n",
       "      <td>0.833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3956</th>\n",
       "      <td>40856</td>\n",
       "      <td>I'd rather laugh with the rarest genius, in be...</td>\n",
       "      <td>sadness</td>\n",
       "      <td>0.688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3957</th>\n",
       "      <td>40857</td>\n",
       "      <td>If you #invest in my new #film I will stop ask...</td>\n",
       "      <td>sadness</td>\n",
       "      <td>0.458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3958</th>\n",
       "      <td>40858</td>\n",
       "      <td>Just watched Django Unchained, Other people ma...</td>\n",
       "      <td>sadness</td>\n",
       "      <td>0.333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3959</th>\n",
       "      <td>40859</td>\n",
       "      <td>@KeithOlbermann depressing how despicable Trum...</td>\n",
       "      <td>sadness</td>\n",
       "      <td>0.708</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3960 rows  4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      SentID                                              Tweet  Emotion  \\\n",
       "0      10000  How the fu*k! Who the heck! moved my fridge!.....    anger   \n",
       "1      10001  So my Indian Uber driver just called someone t...    anger   \n",
       "2      10002  @DPD_UK I asked for my parcel to be delivered ...    anger   \n",
       "3      10003  so ef whichever butt wipe pulled the fire alar...    anger   \n",
       "4      10004  Don't join @BTCare they put the phone down on ...    anger   \n",
       "...      ...                                                ...      ...   \n",
       "3955   40855  Common app just randomly logged me out as I wa...  sadness   \n",
       "3956   40856  I'd rather laugh with the rarest genius, in be...  sadness   \n",
       "3957   40857  If you #invest in my new #film I will stop ask...  sadness   \n",
       "3958   40858  Just watched Django Unchained, Other people ma...  sadness   \n",
       "3959   40859  @KeithOlbermann depressing how despicable Trum...  sadness   \n",
       "\n",
       "      Rating  \n",
       "0      0.938  \n",
       "1      0.896  \n",
       "2      0.896  \n",
       "3      0.896  \n",
       "4      0.896  \n",
       "...      ...  \n",
       "3955   0.833  \n",
       "3956   0.688  \n",
       "3957   0.458  \n",
       "3958   0.333  \n",
       "3959   0.708  \n",
       "\n",
       "[3960 rows x 4 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# plan to train models on the combined training and development sets\n",
    "train = pd.concat([train_anger, train_fear, train_joy, train_sadness, dev_anger, dev_fear, dev_joy, dev_sadness],axis=0,ignore_index=True)\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SentID</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Emotion</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10941</td>\n",
       "      <td>At the point today where if someone says somet...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10942</td>\n",
       "      <td>@CorningFootball  IT'S GAME DAY!!!!      T MIN...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10943</td>\n",
       "      <td>This game has pissed me off more than any othe...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10944</td>\n",
       "      <td>@spamvicious I've just found out it's Candice ...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10945</td>\n",
       "      <td>@moocowward @mrsajhargreaves @Melly77 @GaryBar...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3137</th>\n",
       "      <td>41528</td>\n",
       "      <td>Why does Candice constantly pout #GBBO </td>\n",
       "      <td>sadness</td>\n",
       "      <td>0.396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3138</th>\n",
       "      <td>41529</td>\n",
       "      <td>@redBus_in #unhappy with #redbus CC, when I ta...</td>\n",
       "      <td>sadness</td>\n",
       "      <td>0.604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3139</th>\n",
       "      <td>41530</td>\n",
       "      <td>@AceOperative789 no pull him afew weeks ago, s...</td>\n",
       "      <td>sadness</td>\n",
       "      <td>0.479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3140</th>\n",
       "      <td>41531</td>\n",
       "      <td>I'm buying art supplies and I'm debating how s...</td>\n",
       "      <td>sadness</td>\n",
       "      <td>0.375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3141</th>\n",
       "      <td>41532</td>\n",
       "      <td>@sainsburys Could you ask your Chafford Hundre...</td>\n",
       "      <td>sadness</td>\n",
       "      <td>0.438</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3142 rows  4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      SentID                                              Tweet  Emotion  \\\n",
       "0      10941  At the point today where if someone says somet...    anger   \n",
       "1      10942  @CorningFootball  IT'S GAME DAY!!!!      T MIN...    anger   \n",
       "2      10943  This game has pissed me off more than any othe...    anger   \n",
       "3      10944  @spamvicious I've just found out it's Candice ...    anger   \n",
       "4      10945  @moocowward @mrsajhargreaves @Melly77 @GaryBar...    anger   \n",
       "...      ...                                                ...      ...   \n",
       "3137   41528          Why does Candice constantly pout #GBBO   sadness   \n",
       "3138   41529  @redBus_in #unhappy with #redbus CC, when I ta...  sadness   \n",
       "3139   41530  @AceOperative789 no pull him afew weeks ago, s...  sadness   \n",
       "3140   41531  I'm buying art supplies and I'm debating how s...  sadness   \n",
       "3141   41532  @sainsburys Could you ask your Chafford Hundre...  sadness   \n",
       "\n",
       "      Rating  \n",
       "0      0.319  \n",
       "1      0.144  \n",
       "2      0.898  \n",
       "3      0.271  \n",
       "4      0.646  \n",
       "...      ...  \n",
       "3137   0.396  \n",
       "3138   0.604  \n",
       "3139   0.479  \n",
       "3140   0.375  \n",
       "3141   0.438  \n",
       "\n",
       "[3142 rows x 4 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.concat([test_anger, test_fear, test_joy, test_sadness],axis=0,ignore_index=True)\n",
    "test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (2) Define Text Data Cleaning Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import re\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import bigrams\n",
    "\n",
    "import wordsegment as ws # $ pip install wordsegment    \n",
    "ws.load()     \n",
    "\n",
    "import emoji  # $ pip install emoji\n",
    "\n",
    "# As the glove model contains many words made with grammatical role, tense ,or derivational morphology,\n",
    "# we do not need WordNetLemmatizer or SnowballStemmer here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_text(text):\n",
    "    \n",
    "    # replace emoji to word\n",
    "    # text = emoji.demojize(text)\n",
    "    \n",
    "    # remove characters outside the ascii code 128\n",
    "    # text = ''.join([w if ord(w)<128 else ' ' for w in text])\n",
    "    \n",
    "    # replace '--' with a space\n",
    "    text = text.replace('--',' ')\n",
    "    \n",
    "    # remove any newline characters\n",
    "    text = text.replace('\\n',' ')\n",
    "    \n",
    "    # tweets mentions user using '@' followed by username. Replace all those with <user> to be usable for Glove\n",
    "    text = re.sub('@[^ ]+','<user>',text)\n",
    "    \n",
    "    # Replace all URLs with <url> to be usable for Glove\n",
    "    text = re.sub(r'\\d+','<number>',text)\n",
    "   \n",
    "    # Replace all numbers with <number> to be usable for Glove\n",
    "    text = re.sub(r'http\\S+','<url>',text)\n",
    "    \n",
    "    # turn some abbreviations into a whold word\n",
    "    text = re.sub(r\"\\'s\", \"\", text)\n",
    "    text = re.sub(r\"\\'m\", \" am\", text)\n",
    "    text = re.sub(r\"\\'ve\", \" have\", text)\n",
    "    text = re.sub(r\"can\\'t\", \"can not\", text)\n",
    "    text = re.sub(r\"won\\'t\", \"will not\", text)\n",
    "    text = re.sub(r\"n\\'t\", \" not\", text)\n",
    "    text = re.sub(r\"\\'re\", \" are\", text)\n",
    "    text = re.sub(r\"\\'d\", \" would\", text)\n",
    "    text = re.sub(r\"\\'ll\", \" will\", text)\n",
    "    text = re.sub(r\"fu\\*k\", \" fuck\", text)\n",
    "    text = re.sub(r\"f\\*c+\", \"fuck\", text)\n",
    "    text = text.replace(\"wtf\", \"what the fuck\")\n",
    "    \n",
    "    # prepare spaces between punctuation and words\n",
    "    text1 = text.split('...')\n",
    "    for i in range(len(text1)):\n",
    "        text1[i] = text1[i].replace('/',' / ').replace('\\\\',' \\ ').replace(',',' , ').replace('.',' . ').replace('?',' ? ').replace('!',' ! ').replace(\"'\",\" ' \").replace(':',' : ').replace(';',' ; ').replace('-',' - ').replace('(',' ( ').replace(')',' ) ').replace('[',' [ ').replace(']',' ] ').replace('&',' & ').replace('*',' * ').replace('{',' { ').replace('}',' } ').replace('-',' - ').replace('`',' ` ').replace('\"',' \" ').replace('>','> ').replace('<',' <')\n",
    "    text1 = ' '.join(text1)\n",
    "    \n",
    "    # split into tokens by white space\n",
    "    tokens = text1.split()\n",
    "    \n",
    "    return tokens\n",
    "\n",
    "def clean_text(text):\n",
    "   \n",
    "    tokens = normalize_text(text)\n",
    "    \n",
    "    new_tokens1 = []\n",
    "    for w in tokens:\n",
    "        if w == \"<user>\":\n",
    "            w = w\n",
    "        elif w == \"<url>\":\n",
    "            w = w\n",
    "        elif w == \"<number>\":\n",
    "            w = w\n",
    "        elif w in emoji.UNICODE_EMOJI:\n",
    "            w = w\n",
    "        else:\n",
    "            # prepare regex for char filtering: !\"#$%&'()*+, -./:;<=>?@[\\]^_`{|}~\n",
    "            re_punc = re.compile('[%s]' %re.escape(string.punctuation))\n",
    "            # remove punctuation from each word\n",
    "            w = re_punc.sub('', w)\n",
    "    \n",
    "            # remove remaining tokens that are not alphabetic\n",
    "            if w.isalpha():\n",
    "                w = w\n",
    "        new_tokens1.append(w) \n",
    "        \n",
    "    # filter out stop words\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [w for w in new_tokens1 if not w in stop_words]\n",
    "    \n",
    "    new_tokens2 = []\n",
    "    for w in tokens:\n",
    "        if w == \"<user>\":\n",
    "            w = w\n",
    "        elif w == \"<url>\":\n",
    "            w = w\n",
    "        elif w == \"<number>\":\n",
    "            w = w\n",
    "        elif w in emoji.UNICODE_EMOJI:\n",
    "            w = w\n",
    "        else:\n",
    "            # word segment will convert the hashtag based joined words, for example, it will segment #iamthebest to ['i','am','the','best']\n",
    "            w = ' '.join(ws.segment(w)) \n",
    "        new_tokens2.append(w)\n",
    "        \n",
    "    \n",
    "    # make lower case\n",
    "    tokens = [word.lower() for word in new_tokens2]\n",
    "    \n",
    "    \n",
    "    clean_text = ' '.join(tokens)\n",
    "    tokens = clean_text.split()\n",
    "    \n",
    "    new_tokens3 = []   \n",
    "    # filter out short tokens\n",
    "    for w in tokens:\n",
    "        if w in emoji.UNICODE_EMOJI:\n",
    "            w = w\n",
    "        else:\n",
    "            if len(w) > 1:\n",
    "                w =w\n",
    "        new_tokens3.append(w)\n",
    "    \n",
    "    return ' '.join(new_tokens3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<user> i left dad deal  my work done soon felt wrath slipper '"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# do a sanity check\n",
    "text = \"@laura221b I've left it for my dad to deal with  My work is done as soon as it's felt the wrath of my slipper \"\n",
    "clean_text(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare for clean Hashtag Emotion Intensity Lexicons...\n",
    "\n",
    "def remove_stopwords(string):\n",
    "    split_string = \\\n",
    "        [word for word in string.split()\n",
    "         if word not in stopwords.words('english')]\n",
    "    \n",
    "    return \" \".join(split_string)\n",
    "\n",
    "def clean_str(string):  \n",
    "    string = string.replace(\"\\\\n\", \" \")\n",
    "    string = string.replace(\"_NEG\", \"\")\n",
    "    string = string.replace(\"_NEGFIRST\", \"\")\n",
    "    string = re.sub(r\"@[A-Za-z0-9_s(),!?\\'\\`]+\", \"\", string) # removing any twitter handle mentions\n",
    "\n",
    "    string = re.sub(r\"#\", \"\", string)\n",
    "    string = re.sub(r\"\\*\", \"\", string)\n",
    "    string = re.sub(r\"\\'s\", \"\", string)\n",
    "    string = re.sub(r\"\\'m\", \" am\", string)\n",
    "    string = re.sub(r\"\\'ve\", \" have\", string)\n",
    "    string = re.sub(r\"n\\'t\", \" not\", string)\n",
    "    string = re.sub(r\"\\'re\", \" are\", string)\n",
    "    string = re.sub(r\"\\'d\", \" would\", string)\n",
    "    string = re.sub(r\"\\'ll\", \" will\", string)\n",
    "    string = re.sub(r\",\", \"\", string)\n",
    "    string = re.sub(r\"!\", \" !\", string)\n",
    "    string = re.sub(r\"\\(\", \"\", string)\n",
    "    string = re.sub(r\"\\)\", \"\", string)\n",
    "    string = re.sub(r\"\\?\", \" ?\", string)\n",
    "    string = re.sub(r\"\\s{2,}\", \" \", string)\n",
    "\n",
    "    return remove_stopwords(string.strip().lower())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (3) Clean Text Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Tweet'] = train['Tweet'].apply(clean_text)\n",
    "\n",
    "test['Tweet'] = test['Tweet'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SentID</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Emotion</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10000</td>\n",
       "      <td>how fuck who heck moved fridge i knock landlor...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10001</td>\n",
       "      <td>so indian uber driver called someone n word if...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10002</td>\n",
       "      <td>&lt;user&gt; i asked parcel delivered pick store add...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10003</td>\n",
       "      <td>ef whichever butt wipe pulled fire alarm davis...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10004</td>\n",
       "      <td>do join &lt;user&gt; put phone talk rude taking mone...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10005</td>\n",
       "      <td>my blood boiling</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10006</td>\n",
       "      <td>when still got whole season wentworth watch st...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10007</td>\n",
       "      <td>&lt;user&gt; tracking show equipment delivered why s...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10008</td>\n",
       "      <td>&lt;user&gt; legit furious people fucking idiots</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10009</td>\n",
       "      <td>how suppose work wtf dude thanks pissing</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10010</td>\n",
       "      <td>im mad power rangers im incensed im furious</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>10011</td>\n",
       "      <td>wont use using &lt;user&gt; &lt;user&gt; these guys cant g...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>10012</td>\n",
       "      <td>bitches aggravate like inspires biggest cunt k...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>10013</td>\n",
       "      <td>why &lt;user&gt; come glasgow night i working i fuck...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>10014</td>\n",
       "      <td>fuking fuming </td>\n",
       "      <td>anger</td>\n",
       "      <td>0.854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>10015</td>\n",
       "      <td>zero help &lt;user&gt; customer service just pushing...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>10016</td>\n",
       "      <td>&lt;user&gt; mention gra guy stops let &lt;number&gt; ppl ...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>10017</td>\n",
       "      <td>i hate lawn mower if soul i would condemn fier...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>10018</td>\n",
       "      <td>people offended kendall ends photo shoot like ...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>10019</td>\n",
       "      <td>i block everyone everywhere posting storm i th...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>10020</td>\n",
       "      <td>making buddy cry bitch wait revenge</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>10021</td>\n",
       "      <td>be s you tell true blooded hoop junkie switch ...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>10022</td>\n",
       "      <td>i got no response i rate customer amazon n why...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>10023</td>\n",
       "      <td>tasers immobilize taser someone fuck need shoo...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>10024</td>\n",
       "      <td>&lt;user&gt; &lt;user&gt; &lt;user&gt; the way blood boiling lit...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>10025</td>\n",
       "      <td>actually fuming i nothing wear saturday</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>10026</td>\n",
       "      <td>&lt;user&gt; straight people even arse straight guys...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>10027</td>\n",
       "      <td>bloody parking ticket fuming</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>10028</td>\n",
       "      <td>you ever find people around really irritate so...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>10029</td>\n",
       "      <td>i get angry people know stop sign francis fost...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>10030</td>\n",
       "      <td>this fuck boiling inside gonna good i let</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>10031</td>\n",
       "      <td>&lt;user&gt; &lt;user&gt; wow my bill &lt;number&gt; &lt;number&gt; ha...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>10032</td>\n",
       "      <td>i blame whole season natalie the season would ...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>10033</td>\n",
       "      <td>since update &lt;user&gt; loses power nearly &lt;number...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>10034</td>\n",
       "      <td>&lt;user&gt; i fly fit rage fair</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>10035</td>\n",
       "      <td>unbelievable takes &lt;number&gt; minutes get &lt;user&gt;...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>10036</td>\n",
       "      <td>&lt;user&gt; &lt;user&gt; we blaming &lt;number&gt; fucking idio...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>10037</td>\n",
       "      <td>&lt;user&gt; people infuriate</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>10038</td>\n",
       "      <td>&lt;user&gt; mine party decide party slowly transfor...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>10039</td>\n",
       "      <td>so angry &lt;user&gt; order &lt;number&gt; months ago i pl...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>10040</td>\n",
       "      <td>still log fucking snap chat snap chat snap</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>10041</td>\n",
       "      <td>&lt;user&gt; sam yes not helpful we need sorting asa...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>10042</td>\n",
       "      <td>someone let snakes in my house i bet it &lt;user&gt;...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>10043</td>\n",
       "      <td>ef whichever butt wipe pulled fire alarm davis...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>10044</td>\n",
       "      <td>why &lt;user&gt; come glasgow night i working i fuck...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>10045</td>\n",
       "      <td>feel furious</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>10046</td>\n",
       "      <td>some mexican ladies irritate fuck outta have l...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>10047</td>\n",
       "      <td>still log fucking snap chat snap chat</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>10048</td>\n",
       "      <td>i blame whole season natalie the season would ...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>10049</td>\n",
       "      <td>people irritate mf soul</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>10050</td>\n",
       "      <td>im angry</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>10051</td>\n",
       "      <td>people fuckin irritate</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>10052</td>\n",
       "      <td>&lt;user&gt; cruel cruel man there will be blood rev...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>10053</td>\n",
       "      <td>that way ur angry literally feel ur blood boiling</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>10054</td>\n",
       "      <td>&lt;user&gt; amount greedy mooching makes snarl</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.750</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    SentID                                              Tweet Emotion  Rating\n",
       "0    10000  how fuck who heck moved fridge i knock landlor...   anger   0.938\n",
       "1    10001  so indian uber driver called someone n word if...   anger   0.896\n",
       "2    10002  <user> i asked parcel delivered pick store add...   anger   0.896\n",
       "3    10003  ef whichever butt wipe pulled fire alarm davis...   anger   0.896\n",
       "4    10004  do join <user> put phone talk rude taking mone...   anger   0.896\n",
       "5    10005                                   my blood boiling   anger   0.875\n",
       "6    10006  when still got whole season wentworth watch st...   anger   0.875\n",
       "7    10007  <user> tracking show equipment delivered why s...   anger   0.875\n",
       "8    10008         <user> legit furious people fucking idiots   anger   0.875\n",
       "9    10009           how suppose work wtf dude thanks pissing   anger   0.875\n",
       "10   10010        im mad power rangers im incensed im furious   anger   0.667\n",
       "11   10011  wont use using <user> <user> these guys cant g...   anger   0.854\n",
       "12   10012  bitches aggravate like inspires biggest cunt k...   anger   0.854\n",
       "13   10013  why <user> come glasgow night i working i fuck...   anger   0.938\n",
       "14   10014                                    fuking fuming    anger   0.854\n",
       "15   10015  zero help <user> customer service just pushing...   anger   0.854\n",
       "16   10016  <user> mention gra guy stops let <number> ppl ...   anger   0.854\n",
       "17   10017  i hate lawn mower if soul i would condemn fier...   anger   0.833\n",
       "18   10018  people offended kendall ends photo shoot like ...   anger   0.833\n",
       "19   10019  i block everyone everywhere posting storm i th...   anger   0.812\n",
       "20   10020                making buddy cry bitch wait revenge   anger   0.812\n",
       "21   10021  be s you tell true blooded hoop junkie switch ...   anger   0.891\n",
       "22   10022  i got no response i rate customer amazon n why...   anger   0.812\n",
       "23   10023  tasers immobilize taser someone fuck need shoo...   anger   0.812\n",
       "24   10024  <user> <user> <user> the way blood boiling lit...   anger   0.792\n",
       "25   10025            actually fuming i nothing wear saturday   anger   0.792\n",
       "26   10026  <user> straight people even arse straight guys...   anger   0.792\n",
       "27   10027                       bloody parking ticket fuming   anger   0.792\n",
       "28   10028  you ever find people around really irritate so...   anger   0.792\n",
       "29   10029  i get angry people know stop sign francis fost...   anger   0.792\n",
       "30   10030          this fuck boiling inside gonna good i let   anger   0.792\n",
       "31   10031  <user> <user> wow my bill <number> <number> ha...   anger   0.792\n",
       "32   10032  i blame whole season natalie the season would ...   anger   0.792\n",
       "33   10033  since update <user> loses power nearly <number...   anger   0.792\n",
       "34   10034                         <user> i fly fit rage fair   anger   0.792\n",
       "35   10035  unbelievable takes <number> minutes get <user>...   anger   0.792\n",
       "36   10036  <user> <user> we blaming <number> fucking idio...   anger   0.792\n",
       "37   10037                            <user> people infuriate   anger   0.792\n",
       "38   10038  <user> mine party decide party slowly transfor...   anger   0.792\n",
       "39   10039  so angry <user> order <number> months ago i pl...   anger   0.771\n",
       "40   10040         still log fucking snap chat snap chat snap   anger   0.900\n",
       "41   10041  <user> sam yes not helpful we need sorting asa...   anger   0.771\n",
       "42   10042  someone let snakes in my house i bet it <user>...   anger   0.771\n",
       "43   10043  ef whichever butt wipe pulled fire alarm davis...   anger   0.771\n",
       "44   10044  why <user> come glasgow night i working i fuck...   anger   0.733\n",
       "45   10045                                       feel furious   anger   0.771\n",
       "46   10046  some mexican ladies irritate fuck outta have l...   anger   0.771\n",
       "47   10047              still log fucking snap chat snap chat   anger   0.771\n",
       "48   10048  i blame whole season natalie the season would ...   anger   0.771\n",
       "49   10049                            people irritate mf soul   anger   0.771\n",
       "50   10050                                           im angry   anger   0.750\n",
       "51   10051                             people fuckin irritate   anger   0.750\n",
       "52   10052  <user> cruel cruel man there will be blood rev...   anger   0.840\n",
       "53   10053  that way ur angry literally feel ur blood boiling   anger   0.750\n",
       "54   10054          <user> amount greedy mooching makes snarl   anger   0.750"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# do a sanity check\n",
    "train[0:55]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_csv(\"train_clean.csv\")\n",
    "test.to_csv(\"test_clean.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the distribution of text length (from below: there is no need to truncate any of texts)\n",
    "def show_text_len(train):\n",
    "    train[\"text_len\"] = train['Tweet'].map(lambda x: len(x.split()))\n",
    "    return train[\"text_len\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    3960.000000\n",
       "mean       11.151263\n",
       "std         4.659846\n",
       "min         1.000000\n",
       "25%         7.000000\n",
       "50%        11.000000\n",
       "75%        15.000000\n",
       "max        32.000000\n",
       "Name: text_len, dtype: float64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_text_len(train).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    3142.000000\n",
       "mean       11.172502\n",
       "std         4.652404\n",
       "min         1.000000\n",
       "25%         8.000000\n",
       "50%        11.000000\n",
       "75%        14.000000\n",
       "max        31.000000\n",
       "Name: text_len, dtype: float64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_text_len(test).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is not any reviews' length = 0 after text cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tweets = list(train['Tweet'])\n",
    "train_intensities = list(train['Rating'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['how fuck who heck moved fridge i knock landlord door angry mad',\n",
       " 'so indian uber driver called someone n word if i moving vehicle i would jumped disgusted',\n",
       " '<user> i asked parcel delivered pick store address fuming poor customer service',\n",
       " 'ef whichever butt wipe pulled fire alarm davis bc i sound asleep pissed angry upset tired sad tired h angry',\n",
       " 'do join <user> put phone talk rude taking money acc willy nilly fuming',\n",
       " 'my blood boiling',\n",
       " 'when still got whole season wentworth watch stupid cunt work ruins us <user> raging old cunt',\n",
       " '<user> tracking show equipment delivered why service suddenly delayed we already <number> weeks fuming',\n",
       " '<user> legit furious people fucking idiots',\n",
       " 'how suppose work wtf dude thanks pissing',\n",
       " 'im mad power rangers im incensed im furious',\n",
       " 'wont use using <user> <user> these guys cant get nothing right fuming',\n",
       " 'bitches aggravate like inspires biggest cunt known man kind',\n",
       " 'why <user> come glasgow night i working i fucking gutted waiting appearance ages raging',\n",
       " 'fuking fuming ',\n",
       " 'zero help <user> customer service just pushing buck back forth promising callbacks dont happen anger loathing',\n",
       " '<user> mention gra guy stops let <number> ppl front go wtf my blood boiling',\n",
       " 'i hate lawn mower if soul i would condemn fiery pits hell',\n",
       " 'people offended kendall ends photo shoot like seriously shut fuck',\n",
       " 'i block everyone everywhere posting storm i think everyone aware damn rain quit damn',\n",
       " 'making buddy cry bitch wait revenge',\n",
       " 'be s you tell true blooded hoop junkie switch fuck <user> team juz destroyed team you juz insult',\n",
       " 'i got no response i rate customer amazon n why understand always amazon fault n carrier fault',\n",
       " 'tasers immobilize taser someone fuck need shoot one second later this really sick rage fuck murder',\n",
       " '<user> <user> <user> the way blood boiling little bastards',\n",
       " 'actually fuming i nothing wear saturday',\n",
       " '<user> straight people even arse straight guys think means threesome fine angry fuming',\n",
       " 'bloody parking ticket fuming',\n",
       " 'you ever find people around really irritate sometimes that right ',\n",
       " 'i get angry people know stop sign francis foster road',\n",
       " 'this fuck boiling inside gonna good i let',\n",
       " '<user> <user> wow my bill <number> <number> hav text u prove taken <number> s wines fuming con',\n",
       " 'i blame whole season natalie the season would different turned back alliance pissed',\n",
       " 'since update <user> loses power nearly <number> faster furious',\n",
       " '<user> i fly fit rage fair',\n",
       " 'unbelievable takes <number> minutes get <user> fault call hangs fuming treat customers fairly',\n",
       " '<user> <user> we blaming <number> fucking idiots putting world middle tantrums you one',\n",
       " '<user> people infuriate',\n",
       " '<user> mine party decide party slowly transformed vengeful hell cult white male resentment',\n",
       " 'so angry <user> order <number> months ago i placed order <number> card billed never received n disappointing',\n",
       " 'still log fucking snap chat snap chat snap',\n",
       " '<user> sam yes not helpful we need sorting asap you keep promising stuff happen fuming',\n",
       " 'someone let snakes in my house i bet it <user> i kill that bugger when i get my hands on him rage huck fp <number>',\n",
       " 'ef whichever butt wipe pulled fire alarm davis bc i sound asleep pissed upset tired sad tired h angry',\n",
       " 'why <user> come glasgow night i working i fucking gutted waiting appearance ages',\n",
       " 'feel furious',\n",
       " 'some mexican ladies irritate fuck outta have lil preschool fucking kids welfare amp all ll at smh',\n",
       " 'still log fucking snap chat snap chat',\n",
       " 'i blame whole season natalie the season would different turned back alliance pissed bitter',\n",
       " 'people irritate mf soul',\n",
       " 'im angry',\n",
       " 'people fuckin irritate',\n",
       " '<user> cruel cruel man there will be blood revenge',\n",
       " 'that way ur angry literally feel ur blood boiling',\n",
       " '<user> amount greedy mooching makes snarl',\n",
       " 'my mind raging want end',\n",
       " 'absolutely fuming woman jumped pre booked taxi drove ',\n",
       " 'i nothing hateful bitter fag',\n",
       " '<user> something needs done people hogging machines nobody use <number> machines one time angry not fair why pay',\n",
       " '<user> ikr people still got grudge reason like fuck',\n",
       " '<user> said talking wills uncontrollable animals moving another link these comments help fuming',\n",
       " '<user> <user> bad news ordered online gone happened order phone furious',\n",
       " 'so angry i wanna cry',\n",
       " 'oooo ooooh my god uuuugggghhhhhhhhh',\n",
       " 'boycotting <user> till butter pecan comes back i furious',\n",
       " 'in <number> black people still fighting recognized human beings cant sleep angry',\n",
       " 'mom cut phone i furious ',\n",
       " 'once thing feed na ay raging something brother filling gaps',\n",
       " 'believe achilles killed angry',\n",
       " 'i lost couple niggas i want revenge put coach',\n",
       " '<user> poor packaging amazon fulfilled seller furious much ',\n",
       " 'where outrage black man kills another black man streets',\n",
       " 'makes fucking i rate jesus nobody calling ppl like hajime abusive stop strawmen lmao',\n",
       " 'absolutely fuming i scratched car',\n",
       " '<user> holy shit bee sting like fuck dying',\n",
       " 'how fuck who heck moved fridge i knock landlord door mad',\n",
       " 'i dislike people get offended littlest shit',\n",
       " 'what fuck i supposed lunch dinner money i work furious h angry day <number>',\n",
       " '<user> one person ruins season <number> i angry',\n",
       " 'what fuck i supposed lunch dinner money i work h angry day <number>',\n",
       " '<user> buses unreliable e ticket app unable get two buses late work fuming useless reply',\n",
       " 'so indian uber driver called someone n word if i moving vehicle i would jumped disgusted offended',\n",
       " 'the liberal outrage king saying n word really angers the white yuppie progressives go fuck shame blacks',\n",
       " 'just paid chicken <user> even get goes <number> dollars customer angry',\n",
       " 'mistake half assed excuse burning hell forever',\n",
       " '<user> years irrelevant its absolute joke man utd ticketing fuming no loyalty joke not impressed',\n",
       " '<user> part <number> buzzing cheeky squash ie two not expected sort it out food angry <user> <user>',\n",
       " 'tasers immobilize taser someone fuck need shoot one second later this really sick fuck murder',\n",
       " 'be s you tell true blooded hoop junkie switch fuck <user> team juz destroyed team you juz',\n",
       " '<user> fucked coupon goal raging',\n",
       " 'lvg bribed refs utd personal revenge that foul prick',\n",
       " 'now whole clown rage scared shitless i gonna go cry room',\n",
       " 'worst juror ever michelle you nicole biggest threat bitter bb <number>',\n",
       " 'your twitter picture makes fume',\n",
       " '<user> cruel cruel man there will be blood',\n",
       " 'that really madden career game sucks ea sports piss poor job every year shit',\n",
       " '<user> <user> ha right i san jose ca i offended right dave go walk something next time',\n",
       " '<user> something needs done people hogging machines nobody use <number> machines one time not fair why pay',\n",
       " 'i wonder american city next protest police shootings who next smh when will its top angry how many more times',\n",
       " '<user> <user> another angry white man']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check\n",
    "train_tweets[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.938,\n",
       " 0.8959999999999999,\n",
       " 0.8959999999999999,\n",
       " 0.8959999999999999,\n",
       " 0.8959999999999999,\n",
       " 0.875,\n",
       " 0.875,\n",
       " 0.875,\n",
       " 0.875,\n",
       " 0.875]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check\n",
    "train_intensities[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_tweets = list(test['Tweet'])\n",
    "test_intensities = list(test['Rating'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>max text length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>train</th>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       max text length\n",
       "train               32\n",
       "test                31"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show Max Text Length of All Datasets for comparsion\n",
    "\n",
    "all_tweets_max_len = pd.DataFrame(np.array([max(show_text_len(train)), max(show_text_len(test))]))\n",
    "\n",
    "all_tweets_max_len.index = ['train', 'test']\n",
    "all_tweets_max_len.columns = ['max text length']\n",
    "\n",
    "all_tweets_max_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "all_tweets_max_len.plot(kind='bar')\n",
    "plt.title('Max Text Length of All Datasets')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "we set the length to which each tweet vector will be zero padded to.\n",
    "this is based on the maximum length we got on the training set - we do not want to remove\n",
    "any words as the maximun length of the training set is not very big.\n",
    "'''\n",
    "\n",
    "max_len = max(show_text_len(train))\n",
    "max_len"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Text Data PreparationFeature Extraction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (1) Load Pre-trained Word Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gensim\n",
    "from nltk import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vector_path = \"files/wv_models/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1) Glove"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2) Word2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3) Define Averaged Word Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (2) Load Lexicon Feature Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "lexicons_path = \"files/lexicons/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0.Emoji_Vectors',\n",
       " '1.NRC-Emotion-Intensity-Lexicon',\n",
       " '3.NRC-Emotion-Lexicon',\n",
       " '4.NRC-Hashtag-Emotion-Lexicon',\n",
       " '5.NRC-Emoticon-Lexicon',\n",
       " '6.NRC-Emoticon-AffLexNegLex',\n",
       " '7.NRC-Hashtag-Sentiment-AffLexNegLex',\n",
       " '8.NRC-Hashtag-Sentiment-Lexicon',\n",
       " '9.DepecheMood_V1.0']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paths2 = listdir(lexicons_path)\n",
    "paths2.sort()\n",
    "paths2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (3) Prepare Sentence Vectors as Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_index_mapping = \\\n",
    "    {\n",
    "        0: \"Glove[Twitter]\",\n",
    "        1: \"Word2Vec[Twitter]\",\n",
    "        2: \"NRC-Emotion Intensity Lexicon\",\n",
    "        3: \"Wordnet-Affect\",\n",
    "        4: \"NRC-Emotion-Lexicon\",\n",
    "        5: \"NRC-Emoticon-Lexicon\",\n",
    "        6: \"NRC-Emoticon-AffLexNegLex\",\n",
    "        7: \"NRC-Hashtag-Emotion\",\n",
    "        8: \"NRC-Hashtag-Sentiment-Lexicon\",\n",
    "        9: \"NRC-Hashtag-Sentiment-AffLexNegLex\",\n",
    "        10: \"Emoji Intensity\",\n",
    "        11: \"Depeche Mood\"\n",
    "    \n",
    "    }\n",
    "\n",
    "\n",
    "def get_features_from_identifier(bin_string):\n",
    "    features = list()\n",
    "    for i in range(len(bin_string)):\n",
    "        if int(bin_string[i]):\n",
    "            features.append(feature_index_mapping[i])\n",
    "\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Glove[Twitter]',\n",
       " 'Word2Vec[Twitter]',\n",
       " 'NRC-Emotion-Lexicon',\n",
       " 'NRC-Emoticon-Lexicon',\n",
       " 'NRC-Hashtag-Sentiment-Lexicon',\n",
       " 'Emoji Intensity']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string1 = \"110011001010\"\n",
    "get_features_from_identifier(string1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# restore vectors\n",
    "import pickle\n",
    "x_train_vectors_path_a = \"files/\" + \"anger\" + \"_vectors/x_train.npy\"\n",
    "y_train_vectors_path_a = \"files/\" + \"anger\" + \"_vectors/y_train.npy\"\n",
    "\n",
    "x_test_vectors_path_a = \"files/\" + \"anger\" + \"_vectors/x_test.npy\"\n",
    "y_test_vectors_path_a = \"files/\" + \"anger\" + \"_vectors/y_test.npy\"\n",
    "\n",
    "# Restore vectors\n",
    "with open(x_train_vectors_path_a, 'rb') as x_train_vectors_file_a:\n",
    "    x_train_a = pickle.load(x_train_vectors_file_a)\n",
    "with open(y_train_vectors_path_a, 'rb') as y_train_vectors_file_a:\n",
    "    score_train_a = pickle.load(y_train_vectors_file_a)\n",
    "\n",
    "with open(x_test_vectors_path_a, 'rb') as x_test_vectors_file_a:\n",
    "    x_test_a = pickle.load(x_test_vectors_file_a)\n",
    "with open(y_test_vectors_path_a, 'rb') as y_test_vectors_file_a:\n",
    "    test_intensities_a = pickle.load(y_test_vectors_file_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_vectors_path_f = \"files/\" + \"fear\" + \"_vectors/x_train.npy\"\n",
    "y_train_vectors_path_f = \"files/\" + \"fear\" + \"_vectors/y_train.npy\"\n",
    "\n",
    "x_test_vectors_path_f = \"files/\" + \"fear\" + \"_vectors/x_test.npy\"\n",
    "y_test_vectors_path_f = \"files/\" + \"fear\" + \"_vectors/y_test.npy\"\n",
    "\n",
    "# Restore vectors\n",
    "with open(x_train_vectors_path_f, 'rb') as x_train_vectors_file_f:\n",
    "    x_train_f = pickle.load(x_train_vectors_file_f)\n",
    "with open(y_train_vectors_path_f, 'rb') as y_train_vectors_file_f:\n",
    "    score_train_f = pickle.load(y_train_vectors_file_f)\n",
    "\n",
    "with open(x_test_vectors_path_f, 'rb') as x_test_vectors_file_f:\n",
    "    x_test_f = pickle.load(x_test_vectors_file_f)\n",
    "with open(y_test_vectors_path_f, 'rb') as y_test_vectors_file_f:\n",
    "    test_intensities_f = pickle.load(y_test_vectors_file_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_vectors_path_j = \"files/\" + \"joy\" + \"_vectors/x_train.npy\"\n",
    "y_train_vectors_path_j = \"files/\" + \"joy\" + \"_vectors/y_train.npy\"\n",
    "\n",
    "x_test_vectors_path_j = \"files/\" + \"joy\" + \"_vectors/x_test.npy\"\n",
    "y_test_vectors_path_j = \"files/\" + \"joy\" + \"_vectors/y_test.npy\"\n",
    "\n",
    "# Restore vectors\n",
    "with open(x_train_vectors_path_j, 'rb') as x_train_vectors_file_j:\n",
    "    x_train_j = pickle.load(x_train_vectors_file_j)\n",
    "with open(y_train_vectors_path_j, 'rb') as y_train_vectors_file_j:\n",
    "    score_train_j = pickle.load(y_train_vectors_file_j)\n",
    "\n",
    "with open(x_test_vectors_path_j, 'rb') as x_test_vectors_file_j:\n",
    "    x_test_j = pickle.load(x_test_vectors_file_j)\n",
    "with open(y_test_vectors_path_j, 'rb') as y_test_vectors_file_j:\n",
    "    test_intensities_j = pickle.load(y_test_vectors_file_j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_vectors_path_s = \"files/\" + \"sadness\" + \"_vectors/x_train.npy\"\n",
    "y_train_vectors_path_s = \"files/\" + \"sadness\" + \"_vectors/y_train.npy\"\n",
    "\n",
    "x_test_vectors_path_s = \"files/\" + \"sadness\" + \"_vectors/x_test.npy\"\n",
    "y_test_vectors_path_s = \"files/\" + \"sadness\" + \"_vectors/y_test.npy\"\n",
    "\n",
    "# Restore vectors\n",
    "with open(x_train_vectors_path_s, 'rb') as x_train_vectors_file_s:\n",
    "    x_train_s = pickle.load(x_train_vectors_file_s)\n",
    "with open(y_train_vectors_path_s, 'rb') as y_train_vectors_file_s:\n",
    "    score_train_s = pickle.load(y_train_vectors_file_s)\n",
    "\n",
    "with open(x_test_vectors_path_s, 'rb') as x_test_vectors_file_s:\n",
    "    x_test_s = pickle.load(x_test_vectors_file_s)\n",
    "with open(y_test_vectors_path_s, 'rb') as y_test_vectors_file_s:\n",
    "    test_intensities_s = pickle.load(y_test_vectors_file_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.concatenate((x_train_a, x_train_f, x_train_j, x_train_s),axis=0)\n",
    "score_train = np.concatenate((score_train_a, score_train_f, score_train_j, score_train_s),axis=0)\n",
    "\n",
    "x_test = np.concatenate((x_test_a, x_test_f, x_test_j, x_test_s),axis=0)\n",
    "test_intensities = np.concatenate((test_intensities_a, test_intensities_f, test_intensities_j, test_intensities_s),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.array(x_train)\n",
    "score_train = np.array(score_train)\n",
    "\n",
    "x_test = np.array(x_test)\n",
    "test_intensities = np.array(test_intensities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3960, 943) \n",
      " (3960,) \n",
      " (3142, 943) \n",
      " (3142,)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape,'\\n',score_train.shape,'\\n',x_test.shape, '\\n', test_intensities.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Train a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "import numpy as np\n",
    "import scipy\n",
    "\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_lists(pred, gold):\n",
    "    if len(pred) == len(gold):\n",
    "        gold_scores=gold\n",
    "        pred_scores=pred         \n",
    "        \n",
    "        # lists storing gold and prediction scores where gold score >= 0.5\n",
    "        gold_scores_range_05_1=[]\n",
    "        pred_scores_range_05_1=[]\n",
    "         \n",
    "            \n",
    "        for i in range(len(gold_scores)):\n",
    "            if(gold_scores[i]>=0.5):\n",
    "                gold_scores_range_05_1.append(gold_scores[i])\n",
    "                pred_scores_range_05_1.append(pred_scores[i])\n",
    "                \n",
    "        # return zero correlation if predictions are constant\n",
    "        if np.std(pred_scores)==0 or np.std(gold_scores)==0:\n",
    "            return (0,0,0,0)\n",
    "        \n",
    "        pears_corr=scipy.stats.pearsonr(pred_scores,gold_scores)[0]                                    \n",
    "        spear_corr=scipy.stats.spearmanr(pred_scores,gold_scores)[0]   \n",
    "\n",
    "\n",
    "        pears_corr_range_05_1=scipy.stats.pearsonr(pred_scores_range_05_1,gold_scores_range_05_1)[0]                                    \n",
    "        spear_corr_range_05_1=scipy.stats.spearmanr(pred_scores_range_05_1,gold_scores_range_05_1)[0]           \n",
    "        \n",
    "      \n",
    "        return np.array([pears_corr,spear_corr,pears_corr_range_05_1,spear_corr_range_05_1])\n",
    "    else:\n",
    "        raise ValueError('Predictions and gold data have different number of lines.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1) XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from sklearn.metrics import make_scorer\n",
    "import scipy\n",
    "def pearson_score(ground_truth, predictions):\n",
    "    score = scipy.stats.pearsonr(predictions,ground_truth)[0]\n",
    "    return score\n",
    "PS = make_scorer(pearson_score, greater_is_better=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "ml_model = XGBRegressor(objective=\"reg:squarederror\",seed=0)\n",
    "\n",
    "# specify parameters and distributions to sample from\n",
    "param_dist = {\n",
    "     \"max_depth\": range(3, 11),\n",
    "     \"n_estimators\": [100,300,500,700,900,1000,3000]\n",
    " }\n",
    "\n",
    "\n",
    "# run randomized search\n",
    "grid_search = GridSearchCV(ml_model,param_grid=param_dist, cv=5, n_jobs=-1,return_train_score=True)\n",
    "\n",
    "trainingtime = pd.DataFrame(columns = [\"Model\", \"Training Time(Seconds)\"])\n",
    "start_time_XG =time.time()\n",
    "\n",
    "grid_search.fit(x_train, score_train)\n",
    "trainingtime.loc[0] = [\"XGBoost\", round((time.time()-start_time_XG), 2)] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.12420807820154423"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "             colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "             importance_type='gain', interaction_constraints='',\n",
       "             learning_rate=0.300000012, max_delta_step=0, max_depth=9,\n",
       "             min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "             n_estimators=500, n_jobs=0, num_parallel_tree=1,\n",
       "             objective='reg:squarederror', random_state=0, reg_alpha=0,\n",
       "             reg_lambda=1, scale_pos_weight=1, seed=0, subsample=1,\n",
       "             tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9952548222566241"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_estimator_.score(x_train, score_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>44.058548</td>\n",
       "      <td>0.290272</td>\n",
       "      <td>0.035505</td>\n",
       "      <td>1.352529e-03</td>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_depth': 3, 'n_estimators': 100}</td>\n",
       "      <td>-0.197176</td>\n",
       "      <td>-0.321995</td>\n",
       "      <td>-0.108781</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.126679</td>\n",
       "      <td>0.129944</td>\n",
       "      <td>8</td>\n",
       "      <td>0.835538</td>\n",
       "      <td>0.817868</td>\n",
       "      <td>0.830583</td>\n",
       "      <td>0.844545</td>\n",
       "      <td>0.828643</td>\n",
       "      <td>0.831436</td>\n",
       "      <td>0.008733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>127.753604</td>\n",
       "      <td>1.638965</td>\n",
       "      <td>0.042885</td>\n",
       "      <td>5.085436e-03</td>\n",
       "      <td>3</td>\n",
       "      <td>300</td>\n",
       "      <td>{'max_depth': 3, 'n_estimators': 300}</td>\n",
       "      <td>-0.270734</td>\n",
       "      <td>-0.339127</td>\n",
       "      <td>-0.094779</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.162855</td>\n",
       "      <td>0.130167</td>\n",
       "      <td>37</td>\n",
       "      <td>0.977920</td>\n",
       "      <td>0.975539</td>\n",
       "      <td>0.975241</td>\n",
       "      <td>0.980315</td>\n",
       "      <td>0.977199</td>\n",
       "      <td>0.977243</td>\n",
       "      <td>0.001833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>210.099727</td>\n",
       "      <td>1.282018</td>\n",
       "      <td>0.047074</td>\n",
       "      <td>1.163186e-03</td>\n",
       "      <td>3</td>\n",
       "      <td>500</td>\n",
       "      <td>{'max_depth': 3, 'n_estimators': 500}</td>\n",
       "      <td>-0.279772</td>\n",
       "      <td>-0.347723</td>\n",
       "      <td>-0.092022</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.167663</td>\n",
       "      <td>0.130844</td>\n",
       "      <td>38</td>\n",
       "      <td>0.992700</td>\n",
       "      <td>0.991723</td>\n",
       "      <td>0.991282</td>\n",
       "      <td>0.994318</td>\n",
       "      <td>0.993220</td>\n",
       "      <td>0.992648</td>\n",
       "      <td>0.001081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>288.822194</td>\n",
       "      <td>2.287974</td>\n",
       "      <td>0.054055</td>\n",
       "      <td>1.163121e-03</td>\n",
       "      <td>3</td>\n",
       "      <td>700</td>\n",
       "      <td>{'max_depth': 3, 'n_estimators': 700}</td>\n",
       "      <td>-0.282062</td>\n",
       "      <td>-0.348249</td>\n",
       "      <td>-0.091495</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.169031</td>\n",
       "      <td>0.131161</td>\n",
       "      <td>39</td>\n",
       "      <td>0.995106</td>\n",
       "      <td>0.994209</td>\n",
       "      <td>0.993924</td>\n",
       "      <td>0.996698</td>\n",
       "      <td>0.995806</td>\n",
       "      <td>0.995149</td>\n",
       "      <td>0.001022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>372.710134</td>\n",
       "      <td>3.805927</td>\n",
       "      <td>0.061436</td>\n",
       "      <td>4.886169e-04</td>\n",
       "      <td>3</td>\n",
       "      <td>900</td>\n",
       "      <td>{'max_depth': 3, 'n_estimators': 900}</td>\n",
       "      <td>-0.284930</td>\n",
       "      <td>-0.349409</td>\n",
       "      <td>-0.090884</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.170109</td>\n",
       "      <td>0.131563</td>\n",
       "      <td>49</td>\n",
       "      <td>0.995648</td>\n",
       "      <td>0.994687</td>\n",
       "      <td>0.994493</td>\n",
       "      <td>0.997277</td>\n",
       "      <td>0.996372</td>\n",
       "      <td>0.995696</td>\n",
       "      <td>0.001041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>415.554295</td>\n",
       "      <td>2.625153</td>\n",
       "      <td>0.064627</td>\n",
       "      <td>1.465850e-03</td>\n",
       "      <td>3</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'max_depth': 3, 'n_estimators': 1000}</td>\n",
       "      <td>-0.285458</td>\n",
       "      <td>-0.348756</td>\n",
       "      <td>-0.090279</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.170055</td>\n",
       "      <td>0.131541</td>\n",
       "      <td>48</td>\n",
       "      <td>0.995734</td>\n",
       "      <td>0.994823</td>\n",
       "      <td>0.994616</td>\n",
       "      <td>0.997484</td>\n",
       "      <td>0.996463</td>\n",
       "      <td>0.995824</td>\n",
       "      <td>0.001062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>782.826119</td>\n",
       "      <td>11.872500</td>\n",
       "      <td>0.086754</td>\n",
       "      <td>5.033455e-03</td>\n",
       "      <td>3</td>\n",
       "      <td>3000</td>\n",
       "      <td>{'max_depth': 3, 'n_estimators': 3000}</td>\n",
       "      <td>-0.285685</td>\n",
       "      <td>-0.348937</td>\n",
       "      <td>-0.089587</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.169984</td>\n",
       "      <td>0.131711</td>\n",
       "      <td>47</td>\n",
       "      <td>0.995820</td>\n",
       "      <td>0.994942</td>\n",
       "      <td>0.994734</td>\n",
       "      <td>0.997654</td>\n",
       "      <td>0.996541</td>\n",
       "      <td>0.995938</td>\n",
       "      <td>0.001073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>56.309332</td>\n",
       "      <td>0.551373</td>\n",
       "      <td>0.034907</td>\n",
       "      <td>1.092362e-03</td>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_depth': 4, 'n_estimators': 100}</td>\n",
       "      <td>-0.307987</td>\n",
       "      <td>-0.304382</td>\n",
       "      <td>-0.139305</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.179244</td>\n",
       "      <td>0.109870</td>\n",
       "      <td>50</td>\n",
       "      <td>0.953181</td>\n",
       "      <td>0.951826</td>\n",
       "      <td>0.949443</td>\n",
       "      <td>0.956145</td>\n",
       "      <td>0.949301</td>\n",
       "      <td>0.951979</td>\n",
       "      <td>0.002547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>168.086249</td>\n",
       "      <td>0.839229</td>\n",
       "      <td>0.044281</td>\n",
       "      <td>4.887336e-04</td>\n",
       "      <td>4</td>\n",
       "      <td>300</td>\n",
       "      <td>{'max_depth': 4, 'n_estimators': 300}</td>\n",
       "      <td>-0.351883</td>\n",
       "      <td>-0.316304</td>\n",
       "      <td>-0.137121</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.197850</td>\n",
       "      <td>0.117982</td>\n",
       "      <td>56</td>\n",
       "      <td>0.995026</td>\n",
       "      <td>0.994117</td>\n",
       "      <td>0.993815</td>\n",
       "      <td>0.996672</td>\n",
       "      <td>0.995455</td>\n",
       "      <td>0.995017</td>\n",
       "      <td>0.001018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>280.657242</td>\n",
       "      <td>2.648054</td>\n",
       "      <td>0.055651</td>\n",
       "      <td>4.107185e-03</td>\n",
       "      <td>4</td>\n",
       "      <td>500</td>\n",
       "      <td>{'max_depth': 4, 'n_estimators': 500}</td>\n",
       "      <td>-0.351761</td>\n",
       "      <td>-0.316331</td>\n",
       "      <td>-0.134833</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.197751</td>\n",
       "      <td>0.117934</td>\n",
       "      <td>55</td>\n",
       "      <td>0.995797</td>\n",
       "      <td>0.994913</td>\n",
       "      <td>0.994707</td>\n",
       "      <td>0.997610</td>\n",
       "      <td>0.996515</td>\n",
       "      <td>0.995908</td>\n",
       "      <td>0.001069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>347.637980</td>\n",
       "      <td>6.797852</td>\n",
       "      <td>0.059436</td>\n",
       "      <td>1.706667e-03</td>\n",
       "      <td>4</td>\n",
       "      <td>700</td>\n",
       "      <td>{'max_depth': 4, 'n_estimators': 700}</td>\n",
       "      <td>-0.351570</td>\n",
       "      <td>-0.315768</td>\n",
       "      <td>-0.134754</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.197616</td>\n",
       "      <td>0.117759</td>\n",
       "      <td>51</td>\n",
       "      <td>0.995820</td>\n",
       "      <td>0.994945</td>\n",
       "      <td>0.994744</td>\n",
       "      <td>0.997657</td>\n",
       "      <td>0.996545</td>\n",
       "      <td>0.995942</td>\n",
       "      <td>0.001072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>380.654775</td>\n",
       "      <td>14.479323</td>\n",
       "      <td>0.060012</td>\n",
       "      <td>9.740287e-04</td>\n",
       "      <td>4</td>\n",
       "      <td>900</td>\n",
       "      <td>{'max_depth': 4, 'n_estimators': 900}</td>\n",
       "      <td>-0.351571</td>\n",
       "      <td>-0.315770</td>\n",
       "      <td>-0.134755</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.197617</td>\n",
       "      <td>0.117759</td>\n",
       "      <td>52</td>\n",
       "      <td>0.995820</td>\n",
       "      <td>0.994945</td>\n",
       "      <td>0.994744</td>\n",
       "      <td>0.997657</td>\n",
       "      <td>0.996545</td>\n",
       "      <td>0.995942</td>\n",
       "      <td>0.001072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>391.231674</td>\n",
       "      <td>8.468796</td>\n",
       "      <td>0.065479</td>\n",
       "      <td>7.686293e-03</td>\n",
       "      <td>4</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'max_depth': 4, 'n_estimators': 1000}</td>\n",
       "      <td>-0.351571</td>\n",
       "      <td>-0.315771</td>\n",
       "      <td>-0.134755</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.197617</td>\n",
       "      <td>0.117760</td>\n",
       "      <td>53</td>\n",
       "      <td>0.995820</td>\n",
       "      <td>0.994945</td>\n",
       "      <td>0.994744</td>\n",
       "      <td>0.997657</td>\n",
       "      <td>0.996545</td>\n",
       "      <td>0.995942</td>\n",
       "      <td>0.001072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>690.449250</td>\n",
       "      <td>7.795332</td>\n",
       "      <td>0.073269</td>\n",
       "      <td>2.261266e-03</td>\n",
       "      <td>4</td>\n",
       "      <td>3000</td>\n",
       "      <td>{'max_depth': 4, 'n_estimators': 3000}</td>\n",
       "      <td>-0.351574</td>\n",
       "      <td>-0.315776</td>\n",
       "      <td>-0.134756</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.197619</td>\n",
       "      <td>0.117761</td>\n",
       "      <td>54</td>\n",
       "      <td>0.995820</td>\n",
       "      <td>0.994945</td>\n",
       "      <td>0.994744</td>\n",
       "      <td>0.997657</td>\n",
       "      <td>0.996545</td>\n",
       "      <td>0.995942</td>\n",
       "      <td>0.001072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>72.159844</td>\n",
       "      <td>0.974416</td>\n",
       "      <td>0.037837</td>\n",
       "      <td>4.585007e-04</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_depth': 5, 'n_estimators': 100}</td>\n",
       "      <td>-0.293142</td>\n",
       "      <td>-0.324022</td>\n",
       "      <td>-0.100324</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.156974</td>\n",
       "      <td>0.130694</td>\n",
       "      <td>30</td>\n",
       "      <td>0.990068</td>\n",
       "      <td>0.988839</td>\n",
       "      <td>0.988414</td>\n",
       "      <td>0.992277</td>\n",
       "      <td>0.991038</td>\n",
       "      <td>0.990127</td>\n",
       "      <td>0.001418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>222.035535</td>\n",
       "      <td>2.240570</td>\n",
       "      <td>0.056931</td>\n",
       "      <td>5.304919e-03</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>{'max_depth': 5, 'n_estimators': 300}</td>\n",
       "      <td>-0.304627</td>\n",
       "      <td>-0.321720</td>\n",
       "      <td>-0.096077</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.157984</td>\n",
       "      <td>0.133019</td>\n",
       "      <td>36</td>\n",
       "      <td>0.995825</td>\n",
       "      <td>0.994951</td>\n",
       "      <td>0.994745</td>\n",
       "      <td>0.997664</td>\n",
       "      <td>0.996545</td>\n",
       "      <td>0.995946</td>\n",
       "      <td>0.001073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>252.928902</td>\n",
       "      <td>3.870465</td>\n",
       "      <td>0.055279</td>\n",
       "      <td>2.648632e-03</td>\n",
       "      <td>5</td>\n",
       "      <td>500</td>\n",
       "      <td>{'max_depth': 5, 'n_estimators': 500}</td>\n",
       "      <td>-0.304638</td>\n",
       "      <td>-0.321716</td>\n",
       "      <td>-0.095983</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.157982</td>\n",
       "      <td>0.133022</td>\n",
       "      <td>35</td>\n",
       "      <td>0.995825</td>\n",
       "      <td>0.994951</td>\n",
       "      <td>0.994749</td>\n",
       "      <td>0.997668</td>\n",
       "      <td>0.996545</td>\n",
       "      <td>0.995947</td>\n",
       "      <td>0.001073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>276.349879</td>\n",
       "      <td>3.250725</td>\n",
       "      <td>0.056083</td>\n",
       "      <td>6.776514e-04</td>\n",
       "      <td>5</td>\n",
       "      <td>700</td>\n",
       "      <td>{'max_depth': 5, 'n_estimators': 700}</td>\n",
       "      <td>-0.304638</td>\n",
       "      <td>-0.321714</td>\n",
       "      <td>-0.095983</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.157981</td>\n",
       "      <td>0.133022</td>\n",
       "      <td>34</td>\n",
       "      <td>0.995825</td>\n",
       "      <td>0.994951</td>\n",
       "      <td>0.994749</td>\n",
       "      <td>0.997668</td>\n",
       "      <td>0.996545</td>\n",
       "      <td>0.995947</td>\n",
       "      <td>0.001073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>307.678249</td>\n",
       "      <td>3.966909</td>\n",
       "      <td>0.057105</td>\n",
       "      <td>8.565247e-04</td>\n",
       "      <td>5</td>\n",
       "      <td>900</td>\n",
       "      <td>{'max_depth': 5, 'n_estimators': 900}</td>\n",
       "      <td>-0.304638</td>\n",
       "      <td>-0.321712</td>\n",
       "      <td>-0.095982</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.157980</td>\n",
       "      <td>0.133022</td>\n",
       "      <td>33</td>\n",
       "      <td>0.995825</td>\n",
       "      <td>0.994951</td>\n",
       "      <td>0.994749</td>\n",
       "      <td>0.997668</td>\n",
       "      <td>0.996545</td>\n",
       "      <td>0.995947</td>\n",
       "      <td>0.001073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>322.019738</td>\n",
       "      <td>3.031565</td>\n",
       "      <td>0.059061</td>\n",
       "      <td>1.070180e-03</td>\n",
       "      <td>5</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'max_depth': 5, 'n_estimators': 1000}</td>\n",
       "      <td>-0.304639</td>\n",
       "      <td>-0.321712</td>\n",
       "      <td>-0.095982</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.157980</td>\n",
       "      <td>0.133022</td>\n",
       "      <td>32</td>\n",
       "      <td>0.995825</td>\n",
       "      <td>0.994951</td>\n",
       "      <td>0.994749</td>\n",
       "      <td>0.997668</td>\n",
       "      <td>0.996545</td>\n",
       "      <td>0.995947</td>\n",
       "      <td>0.001073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>615.317327</td>\n",
       "      <td>3.418895</td>\n",
       "      <td>0.069343</td>\n",
       "      <td>7.393402e-04</td>\n",
       "      <td>5</td>\n",
       "      <td>3000</td>\n",
       "      <td>{'max_depth': 5, 'n_estimators': 3000}</td>\n",
       "      <td>-0.304640</td>\n",
       "      <td>-0.321708</td>\n",
       "      <td>-0.095980</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.157978</td>\n",
       "      <td>0.133022</td>\n",
       "      <td>31</td>\n",
       "      <td>0.995825</td>\n",
       "      <td>0.994951</td>\n",
       "      <td>0.994749</td>\n",
       "      <td>0.997668</td>\n",
       "      <td>0.996545</td>\n",
       "      <td>0.995947</td>\n",
       "      <td>0.001073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>87.605506</td>\n",
       "      <td>0.694075</td>\n",
       "      <td>0.040724</td>\n",
       "      <td>2.057128e-03</td>\n",
       "      <td>6</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_depth': 6, 'n_estimators': 100}</td>\n",
       "      <td>-0.192646</td>\n",
       "      <td>-0.279846</td>\n",
       "      <td>-0.148437</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.133615</td>\n",
       "      <td>0.108591</td>\n",
       "      <td>23</td>\n",
       "      <td>0.995387</td>\n",
       "      <td>0.994563</td>\n",
       "      <td>0.994401</td>\n",
       "      <td>0.997246</td>\n",
       "      <td>0.996054</td>\n",
       "      <td>0.995530</td>\n",
       "      <td>0.001044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>169.636222</td>\n",
       "      <td>6.292834</td>\n",
       "      <td>0.048348</td>\n",
       "      <td>1.408222e-03</td>\n",
       "      <td>6</td>\n",
       "      <td>300</td>\n",
       "      <td>{'max_depth': 6, 'n_estimators': 300}</td>\n",
       "      <td>-0.195794</td>\n",
       "      <td>-0.280888</td>\n",
       "      <td>-0.148119</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.134538</td>\n",
       "      <td>0.109126</td>\n",
       "      <td>24</td>\n",
       "      <td>0.995825</td>\n",
       "      <td>0.994953</td>\n",
       "      <td>0.994750</td>\n",
       "      <td>0.997667</td>\n",
       "      <td>0.996549</td>\n",
       "      <td>0.995949</td>\n",
       "      <td>0.001073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>200.482325</td>\n",
       "      <td>4.670473</td>\n",
       "      <td>0.053119</td>\n",
       "      <td>3.129919e-03</td>\n",
       "      <td>6</td>\n",
       "      <td>500</td>\n",
       "      <td>{'max_depth': 6, 'n_estimators': 500}</td>\n",
       "      <td>-0.195795</td>\n",
       "      <td>-0.280890</td>\n",
       "      <td>-0.148120</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.134538</td>\n",
       "      <td>0.109126</td>\n",
       "      <td>25</td>\n",
       "      <td>0.995825</td>\n",
       "      <td>0.994953</td>\n",
       "      <td>0.994750</td>\n",
       "      <td>0.997667</td>\n",
       "      <td>0.996549</td>\n",
       "      <td>0.995949</td>\n",
       "      <td>0.001073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>231.870157</td>\n",
       "      <td>3.595047</td>\n",
       "      <td>0.053048</td>\n",
       "      <td>2.513679e-03</td>\n",
       "      <td>6</td>\n",
       "      <td>700</td>\n",
       "      <td>{'max_depth': 6, 'n_estimators': 700}</td>\n",
       "      <td>-0.195796</td>\n",
       "      <td>-0.280891</td>\n",
       "      <td>-0.148120</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.134539</td>\n",
       "      <td>0.109127</td>\n",
       "      <td>26</td>\n",
       "      <td>0.995825</td>\n",
       "      <td>0.994953</td>\n",
       "      <td>0.994750</td>\n",
       "      <td>0.997667</td>\n",
       "      <td>0.996549</td>\n",
       "      <td>0.995949</td>\n",
       "      <td>0.001073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>258.780024</td>\n",
       "      <td>4.868810</td>\n",
       "      <td>0.052832</td>\n",
       "      <td>6.655514e-04</td>\n",
       "      <td>6</td>\n",
       "      <td>900</td>\n",
       "      <td>{'max_depth': 6, 'n_estimators': 900}</td>\n",
       "      <td>-0.195796</td>\n",
       "      <td>-0.280892</td>\n",
       "      <td>-0.148121</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.134539</td>\n",
       "      <td>0.109127</td>\n",
       "      <td>27</td>\n",
       "      <td>0.995825</td>\n",
       "      <td>0.994953</td>\n",
       "      <td>0.994750</td>\n",
       "      <td>0.997667</td>\n",
       "      <td>0.996549</td>\n",
       "      <td>0.995949</td>\n",
       "      <td>0.001073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>273.095476</td>\n",
       "      <td>3.665066</td>\n",
       "      <td>0.055650</td>\n",
       "      <td>2.478558e-03</td>\n",
       "      <td>6</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'max_depth': 6, 'n_estimators': 1000}</td>\n",
       "      <td>-0.195796</td>\n",
       "      <td>-0.280892</td>\n",
       "      <td>-0.148121</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.134540</td>\n",
       "      <td>0.109128</td>\n",
       "      <td>28</td>\n",
       "      <td>0.995825</td>\n",
       "      <td>0.994953</td>\n",
       "      <td>0.994750</td>\n",
       "      <td>0.997667</td>\n",
       "      <td>0.996549</td>\n",
       "      <td>0.995949</td>\n",
       "      <td>0.001073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>566.005110</td>\n",
       "      <td>6.042683</td>\n",
       "      <td>0.062484</td>\n",
       "      <td>1.087356e-06</td>\n",
       "      <td>6</td>\n",
       "      <td>3000</td>\n",
       "      <td>{'max_depth': 6, 'n_estimators': 3000}</td>\n",
       "      <td>-0.195799</td>\n",
       "      <td>-0.280897</td>\n",
       "      <td>-0.148122</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.134542</td>\n",
       "      <td>0.109129</td>\n",
       "      <td>29</td>\n",
       "      <td>0.995825</td>\n",
       "      <td>0.994953</td>\n",
       "      <td>0.994750</td>\n",
       "      <td>0.997667</td>\n",
       "      <td>0.996549</td>\n",
       "      <td>0.995949</td>\n",
       "      <td>0.001073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>102.924462</td>\n",
       "      <td>1.326606</td>\n",
       "      <td>0.040631</td>\n",
       "      <td>5.112091e-03</td>\n",
       "      <td>7</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_depth': 7, 'n_estimators': 100}</td>\n",
       "      <td>-0.239784</td>\n",
       "      <td>-0.335526</td>\n",
       "      <td>-0.156987</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.169522</td>\n",
       "      <td>0.117141</td>\n",
       "      <td>40</td>\n",
       "      <td>0.995824</td>\n",
       "      <td>0.994928</td>\n",
       "      <td>0.994749</td>\n",
       "      <td>0.997654</td>\n",
       "      <td>0.996540</td>\n",
       "      <td>0.995939</td>\n",
       "      <td>0.001073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>140.662512</td>\n",
       "      <td>4.970883</td>\n",
       "      <td>0.046863</td>\n",
       "      <td>5.135693e-07</td>\n",
       "      <td>7</td>\n",
       "      <td>300</td>\n",
       "      <td>{'max_depth': 7, 'n_estimators': 300}</td>\n",
       "      <td>-0.239861</td>\n",
       "      <td>-0.335376</td>\n",
       "      <td>-0.157071</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.169556</td>\n",
       "      <td>0.117025</td>\n",
       "      <td>46</td>\n",
       "      <td>0.995829</td>\n",
       "      <td>0.994953</td>\n",
       "      <td>0.994751</td>\n",
       "      <td>0.997669</td>\n",
       "      <td>0.996550</td>\n",
       "      <td>0.995950</td>\n",
       "      <td>0.001074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>169.811475</td>\n",
       "      <td>5.735528</td>\n",
       "      <td>0.043740</td>\n",
       "      <td>6.248689e-03</td>\n",
       "      <td>7</td>\n",
       "      <td>500</td>\n",
       "      <td>{'max_depth': 7, 'n_estimators': 500}</td>\n",
       "      <td>-0.239862</td>\n",
       "      <td>-0.335375</td>\n",
       "      <td>-0.157072</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.169556</td>\n",
       "      <td>0.117024</td>\n",
       "      <td>45</td>\n",
       "      <td>0.995829</td>\n",
       "      <td>0.994953</td>\n",
       "      <td>0.994751</td>\n",
       "      <td>0.997669</td>\n",
       "      <td>0.996550</td>\n",
       "      <td>0.995950</td>\n",
       "      <td>0.001074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>200.920684</td>\n",
       "      <td>5.165145</td>\n",
       "      <td>0.046863</td>\n",
       "      <td>1.248913e-06</td>\n",
       "      <td>7</td>\n",
       "      <td>700</td>\n",
       "      <td>{'max_depth': 7, 'n_estimators': 700}</td>\n",
       "      <td>-0.239863</td>\n",
       "      <td>-0.335373</td>\n",
       "      <td>-0.157072</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.169556</td>\n",
       "      <td>0.117024</td>\n",
       "      <td>44</td>\n",
       "      <td>0.995829</td>\n",
       "      <td>0.994953</td>\n",
       "      <td>0.994751</td>\n",
       "      <td>0.997669</td>\n",
       "      <td>0.996550</td>\n",
       "      <td>0.995950</td>\n",
       "      <td>0.001074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>230.892421</td>\n",
       "      <td>5.427054</td>\n",
       "      <td>0.053112</td>\n",
       "      <td>7.654072e-03</td>\n",
       "      <td>7</td>\n",
       "      <td>900</td>\n",
       "      <td>{'max_depth': 7, 'n_estimators': 900}</td>\n",
       "      <td>-0.239864</td>\n",
       "      <td>-0.335372</td>\n",
       "      <td>-0.157073</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.169556</td>\n",
       "      <td>0.117024</td>\n",
       "      <td>43</td>\n",
       "      <td>0.995829</td>\n",
       "      <td>0.994953</td>\n",
       "      <td>0.994751</td>\n",
       "      <td>0.997669</td>\n",
       "      <td>0.996550</td>\n",
       "      <td>0.995950</td>\n",
       "      <td>0.001074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>243.505167</td>\n",
       "      <td>5.101875</td>\n",
       "      <td>0.046864</td>\n",
       "      <td>1.248913e-06</td>\n",
       "      <td>7</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'max_depth': 7, 'n_estimators': 1000}</td>\n",
       "      <td>-0.239864</td>\n",
       "      <td>-0.335372</td>\n",
       "      <td>-0.157073</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.169556</td>\n",
       "      <td>0.117024</td>\n",
       "      <td>42</td>\n",
       "      <td>0.995829</td>\n",
       "      <td>0.994953</td>\n",
       "      <td>0.994751</td>\n",
       "      <td>0.997669</td>\n",
       "      <td>0.996550</td>\n",
       "      <td>0.995950</td>\n",
       "      <td>0.001074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>542.025809</td>\n",
       "      <td>4.675017</td>\n",
       "      <td>0.058918</td>\n",
       "      <td>6.088036e-03</td>\n",
       "      <td>7</td>\n",
       "      <td>3000</td>\n",
       "      <td>{'max_depth': 7, 'n_estimators': 3000}</td>\n",
       "      <td>-0.239867</td>\n",
       "      <td>-0.335367</td>\n",
       "      <td>-0.157075</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.169555</td>\n",
       "      <td>0.117022</td>\n",
       "      <td>41</td>\n",
       "      <td>0.995829</td>\n",
       "      <td>0.994953</td>\n",
       "      <td>0.994751</td>\n",
       "      <td>0.997669</td>\n",
       "      <td>0.996550</td>\n",
       "      <td>0.995950</td>\n",
       "      <td>0.001074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>89.725603</td>\n",
       "      <td>3.353761</td>\n",
       "      <td>0.043739</td>\n",
       "      <td>6.248975e-03</td>\n",
       "      <td>8</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_depth': 8, 'n_estimators': 100}</td>\n",
       "      <td>-0.189375</td>\n",
       "      <td>-0.233976</td>\n",
       "      <td>-0.096703</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.130841</td>\n",
       "      <td>0.076349</td>\n",
       "      <td>14</td>\n",
       "      <td>0.995828</td>\n",
       "      <td>0.994955</td>\n",
       "      <td>0.994755</td>\n",
       "      <td>0.997670</td>\n",
       "      <td>0.996549</td>\n",
       "      <td>0.995951</td>\n",
       "      <td>0.001073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>120.856689</td>\n",
       "      <td>4.161946</td>\n",
       "      <td>0.043740</td>\n",
       "      <td>6.249285e-03</td>\n",
       "      <td>8</td>\n",
       "      <td>300</td>\n",
       "      <td>{'max_depth': 8, 'n_estimators': 300}</td>\n",
       "      <td>-0.189373</td>\n",
       "      <td>-0.233972</td>\n",
       "      <td>-0.096704</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.130841</td>\n",
       "      <td>0.076346</td>\n",
       "      <td>13</td>\n",
       "      <td>0.995828</td>\n",
       "      <td>0.994955</td>\n",
       "      <td>0.994755</td>\n",
       "      <td>0.997670</td>\n",
       "      <td>0.996549</td>\n",
       "      <td>0.995951</td>\n",
       "      <td>0.001073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>152.799056</td>\n",
       "      <td>5.320521</td>\n",
       "      <td>0.046863</td>\n",
       "      <td>9.879931e-03</td>\n",
       "      <td>8</td>\n",
       "      <td>500</td>\n",
       "      <td>{'max_depth': 8, 'n_estimators': 500}</td>\n",
       "      <td>-0.189372</td>\n",
       "      <td>-0.233969</td>\n",
       "      <td>-0.096705</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.130841</td>\n",
       "      <td>0.076345</td>\n",
       "      <td>11</td>\n",
       "      <td>0.995828</td>\n",
       "      <td>0.994955</td>\n",
       "      <td>0.994755</td>\n",
       "      <td>0.997670</td>\n",
       "      <td>0.996549</td>\n",
       "      <td>0.995951</td>\n",
       "      <td>0.001073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>181.930738</td>\n",
       "      <td>4.567693</td>\n",
       "      <td>0.046864</td>\n",
       "      <td>3.234067e-07</td>\n",
       "      <td>8</td>\n",
       "      <td>700</td>\n",
       "      <td>{'max_depth': 8, 'n_estimators': 700}</td>\n",
       "      <td>-0.189371</td>\n",
       "      <td>-0.233968</td>\n",
       "      <td>-0.096705</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.130841</td>\n",
       "      <td>0.076345</td>\n",
       "      <td>9</td>\n",
       "      <td>0.995828</td>\n",
       "      <td>0.994955</td>\n",
       "      <td>0.994755</td>\n",
       "      <td>0.997670</td>\n",
       "      <td>0.996549</td>\n",
       "      <td>0.995951</td>\n",
       "      <td>0.001073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>214.056546</td>\n",
       "      <td>2.210308</td>\n",
       "      <td>0.049988</td>\n",
       "      <td>6.248665e-03</td>\n",
       "      <td>8</td>\n",
       "      <td>900</td>\n",
       "      <td>{'max_depth': 8, 'n_estimators': 900}</td>\n",
       "      <td>-0.189370</td>\n",
       "      <td>-0.233967</td>\n",
       "      <td>-0.096706</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.130841</td>\n",
       "      <td>0.076344</td>\n",
       "      <td>10</td>\n",
       "      <td>0.995828</td>\n",
       "      <td>0.994955</td>\n",
       "      <td>0.994755</td>\n",
       "      <td>0.997670</td>\n",
       "      <td>0.996549</td>\n",
       "      <td>0.995951</td>\n",
       "      <td>0.001073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>226.122489</td>\n",
       "      <td>4.556349</td>\n",
       "      <td>0.043739</td>\n",
       "      <td>6.249261e-03</td>\n",
       "      <td>8</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'max_depth': 8, 'n_estimators': 1000}</td>\n",
       "      <td>-0.189370</td>\n",
       "      <td>-0.233967</td>\n",
       "      <td>-0.096706</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.130841</td>\n",
       "      <td>0.076344</td>\n",
       "      <td>12</td>\n",
       "      <td>0.995828</td>\n",
       "      <td>0.994955</td>\n",
       "      <td>0.994755</td>\n",
       "      <td>0.997670</td>\n",
       "      <td>0.996549</td>\n",
       "      <td>0.995951</td>\n",
       "      <td>0.001073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>523.140440</td>\n",
       "      <td>5.667736</td>\n",
       "      <td>0.058918</td>\n",
       "      <td>6.088017e-03</td>\n",
       "      <td>8</td>\n",
       "      <td>3000</td>\n",
       "      <td>{'max_depth': 8, 'n_estimators': 3000}</td>\n",
       "      <td>-0.189367</td>\n",
       "      <td>-0.233962</td>\n",
       "      <td>-0.096709</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.130842</td>\n",
       "      <td>0.076341</td>\n",
       "      <td>15</td>\n",
       "      <td>0.995828</td>\n",
       "      <td>0.994955</td>\n",
       "      <td>0.994755</td>\n",
       "      <td>0.997670</td>\n",
       "      <td>0.996549</td>\n",
       "      <td>0.995951</td>\n",
       "      <td>0.001073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>78.981259</td>\n",
       "      <td>0.597218</td>\n",
       "      <td>0.043739</td>\n",
       "      <td>6.248474e-03</td>\n",
       "      <td>9</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_depth': 9, 'n_estimators': 100}</td>\n",
       "      <td>-0.129311</td>\n",
       "      <td>-0.248700</td>\n",
       "      <td>-0.099727</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.124208</td>\n",
       "      <td>0.070212</td>\n",
       "      <td>4</td>\n",
       "      <td>0.995830</td>\n",
       "      <td>0.994956</td>\n",
       "      <td>0.994755</td>\n",
       "      <td>0.997673</td>\n",
       "      <td>0.996551</td>\n",
       "      <td>0.995953</td>\n",
       "      <td>0.001073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>107.643789</td>\n",
       "      <td>1.415365</td>\n",
       "      <td>0.037490</td>\n",
       "      <td>7.653312e-03</td>\n",
       "      <td>9</td>\n",
       "      <td>300</td>\n",
       "      <td>{'max_depth': 9, 'n_estimators': 300}</td>\n",
       "      <td>-0.129310</td>\n",
       "      <td>-0.248696</td>\n",
       "      <td>-0.099728</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.124208</td>\n",
       "      <td>0.070210</td>\n",
       "      <td>3</td>\n",
       "      <td>0.995830</td>\n",
       "      <td>0.994956</td>\n",
       "      <td>0.994755</td>\n",
       "      <td>0.997673</td>\n",
       "      <td>0.996551</td>\n",
       "      <td>0.995953</td>\n",
       "      <td>0.001073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>138.664329</td>\n",
       "      <td>1.369871</td>\n",
       "      <td>0.040615</td>\n",
       "      <td>7.653429e-03</td>\n",
       "      <td>9</td>\n",
       "      <td>500</td>\n",
       "      <td>{'max_depth': 9, 'n_estimators': 500}</td>\n",
       "      <td>-0.129309</td>\n",
       "      <td>-0.248694</td>\n",
       "      <td>-0.099729</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.124208</td>\n",
       "      <td>0.070209</td>\n",
       "      <td>1</td>\n",
       "      <td>0.995830</td>\n",
       "      <td>0.994956</td>\n",
       "      <td>0.994755</td>\n",
       "      <td>0.997673</td>\n",
       "      <td>0.996551</td>\n",
       "      <td>0.995953</td>\n",
       "      <td>0.001073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>169.405544</td>\n",
       "      <td>1.533915</td>\n",
       "      <td>0.040616</td>\n",
       "      <td>7.653565e-03</td>\n",
       "      <td>9</td>\n",
       "      <td>700</td>\n",
       "      <td>{'max_depth': 9, 'n_estimators': 700}</td>\n",
       "      <td>-0.129308</td>\n",
       "      <td>-0.248692</td>\n",
       "      <td>-0.099730</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.124208</td>\n",
       "      <td>0.070208</td>\n",
       "      <td>2</td>\n",
       "      <td>0.995830</td>\n",
       "      <td>0.994956</td>\n",
       "      <td>0.994755</td>\n",
       "      <td>0.997673</td>\n",
       "      <td>0.996551</td>\n",
       "      <td>0.995953</td>\n",
       "      <td>0.001073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>200.985270</td>\n",
       "      <td>3.186736</td>\n",
       "      <td>0.043739</td>\n",
       "      <td>6.249452e-03</td>\n",
       "      <td>9</td>\n",
       "      <td>900</td>\n",
       "      <td>{'max_depth': 9, 'n_estimators': 900}</td>\n",
       "      <td>-0.129308</td>\n",
       "      <td>-0.248691</td>\n",
       "      <td>-0.099730</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.124208</td>\n",
       "      <td>0.070208</td>\n",
       "      <td>5</td>\n",
       "      <td>0.995830</td>\n",
       "      <td>0.994956</td>\n",
       "      <td>0.994755</td>\n",
       "      <td>0.997673</td>\n",
       "      <td>0.996551</td>\n",
       "      <td>0.995953</td>\n",
       "      <td>0.001073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>212.506165</td>\n",
       "      <td>0.504139</td>\n",
       "      <td>0.046864</td>\n",
       "      <td>4.672031e-07</td>\n",
       "      <td>9</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'max_depth': 9, 'n_estimators': 1000}</td>\n",
       "      <td>-0.129308</td>\n",
       "      <td>-0.248691</td>\n",
       "      <td>-0.099731</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.124208</td>\n",
       "      <td>0.070208</td>\n",
       "      <td>6</td>\n",
       "      <td>0.995830</td>\n",
       "      <td>0.994956</td>\n",
       "      <td>0.994755</td>\n",
       "      <td>0.997673</td>\n",
       "      <td>0.996551</td>\n",
       "      <td>0.995953</td>\n",
       "      <td>0.001073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>509.859429</td>\n",
       "      <td>1.985457</td>\n",
       "      <td>0.059360</td>\n",
       "      <td>1.168999e-02</td>\n",
       "      <td>9</td>\n",
       "      <td>3000</td>\n",
       "      <td>{'max_depth': 9, 'n_estimators': 3000}</td>\n",
       "      <td>-0.129307</td>\n",
       "      <td>-0.248685</td>\n",
       "      <td>-0.099732</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.124209</td>\n",
       "      <td>0.070204</td>\n",
       "      <td>7</td>\n",
       "      <td>0.995830</td>\n",
       "      <td>0.994956</td>\n",
       "      <td>0.994755</td>\n",
       "      <td>0.997673</td>\n",
       "      <td>0.996551</td>\n",
       "      <td>0.995953</td>\n",
       "      <td>0.001073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>71.316470</td>\n",
       "      <td>1.721030</td>\n",
       "      <td>0.034369</td>\n",
       "      <td>6.247953e-03</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_depth': 10, 'n_estimators': 100}</td>\n",
       "      <td>-0.121870</td>\n",
       "      <td>-0.310031</td>\n",
       "      <td>-0.111465</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.133071</td>\n",
       "      <td>0.099331</td>\n",
       "      <td>19</td>\n",
       "      <td>0.995831</td>\n",
       "      <td>0.994958</td>\n",
       "      <td>0.994757</td>\n",
       "      <td>0.997674</td>\n",
       "      <td>0.996552</td>\n",
       "      <td>0.995955</td>\n",
       "      <td>0.001073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>101.292637</td>\n",
       "      <td>1.974466</td>\n",
       "      <td>0.037490</td>\n",
       "      <td>7.653410e-03</td>\n",
       "      <td>10</td>\n",
       "      <td>300</td>\n",
       "      <td>{'max_depth': 10, 'n_estimators': 300}</td>\n",
       "      <td>-0.121868</td>\n",
       "      <td>-0.310028</td>\n",
       "      <td>-0.111466</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.133070</td>\n",
       "      <td>0.099329</td>\n",
       "      <td>18</td>\n",
       "      <td>0.995831</td>\n",
       "      <td>0.994958</td>\n",
       "      <td>0.994757</td>\n",
       "      <td>0.997674</td>\n",
       "      <td>0.996552</td>\n",
       "      <td>0.995955</td>\n",
       "      <td>0.001073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>132.708219</td>\n",
       "      <td>3.628534</td>\n",
       "      <td>0.040615</td>\n",
       "      <td>7.653059e-03</td>\n",
       "      <td>10</td>\n",
       "      <td>500</td>\n",
       "      <td>{'max_depth': 10, 'n_estimators': 500}</td>\n",
       "      <td>-0.121868</td>\n",
       "      <td>-0.310026</td>\n",
       "      <td>-0.111467</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.133070</td>\n",
       "      <td>0.099328</td>\n",
       "      <td>16</td>\n",
       "      <td>0.995831</td>\n",
       "      <td>0.994958</td>\n",
       "      <td>0.994757</td>\n",
       "      <td>0.997674</td>\n",
       "      <td>0.996552</td>\n",
       "      <td>0.995955</td>\n",
       "      <td>0.001073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>161.562334</td>\n",
       "      <td>2.339276</td>\n",
       "      <td>0.043740</td>\n",
       "      <td>6.248617e-03</td>\n",
       "      <td>10</td>\n",
       "      <td>700</td>\n",
       "      <td>{'max_depth': 10, 'n_estimators': 700}</td>\n",
       "      <td>-0.121867</td>\n",
       "      <td>-0.310024</td>\n",
       "      <td>-0.111467</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.133070</td>\n",
       "      <td>0.099327</td>\n",
       "      <td>17</td>\n",
       "      <td>0.995831</td>\n",
       "      <td>0.994958</td>\n",
       "      <td>0.994757</td>\n",
       "      <td>0.997674</td>\n",
       "      <td>0.996552</td>\n",
       "      <td>0.995955</td>\n",
       "      <td>0.001073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>189.458731</td>\n",
       "      <td>1.807160</td>\n",
       "      <td>0.046864</td>\n",
       "      <td>5.761645e-07</td>\n",
       "      <td>10</td>\n",
       "      <td>900</td>\n",
       "      <td>{'max_depth': 10, 'n_estimators': 900}</td>\n",
       "      <td>-0.121867</td>\n",
       "      <td>-0.310024</td>\n",
       "      <td>-0.111468</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.133071</td>\n",
       "      <td>0.099327</td>\n",
       "      <td>20</td>\n",
       "      <td>0.995831</td>\n",
       "      <td>0.994958</td>\n",
       "      <td>0.994757</td>\n",
       "      <td>0.997674</td>\n",
       "      <td>0.996552</td>\n",
       "      <td>0.995955</td>\n",
       "      <td>0.001073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>194.497253</td>\n",
       "      <td>4.129064</td>\n",
       "      <td>0.028118</td>\n",
       "      <td>6.248379e-03</td>\n",
       "      <td>10</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'max_depth': 10, 'n_estimators': 1000}</td>\n",
       "      <td>-0.121867</td>\n",
       "      <td>-0.310023</td>\n",
       "      <td>-0.111468</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.133071</td>\n",
       "      <td>0.099327</td>\n",
       "      <td>21</td>\n",
       "      <td>0.995831</td>\n",
       "      <td>0.994958</td>\n",
       "      <td>0.994757</td>\n",
       "      <td>0.997674</td>\n",
       "      <td>0.996552</td>\n",
       "      <td>0.995955</td>\n",
       "      <td>0.001073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>323.313692</td>\n",
       "      <td>16.355769</td>\n",
       "      <td>0.031242</td>\n",
       "      <td>9.879780e-03</td>\n",
       "      <td>10</td>\n",
       "      <td>3000</td>\n",
       "      <td>{'max_depth': 10, 'n_estimators': 3000}</td>\n",
       "      <td>-0.121866</td>\n",
       "      <td>-0.310018</td>\n",
       "      <td>-0.111469</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.133071</td>\n",
       "      <td>0.099324</td>\n",
       "      <td>22</td>\n",
       "      <td>0.995831</td>\n",
       "      <td>0.994958</td>\n",
       "      <td>0.994757</td>\n",
       "      <td>0.997674</td>\n",
       "      <td>0.996552</td>\n",
       "      <td>0.995955</td>\n",
       "      <td>0.001073</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>56 rows  22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0       44.058548      0.290272         0.035505    1.352529e-03   \n",
       "1      127.753604      1.638965         0.042885    5.085436e-03   \n",
       "2      210.099727      1.282018         0.047074    1.163186e-03   \n",
       "3      288.822194      2.287974         0.054055    1.163121e-03   \n",
       "4      372.710134      3.805927         0.061436    4.886169e-04   \n",
       "5      415.554295      2.625153         0.064627    1.465850e-03   \n",
       "6      782.826119     11.872500         0.086754    5.033455e-03   \n",
       "7       56.309332      0.551373         0.034907    1.092362e-03   \n",
       "8      168.086249      0.839229         0.044281    4.887336e-04   \n",
       "9      280.657242      2.648054         0.055651    4.107185e-03   \n",
       "10     347.637980      6.797852         0.059436    1.706667e-03   \n",
       "11     380.654775     14.479323         0.060012    9.740287e-04   \n",
       "12     391.231674      8.468796         0.065479    7.686293e-03   \n",
       "13     690.449250      7.795332         0.073269    2.261266e-03   \n",
       "14      72.159844      0.974416         0.037837    4.585007e-04   \n",
       "15     222.035535      2.240570         0.056931    5.304919e-03   \n",
       "16     252.928902      3.870465         0.055279    2.648632e-03   \n",
       "17     276.349879      3.250725         0.056083    6.776514e-04   \n",
       "18     307.678249      3.966909         0.057105    8.565247e-04   \n",
       "19     322.019738      3.031565         0.059061    1.070180e-03   \n",
       "20     615.317327      3.418895         0.069343    7.393402e-04   \n",
       "21      87.605506      0.694075         0.040724    2.057128e-03   \n",
       "22     169.636222      6.292834         0.048348    1.408222e-03   \n",
       "23     200.482325      4.670473         0.053119    3.129919e-03   \n",
       "24     231.870157      3.595047         0.053048    2.513679e-03   \n",
       "25     258.780024      4.868810         0.052832    6.655514e-04   \n",
       "26     273.095476      3.665066         0.055650    2.478558e-03   \n",
       "27     566.005110      6.042683         0.062484    1.087356e-06   \n",
       "28     102.924462      1.326606         0.040631    5.112091e-03   \n",
       "29     140.662512      4.970883         0.046863    5.135693e-07   \n",
       "30     169.811475      5.735528         0.043740    6.248689e-03   \n",
       "31     200.920684      5.165145         0.046863    1.248913e-06   \n",
       "32     230.892421      5.427054         0.053112    7.654072e-03   \n",
       "33     243.505167      5.101875         0.046864    1.248913e-06   \n",
       "34     542.025809      4.675017         0.058918    6.088036e-03   \n",
       "35      89.725603      3.353761         0.043739    6.248975e-03   \n",
       "36     120.856689      4.161946         0.043740    6.249285e-03   \n",
       "37     152.799056      5.320521         0.046863    9.879931e-03   \n",
       "38     181.930738      4.567693         0.046864    3.234067e-07   \n",
       "39     214.056546      2.210308         0.049988    6.248665e-03   \n",
       "40     226.122489      4.556349         0.043739    6.249261e-03   \n",
       "41     523.140440      5.667736         0.058918    6.088017e-03   \n",
       "42      78.981259      0.597218         0.043739    6.248474e-03   \n",
       "43     107.643789      1.415365         0.037490    7.653312e-03   \n",
       "44     138.664329      1.369871         0.040615    7.653429e-03   \n",
       "45     169.405544      1.533915         0.040616    7.653565e-03   \n",
       "46     200.985270      3.186736         0.043739    6.249452e-03   \n",
       "47     212.506165      0.504139         0.046864    4.672031e-07   \n",
       "48     509.859429      1.985457         0.059360    1.168999e-02   \n",
       "49      71.316470      1.721030         0.034369    6.247953e-03   \n",
       "50     101.292637      1.974466         0.037490    7.653410e-03   \n",
       "51     132.708219      3.628534         0.040615    7.653059e-03   \n",
       "52     161.562334      2.339276         0.043740    6.248617e-03   \n",
       "53     189.458731      1.807160         0.046864    5.761645e-07   \n",
       "54     194.497253      4.129064         0.028118    6.248379e-03   \n",
       "55     323.313692     16.355769         0.031242    9.879780e-03   \n",
       "\n",
       "   param_max_depth param_n_estimators  \\\n",
       "0                3                100   \n",
       "1                3                300   \n",
       "2                3                500   \n",
       "3                3                700   \n",
       "4                3                900   \n",
       "5                3               1000   \n",
       "6                3               3000   \n",
       "7                4                100   \n",
       "8                4                300   \n",
       "9                4                500   \n",
       "10               4                700   \n",
       "11               4                900   \n",
       "12               4               1000   \n",
       "13               4               3000   \n",
       "14               5                100   \n",
       "15               5                300   \n",
       "16               5                500   \n",
       "17               5                700   \n",
       "18               5                900   \n",
       "19               5               1000   \n",
       "20               5               3000   \n",
       "21               6                100   \n",
       "22               6                300   \n",
       "23               6                500   \n",
       "24               6                700   \n",
       "25               6                900   \n",
       "26               6               1000   \n",
       "27               6               3000   \n",
       "28               7                100   \n",
       "29               7                300   \n",
       "30               7                500   \n",
       "31               7                700   \n",
       "32               7                900   \n",
       "33               7               1000   \n",
       "34               7               3000   \n",
       "35               8                100   \n",
       "36               8                300   \n",
       "37               8                500   \n",
       "38               8                700   \n",
       "39               8                900   \n",
       "40               8               1000   \n",
       "41               8               3000   \n",
       "42               9                100   \n",
       "43               9                300   \n",
       "44               9                500   \n",
       "45               9                700   \n",
       "46               9                900   \n",
       "47               9               1000   \n",
       "48               9               3000   \n",
       "49              10                100   \n",
       "50              10                300   \n",
       "51              10                500   \n",
       "52              10                700   \n",
       "53              10                900   \n",
       "54              10               1000   \n",
       "55              10               3000   \n",
       "\n",
       "                                     params  split0_test_score  \\\n",
       "0     {'max_depth': 3, 'n_estimators': 100}          -0.197176   \n",
       "1     {'max_depth': 3, 'n_estimators': 300}          -0.270734   \n",
       "2     {'max_depth': 3, 'n_estimators': 500}          -0.279772   \n",
       "3     {'max_depth': 3, 'n_estimators': 700}          -0.282062   \n",
       "4     {'max_depth': 3, 'n_estimators': 900}          -0.284930   \n",
       "5    {'max_depth': 3, 'n_estimators': 1000}          -0.285458   \n",
       "6    {'max_depth': 3, 'n_estimators': 3000}          -0.285685   \n",
       "7     {'max_depth': 4, 'n_estimators': 100}          -0.307987   \n",
       "8     {'max_depth': 4, 'n_estimators': 300}          -0.351883   \n",
       "9     {'max_depth': 4, 'n_estimators': 500}          -0.351761   \n",
       "10    {'max_depth': 4, 'n_estimators': 700}          -0.351570   \n",
       "11    {'max_depth': 4, 'n_estimators': 900}          -0.351571   \n",
       "12   {'max_depth': 4, 'n_estimators': 1000}          -0.351571   \n",
       "13   {'max_depth': 4, 'n_estimators': 3000}          -0.351574   \n",
       "14    {'max_depth': 5, 'n_estimators': 100}          -0.293142   \n",
       "15    {'max_depth': 5, 'n_estimators': 300}          -0.304627   \n",
       "16    {'max_depth': 5, 'n_estimators': 500}          -0.304638   \n",
       "17    {'max_depth': 5, 'n_estimators': 700}          -0.304638   \n",
       "18    {'max_depth': 5, 'n_estimators': 900}          -0.304638   \n",
       "19   {'max_depth': 5, 'n_estimators': 1000}          -0.304639   \n",
       "20   {'max_depth': 5, 'n_estimators': 3000}          -0.304640   \n",
       "21    {'max_depth': 6, 'n_estimators': 100}          -0.192646   \n",
       "22    {'max_depth': 6, 'n_estimators': 300}          -0.195794   \n",
       "23    {'max_depth': 6, 'n_estimators': 500}          -0.195795   \n",
       "24    {'max_depth': 6, 'n_estimators': 700}          -0.195796   \n",
       "25    {'max_depth': 6, 'n_estimators': 900}          -0.195796   \n",
       "26   {'max_depth': 6, 'n_estimators': 1000}          -0.195796   \n",
       "27   {'max_depth': 6, 'n_estimators': 3000}          -0.195799   \n",
       "28    {'max_depth': 7, 'n_estimators': 100}          -0.239784   \n",
       "29    {'max_depth': 7, 'n_estimators': 300}          -0.239861   \n",
       "30    {'max_depth': 7, 'n_estimators': 500}          -0.239862   \n",
       "31    {'max_depth': 7, 'n_estimators': 700}          -0.239863   \n",
       "32    {'max_depth': 7, 'n_estimators': 900}          -0.239864   \n",
       "33   {'max_depth': 7, 'n_estimators': 1000}          -0.239864   \n",
       "34   {'max_depth': 7, 'n_estimators': 3000}          -0.239867   \n",
       "35    {'max_depth': 8, 'n_estimators': 100}          -0.189375   \n",
       "36    {'max_depth': 8, 'n_estimators': 300}          -0.189373   \n",
       "37    {'max_depth': 8, 'n_estimators': 500}          -0.189372   \n",
       "38    {'max_depth': 8, 'n_estimators': 700}          -0.189371   \n",
       "39    {'max_depth': 8, 'n_estimators': 900}          -0.189370   \n",
       "40   {'max_depth': 8, 'n_estimators': 1000}          -0.189370   \n",
       "41   {'max_depth': 8, 'n_estimators': 3000}          -0.189367   \n",
       "42    {'max_depth': 9, 'n_estimators': 100}          -0.129311   \n",
       "43    {'max_depth': 9, 'n_estimators': 300}          -0.129310   \n",
       "44    {'max_depth': 9, 'n_estimators': 500}          -0.129309   \n",
       "45    {'max_depth': 9, 'n_estimators': 700}          -0.129308   \n",
       "46    {'max_depth': 9, 'n_estimators': 900}          -0.129308   \n",
       "47   {'max_depth': 9, 'n_estimators': 1000}          -0.129308   \n",
       "48   {'max_depth': 9, 'n_estimators': 3000}          -0.129307   \n",
       "49   {'max_depth': 10, 'n_estimators': 100}          -0.121870   \n",
       "50   {'max_depth': 10, 'n_estimators': 300}          -0.121868   \n",
       "51   {'max_depth': 10, 'n_estimators': 500}          -0.121868   \n",
       "52   {'max_depth': 10, 'n_estimators': 700}          -0.121867   \n",
       "53   {'max_depth': 10, 'n_estimators': 900}          -0.121867   \n",
       "54  {'max_depth': 10, 'n_estimators': 1000}          -0.121867   \n",
       "55  {'max_depth': 10, 'n_estimators': 3000}          -0.121866   \n",
       "\n",
       "    split1_test_score  split2_test_score  ...  mean_test_score  \\\n",
       "0           -0.321995          -0.108781  ...        -0.126679   \n",
       "1           -0.339127          -0.094779  ...        -0.162855   \n",
       "2           -0.347723          -0.092022  ...        -0.167663   \n",
       "3           -0.348249          -0.091495  ...        -0.169031   \n",
       "4           -0.349409          -0.090884  ...        -0.170109   \n",
       "5           -0.348756          -0.090279  ...        -0.170055   \n",
       "6           -0.348937          -0.089587  ...        -0.169984   \n",
       "7           -0.304382          -0.139305  ...        -0.179244   \n",
       "8           -0.316304          -0.137121  ...        -0.197850   \n",
       "9           -0.316331          -0.134833  ...        -0.197751   \n",
       "10          -0.315768          -0.134754  ...        -0.197616   \n",
       "11          -0.315770          -0.134755  ...        -0.197617   \n",
       "12          -0.315771          -0.134755  ...        -0.197617   \n",
       "13          -0.315776          -0.134756  ...        -0.197619   \n",
       "14          -0.324022          -0.100324  ...        -0.156974   \n",
       "15          -0.321720          -0.096077  ...        -0.157984   \n",
       "16          -0.321716          -0.095983  ...        -0.157982   \n",
       "17          -0.321714          -0.095983  ...        -0.157981   \n",
       "18          -0.321712          -0.095982  ...        -0.157980   \n",
       "19          -0.321712          -0.095982  ...        -0.157980   \n",
       "20          -0.321708          -0.095980  ...        -0.157978   \n",
       "21          -0.279846          -0.148437  ...        -0.133615   \n",
       "22          -0.280888          -0.148119  ...        -0.134538   \n",
       "23          -0.280890          -0.148120  ...        -0.134538   \n",
       "24          -0.280891          -0.148120  ...        -0.134539   \n",
       "25          -0.280892          -0.148121  ...        -0.134539   \n",
       "26          -0.280892          -0.148121  ...        -0.134540   \n",
       "27          -0.280897          -0.148122  ...        -0.134542   \n",
       "28          -0.335526          -0.156987  ...        -0.169522   \n",
       "29          -0.335376          -0.157071  ...        -0.169556   \n",
       "30          -0.335375          -0.157072  ...        -0.169556   \n",
       "31          -0.335373          -0.157072  ...        -0.169556   \n",
       "32          -0.335372          -0.157073  ...        -0.169556   \n",
       "33          -0.335372          -0.157073  ...        -0.169556   \n",
       "34          -0.335367          -0.157075  ...        -0.169555   \n",
       "35          -0.233976          -0.096703  ...        -0.130841   \n",
       "36          -0.233972          -0.096704  ...        -0.130841   \n",
       "37          -0.233969          -0.096705  ...        -0.130841   \n",
       "38          -0.233968          -0.096705  ...        -0.130841   \n",
       "39          -0.233967          -0.096706  ...        -0.130841   \n",
       "40          -0.233967          -0.096706  ...        -0.130841   \n",
       "41          -0.233962          -0.096709  ...        -0.130842   \n",
       "42          -0.248700          -0.099727  ...        -0.124208   \n",
       "43          -0.248696          -0.099728  ...        -0.124208   \n",
       "44          -0.248694          -0.099729  ...        -0.124208   \n",
       "45          -0.248692          -0.099730  ...        -0.124208   \n",
       "46          -0.248691          -0.099730  ...        -0.124208   \n",
       "47          -0.248691          -0.099731  ...        -0.124208   \n",
       "48          -0.248685          -0.099732  ...        -0.124209   \n",
       "49          -0.310031          -0.111465  ...        -0.133071   \n",
       "50          -0.310028          -0.111466  ...        -0.133070   \n",
       "51          -0.310026          -0.111467  ...        -0.133070   \n",
       "52          -0.310024          -0.111467  ...        -0.133070   \n",
       "53          -0.310024          -0.111468  ...        -0.133071   \n",
       "54          -0.310023          -0.111468  ...        -0.133071   \n",
       "55          -0.310018          -0.111469  ...        -0.133071   \n",
       "\n",
       "    std_test_score  rank_test_score  split0_train_score  split1_train_score  \\\n",
       "0         0.129944                8            0.835538            0.817868   \n",
       "1         0.130167               37            0.977920            0.975539   \n",
       "2         0.130844               38            0.992700            0.991723   \n",
       "3         0.131161               39            0.995106            0.994209   \n",
       "4         0.131563               49            0.995648            0.994687   \n",
       "5         0.131541               48            0.995734            0.994823   \n",
       "6         0.131711               47            0.995820            0.994942   \n",
       "7         0.109870               50            0.953181            0.951826   \n",
       "8         0.117982               56            0.995026            0.994117   \n",
       "9         0.117934               55            0.995797            0.994913   \n",
       "10        0.117759               51            0.995820            0.994945   \n",
       "11        0.117759               52            0.995820            0.994945   \n",
       "12        0.117760               53            0.995820            0.994945   \n",
       "13        0.117761               54            0.995820            0.994945   \n",
       "14        0.130694               30            0.990068            0.988839   \n",
       "15        0.133019               36            0.995825            0.994951   \n",
       "16        0.133022               35            0.995825            0.994951   \n",
       "17        0.133022               34            0.995825            0.994951   \n",
       "18        0.133022               33            0.995825            0.994951   \n",
       "19        0.133022               32            0.995825            0.994951   \n",
       "20        0.133022               31            0.995825            0.994951   \n",
       "21        0.108591               23            0.995387            0.994563   \n",
       "22        0.109126               24            0.995825            0.994953   \n",
       "23        0.109126               25            0.995825            0.994953   \n",
       "24        0.109127               26            0.995825            0.994953   \n",
       "25        0.109127               27            0.995825            0.994953   \n",
       "26        0.109128               28            0.995825            0.994953   \n",
       "27        0.109129               29            0.995825            0.994953   \n",
       "28        0.117141               40            0.995824            0.994928   \n",
       "29        0.117025               46            0.995829            0.994953   \n",
       "30        0.117024               45            0.995829            0.994953   \n",
       "31        0.117024               44            0.995829            0.994953   \n",
       "32        0.117024               43            0.995829            0.994953   \n",
       "33        0.117024               42            0.995829            0.994953   \n",
       "34        0.117022               41            0.995829            0.994953   \n",
       "35        0.076349               14            0.995828            0.994955   \n",
       "36        0.076346               13            0.995828            0.994955   \n",
       "37        0.076345               11            0.995828            0.994955   \n",
       "38        0.076345                9            0.995828            0.994955   \n",
       "39        0.076344               10            0.995828            0.994955   \n",
       "40        0.076344               12            0.995828            0.994955   \n",
       "41        0.076341               15            0.995828            0.994955   \n",
       "42        0.070212                4            0.995830            0.994956   \n",
       "43        0.070210                3            0.995830            0.994956   \n",
       "44        0.070209                1            0.995830            0.994956   \n",
       "45        0.070208                2            0.995830            0.994956   \n",
       "46        0.070208                5            0.995830            0.994956   \n",
       "47        0.070208                6            0.995830            0.994956   \n",
       "48        0.070204                7            0.995830            0.994956   \n",
       "49        0.099331               19            0.995831            0.994958   \n",
       "50        0.099329               18            0.995831            0.994958   \n",
       "51        0.099328               16            0.995831            0.994958   \n",
       "52        0.099327               17            0.995831            0.994958   \n",
       "53        0.099327               20            0.995831            0.994958   \n",
       "54        0.099327               21            0.995831            0.994958   \n",
       "55        0.099324               22            0.995831            0.994958   \n",
       "\n",
       "    split2_train_score  split3_train_score  split4_train_score  \\\n",
       "0             0.830583            0.844545            0.828643   \n",
       "1             0.975241            0.980315            0.977199   \n",
       "2             0.991282            0.994318            0.993220   \n",
       "3             0.993924            0.996698            0.995806   \n",
       "4             0.994493            0.997277            0.996372   \n",
       "5             0.994616            0.997484            0.996463   \n",
       "6             0.994734            0.997654            0.996541   \n",
       "7             0.949443            0.956145            0.949301   \n",
       "8             0.993815            0.996672            0.995455   \n",
       "9             0.994707            0.997610            0.996515   \n",
       "10            0.994744            0.997657            0.996545   \n",
       "11            0.994744            0.997657            0.996545   \n",
       "12            0.994744            0.997657            0.996545   \n",
       "13            0.994744            0.997657            0.996545   \n",
       "14            0.988414            0.992277            0.991038   \n",
       "15            0.994745            0.997664            0.996545   \n",
       "16            0.994749            0.997668            0.996545   \n",
       "17            0.994749            0.997668            0.996545   \n",
       "18            0.994749            0.997668            0.996545   \n",
       "19            0.994749            0.997668            0.996545   \n",
       "20            0.994749            0.997668            0.996545   \n",
       "21            0.994401            0.997246            0.996054   \n",
       "22            0.994750            0.997667            0.996549   \n",
       "23            0.994750            0.997667            0.996549   \n",
       "24            0.994750            0.997667            0.996549   \n",
       "25            0.994750            0.997667            0.996549   \n",
       "26            0.994750            0.997667            0.996549   \n",
       "27            0.994750            0.997667            0.996549   \n",
       "28            0.994749            0.997654            0.996540   \n",
       "29            0.994751            0.997669            0.996550   \n",
       "30            0.994751            0.997669            0.996550   \n",
       "31            0.994751            0.997669            0.996550   \n",
       "32            0.994751            0.997669            0.996550   \n",
       "33            0.994751            0.997669            0.996550   \n",
       "34            0.994751            0.997669            0.996550   \n",
       "35            0.994755            0.997670            0.996549   \n",
       "36            0.994755            0.997670            0.996549   \n",
       "37            0.994755            0.997670            0.996549   \n",
       "38            0.994755            0.997670            0.996549   \n",
       "39            0.994755            0.997670            0.996549   \n",
       "40            0.994755            0.997670            0.996549   \n",
       "41            0.994755            0.997670            0.996549   \n",
       "42            0.994755            0.997673            0.996551   \n",
       "43            0.994755            0.997673            0.996551   \n",
       "44            0.994755            0.997673            0.996551   \n",
       "45            0.994755            0.997673            0.996551   \n",
       "46            0.994755            0.997673            0.996551   \n",
       "47            0.994755            0.997673            0.996551   \n",
       "48            0.994755            0.997673            0.996551   \n",
       "49            0.994757            0.997674            0.996552   \n",
       "50            0.994757            0.997674            0.996552   \n",
       "51            0.994757            0.997674            0.996552   \n",
       "52            0.994757            0.997674            0.996552   \n",
       "53            0.994757            0.997674            0.996552   \n",
       "54            0.994757            0.997674            0.996552   \n",
       "55            0.994757            0.997674            0.996552   \n",
       "\n",
       "    mean_train_score  std_train_score  \n",
       "0           0.831436         0.008733  \n",
       "1           0.977243         0.001833  \n",
       "2           0.992648         0.001081  \n",
       "3           0.995149         0.001022  \n",
       "4           0.995696         0.001041  \n",
       "5           0.995824         0.001062  \n",
       "6           0.995938         0.001073  \n",
       "7           0.951979         0.002547  \n",
       "8           0.995017         0.001018  \n",
       "9           0.995908         0.001069  \n",
       "10          0.995942         0.001072  \n",
       "11          0.995942         0.001072  \n",
       "12          0.995942         0.001072  \n",
       "13          0.995942         0.001072  \n",
       "14          0.990127         0.001418  \n",
       "15          0.995946         0.001073  \n",
       "16          0.995947         0.001073  \n",
       "17          0.995947         0.001073  \n",
       "18          0.995947         0.001073  \n",
       "19          0.995947         0.001073  \n",
       "20          0.995947         0.001073  \n",
       "21          0.995530         0.001044  \n",
       "22          0.995949         0.001073  \n",
       "23          0.995949         0.001073  \n",
       "24          0.995949         0.001073  \n",
       "25          0.995949         0.001073  \n",
       "26          0.995949         0.001073  \n",
       "27          0.995949         0.001073  \n",
       "28          0.995939         0.001073  \n",
       "29          0.995950         0.001074  \n",
       "30          0.995950         0.001074  \n",
       "31          0.995950         0.001074  \n",
       "32          0.995950         0.001074  \n",
       "33          0.995950         0.001074  \n",
       "34          0.995950         0.001074  \n",
       "35          0.995951         0.001073  \n",
       "36          0.995951         0.001073  \n",
       "37          0.995951         0.001073  \n",
       "38          0.995951         0.001073  \n",
       "39          0.995951         0.001073  \n",
       "40          0.995951         0.001073  \n",
       "41          0.995951         0.001073  \n",
       "42          0.995953         0.001073  \n",
       "43          0.995953         0.001073  \n",
       "44          0.995953         0.001073  \n",
       "45          0.995953         0.001073  \n",
       "46          0.995953         0.001073  \n",
       "47          0.995953         0.001073  \n",
       "48          0.995953         0.001073  \n",
       "49          0.995955         0.001073  \n",
       "50          0.995955         0.001073  \n",
       "51          0.995955         0.001073  \n",
       "52          0.995955         0.001073  \n",
       "53          0.995955         0.001073  \n",
       "54          0.995955         0.001073  \n",
       "55          0.995955         0.001073  \n",
       "\n",
       "[56 rows x 22 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(grid_search.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 9, 'n_estimators': 500}"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "             colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "             importance_type='gain', interaction_constraints='',\n",
       "             learning_rate=0.300000012, max_delta_step=0, max_depth=9,\n",
       "             min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "             n_estimators=500, n_jobs=0, num_parallel_tree=1,\n",
       "             objective='reg:squarederror', random_state=0, reg_alpha=0,\n",
       "             reg_lambda=1, scale_pos_weight=1, seed=0, subsample=1,\n",
       "             tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ml_model_best = grid_search.best_estimator_\n",
    "\n",
    "ml_model_best.fit(x_train, score_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import learning_curve\n",
    "def plot_learningcurve(classifier, X, y, plt_titile):\n",
    "    # check whether there is overfitting or underfitting by learning_curve\n",
    "    # choose five kinds of fraction of the maximum size of the training set: np.linspace(0.1,1.0,5)\n",
    "    train_size, train_score, test_score = learning_curve(classifier, X, y, cv=5, train_sizes=np.linspace(0.1,1.0,5))\n",
    "    train_scores_mean = np.mean(train_score, axis=1)\n",
    "    train_scores_std = np.std(train_score, axis=1)\n",
    "    test_scores_mean = np.mean(test_score, axis=1)\n",
    "    test_scores_std = np.std(test_score, axis=1)\n",
    "    plt.fill_between(train_size, train_scores_mean - train_scores_std, train_scores_mean + train_scores_std, alpha=0.1, color=\"r\")\n",
    "    plt.fill_between(train_size, test_scores_mean - test_scores_std, test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n",
    "    plt.plot(train_size, train_scores_mean,'o--', color=\"r\",label=\"Training score\")\n",
    "    plt.plot(train_size, test_scores_mean,'o-', color=\"g\",label=\"Testing score\")\n",
    "    plt.grid()\n",
    "    plt.title(plt_titile)\n",
    "    plt.legend(loc=\"best\")\n",
    "    return plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_learningcurve(grid_search.best_estimator_, x_train, score_train, 'Learning Curve (XGBoost)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.41635133, 0.39958636, 0.30618782, 0.2697746 ])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = ml_model_best.predict(x_test)\n",
    "\n",
    "score1 = evaluate_lists(y_pred, test_intensities)\n",
    "score1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgboost_path = \"files/final_models/\" + \"xgboost_\"+ emotion + \".dat\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(xgboost_path, 'wb') as xgboost_file:\n",
    "    pickle.dump(grid_search.best_estimator_, xgboost_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = pickle.load(open(xgboost_path,'rb'))\n",
    "#model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2) Feedfoward Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "class LinearModel(torch.nn.Module):\n",
    "    def __init__(self,n_feature,n_hidden,n_output):\n",
    "        super(LinearModel,self).__init__() \n",
    "        self.hidden = torch.nn.Linear(n_feature,n_hidden)\n",
    "        self.hidden.weight = torch.nn.init.xavier_normal(self.hidden.weight)\n",
    "        self.dropout = torch.nn.Dropout(p=0.25)\n",
    "        self.predict = torch.nn.Linear(n_hidden,n_output)\n",
    "    def forward(self,x):\n",
    "        out=F.relu(self.hidden(x))\n",
    "        out=self.dropout(out)\n",
    "        out=F.sigmoid(self.predict(out))\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.1300, -0.1311,  0.0931,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [-0.1948, -0.1537,  0.0384,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.1333,  0.0675,  0.0822,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        ...,\n",
      "        [ 0.1232,  0.0045, -0.0948,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.1621,  0.0118, -0.1142,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.1808, -0.0800, -0.0515,  ...,  0.0000,  0.0000,  0.0000]]) \n",
      " tensor([0.3750, 0.3800, 0.1880, 0.3750, 0.4660, 0.5000, 0.5620, 0.5830, 0.8750,\n",
      "        0.8540, 0.3120, 0.4240, 0.6670, 0.2500, 0.3540, 0.6670, 0.5000, 0.4580,\n",
      "        0.4810, 0.5190, 0.4580, 0.2550, 0.6040, 0.3120, 0.4790, 0.9340, 0.6460,\n",
      "        0.6360, 0.3120, 0.4380, 0.8540, 0.4580, 0.5210, 0.3730, 0.5420, 0.1460,\n",
      "        0.3200, 0.3540, 0.5420, 0.4580, 0.4380, 0.5620, 0.2710, 0.8960, 0.4790,\n",
      "        0.4380, 0.1890, 0.6040, 0.5420, 0.3750, 0.7710, 0.6040, 0.7050, 0.4400,\n",
      "        0.6460, 0.5830, 0.3540, 0.6250, 0.7080, 0.5620, 0.3120, 0.4200, 0.8330,\n",
      "        0.7920, 0.5210, 0.4580, 0.4580, 0.7540, 0.7080, 0.5000, 0.4170, 0.4170,\n",
      "        0.6600, 0.1460, 0.6600, 0.5830, 0.4580, 0.5000, 0.2350, 0.7080, 0.7500,\n",
      "        0.3960, 0.5830, 0.3510, 0.3800, 0.2710, 0.0380, 0.3120, 0.4170, 0.8750,\n",
      "        0.1840, 0.0880, 0.7290, 0.2310, 0.9170, 0.7290, 0.3800, 0.5170, 0.9380,\n",
      "        0.5210, 0.2710, 0.5000, 0.5630, 0.2290, 0.7290, 0.3120, 0.8120, 0.6820,\n",
      "        0.8490, 0.5420, 0.3960, 0.2920, 0.2290, 0.4170, 0.4580, 0.4380, 0.7710,\n",
      "        0.3540, 0.6460, 0.3750, 0.7330, 0.7920, 0.1460, 0.3540, 0.5210, 0.2920,\n",
      "        0.7710, 0.1610])\n"
     ]
    }
   ],
   "source": [
    "import torch.utils.data as Data\n",
    "batch_size = 128\n",
    "dataset = Data.TensorDataset(torch.tensor(x_train.astype(np.float32)), torch.tensor(score_train.astype(np.float32)))\n",
    "data_iter = Data.DataLoader(dataset = dataset,batch_size = batch_size, shuffle = True, num_workers = 2)\n",
    "\n",
    "for X,y in data_iter:\n",
    "    print(X, '\\n', y)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearModel(\n",
      "  (hidden): Linear(in_features=943, out_features=10000, bias=True)\n",
      "  (dropout): Dropout(p=0.25, inplace=False)\n",
      "  (predict): Linear(in_features=10000, out_features=1, bias=True)\n",
      ")\n",
      "<generator object Module.parameters at 0x000002B17EC94E60>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dell\\Anaconda3\\envs\\tf2\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: nn.init.xavier_normal is now deprecated in favor of nn.init.xavier_normal_.\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "# architecure: 1100001\n",
    "net = LinearModel(x_train.shape[1],10000,1)\n",
    "print(net)\n",
    "print(net.parameters())    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Parameter containing:\n",
      "tensor([[-0.0022,  0.0069, -0.0226,  ..., -0.0109,  0.0063, -0.0304],\n",
      "        [ 0.0019, -0.0076,  0.0105,  ...,  0.0086, -0.0054, -0.0286],\n",
      "        [ 0.0427,  0.0062,  0.0069,  ..., -0.0079,  0.0116, -0.0279],\n",
      "        ...,\n",
      "        [-0.0329,  0.0071, -0.0130,  ..., -0.0009,  0.0190,  0.0102],\n",
      "        [-0.0254,  0.0018,  0.0148,  ..., -0.0022,  0.0088,  0.0121],\n",
      "        [-0.0018, -0.0035, -0.0106,  ..., -0.0064, -0.0182,  0.0025]],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([-0.0011,  0.0145, -0.0315,  ...,  0.0209, -0.0030,  0.0020],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([[ 0.0057, -0.0019, -0.0016,  ..., -0.0005,  0.0073, -0.0041]],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([0.0005], requires_grad=True)]\n"
     ]
    }
   ],
   "source": [
    "para = list(net.parameters())\n",
    "print(para)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    lr: 0.001\n",
      "    weight_decay: 0\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(net.parameters())\n",
    "print(optimizer)\n",
    "\n",
    "loss_func = torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_test = Data.TensorDataset(torch.tensor(x_test.astype(np.float32)), torch.tensor(test_intensities.astype(np.float32)))\n",
    "data_iter_test = Data.DataLoader(dataset = dataset_test,batch_size = batch_size, num_workers = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dell\\Anaconda3\\envs\\tf2\\lib\\site-packages\\torch\\nn\\functional.py:1351: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch10,train_loss0.013165365904569626\n",
      "epoch10,test_loss0.023963527753949165\n",
      "epoch20,train_loss0.006808039732277393\n",
      "epoch20,test_loss0.022863514721393585\n",
      "epoch30,train_loss0.004183076787739992\n",
      "epoch30,test_loss0.02381271682679653\n",
      "epoch40,train_loss0.003074134001508355\n",
      "epoch40,test_loss0.025029631331562996\n",
      "epoch50,train_loss0.0021810405887663364\n",
      "epoch50,test_loss0.023067651316523552\n",
      "epoch60,train_loss0.0017500483663752675\n",
      "epoch60,test_loss0.024035967886447906\n",
      "epoch70,train_loss0.0018793410854414105\n",
      "epoch70,test_loss0.023215919733047485\n",
      "epoch80,train_loss0.0023803473450243473\n",
      "epoch80,test_loss0.02402171492576599\n",
      "epoch90,train_loss0.0020870077423751354\n",
      "epoch90,test_loss0.024356229230761528\n",
      "epoch100,train_loss0.0015697585185989738\n",
      "epoch100,test_loss0.024350790306925774\n",
      "epoch110,train_loss0.00092846475308761\n",
      "epoch110,test_loss0.024394545704126358\n",
      "epoch120,train_loss0.0015669873682782054\n",
      "epoch120,test_loss0.02450418658554554\n",
      "epoch130,train_loss0.0018593738786876202\n",
      "epoch130,test_loss0.02439887635409832\n",
      "epoch140,train_loss0.0012040530564263463\n",
      "epoch140,test_loss0.02396467700600624\n",
      "epoch150,train_loss0.00115213415119797\n",
      "epoch150,test_loss0.021466325968503952\n",
      "epoch160,train_loss0.0012069344520568848\n",
      "epoch160,test_loss0.02230496145784855\n",
      "epoch170,train_loss0.0011872772593051195\n",
      "epoch170,test_loss0.02385382167994976\n",
      "epoch180,train_loss0.0012108518276363611\n",
      "epoch180,test_loss0.02269694209098816\n",
      "epoch190,train_loss0.0013864280190318823\n",
      "epoch190,test_loss0.02288641221821308\n",
      "epoch200,train_loss0.0014128634938970208\n",
      "epoch200,test_loss0.0215885192155838\n",
      "epoch210,train_loss0.001362539129331708\n",
      "epoch210,test_loss0.022859349846839905\n",
      "epoch220,train_loss0.0014531876659020782\n",
      "epoch220,test_loss0.021710459142923355\n",
      "epoch230,train_loss0.0008328333497047424\n",
      "epoch230,test_loss0.023136574774980545\n",
      "epoch240,train_loss0.0011186448391526937\n",
      "epoch240,test_loss0.02089216746389866\n",
      "epoch250,train_loss0.0008955872035585344\n",
      "epoch250,test_loss0.021267028525471687\n",
      "epoch260,train_loss0.0006072241230867803\n",
      "epoch260,test_loss0.02259741723537445\n",
      "epoch270,train_loss0.0015538409352302551\n",
      "epoch270,test_loss0.020872876048088074\n",
      "epoch280,train_loss0.0006453783717006445\n",
      "epoch280,test_loss0.02153131738305092\n",
      "epoch290,train_loss0.0008426632848568261\n",
      "epoch290,test_loss0.02298031933605671\n",
      "epoch300,train_loss0.0006991383270360529\n",
      "epoch300,test_loss0.02225176990032196\n",
      "epoch310,train_loss0.0010385484201833606\n",
      "epoch310,test_loss0.021120557561516762\n",
      "epoch320,train_loss0.0011787962866947055\n",
      "epoch320,test_loss0.021423768252134323\n",
      "epoch330,train_loss0.0007882476202212274\n",
      "epoch330,test_loss0.021214071661233902\n",
      "epoch340,train_loss0.0011319851037114859\n",
      "epoch340,test_loss0.022622080519795418\n",
      "epoch350,train_loss0.0012358371168375015\n",
      "epoch350,test_loss0.02258186787366867\n",
      "epoch360,train_loss0.0009132224950008094\n",
      "epoch360,test_loss0.022911466658115387\n",
      "epoch370,train_loss0.0007650333573110402\n",
      "epoch370,test_loss0.02231118455529213\n",
      "epoch380,train_loss0.0008758115000091493\n",
      "epoch380,test_loss0.021910768002271652\n",
      "epoch390,train_loss0.0008293853607028723\n",
      "epoch390,test_loss0.022762615233659744\n",
      "epoch400,train_loss0.0007189004099927843\n",
      "epoch400,test_loss0.02206658385694027\n",
      "epoch410,train_loss0.000892653944902122\n",
      "epoch410,test_loss0.021867971867322922\n",
      "epoch420,train_loss0.0008972564246505499\n",
      "epoch420,test_loss0.02147332765161991\n",
      "epoch430,train_loss0.0011552231153473258\n",
      "epoch430,test_loss0.021753361448645592\n",
      "epoch440,train_loss0.0007291359361261129\n",
      "epoch440,test_loss0.022588718682527542\n",
      "epoch450,train_loss0.0011030033929273486\n",
      "epoch450,test_loss0.02200685627758503\n",
      "epoch460,train_loss0.0007575168856419623\n",
      "epoch460,test_loss0.02185220457613468\n",
      "epoch470,train_loss0.00048512316425330937\n",
      "epoch470,test_loss0.022575797513127327\n",
      "epoch480,train_loss0.0011128654005005956\n",
      "epoch480,test_loss0.021524515002965927\n",
      "epoch490,train_loss0.000621340936049819\n",
      "epoch490,test_loss0.021745290607213974\n",
      "epoch500,train_loss0.0008203749312087893\n",
      "epoch500,test_loss0.021577730774879456\n",
      "epoch510,train_loss0.0006063211476430297\n",
      "epoch510,test_loss0.022004088386893272\n",
      "epoch520,train_loss0.0009745234856382012\n",
      "epoch520,test_loss0.020838946104049683\n",
      "epoch530,train_loss0.0004650130867958069\n",
      "epoch530,test_loss0.021665066480636597\n",
      "epoch540,train_loss0.0006256920751184225\n",
      "epoch540,test_loss0.02305544912815094\n",
      "epoch550,train_loss0.0010203110286965966\n",
      "epoch550,test_loss0.021451307460665703\n",
      "epoch560,train_loss0.0011827434645965695\n",
      "epoch560,test_loss0.02253507636487484\n",
      "epoch570,train_loss0.00082060118438676\n",
      "epoch570,test_loss0.022892026230692863\n",
      "epoch580,train_loss0.0005825514090247452\n",
      "epoch580,test_loss0.020833780989050865\n",
      "epoch590,train_loss0.0005463034030981362\n",
      "epoch590,test_loss0.021898329257965088\n",
      "epoch600,train_loss0.00046235942863859236\n",
      "epoch600,test_loss0.022087162360548973\n",
      "epoch610,train_loss0.0010827892692759633\n",
      "epoch610,test_loss0.022396298125386238\n",
      "epoch620,train_loss0.0005758776096627116\n",
      "epoch620,test_loss0.022489577531814575\n",
      "epoch630,train_loss0.0007025377708487213\n",
      "epoch630,test_loss0.021056056022644043\n",
      "epoch640,train_loss0.0005795501638203859\n",
      "epoch640,test_loss0.021369414404034615\n",
      "epoch650,train_loss0.0009939157171174884\n",
      "epoch650,test_loss0.021995622664690018\n",
      "epoch660,train_loss0.0012487961212173104\n",
      "epoch660,test_loss0.02157469280064106\n",
      "epoch670,train_loss0.0007542669773101807\n",
      "epoch670,test_loss0.02225354127585888\n",
      "epoch680,train_loss0.00038373717688955367\n",
      "epoch680,test_loss0.021567514166235924\n",
      "epoch690,train_loss0.0005895023932680488\n",
      "epoch690,test_loss0.021804265677928925\n",
      "epoch700,train_loss0.001052322331815958\n",
      "epoch700,test_loss0.0205901600420475\n",
      "epoch710,train_loss0.0006468405481427908\n",
      "epoch710,test_loss0.023372037336230278\n",
      "epoch720,train_loss0.0004637330712284893\n",
      "epoch720,test_loss0.021699944511055946\n",
      "epoch730,train_loss0.0004155330534558743\n",
      "epoch730,test_loss0.02228310890495777\n",
      "epoch740,train_loss0.0005373472231440246\n",
      "epoch740,test_loss0.022093161940574646\n",
      "epoch750,train_loss0.0003930938255507499\n",
      "epoch750,test_loss0.02210928313434124\n",
      "epoch760,train_loss0.000621265557128936\n",
      "epoch760,test_loss0.0215731393545866\n",
      "epoch770,train_loss0.00039803580148145556\n",
      "epoch770,test_loss0.020624930039048195\n",
      "epoch780,train_loss0.0007764211622998118\n",
      "epoch780,test_loss0.02196219563484192\n",
      "epoch790,train_loss0.0005064157303422689\n",
      "epoch790,test_loss0.02175469696521759\n",
      "epoch800,train_loss0.0004988743457943201\n",
      "epoch800,test_loss0.022105813026428223\n",
      "epoch810,train_loss0.00048138725105673075\n",
      "epoch810,test_loss0.02175181172788143\n",
      "epoch820,train_loss0.000430698913987726\n",
      "epoch820,test_loss0.02176283299922943\n",
      "epoch830,train_loss0.00032917733187787235\n",
      "epoch830,test_loss0.021909495815634727\n",
      "epoch840,train_loss0.0004957975470460951\n",
      "epoch840,test_loss0.022222207859158516\n",
      "epoch850,train_loss0.0007567873108200729\n",
      "epoch850,test_loss0.02242305688560009\n",
      "epoch860,train_loss0.0007597763324156404\n",
      "epoch860,test_loss0.021905148401856422\n",
      "epoch870,train_loss0.0003315054054837674\n",
      "epoch870,test_loss0.02160991169512272\n",
      "epoch880,train_loss0.0005494633805938065\n",
      "epoch880,test_loss0.022490764036774635\n",
      "epoch890,train_loss0.000667885469738394\n",
      "epoch890,test_loss0.021232832223176956\n",
      "epoch900,train_loss0.0004959609359502792\n",
      "epoch900,test_loss0.021485093981027603\n",
      "epoch910,train_loss0.00046279761590994895\n",
      "epoch910,test_loss0.021794039756059647\n",
      "epoch920,train_loss0.00047635752707719803\n",
      "epoch920,test_loss0.02217671275138855\n",
      "epoch930,train_loss0.000887425325345248\n",
      "epoch930,test_loss0.021189944818615913\n",
      "epoch940,train_loss0.0007275028619915247\n",
      "epoch940,test_loss0.02119164727628231\n",
      "epoch950,train_loss0.0006153960130177438\n",
      "epoch950,test_loss0.02112913690507412\n",
      "epoch960,train_loss0.0006335924263112247\n",
      "epoch960,test_loss0.0221260879188776\n",
      "epoch970,train_loss0.0003020385338459164\n",
      "epoch970,test_loss0.021528422832489014\n",
      "epoch980,train_loss0.0007195656071417034\n",
      "epoch980,test_loss0.02167503535747528\n",
      "epoch990,train_loss0.0005431290483102202\n",
      "epoch990,test_loss0.021238351240754128\n",
      "epoch1000,train_loss0.0003451090888120234\n",
      "epoch1000,test_loss0.021805573254823685\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "\n",
    "\n",
    "start_time_NN =time.time()\n",
    "\n",
    "train_losses = []\n",
    "\n",
    "test_losses = []\n",
    "\n",
    "num_epochs = 1000\n",
    "train_interval = 10\n",
    "test_interval = 10\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    net.train()\n",
    "    for X,y in data_iter:\n",
    "        prediction = net(X)\n",
    "        loss = loss_func(prediction,y.view(-1,1))\n",
    "    \n",
    "    # reset gradient, equal to net.zero_grad()\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward() \n",
    "        optimizer.step()\n",
    "        \n",
    "        \n",
    "\n",
    "    if((epoch+1)%train_interval==0):\n",
    "        print(\"epoch{},train_loss{}\".format(epoch+1,loss.data))\n",
    "        train_losses.append(loss.item())\n",
    "   \n",
    "\n",
    "      \n",
    "    net.eval()\n",
    "    with torch.no_grad():\n",
    "        \n",
    "        for X_test, y_test in data_iter_test:\n",
    "            \n",
    "            prediction1 = net(X_test)\n",
    "            loss1 = loss_func(prediction1, y_test.view(-1,1))\n",
    "            \n",
    "    if ((epoch+1) % test_interval == 0):       \n",
    "        print(\"epoch{},test_loss{}\".format(epoch+1,loss1.data))\n",
    "        #test_loss += float(loss1.item())\n",
    "        test_losses.append(loss1.item())\n",
    "        \n",
    "trainingtime.loc[1] = [\"Simple Neural Network\", round((time.time()-start_time_NN), 2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = range(len(train_losses))\n",
    "train_y = train_losses\n",
    "\n",
    "train_iters = len(data_iter)\n",
    "#test_x = np.arange(1, len(test_losses)+1) * train_iters*test_interval \n",
    "test_x = range(len(test_losses))\n",
    "test_y = test_losses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8,8))\n",
    "plt.plot(train_x, train_y, label='Train')\n",
    "plt.plot(test_x, test_y, label='Test')\n",
    "plt.legend(loc='lower right')\n",
    "plt.ylabel('loss value')\n",
    "plt.xlabel('Iteration')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3142,)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_tensor = net(torch.tensor(x_test.astype(np.float32)))\n",
    "# len(y_pred)\n",
    "y_pred_array = y_pred_tensor.detach().numpy()\n",
    "y_pred_a = np.concatenate((y_pred_array), axis=None)\n",
    "y_pred_a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.52066891, 0.51865713, 0.40080865, 0.38154487])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score2 = evaluate_lists(y_pred_a, test_intensities)\n",
    "score2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'files/final_models/simpleNN_whole.pkl.tar'"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_neural_network_path = \"files/final_models/\" + \"simpleNN_\"+ emotion + \".pkl.tar\"\n",
    "simple_neural_network_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.save(net, simple_neural_network_path) \n",
    "torch.save({'state_dict': net.state_dict()}, simple_neural_network_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Compare the Performance and Training Time Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Training Time(Seconds)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>6060.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Simple Neural Network</td>\n",
       "      <td>8300.87</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Model  Training Time(Seconds)\n",
       "0                XGBoost                 6060.36\n",
       "1  Simple Neural Network                 8300.87"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainingtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingtime.to_csv(\"training_time_\"+emotion+\".csv\",mode='w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pears-corr</th>\n",
       "      <th>spear-corr</th>\n",
       "      <th>pears-corr-range-05-1</th>\n",
       "      <th>spear-corr-range-05-1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>xgboost</th>\n",
       "      <td>0.416351</td>\n",
       "      <td>0.399586</td>\n",
       "      <td>0.306188</td>\n",
       "      <td>0.269775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>simpleNN</th>\n",
       "      <td>0.520669</td>\n",
       "      <td>0.518657</td>\n",
       "      <td>0.400809</td>\n",
       "      <td>0.381545</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          pears-corr  spear-corr  pears-corr-range-05-1  spear-corr-range-05-1\n",
       "xgboost     0.416351    0.399586               0.306188               0.269775\n",
       "simpleNN    0.520669    0.518657               0.400809               0.381545"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_score = pd.DataFrame(data = [score1,score2], columns = ['pears-corr','spear-corr','pears-corr-range-05-1','spear-corr-range-05-1'],\\\n",
    "             index = ['xgboost','simpleNN'])\n",
    "all_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_score.to_csv('score_'+emotion+'.csv',mode='w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
