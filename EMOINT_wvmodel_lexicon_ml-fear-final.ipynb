{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (1) Reading the Training, the Development and the Testing Datasets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from os import listdir\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['anger-ratings-0to1.train.txt',\n",
       " 'fear-ratings-0to1.train.txt',\n",
       " 'joy-ratings-0to1.train.txt',\n",
       " 'sadness-ratings-0to1.train.txt']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "directory1 = 'data/train'\n",
    "paths1 = listdir(directory1)\n",
    "paths1.sort()\n",
    "paths1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define the path of training dataset\n",
    "path1 = paths1[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'fear'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If you want to restore x_train vectors, y_train_vectors, x_test_vectors, y_test_vectors: you can change the 'emotion' here \n",
    "# and then restore those vectors\n",
    "\n",
    "emotion = path1.split(\"-\")[0]\n",
    "emotion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20000</td>\n",
       "      <td>I feel like I am drowning. #depression #anxiet...</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20001</td>\n",
       "      <td>I get so nervous even thinking about talking t...</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20002</td>\n",
       "      <td>I lost my blinders .... #panic</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20003</td>\n",
       "      <td>I feel like I am drowning. #depression  #falur...</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20004</td>\n",
       "      <td>This is the scariest American Horror Story out...</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.938</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0                                                  1     2      3\n",
       "0  20000  I feel like I am drowning. #depression #anxiet...  fear  0.979\n",
       "1  20001  I get so nervous even thinking about talking t...  fear  0.979\n",
       "2  20002                     I lost my blinders .... #panic  fear  0.975\n",
       "3  20003  I feel like I am drowning. #depression  #falur...  fear  0.938\n",
       "4  20004  This is the scariest American Horror Story out...  fear  0.938"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('%s/%s' %(directory1,path1), delimiter='\\t',header=None)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SentID</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Emotion</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20000</td>\n",
       "      <td>I feel like I am drowning. #depression #anxiet...</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20001</td>\n",
       "      <td>I get so nervous even thinking about talking t...</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20002</td>\n",
       "      <td>I lost my blinders .... #panic</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20003</td>\n",
       "      <td>I feel like I am drowning. #depression  #falur...</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20004</td>\n",
       "      <td>This is the scariest American Horror Story out...</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>20005</td>\n",
       "      <td>@mgcsartwork I nearly started crying and havin...</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>20006</td>\n",
       "      <td>I have to finally tell my therapist about my s...</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>20007</td>\n",
       "      <td>@laura221b I don't think I've ever moved so fa...</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>20008</td>\n",
       "      <td>My bus was in a car crash... I'm still shaking...</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>20009</td>\n",
       "      <td>My bus was in a car crash... I'm still shaking...</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.920</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SentID                                              Tweet Emotion  Rating\n",
       "0   20000  I feel like I am drowning. #depression #anxiet...    fear   0.979\n",
       "1   20001  I get so nervous even thinking about talking t...    fear   0.979\n",
       "2   20002                     I lost my blinders .... #panic    fear   0.975\n",
       "3   20003  I feel like I am drowning. #depression  #falur...    fear   0.938\n",
       "4   20004  This is the scariest American Horror Story out...    fear   0.938\n",
       "5   20005  @mgcsartwork I nearly started crying and havin...    fear   0.938\n",
       "6   20006  I have to finally tell my therapist about my s...    fear   0.938\n",
       "7   20007  @laura221b I don't think I've ever moved so fa...    fear   0.938\n",
       "8   20008  My bus was in a car crash... I'm still shaking...    fear   0.938\n",
       "9   20009  My bus was in a car crash... I'm still shaking...    fear   0.920"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns = ['SentID', 'Tweet', 'Emotion', 'Rating']\n",
    "train[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if there are any duplicates(subset = all of the columns)\n",
    "\n",
    "assert train.duplicated().sum() == 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1147 entries, 0 to 1146\n",
      "Data columns (total 4 columns):\n",
      " #   Column   Non-Null Count  Dtype  \n",
      "---  ------   --------------  -----  \n",
      " 0   SentID   1147 non-null   int64  \n",
      " 1   Tweet    1147 non-null   object \n",
      " 2   Emotion  1147 non-null   object \n",
      " 3   Rating   1147 non-null   float64\n",
      "dtypes: float64(1), int64(1), object(2)\n",
      "memory usage: 36.0+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# checking missing data & len(train),len(test)\n",
    "print(train.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             SentID       Rating\n",
      "count   1147.000000  1147.000000\n",
      "mean   20573.000000     0.495579\n",
      "std      331.254686     0.194792\n",
      "min    20000.000000     0.062000\n",
      "25%    20286.500000     0.354000\n",
      "50%    20573.000000     0.479000\n",
      "75%    20859.500000     0.625000\n",
      "max    21146.000000     0.979000\n"
     ]
    }
   ],
   "source": [
    "print(train.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['anger-ratings-0to1.dev.gold.txt',\n",
       " 'fear-ratings-0to1.dev.gold.txt',\n",
       " 'joy-ratings-0to1.dev.gold.txt',\n",
       " 'sadness-ratings-0to1.dev.gold.txt']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "directory2 = 'data/dev'\n",
    "paths2 = listdir(directory2)\n",
    "paths2.sort()\n",
    "paths2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define the path of training dataset\n",
    "path2 = emotion + \"-ratings-0to1.dev.gold.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SentID</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Emotion</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>21147</td>\n",
       "      <td>I know this is going to be one of those nights...</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21148</td>\n",
       "      <td>This is #horrible: Lewis Dunk has begun networ...</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21149</td>\n",
       "      <td>@JeffersonLake speaking of ex cobblers, saw Ri...</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21150</td>\n",
       "      <td>@1johndes ball watching &amp;amp; Rojo'd header wa...</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>21151</td>\n",
       "      <td>Really.....#Jumanji 2....w/ The Rock, Jack Bla...</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>21152</td>\n",
       "      <td>Really.....#Jumanji 2....w/ The Rock, Jack Bla...</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>21153</td>\n",
       "      <td>Losing to Villa...'@M0tivati0nQuote: Most of t...</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>21154</td>\n",
       "      <td>Are you worrying/worried?\\n1Peter 5:7\\nThrow a...</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>21155</td>\n",
       "      <td>If my concerns &amp;amp; anxiety don't matter to y...</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>21156</td>\n",
       "      <td>There goes the butterflies in my stomach. #ner...</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.812</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SentID                                              Tweet Emotion  Rating\n",
       "0   21147  I know this is going to be one of those nights...    fear   0.771\n",
       "1   21148  This is #horrible: Lewis Dunk has begun networ...    fear   0.479\n",
       "2   21149  @JeffersonLake speaking of ex cobblers, saw Ri...    fear   0.417\n",
       "3   21150  @1johndes ball watching &amp; Rojo'd header wa...    fear   0.475\n",
       "4   21151  Really.....#Jumanji 2....w/ The Rock, Jack Bla...    fear   0.542\n",
       "5   21152  Really.....#Jumanji 2....w/ The Rock, Jack Bla...    fear   0.542\n",
       "6   21153  Losing to Villa...'@M0tivati0nQuote: Most of t...    fear   0.311\n",
       "7   21154  Are you worrying/worried?\\n1Peter 5:7\\nThrow a...    fear   0.438\n",
       "8   21155  If my concerns &amp; anxiety don't matter to y...    fear   0.729\n",
       "9   21156  There goes the butterflies in my stomach. #ner...    fear   0.812"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev = pd.read_csv('%s/%s' %(directory2,path2), delimiter='\\t',header=None)\n",
    "dev.columns = train.columns\n",
    "dev[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if there are any duplicates(subset = all of the columns)\n",
    "\n",
    "assert dev.duplicated().sum() == 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 110 entries, 0 to 109\n",
      "Data columns (total 4 columns):\n",
      " #   Column   Non-Null Count  Dtype  \n",
      "---  ------   --------------  -----  \n",
      " 0   SentID   110 non-null    int64  \n",
      " 1   Tweet    110 non-null    object \n",
      " 2   Emotion  110 non-null    object \n",
      " 3   Rating   110 non-null    float64\n",
      "dtypes: float64(1), int64(1), object(2)\n",
      "memory usage: 3.6+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# checking missing data & len(train),len(test)\n",
    "print(dev.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             SentID      Rating\n",
      "count    110.000000  110.000000\n",
      "mean   21201.500000    0.489309\n",
      "std       31.898276    0.185675\n",
      "min    21147.000000    0.060000\n",
      "25%    21174.250000    0.354000\n",
      "50%    21201.500000    0.466500\n",
      "75%    21228.750000    0.632500\n",
      "max    21256.000000    0.896000\n"
     ]
    }
   ],
   "source": [
    "print(dev.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['anger-ratings-0to1.test.gold.txt',\n",
       " 'fear-ratings-0to1.test.gold.txt',\n",
       " 'joy-ratings-0to1.test.gold.txt',\n",
       " 'sadness-ratings-0to1.test.gold.txt']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "directory3 = 'data/test'\n",
    "paths3 = listdir(directory3)\n",
    "paths3.sort()\n",
    "paths3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define the path of training dataset\n",
    "path3 = emotion + \"-ratings-0to1.test.gold.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SentID</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Emotion</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>21257</td>\n",
       "      <td>#Matthew 25; 1-13\\nCould somebody shoot a #vid...</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21258</td>\n",
       "      <td>@bkero @whispersystems Which really sucks beca...</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21259</td>\n",
       "      <td>Be #afraid of the #quiet ones they are the one...</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21260</td>\n",
       "      <td>@riinkanei he's a horrible person and now i ga...</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>21261</td>\n",
       "      <td>What we fear doing most is usually what we mos...</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>21262</td>\n",
       "      <td>What we fear doing most is usually what we mos...</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>21263</td>\n",
       "      <td>a pedicure is supposed to be nice but honestly...</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>21264</td>\n",
       "      <td>US you need to band together not apart #nevert...</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>21265</td>\n",
       "      <td>US you need to band together not apart #nevert...</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>21266</td>\n",
       "      <td>What a shamefull, unequal, dangerous and worry...</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.825</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SentID                                              Tweet Emotion  Rating\n",
       "0   21257  #Matthew 25; 1-13\\nCould somebody shoot a #vid...    fear   0.417\n",
       "1   21258  @bkero @whispersystems Which really sucks beca...    fear   0.438\n",
       "2   21259  Be #afraid of the #quiet ones they are the one...    fear   0.542\n",
       "3   21260  @riinkanei he's a horrible person and now i ga...    fear   0.583\n",
       "4   21261  What we fear doing most is usually what we mos...    fear   0.292\n",
       "5   21262  What we fear doing most is usually what we mos...    fear   0.188\n",
       "6   21263  a pedicure is supposed to be nice but honestly...    fear   0.604\n",
       "7   21264  US you need to band together not apart #nevert...    fear   0.729\n",
       "8   21265  US you need to band together not apart #nevert...    fear   0.625\n",
       "9   21266  What a shamefull, unequal, dangerous and worry...    fear   0.825"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv('%s/%s' %(directory3,path3), delimiter='\\t',header=None)\n",
    "test.columns = train.columns\n",
    "\n",
    "test[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if there are any duplicates(subset = all of the columns)\n",
    "\n",
    "assert test.duplicated().sum() == 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 995 entries, 0 to 994\n",
      "Data columns (total 4 columns):\n",
      " #   Column   Non-Null Count  Dtype  \n",
      "---  ------   --------------  -----  \n",
      " 0   SentID   995 non-null    int64  \n",
      " 1   Tweet    995 non-null    object \n",
      " 2   Emotion  995 non-null    object \n",
      " 3   Rating   995 non-null    float64\n",
      "dtypes: float64(1), int64(1), object(2)\n",
      "memory usage: 31.2+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# checking missing data & len(train),len(test)\n",
    "print(test.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            SentID     Rating\n",
      "count    995.00000  995.00000\n",
      "mean   21754.00000    0.50247\n",
      "std      287.37606    0.20094\n",
      "min    21257.00000    0.06200\n",
      "25%    21505.50000    0.35400\n",
      "50%    21754.00000    0.50000\n",
      "75%    22002.50000    0.64600\n",
      "max    22251.00000    1.00000\n"
     ]
    }
   ],
   "source": [
    "print(test.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SentID</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Emotion</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20000</td>\n",
       "      <td>I feel like I am drowning. #depression #anxiet...</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20001</td>\n",
       "      <td>I get so nervous even thinking about talking t...</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20002</td>\n",
       "      <td>I lost my blinders .... #panic</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20003</td>\n",
       "      <td>I feel like I am drowning. #depression  #falur...</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20004</td>\n",
       "      <td>This is the scariest American Horror Story out...</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1252</th>\n",
       "      <td>21252</td>\n",
       "      <td>Staff on @ryainair FR1005. Asked for info and ...</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1253</th>\n",
       "      <td>21253</td>\n",
       "      <td>Staff on @ryainair FR1005. Asked for info and ...</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1254</th>\n",
       "      <td>21254</td>\n",
       "      <td>An adviser to the #European #Unionâ€™s top #cour...</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1255</th>\n",
       "      <td>21255</td>\n",
       "      <td>So about 18mths ago i signed up to @Lumo_Energ...</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1256</th>\n",
       "      <td>21256</td>\n",
       "      <td>So about 18mths ago i signed up to @Lumo_Energ...</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.271</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1257 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      SentID                                              Tweet Emotion  \\\n",
       "0      20000  I feel like I am drowning. #depression #anxiet...    fear   \n",
       "1      20001  I get so nervous even thinking about talking t...    fear   \n",
       "2      20002                     I lost my blinders .... #panic    fear   \n",
       "3      20003  I feel like I am drowning. #depression  #falur...    fear   \n",
       "4      20004  This is the scariest American Horror Story out...    fear   \n",
       "...      ...                                                ...     ...   \n",
       "1252   21252  Staff on @ryainair FR1005. Asked for info and ...    fear   \n",
       "1253   21253  Staff on @ryainair FR1005. Asked for info and ...    fear   \n",
       "1254   21254  An adviser to the #European #Unionâ€™s top #cour...    fear   \n",
       "1255   21255  So about 18mths ago i signed up to @Lumo_Energ...    fear   \n",
       "1256   21256  So about 18mths ago i signed up to @Lumo_Energ...    fear   \n",
       "\n",
       "      Rating  \n",
       "0      0.979  \n",
       "1      0.979  \n",
       "2      0.975  \n",
       "3      0.938  \n",
       "4      0.938  \n",
       "...      ...  \n",
       "1252   0.312  \n",
       "1253   0.271  \n",
       "1254   0.500  \n",
       "1255   0.479  \n",
       "1256   0.271  \n",
       "\n",
       "[1257 rows x 4 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# plan to train models on the combined training and development sets\n",
    "train = pd.concat([train, dev],axis=0,ignore_index=True)\n",
    "train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (2) Define Text Data Cleaning Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import re\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import bigrams\n",
    "\n",
    "import wordsegment as ws # $ pip install wordsegment    \n",
    "ws.load()     \n",
    "\n",
    "import emoji  # $ pip install emoji\n",
    "\n",
    "# As the glove model contains many words made with grammatical role, tense ,or derivational morphology,\n",
    "# we do not need WordNetLemmatizer or SnowballStemmer here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_text(text):\n",
    "    \n",
    "    # replace emoji to word\n",
    "    # text = emoji.demojize(text)\n",
    "    \n",
    "    # remove characters outside the ascii code 128\n",
    "    # text = ''.join([w if ord(w)<128 else ' ' for w in text])\n",
    "    \n",
    "    # replace '--' with a space\n",
    "    text = text.replace('--',' ')\n",
    "    \n",
    "    # remove any newline characters\n",
    "    text = text.replace('\\n',' ')\n",
    "    \n",
    "    # tweets mentions user using '@' followed by username. Replace all those with <user> to be usable for Glove\n",
    "    text = re.sub('@[^ ]+','<user>',text)\n",
    "    \n",
    "    # Replace all URLs with <url> to be usable for Glove\n",
    "    text = re.sub(r'\\d+','<number>',text)\n",
    "   \n",
    "    # Replace all numbers with <number> to be usable for Glove\n",
    "    text = re.sub(r'http\\S+','<url>',text)\n",
    "    \n",
    "    # turn some abbreviations into a whold word\n",
    "    text = re.sub(r\"\\'s\", \"\", text)\n",
    "    text = re.sub(r\"\\'m\", \" am\", text)\n",
    "    text = re.sub(r\"\\'ve\", \" have\", text)\n",
    "    text = re.sub(r\"can\\'t\", \"can not\", text)\n",
    "    text = re.sub(r\"won\\'t\", \"will not\", text)\n",
    "    text = re.sub(r\"n\\'t\", \" not\", text)\n",
    "    text = re.sub(r\"\\'re\", \" are\", text)\n",
    "    text = re.sub(r\"\\'d\", \" would\", text)\n",
    "    text = re.sub(r\"\\'ll\", \" will\", text)\n",
    "    text = re.sub(r\"fu\\*k\", \" fuck\", text)\n",
    "    text = re.sub(r\"f\\*c+\", \"fuck\", text)\n",
    "    text = text.replace(\"wtf\", \"what the fuck\")\n",
    "    \n",
    "    # prepare spaces between punctuation and words\n",
    "    text1 = text.split('...')\n",
    "    for i in range(len(text1)):\n",
    "        text1[i] = text1[i].replace('/',' / ').replace('\\\\',' \\ ').replace(',',' , ').replace('.',' . ').replace('?',' ? ').replace('!',' ! ').replace(\"'\",\" ' \").replace(':',' : ').replace(';',' ; ').replace('-',' - ').replace('(',' ( ').replace(')',' ) ').replace('[',' [ ').replace(']',' ] ').replace('&',' & ').replace('*',' * ').replace('{',' { ').replace('}',' } ').replace('-',' - ').replace('`',' ` ').replace('\"',' \" ').replace('>','> ').replace('<',' <')\n",
    "    text1 = ' '.join(text1)\n",
    "    \n",
    "    # split into tokens by white space\n",
    "    tokens = text1.split()\n",
    "    \n",
    "    return tokens\n",
    "\n",
    "def clean_text(text):\n",
    "   \n",
    "    tokens = normalize_text(text)\n",
    "    \n",
    "    new_tokens1 = []\n",
    "    for w in tokens:\n",
    "        if w == \"<user>\":\n",
    "            w = w\n",
    "        elif w == \"<url>\":\n",
    "            w = w\n",
    "        elif w == \"<number>\":\n",
    "            w = w\n",
    "        elif w in emoji.UNICODE_EMOJI:\n",
    "            w = w\n",
    "        else:\n",
    "            # prepare regex for char filtering: !\"#$%&'()*+, -./:;<=>?@[\\]^_`{|}~\n",
    "            re_punc = re.compile('[%s]' %re.escape(string.punctuation))\n",
    "            # remove punctuation from each word\n",
    "            w = re_punc.sub('', w)\n",
    "    \n",
    "            # remove remaining tokens that are not alphabetic\n",
    "            if w.isalpha():\n",
    "                w = w\n",
    "        new_tokens1.append(w) \n",
    "        \n",
    "    # filter out stop words\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [w for w in new_tokens1 if not w in stop_words]\n",
    "    \n",
    "    new_tokens2 = []\n",
    "    for w in tokens:\n",
    "        if w == \"<user>\":\n",
    "            w = w\n",
    "        elif w == \"<url>\":\n",
    "            w = w\n",
    "        elif w == \"<number>\":\n",
    "            w = w\n",
    "        elif w in emoji.UNICODE_EMOJI:\n",
    "            w = w\n",
    "        else:\n",
    "            # word segment will convert the hashtag based joined words, for example, it will segment #iamthebest to ['i','am','the','best']\n",
    "            w = ' '.join(ws.segment(w)) \n",
    "        new_tokens2.append(w)\n",
    "        \n",
    "    \n",
    "    # make lower case\n",
    "    tokens = [word.lower() for word in new_tokens2]\n",
    "    \n",
    "    \n",
    "    clean_text = ' '.join(tokens)\n",
    "    tokens = clean_text.split()\n",
    "    \n",
    "    new_tokens3 = []   \n",
    "    # filter out short tokens\n",
    "    for w in tokens:\n",
    "        if w in emoji.UNICODE_EMOJI:\n",
    "            w = w\n",
    "        else:\n",
    "            if len(w) > 1:\n",
    "                w =w\n",
    "        new_tokens3.append(w)\n",
    "    \n",
    "    return ' '.join(new_tokens3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<user> i left dad deal ðŸ˜‚ my work done soon felt wrath slipper ðŸ˜·'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# do a sanity check\n",
    "text = \"@laura221b I've left it for my dad to deal with ðŸ˜‚ My work is done as soon as it's felt the wrath of my slipper ðŸ˜·\"\n",
    "clean_text(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare for clean Hashtag Emotion Intensity Lexicons...\n",
    "\n",
    "def remove_stopwords(string):\n",
    "    split_string = \\\n",
    "        [word for word in string.split()\n",
    "         if word not in stopwords.words('english')]\n",
    "    \n",
    "    return \" \".join(split_string)\n",
    "\n",
    "def clean_str(string):  \n",
    "    string = string.replace(\"\\\\n\", \" \")\n",
    "    string = string.replace(\"_NEG\", \"\")\n",
    "    string = string.replace(\"_NEGFIRST\", \"\")\n",
    "    string = re.sub(r\"@[A-Za-z0-9_s(),!?\\'\\`]+\", \"\", string) # removing any twitter handle mentions\n",
    "\n",
    "    string = re.sub(r\"#\", \"\", string)\n",
    "    string = re.sub(r\"\\*\", \"\", string)\n",
    "    string = re.sub(r\"\\'s\", \"\", string)\n",
    "    string = re.sub(r\"\\'m\", \" am\", string)\n",
    "    string = re.sub(r\"\\'ve\", \" have\", string)\n",
    "    string = re.sub(r\"n\\'t\", \" not\", string)\n",
    "    string = re.sub(r\"\\'re\", \" are\", string)\n",
    "    string = re.sub(r\"\\'d\", \" would\", string)\n",
    "    string = re.sub(r\"\\'ll\", \" will\", string)\n",
    "    string = re.sub(r\",\", \"\", string)\n",
    "    string = re.sub(r\"!\", \" !\", string)\n",
    "    string = re.sub(r\"\\(\", \"\", string)\n",
    "    string = re.sub(r\"\\)\", \"\", string)\n",
    "    string = re.sub(r\"\\?\", \" ?\", string)\n",
    "    string = re.sub(r\"\\s{2,}\", \" \", string)\n",
    "\n",
    "    return remove_stopwords(string.strip().lower())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (3) Clean Text Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Tweet'] = train['Tweet'].apply(clean_text)\n",
    "\n",
    "test['Tweet'] = test['Tweet'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SentID</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Emotion</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20000</td>\n",
       "      <td>i feel like i drowning depression anxiety fa l...</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20001</td>\n",
       "      <td>i get nervous even thinking talking i wanna die</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20002</td>\n",
       "      <td>i lost blinders panic</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20003</td>\n",
       "      <td>i feel like i drowning depression fa lure wort...</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20004</td>\n",
       "      <td>this scariest american horror story i gonna wa...</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>20005</td>\n",
       "      <td>&lt;user&gt; i nearly started crying full panic atta...</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>20006</td>\n",
       "      <td>i finally tell therapist sexuality last fronti...</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>20007</td>\n",
       "      <td>&lt;user&gt; i think i ever moved fast panic life ðŸ˜‚ ...</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>20008</td>\n",
       "      <td>my bus car crash i still shaking bit this week...</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>20009</td>\n",
       "      <td>my bus car crash i still shaking bit this week...</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>20010</td>\n",
       "      <td>proc ra sting fun im hour away time due still ...</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>20011</td>\n",
       "      <td>my anxiety rising tonight i sure sometimes i w...</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>20012</td>\n",
       "      <td>im nervous wreck im nervous pile up going craz...</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>20013</td>\n",
       "      <td>panic panic attack fear starting new medication</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>20014</td>\n",
       "      <td>job interview afternoon nervous ek</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>20015</td>\n",
       "      <td>i beyond mad i lost track brown spider brown c...</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>20016</td>\n",
       "      <td>anxiety level &lt;number&gt;</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>20017</td>\n",
       "      <td>wah woke frm fucking nightmare</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>20018</td>\n",
       "      <td>i get much pussy np panic attacks nu uncontrol...</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20019</td>\n",
       "      <td>cosplaying properly first time saturday pretty...</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20020</td>\n",
       "      <td>&lt;user&gt; i surrounded trump voters you right fuc...</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>20021</td>\n",
       "      <td>ignored broken tooth long abscess need dentist...</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>20022</td>\n",
       "      <td>&lt;user&gt; we much trouble i think rev see funny s...</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>20023</td>\n",
       "      <td>im crying katherine one whos like talking anxi...</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>20024</td>\n",
       "      <td>ever really lonely phone keeps blowing cant pi...</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>20025</td>\n",
       "      <td>super shitting tattoo nervous</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>20026</td>\n",
       "      <td>breaking hives first time since college finals...</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>20027</td>\n",
       "      <td>&lt;user&gt; &lt;user&gt; ni get sick stomach every time i...</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>20028</td>\n",
       "      <td>i beyond mad i lost track brown spider brown c...</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>20029</td>\n",
       "      <td>&lt;number&gt; &lt;number&gt; minutes perform i nervous i ...</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>20030</td>\n",
       "      <td>i hate people say i need talk need talk my anx...</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>20031</td>\n",
       "      <td>he replied comments &lt;number&gt; times shaking omg</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>20032</td>\n",
       "      <td>being stuck roof house provides amazing view s...</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>20033</td>\n",
       "      <td>just want saturday i want good lsat nervous</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>20034</td>\n",
       "      <td>im nervous wreck im pile up going crazy help m...</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>20035</td>\n",
       "      <td>i literally shaking getting ekg done lol ðŸ™„</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>20036</td>\n",
       "      <td>&lt;user&gt; thanks ryan amp brad scary shit us firs...</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>20037</td>\n",
       "      <td>&lt;user&gt; operation echoes gathering momentum ten...</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>20038</td>\n",
       "      <td>weird wednesday okay that jump scared poop rig...</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>20039</td>\n",
       "      <td>&lt;user&gt; i fear future mankind</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>20040</td>\n",
       "      <td>first day college feeling nervous</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>20041</td>\n",
       "      <td>might hysteria kno anxiety need diagnosis cuz ...</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>20042</td>\n",
       "      <td>&lt;user&gt; made cry shake point parents calm give ...</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>20043</td>\n",
       "      <td>gonna get acupuncture today damn anxiety</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>20044</td>\n",
       "      <td>anthony weiner distraction really going select...</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>20045</td>\n",
       "      <td>&lt;user&gt; would great card crashes ðŸ˜± it happened ...</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>20046</td>\n",
       "      <td>&lt;user&gt; im feeling worry</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>20047</td>\n",
       "      <td>that feeling get know information scared might...</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>20048</td>\n",
       "      <td>hard time falling sleep woke several times afr...</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>20049</td>\n",
       "      <td>white americans worried arab terrorists black ...</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>20050</td>\n",
       "      <td>today horrible half day</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>20051</td>\n",
       "      <td>obama legacy weekly riots terror attacks gt &lt;n...</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>20052</td>\n",
       "      <td>bad news fam life still hard awful depression ...</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>20053</td>\n",
       "      <td>&lt;user&gt; fucking hell mate absolute nightmare ðŸ˜“</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>20054</td>\n",
       "      <td>&lt;user&gt; i surrounded trump voters you right fuc...</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.854</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    SentID                                              Tweet Emotion  Rating\n",
       "0    20000  i feel like i drowning depression anxiety fa l...    fear   0.979\n",
       "1    20001    i get nervous even thinking talking i wanna die    fear   0.979\n",
       "2    20002                              i lost blinders panic    fear   0.975\n",
       "3    20003  i feel like i drowning depression fa lure wort...    fear   0.938\n",
       "4    20004  this scariest american horror story i gonna wa...    fear   0.938\n",
       "5    20005  <user> i nearly started crying full panic atta...    fear   0.938\n",
       "6    20006  i finally tell therapist sexuality last fronti...    fear   0.938\n",
       "7    20007  <user> i think i ever moved fast panic life ðŸ˜‚ ...    fear   0.938\n",
       "8    20008  my bus car crash i still shaking bit this week...    fear   0.938\n",
       "9    20009  my bus car crash i still shaking bit this week...    fear   0.920\n",
       "10   20010  proc ra sting fun im hour away time due still ...    fear   0.920\n",
       "11   20011  my anxiety rising tonight i sure sometimes i w...    fear   0.917\n",
       "12   20012  im nervous wreck im nervous pile up going craz...    fear   0.917\n",
       "13   20013    panic panic attack fear starting new medication    fear   0.917\n",
       "14   20014                 job interview afternoon nervous ek    fear   0.917\n",
       "15   20015  i beyond mad i lost track brown spider brown c...    fear   0.917\n",
       "16   20016                             anxiety level <number>    fear   0.905\n",
       "17   20017                     wah woke frm fucking nightmare    fear   0.898\n",
       "18   20018  i get much pussy np panic attacks nu uncontrol...    fear   0.896\n",
       "19   20019  cosplaying properly first time saturday pretty...    fear   0.896\n",
       "20   20020  <user> i surrounded trump voters you right fuc...    fear   0.896\n",
       "21   20021  ignored broken tooth long abscess need dentist...    fear   0.896\n",
       "22   20022  <user> we much trouble i think rev see funny s...    fear   0.896\n",
       "23   20023  im crying katherine one whos like talking anxi...    fear   0.896\n",
       "24   20024  ever really lonely phone keeps blowing cant pi...    fear   0.893\n",
       "25   20025                      super shitting tattoo nervous    fear   0.880\n",
       "26   20026  breaking hives first time since college finals...    fear   0.880\n",
       "27   20027  <user> <user> ni get sick stomach every time i...    fear   0.875\n",
       "28   20028  i beyond mad i lost track brown spider brown c...    fear   0.875\n",
       "29   20029  <number> <number> minutes perform i nervous i ...    fear   0.875\n",
       "30   20030  i hate people say i need talk need talk my anx...    fear   0.875\n",
       "31   20031     he replied comments <number> times shaking omg    fear   0.875\n",
       "32   20032  being stuck roof house provides amazing view s...    fear   0.875\n",
       "33   20033        just want saturday i want good lsat nervous    fear   0.875\n",
       "34   20034  im nervous wreck im pile up going crazy help m...    fear   0.875\n",
       "35   20035         i literally shaking getting ekg done lol ðŸ™„    fear   0.875\n",
       "36   20036  <user> thanks ryan amp brad scary shit us firs...    fear   0.875\n",
       "37   20037  <user> operation echoes gathering momentum ten...    fear   0.875\n",
       "38   20038  weird wednesday okay that jump scared poop rig...    fear   0.875\n",
       "39   20039                       <user> i fear future mankind    fear   0.870\n",
       "40   20040                  first day college feeling nervous    fear   0.865\n",
       "41   20041  might hysteria kno anxiety need diagnosis cuz ...    fear   0.860\n",
       "42   20042  <user> made cry shake point parents calm give ...    fear   0.860\n",
       "43   20043           gonna get acupuncture today damn anxiety    fear   0.854\n",
       "44   20044  anthony weiner distraction really going select...    fear   0.854\n",
       "45   20045  <user> would great card crashes ðŸ˜± it happened ...    fear   0.854\n",
       "46   20046                            <user> im feeling worry    fear   0.854\n",
       "47   20047  that feeling get know information scared might...    fear   0.854\n",
       "48   20048  hard time falling sleep woke several times afr...    fear   0.854\n",
       "49   20049  white americans worried arab terrorists black ...    fear   0.854\n",
       "50   20050                            today horrible half day    fear   0.854\n",
       "51   20051  obama legacy weekly riots terror attacks gt <n...    fear   0.854\n",
       "52   20052  bad news fam life still hard awful depression ...    fear   0.854\n",
       "53   20053      <user> fucking hell mate absolute nightmare ðŸ˜“    fear   0.854\n",
       "54   20054  <user> i surrounded trump voters you right fuc...    fear   0.854"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# do a sanity check\n",
    "train[0:55]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SentID</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Emotion</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20000</td>\n",
       "      <td>i feel like i drowning depression anxiety fa l...</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20001</td>\n",
       "      <td>i get nervous even thinking talking i wanna die</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20002</td>\n",
       "      <td>i lost blinders panic</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20003</td>\n",
       "      <td>i feel like i drowning depression fa lure wort...</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20004</td>\n",
       "      <td>this scariest american horror story i gonna wa...</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>20005</td>\n",
       "      <td>&lt;user&gt; i nearly started crying full panic atta...</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>20006</td>\n",
       "      <td>i finally tell therapist sexuality last fronti...</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>20007</td>\n",
       "      <td>&lt;user&gt; i think i ever moved fast panic life ðŸ˜‚ ...</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>20008</td>\n",
       "      <td>my bus car crash i still shaking bit this week...</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>20009</td>\n",
       "      <td>my bus car crash i still shaking bit this week...</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.920</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SentID                                              Tweet Emotion  Rating\n",
       "0   20000  i feel like i drowning depression anxiety fa l...    fear   0.979\n",
       "1   20001    i get nervous even thinking talking i wanna die    fear   0.979\n",
       "2   20002                              i lost blinders panic    fear   0.975\n",
       "3   20003  i feel like i drowning depression fa lure wort...    fear   0.938\n",
       "4   20004  this scariest american horror story i gonna wa...    fear   0.938\n",
       "5   20005  <user> i nearly started crying full panic atta...    fear   0.938\n",
       "6   20006  i finally tell therapist sexuality last fronti...    fear   0.938\n",
       "7   20007  <user> i think i ever moved fast panic life ðŸ˜‚ ...    fear   0.938\n",
       "8   20008  my bus car crash i still shaking bit this week...    fear   0.938\n",
       "9   20009  my bus car crash i still shaking bit this week...    fear   0.920"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# do a sanity check\n",
    "train[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the distribution of text length (from below: there is no need to truncate any of texts)\n",
    "def show_text_len(train):\n",
    "    train[\"text_len\"] = train['Tweet'].map(lambda x: len(x.split()))\n",
    "    return train[\"text_len\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    1257.000000\n",
       "mean       11.422434\n",
       "std         4.583504\n",
       "min         2.000000\n",
       "25%         8.000000\n",
       "50%        12.000000\n",
       "75%        15.000000\n",
       "max        27.000000\n",
       "Name: text_len, dtype: float64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_text_len(train).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    995.000000\n",
       "mean      11.202010\n",
       "std        4.669176\n",
       "min        1.000000\n",
       "25%        8.000000\n",
       "50%       11.000000\n",
       "75%       14.000000\n",
       "max       26.000000\n",
       "Name: text_len, dtype: float64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_text_len(test).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is not any reviews' length = 0 after text cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tweets = list(train['Tweet'])\n",
    "train_intensities = list(train['Rating'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i feel like i drowning depression anxiety fa lure worthless',\n",
       " 'i get nervous even thinking talking i wanna die',\n",
       " 'i lost blinders panic',\n",
       " 'i feel like i drowning depression fa lure worthless',\n",
       " 'this scariest american horror story i gonna watch daytime frightened',\n",
       " '<user> i nearly started crying full panic attack tatin of bc crowds i feel',\n",
       " 'i finally tell therapist sexuality last frontier sure i am fear single girl problems',\n",
       " '<user> i think i ever moved fast panic life ðŸ˜‚ gave fright ðŸ˜“',\n",
       " 'my bus car crash i still shaking bit this week absolute horror icing cake terrible',\n",
       " 'my bus car crash i still shaking bit this week absolute horror icing cake',\n",
       " 'proc ra sting fun im hour away time due still havent finished panic attack',\n",
       " 'my anxiety rising tonight i sure sometimes i wonder i magnet free floating anxiety universe',\n",
       " 'im nervous wreck im nervous pile up going crazy help me insane antisocial',\n",
       " 'panic panic attack fear starting new medication',\n",
       " 'job interview afternoon nervous ek',\n",
       " 'i beyond mad i lost track brown spider brown carpet where go ðŸ•· sneaking',\n",
       " 'anxiety level <number>',\n",
       " 'wah woke frm fucking nightmare',\n",
       " 'i get much pussy np panic attacks nu uncontrollable anxiety ns suicidal fantasies ns sadness ny yearning death',\n",
       " 'cosplaying properly first time saturday pretty nervous',\n",
       " '<user> i surrounded trump voters you right fucking terrifying redstate despair',\n",
       " 'ignored broken tooth long abscess need dentist fear makes hard go <number> still go dentist',\n",
       " '<user> we much trouble i think rev see funny side project nervous',\n",
       " 'im crying katherine one whos like talking anxiety attack im gonna faint',\n",
       " 'ever really lonely phone keeps blowing cant pick respond people anxiety recluse issues',\n",
       " 'super shitting tattoo nervous',\n",
       " 'breaking hives first time since college finals anxiety sucks',\n",
       " '<user> <user> ni get sick stomach every time i see video amp helicopter crew make comments revolting',\n",
       " 'i beyond mad i lost track brown spider brown carpet where go ðŸ•· sneaking frightened',\n",
       " '<number> <number> minutes perform i nervous i wish noises would stop handicapped annoyed',\n",
       " 'i hate people say i need talk need talk my anxiety immediately goes',\n",
       " 'he replied comments <number> times shaking omg',\n",
       " 'being stuck roof house provides amazing view sheer terror falling kinda like life',\n",
       " 'just want saturday i want good lsat nervous',\n",
       " 'im nervous wreck im pile up going crazy help me insane antisocial',\n",
       " 'i literally shaking getting ekg done lol ðŸ™„',\n",
       " '<user> thanks ryan amp brad scary shit us first episode do think heart make <number> horrific',\n",
       " '<user> operation echoes gathering momentum tense nervous feel sick excited',\n",
       " 'weird wednesday okay that jump scared poop right bad dog bad total code brown favorite pants damnit',\n",
       " '<user> i fear future mankind',\n",
       " 'first day college feeling nervous',\n",
       " 'might hysteria kno anxiety need diagnosis cuz somethin messed need ert bu nvr come',\n",
       " '<user> made cry shake point parents calm give calming tablets',\n",
       " 'gonna get acupuncture today damn anxiety',\n",
       " 'anthony weiner distraction really going selection election syria terrorism race riots gas crisis <number> noda pl rape',\n",
       " '<user> would great card crashes ðŸ˜± it happened twice nightmare',\n",
       " '<user> im feeling worry',\n",
       " 'that feeling get know information scared might bad test college life nervous',\n",
       " 'hard time falling sleep woke several times afraid bugs crawling ended waking bite',\n",
       " 'white americans worried arab terrorists black americans fearful terrorist police uniform daily basis',\n",
       " 'today horrible half day',\n",
       " 'obama legacy weekly riots terror attacks gt <number> k dead syrians jews fleeing persecution europe christian genocide me',\n",
       " 'bad news fam life still hard awful depression anxiety at least i have buffy',\n",
       " '<user> fucking hell mate absolute nightmare ðŸ˜“',\n",
       " '<user> i surrounded trump voters you right fucking terrifying redstate',\n",
       " 'life long fear havin shit spider crawls ya bum',\n",
       " 'what shame full unequal dangerous worrying world live nowadays terrifying charlotte terrorism shit world for our kids',\n",
       " '<user> thanks ryan amp brad scary shit us first episode do think heart make <number>',\n",
       " 'i start work tm rw yall nervous lol',\n",
       " 'i do know make pakistan fear terrorist terrorism terror state pak',\n",
       " '<user> if ban goes harm many people disabled veterans people chronic pain anxiety i am kratom',\n",
       " 'wish i could convince rest children go fucking preschool elementary schools fear gun violence',\n",
       " 'i panic attack i could find <user> twitter turns twitter jerk i still see nyssa al ghul panic',\n",
       " 'now getting hand i freaked death i god momma grendel intimidation',\n",
       " 'saga when devices teles fail time bake panic gb bo',\n",
       " 'feeling like i worst night sleep ever great london brighton cycle ride <user> ðŸš´ <number> k',\n",
       " 'do think humans sense recognizing impending doom anxiety',\n",
       " 'i finally tell therapist sexuality last frontier sure i am single girl problems',\n",
       " 'im literally shaking bc im nervous bc fucking cold oh love life',\n",
       " 'i feel horrible i accounting today physically mentally okay ðŸ˜ª',\n",
       " '<user> n likewise death cutting despair',\n",
       " 'i coward i feel terrible but i even face ðŸ˜­',\n",
       " 'weird wednesday okay that jump scared poop right bad dog bad total code brown favorite pants damnit horror',\n",
       " '<user> <user> i would rather leave child <user> shudder',\n",
       " '<user> bridge i drive i stop breathing y ooo i i afraid',\n",
       " 'my roommate talks laughs sleep it never fails scare shit',\n",
       " 'i dream i dropped i phone <number> broke tt cry i phone <number>',\n",
       " 'i deleted save file trying load now i start all over again i going freaking kill someone pray',\n",
       " '<user> omg horrific something needs done ðŸ˜¢',\n",
       " 'i getting nervous first anatomy exam ðŸ˜©',\n",
       " '<user> fact your e nervous makes want crawl hole',\n",
       " 'mm nothing like good old fashioned panic induced cry living room floor',\n",
       " 'r u scared present front class severe anxiety whats that r u sad sometimes go get ur depression checked imediately',\n",
       " 'now getting hand i freaked death i god momma grendel',\n",
       " 'in bangladesh war us almost bombed us russia what strategy china pakistan time ripe crush terror camps',\n",
       " 'i another test tonight nervous',\n",
       " '<user> <user> <user> <user> these interviews scare crap i never imagined many dumb dumb americans',\n",
       " 'ca believe nervous i feel tonight feels mufc',\n",
       " '<user> <user> was there a clown in your neighborhood creepy enough is enough',\n",
       " '<user> <user> was there a clown in your neighborhood nightmare creepy enough is enough',\n",
       " 'bloody hell pam calm but could sworn something black amp hairy ran across carpet perils of living alone',\n",
       " 'she posh frightened i still scared',\n",
       " 'in wake fresh terror threat sounding alert mumbai praying safety amp security everybody city maharashtra news',\n",
       " 'woke nightmare <number> am could sleep took use all the hot water shower now i time read',\n",
       " 'ughh i want like nightmare get along',\n",
       " 'i seem alternate leep full sleepless nights tonight sleepless one ðŸ˜• insomnia anxiety not fair',\n",
       " 'jimmy carr makes want cry cry shiver',\n",
       " 'dream they trying steal kidney nightmare black market why did i watch that',\n",
       " 'jimmy carr makes want cry cry shiver awful',\n",
       " 'being forced fake hug someone didnt flinch get litigious past awful']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check\n",
    "train_tweets[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9790000000000001,\n",
       " 0.9790000000000001,\n",
       " 0.975,\n",
       " 0.938,\n",
       " 0.938,\n",
       " 0.938,\n",
       " 0.938,\n",
       " 0.938,\n",
       " 0.938,\n",
       " 0.92]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check\n",
    "train_intensities[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_tweets = list(test['Tweet'])\n",
    "test_intensities = list(test['Rating'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>max text length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>train</th>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       max text length\n",
       "train               27\n",
       "test                26"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show Max Text Length of All Datasets for comparsion\n",
    "\n",
    "all_tweets_max_len = pd.DataFrame(np.array([max(show_text_len(train)), max(show_text_len(test))]))\n",
    "\n",
    "all_tweets_max_len.index = ['train', 'test']\n",
    "all_tweets_max_len.columns = ['max text length']\n",
    "\n",
    "all_tweets_max_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "all_tweets_max_len.plot(kind='bar')\n",
    "plt.title('Max Text Length of All Datasets')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "we set the length to which each tweet vector will be zero padded to.\n",
    "this is based on the maximum length we got on the training set - we do not want to remove\n",
    "any words as the maximun length of the training set is not very big.\n",
    "'''\n",
    "\n",
    "max_len = max(show_text_len(train))\n",
    "max_len"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Text Data Preparationï¼ˆFeature Extraction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (1) Load Pre-trained Word Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gensim\n",
    "from nltk import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vector_path = \"files/wv_models/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1) Glove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadGloveModel(gloveFile):\n",
    "    print(\"Loading Glove Model\")\n",
    "    f = open(gloveFile,'r', encoding = 'UTF-8')\n",
    "    model = {}\n",
    "    num = 1\n",
    "    for line in f:\n",
    "        try:\n",
    "            splitLine = line.split()\n",
    "            word = splitLine[0]\n",
    "            coefs = np.asarray(splitLine[1:], dtype = 'float32')\n",
    "            model[word] = coefs\n",
    "            num += 1\n",
    "        except Exception as e:\n",
    "            print(\"Failed at line \" + str(num))\n",
    "    print(\"Done. Found %s word vectors.\" %len(model),\" words loaded!\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Glove Model\n",
      "Done. Found 1193514 word vectors.  words loaded!\n"
     ]
    }
   ],
   "source": [
    "# To download the pretrained glove model (2B tweets, 27B tokens) - [https://nlp.stanford.edu/projects/glove/   glove.twitter.27B.zip]\n",
    "# choose glove.twitter.27B.200d.txt from glove.twitter.27B.zip. [200-dimension vectors]\n",
    "\n",
    "wv_model_path1 = word_vector_path + \"glove.twitter.27B.200d.txt\"\n",
    " \n",
    "wv_model_g = loadGloveModel(wv_model_path1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2) Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To download the pretrained word2vec model  - [https://github.com/FredericGodin/TwitterEmbeddings]\n",
    "\n",
    "wv_model_path2 = word_vector_path + \"word2vec_twitter_tokens.bin\"\n",
    "wv_model_w = gensim.models.KeyedVectors.load_word2vec_format(wv_model_path2, binary=True, unicode_errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word Vectors: 3039345\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dell\\Anaconda3\\envs\\tf2\\lib\\site-packages\\ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "words = list(wv_model_w.wv.vocab)\n",
    "print('Word Vectors: %d' % len(words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3) Define Averaged Word Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_dimensions_g = len(wv_model_g['word'])\n",
    "w2v_dimensions_w = len(wv_model_w['word'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200 400\n"
     ]
    }
   ],
   "source": [
    "print(w2v_dimensions_g,w2v_dimensions_w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_averaged_embeddings(tweet, model, dimensions):\n",
    "    tokens = word_tokenize(tweet)\n",
    "    vector_list = []\n",
    "    for token in tokens:\n",
    "        try:\n",
    "            vector_list.append(model[token])\n",
    "        except Exception as e:\n",
    "            pass\n",
    "    if len(vector_list) == 0:\n",
    "        uni_vec_rep = np.zeros(dimensions).tolist()\n",
    "    else:\n",
    "        uni_vec_rep = sum(vector_list) / float(len(vector_list))\n",
    "    return uni_vec_rep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (2) Load Lexicon Feature Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "lexicons_path = \"files/lexicons/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0.Emoji_Vectors',\n",
       " '1.NRC-Emotion-Intensity-Lexicon',\n",
       " '3.NRC-Emotion-Lexicon',\n",
       " '4.NRC-Hashtag-Emotion-Lexicon',\n",
       " '5.NRC-Emoticon-Lexicon',\n",
       " '6.NRC-Emoticon-AffLexNegLex',\n",
       " '7.NRC-Hashtag-Sentiment-AffLexNegLex',\n",
       " '8.NRC-Hashtag-Sentiment-Lexicon',\n",
       " '9.DepecheMood_V1.0']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paths2 = listdir(lexicons_path)\n",
    "paths2.sort()\n",
    "paths2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1) Emoji Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(('%s%s/' %(lexicons_path, paths2[0])) + listdir('%s%s/' %(lexicons_path, paths2[0]))[0], encoding = 'UTF-8') \\\n",
    "as emoji_file:\n",
    "    emoji_list = json.load(emoji_file)\n",
    "    \n",
    "emoji_dict = dict()\n",
    "for emoji in emoji_list:\n",
    "    emoji_dict[emoji[\"emoji\"]] = (emoji[\"name\"], emoji[\"polarity\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('joy', 3)\n"
     ]
    }
   ],
   "source": [
    "# do a sanity check\n",
    "print(emoji_dict[\"ðŸ˜‚\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly_emoji_intensity = PolynomialFeatures(5)\n",
    "\n",
    "def get_emoji_intensity(tweet):\n",
    "    score = 0.0\n",
    "    for emoji in emoji_dict.keys():\n",
    "        count = tweet.count(emoji)\n",
    "        score += count * emoji_dict[emoji][1]\n",
    "        \n",
    "    return normalize(poly_emoji_intensity.fit_transform(np.array([score]).reshape(1, -1))[0].reshape(1, -1))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00387988, 0.01163963, 0.03491889, 0.10475666, 0.31426998,\n",
       "       0.94280993])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# do a sanity check\n",
    "get_emoji_intensity(\"ðŸ˜‚\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2) Emotion Intensity Lexicon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "affect_intensity_file_path = ('%s%s/' %(lexicons_path, paths2[1])) + listdir('%s%s/' %(lexicons_path, paths2[1]))[0]\n",
    "\n",
    "def get_word_affect_intensity_dict(emotion):\n",
    "    word_intensities = dict()\n",
    "\n",
    "    with open(affect_intensity_file_path) as affect_intensity_file:\n",
    "        for line in affect_intensity_file:\n",
    "            word_int_array = line.replace(\"\\n\", \"\").split(\"\\t\")\n",
    "\n",
    "            if (word_int_array[1] == emotion):\n",
    "                word_intensities[word_int_array[0]] = float(word_int_array[2])\n",
    "\n",
    "    return word_intensities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'torture': 0.984,\n",
       " 'terrorist': 0.972,\n",
       " 'terrorism': 0.969,\n",
       " 'terrorists': 0.969,\n",
       " 'horrific': 0.969,\n",
       " 'suicidebombing': 0.967,\n",
       " 'kill': 0.962,\n",
       " 'homicidal': 0.959,\n",
       " 'catastrophe': 0.953,\n",
       " 'murderer': 0.953,\n",
       " 'annihilate': 0.953,\n",
       " 'terror': 0.953,\n",
       " 'dying': 0.948,\n",
       " 'war': 0.942,\n",
       " 'bombing': 0.938,\n",
       " 'bomb': 0.935,\n",
       " 'missiles': 0.934,\n",
       " 'horror': 0.923,\n",
       " 'horrified': 0.922,\n",
       " 'brutality': 0.922,\n",
       " 'bloodthirsty': 0.922,\n",
       " 'terrorize': 0.922,\n",
       " 'murderous': 0.92,\n",
       " 'massacre': 0.911,\n",
       " 'terrifying': 0.906,\n",
       " 'murder': 0.906,\n",
       " 'fatality': 0.906,\n",
       " 'horrifying': 0.906,\n",
       " 'mutilation': 0.906,\n",
       " 'horrors': 0.906,\n",
       " 'killing': 0.906,\n",
       " 'devastation': 0.906,\n",
       " 'assassinate': 0.906,\n",
       " 'holocaust': 0.906,\n",
       " 'demon': 0.906,\n",
       " 'terrified': 0.906,\n",
       " 'suicidal': 0.898,\n",
       " 'assault': 0.891,\n",
       " 'crucifixion': 0.891,\n",
       " 'slaughter': 0.891,\n",
       " 'kidnap': 0.891,\n",
       " 'doomed': 0.888,\n",
       " 'poisoned': 0.886,\n",
       " 'suicide': 0.879,\n",
       " 'explosion': 0.879,\n",
       " 'deadly': 0.875,\n",
       " 'disaster': 0.875,\n",
       " 'annihilation': 0.875,\n",
       " 'dismemberment': 0.875,\n",
       " 'threatening': 0.875,\n",
       " 'suffocation': 0.875,\n",
       " 'assassin': 0.875,\n",
       " 'disastrous': 0.875,\n",
       " 'savagery': 0.875,\n",
       " 'slaughtering': 0.875,\n",
       " 'rape': 0.87,\n",
       " 'hell': 0.86,\n",
       " 'explosive': 0.859,\n",
       " 'paralyzed': 0.859,\n",
       " 'attacking': 0.859,\n",
       " 'executioner': 0.859,\n",
       " 'tragedy': 0.859,\n",
       " 'slaughterhouse': 0.859,\n",
       " 'warfare': 0.859,\n",
       " 'anthrax': 0.859,\n",
       " 'molestation': 0.859,\n",
       " 'guillotine': 0.859,\n",
       " 'annihilated': 0.859,\n",
       " 'homicide': 0.859,\n",
       " 'bloodshed': 0.859,\n",
       " 'ihatespiders': 0.859,\n",
       " 'peril': 0.859,\n",
       " 'barbaric': 0.859,\n",
       " 'demonic': 0.859,\n",
       " 'dread': 0.859,\n",
       " 'suffocating': 0.858,\n",
       " 'treachery': 0.856,\n",
       " 'fright': 0.853,\n",
       " 'panicked': 0.844,\n",
       " 'slayer': 0.844,\n",
       " 'morgue': 0.844,\n",
       " 'apocalypse': 0.844,\n",
       " 'monster': 0.844,\n",
       " 'afraid': 0.844,\n",
       " 'abomination': 0.844,\n",
       " 'drown': 0.844,\n",
       " 'painful': 0.844,\n",
       " 'scare': 0.844,\n",
       " 'petrified': 0.844,\n",
       " 'frightened': 0.844,\n",
       " 'execution': 0.844,\n",
       " 'traumatic': 0.844,\n",
       " 'frightening': 0.844,\n",
       " 'vengeance': 0.844,\n",
       " 'bombardment': 0.844,\n",
       " 'destroying': 0.844,\n",
       " 'scariest': 0.844,\n",
       " 'death': 0.843,\n",
       " 'chaos': 0.839,\n",
       " 'ghastly': 0.836,\n",
       " 'evil': 0.833,\n",
       " 'assassination': 0.828,\n",
       " 'violently': 0.828,\n",
       " 'fatal': 0.828,\n",
       " 'grenade': 0.828,\n",
       " 'frighten': 0.828,\n",
       " 'devil': 0.828,\n",
       " 'hellish': 0.828,\n",
       " 'cancer': 0.828,\n",
       " 'nightmare': 0.828,\n",
       " 'intruder': 0.828,\n",
       " 'doom': 0.828,\n",
       " 'gunmen': 0.828,\n",
       " 'explode': 0.828,\n",
       " 'trauma': 0.828,\n",
       " 'fear': 0.828,\n",
       " 'doomsday': 0.828,\n",
       " 'kidnapped': 0.828,\n",
       " 'brutal': 0.828,\n",
       " 'paralyze': 0.828,\n",
       " 'manslaughter': 0.828,\n",
       " 'eradication': 0.828,\n",
       " 'morbidity': 0.82,\n",
       " 'crippling': 0.817,\n",
       " 'savage': 0.814,\n",
       " 'poisonous': 0.812,\n",
       " 'violence': 0.812,\n",
       " 'destructive': 0.812,\n",
       " 'aggressor': 0.812,\n",
       " 'heartattack': 0.812,\n",
       " 'shooting': 0.812,\n",
       " 'quake': 0.812,\n",
       " 'damnation': 0.812,\n",
       " 'suffering': 0.812,\n",
       " 'crushed': 0.812,\n",
       " 'frightful': 0.812,\n",
       " 'violent': 0.812,\n",
       " 'earthquake': 0.812,\n",
       " 'hurricane': 0.811,\n",
       " 'imprisoned': 0.811,\n",
       " 'exterminate': 0.81,\n",
       " 'fearing': 0.808,\n",
       " 'hemorrhage': 0.807,\n",
       " 'lethal': 0.806,\n",
       " 'torment': 0.806,\n",
       " 'venom': 0.804,\n",
       " 'claustrophobia': 0.803,\n",
       " 'danger': 0.802,\n",
       " 'snakes': 0.802,\n",
       " 'robbery': 0.8,\n",
       " 'obliterated': 0.8,\n",
       " 'exorcism': 0.8,\n",
       " 'terrifies': 0.798,\n",
       " 'monstrosity': 0.797,\n",
       " 'mortality': 0.797,\n",
       " 'persecution': 0.797,\n",
       " 'bombers': 0.797,\n",
       " 'extermination': 0.797,\n",
       " 'destruction': 0.797,\n",
       " 'poison': 0.797,\n",
       " 'cruelty': 0.797,\n",
       " 'cyanide': 0.797,\n",
       " 'attack': 0.797,\n",
       " 'harmful': 0.797,\n",
       " 'hysteria': 0.797,\n",
       " 'biggestfear': 0.797,\n",
       " 'anxietyattack': 0.797,\n",
       " 'incurable': 0.797,\n",
       " 'dreadfully': 0.796,\n",
       " 'arson': 0.794,\n",
       " 'devastate': 0.792,\n",
       " 'tyrant': 0.788,\n",
       " 'warcrimes': 0.785,\n",
       " 'perish': 0.784,\n",
       " 'feared': 0.782,\n",
       " 'freakingout': 0.781,\n",
       " 'warlike': 0.781,\n",
       " 'lifeless': 0.781,\n",
       " 'enslaved': 0.781,\n",
       " 'screaming': 0.781,\n",
       " 'maniac': 0.781,\n",
       " 'venomous': 0.781,\n",
       " 'bloody': 0.781,\n",
       " 'rampage': 0.781,\n",
       " 'epidemic': 0.776,\n",
       " 'snake': 0.776,\n",
       " 'panicattack': 0.774,\n",
       " 'dangerously': 0.766,\n",
       " 'violation': 0.766,\n",
       " 'riot': 0.766,\n",
       " 'ohshit': 0.766,\n",
       " 'shipwreck': 0.766,\n",
       " 'tumor': 0.766,\n",
       " 'fearful': 0.766,\n",
       " 'hazardous': 0.766,\n",
       " 'obliterate': 0.766,\n",
       " 'reprisal': 0.766,\n",
       " 'crisis': 0.766,\n",
       " 'criminal': 0.766,\n",
       " 'detonate': 0.766,\n",
       " 'inferno': 0.766,\n",
       " 'invader': 0.766,\n",
       " 'invade': 0.766,\n",
       " 'jihad': 0.766,\n",
       " 'die': 0.766,\n",
       " 'leprosy': 0.766,\n",
       " 'scary': 0.766,\n",
       " 'claustrophobic': 0.765,\n",
       " 'hyperventilating': 0.762,\n",
       " 'nightmares': 0.759,\n",
       " 'destroyed': 0.754,\n",
       " 'ghostly': 0.754,\n",
       " 'tyranny': 0.75,\n",
       " 'treacherous': 0.75,\n",
       " 'obliteration': 0.75,\n",
       " 'hurricanes': 0.75,\n",
       " 'dangerous': 0.75,\n",
       " 'panic': 0.75,\n",
       " 'anarchist': 0.75,\n",
       " 'projectiles': 0.75,\n",
       " 'dreadful': 0.75,\n",
       " 'tragedies': 0.75,\n",
       " 'anarchy': 0.75,\n",
       " 'cholera': 0.75,\n",
       " 'destroyer': 0.75,\n",
       " 'riotous': 0.75,\n",
       " 'ptsd': 0.75,\n",
       " 'mortuary': 0.75,\n",
       " 'strangle': 0.75,\n",
       " 'imprisonment': 0.75,\n",
       " 'fears': 0.75,\n",
       " 'anaconda': 0.75,\n",
       " 'slavery': 0.75,\n",
       " 'hazard': 0.75,\n",
       " 'accident': 0.75,\n",
       " 'agony': 0.75,\n",
       " 'wrenching': 0.75,\n",
       " 'malignancy': 0.742,\n",
       " 'cannibal': 0.74,\n",
       " 'bombard': 0.74,\n",
       " 'abominable': 0.738,\n",
       " 'beast': 0.734,\n",
       " 'diseased': 0.734,\n",
       " 'mafia': 0.734,\n",
       " 'gun': 0.734,\n",
       " 'malignant': 0.734,\n",
       " 'melee': 0.734,\n",
       " 'bomber': 0.734,\n",
       " 'gore': 0.734,\n",
       " 'missile': 0.734,\n",
       " 'crash': 0.734,\n",
       " 'dictatorship': 0.734,\n",
       " 'mutiny': 0.734,\n",
       " 'hostage': 0.734,\n",
       " 'paralysis': 0.734,\n",
       " 'victimized': 0.734,\n",
       " 'threaten': 0.734,\n",
       " 'horrible': 0.734,\n",
       " 'scared': 0.734,\n",
       " 'shoot': 0.734,\n",
       " 'shot': 0.734,\n",
       " 'cursed': 0.734,\n",
       " 'misery': 0.734,\n",
       " 'hyperventilate': 0.734,\n",
       " 'depraved': 0.734,\n",
       " 'tyrannical': 0.734,\n",
       " 'tornado': 0.734,\n",
       " 'devilish': 0.734,\n",
       " 'turmoil': 0.733,\n",
       " 'combat': 0.728,\n",
       " 'alligator': 0.727,\n",
       " 'ruin': 0.725,\n",
       " 'shooter': 0.722,\n",
       " 'contagious': 0.72,\n",
       " 'scream': 0.719,\n",
       " 'devastating': 0.719,\n",
       " 'crime': 0.719,\n",
       " 'excruciating': 0.719,\n",
       " 'emergency': 0.719,\n",
       " 'seizure': 0.719,\n",
       " 'shock': 0.719,\n",
       " 'phobia': 0.719,\n",
       " 'mortification': 0.719,\n",
       " 'starvation': 0.719,\n",
       " 'fight': 0.719,\n",
       " 'injured': 0.719,\n",
       " 'casualty': 0.719,\n",
       " 'desperation': 0.719,\n",
       " 'miscarriage': 0.719,\n",
       " 'harm': 0.719,\n",
       " 'havoc': 0.719,\n",
       " 'struggle': 0.719,\n",
       " 'lynch': 0.719,\n",
       " 'frantically': 0.717,\n",
       " 'carnage': 0.717,\n",
       " 'infestation': 0.716,\n",
       " 'standoff': 0.716,\n",
       " 'soscary': 0.712,\n",
       " 'panicking': 0.708,\n",
       " 'rupture': 0.706,\n",
       " 'horrid': 0.705,\n",
       " 'frantic': 0.705,\n",
       " 'plague': 0.703,\n",
       " 'collapse': 0.703,\n",
       " 'deranged': 0.703,\n",
       " 'dreaded': 0.703,\n",
       " 'neurotic': 0.703,\n",
       " 'grisly': 0.703,\n",
       " 'gash': 0.703,\n",
       " 'arsenic': 0.703,\n",
       " 'sos': 0.703,\n",
       " 'burial': 0.703,\n",
       " 'sabotage': 0.703,\n",
       " 'malevolent': 0.703,\n",
       " 'infectious': 0.703,\n",
       " 'agonizing': 0.703,\n",
       " 'witchcraft': 0.703,\n",
       " 'harrowing': 0.703,\n",
       " 'assailant': 0.703,\n",
       " 'wrecked': 0.703,\n",
       " 'hysterical': 0.703,\n",
       " 'terminal': 0.703,\n",
       " 'schizophrenia': 0.703,\n",
       " 'diabolical': 0.703,\n",
       " 'fugitive': 0.703,\n",
       " 'freaked': 0.703,\n",
       " 'cobra': 0.703,\n",
       " 'aggressive': 0.703,\n",
       " 'vendetta': 0.703,\n",
       " 'carcinoma': 0.703,\n",
       " 'psychosis': 0.703,\n",
       " 'upheaval': 0.703,\n",
       " 'hatred': 0.703,\n",
       " 'prey': 0.703,\n",
       " 'cripple': 0.703,\n",
       " 'armed': 0.703,\n",
       " 'avalanche': 0.703,\n",
       " 'anguish': 0.703,\n",
       " 'forcibly': 0.7,\n",
       " 'crocodile': 0.7,\n",
       " 'abduction': 0.7,\n",
       " 'offender': 0.698,\n",
       " 'mayhem': 0.69,\n",
       " 'socialanxiety': 0.688,\n",
       " 'gory': 0.688,\n",
       " 'banish': 0.688,\n",
       " 'beastly': 0.688,\n",
       " 'hostile': 0.688,\n",
       " 'radiation': 0.688,\n",
       " 'oppression': 0.688,\n",
       " 'agoraphobia': 0.688,\n",
       " 'hurt': 0.688,\n",
       " 'contagion': 0.688,\n",
       " 'disease': 0.688,\n",
       " 'shrapnel': 0.688,\n",
       " 'anarchism': 0.688,\n",
       " 'trepidation': 0.688,\n",
       " 'ambush': 0.688,\n",
       " 'blast': 0.688,\n",
       " 'endanger': 0.688,\n",
       " 'alarm': 0.688,\n",
       " 'wounding': 0.688,\n",
       " 'paranoid': 0.688,\n",
       " 'cyclone': 0.688,\n",
       " 'guerilla': 0.688,\n",
       " 'rabid': 0.688,\n",
       " 'hopeless': 0.688,\n",
       " 'leukemia': 0.688,\n",
       " 'brawl': 0.688,\n",
       " 'cadaver': 0.688,\n",
       " 'gallows': 0.686,\n",
       " 'coffin': 0.684,\n",
       " 'madness': 0.675,\n",
       " 'spook': 0.673,\n",
       " 'grim': 0.672,\n",
       " 'carcass': 0.672,\n",
       " 'ghost': 0.672,\n",
       " 'dungeon': 0.672,\n",
       " 'menace': 0.672,\n",
       " 'injury': 0.672,\n",
       " 'menacing': 0.672,\n",
       " 'militants': 0.672,\n",
       " 'felon': 0.672,\n",
       " 'crushing': 0.672,\n",
       " 'soscared': 0.672,\n",
       " 'viper': 0.672,\n",
       " 'perishing': 0.672,\n",
       " 'frankenstorm': 0.672,\n",
       " 'militia': 0.672,\n",
       " 'outbreak': 0.672,\n",
       " 'nervouswreck': 0.672,\n",
       " 'vermin': 0.672,\n",
       " 'revolver': 0.672,\n",
       " 'freakedout': 0.672,\n",
       " 'awful': 0.672,\n",
       " 'victim': 0.672,\n",
       " 'combatant': 0.672,\n",
       " 'sinister': 0.672,\n",
       " 'abhorrent': 0.672,\n",
       " 'thug': 0.672,\n",
       " 'atrocity': 0.672,\n",
       " 'persecute': 0.672,\n",
       " 'abuse': 0.672,\n",
       " 'stab': 0.672,\n",
       " 'mangle': 0.672,\n",
       " 'hurting': 0.672,\n",
       " 'tarantula': 0.672,\n",
       " 'gang': 0.672,\n",
       " 'shatter': 0.672,\n",
       " 'fangs': 0.672,\n",
       " 'fury': 0.672,\n",
       " 'scarier': 0.672,\n",
       " 'eruption': 0.672,\n",
       " 'trembling': 0.672,\n",
       " 'battered': 0.667,\n",
       " 'ferocious': 0.667,\n",
       " 'desolation': 0.667,\n",
       " 'cutthroat': 0.664,\n",
       " 'pandemic': 0.664,\n",
       " 'volcano': 0.663,\n",
       " 'scares': 0.66,\n",
       " 'cruelly': 0.658,\n",
       " 'smash': 0.656,\n",
       " 'traitor': 0.656,\n",
       " 'punishment': 0.656,\n",
       " 'ruthless': 0.656,\n",
       " 'alarming': 0.656,\n",
       " 'oppressive': 0.656,\n",
       " 'spider': 0.656,\n",
       " 'dictator': 0.656,\n",
       " 'revenge': 0.656,\n",
       " 'stroke': 0.656,\n",
       " 'typhoon': 0.656,\n",
       " 'endangered': 0.656,\n",
       " 'purgatory': 0.656,\n",
       " 'bully': 0.656,\n",
       " 'armament': 0.656,\n",
       " 'crazed': 0.656,\n",
       " 'lunatic': 0.656,\n",
       " 'distress': 0.656,\n",
       " 'malicious': 0.656,\n",
       " 'emetophobia': 0.656,\n",
       " 'coma': 0.656,\n",
       " 'battlefield': 0.656,\n",
       " 'nefarious': 0.656,\n",
       " 'fearfully': 0.656,\n",
       " 'insane': 0.656,\n",
       " 'selfharm': 0.656,\n",
       " 'blizzard': 0.656,\n",
       " 'tumult': 0.656,\n",
       " 'cruel': 0.656,\n",
       " 'radioactive': 0.656,\n",
       " 'debauchery': 0.656,\n",
       " 'despotic': 0.656,\n",
       " 'neurosis': 0.656,\n",
       " 'xenophobia': 0.656,\n",
       " 'shitless': 0.656,\n",
       " 'encroachment': 0.656,\n",
       " 'treason': 0.656,\n",
       " 'projectile': 0.654,\n",
       " 'flog': 0.653,\n",
       " 'bang': 0.652,\n",
       " 'ransom': 0.644,\n",
       " 'criminality': 0.642,\n",
       " 'intimidate': 0.641,\n",
       " 'injurious': 0.641,\n",
       " 'duress': 0.641,\n",
       " 'hanging': 0.641,\n",
       " 'wildfire': 0.641,\n",
       " 'aghast': 0.641,\n",
       " 'retaliation': 0.641,\n",
       " 'hideous': 0.641,\n",
       " 'dreading': 0.641,\n",
       " 'perilous': 0.641,\n",
       " 'dementia': 0.641,\n",
       " 'raging': 0.641,\n",
       " 'vehement': 0.641,\n",
       " 'perturbation': 0.641,\n",
       " 'dastardly': 0.641,\n",
       " 'scoundrel': 0.641,\n",
       " 'targeted': 0.641,\n",
       " 'warlock': 0.641,\n",
       " 'tumour': 0.641,\n",
       " 'wreck': 0.641,\n",
       " 'demise': 0.641,\n",
       " 'rattlesnake': 0.641,\n",
       " 'deteriorate': 0.641,\n",
       " 'antichrist': 0.641,\n",
       " 'abortion': 0.641,\n",
       " 'isolated': 0.641,\n",
       " 'quivering': 0.641,\n",
       " 'punished': 0.641,\n",
       " 'conflict': 0.641,\n",
       " 'demented': 0.641,\n",
       " 'raptors': 0.641,\n",
       " 'haunt': 0.641,\n",
       " 'cantbreathe': 0.641,\n",
       " 'banshee': 0.641,\n",
       " 'despair': 0.641,\n",
       " 'bestial': 0.639,\n",
       " 'serpent': 0.638,\n",
       " 'condemnation': 0.637,\n",
       " 'armaments': 0.636,\n",
       " 'fire': 0.636,\n",
       " 'corrosive': 0.636,\n",
       " 'exclusion': 0.636,\n",
       " 'nervousness': 0.627,\n",
       " 'daemon': 0.625,\n",
       " 'incarceration': 0.625,\n",
       " 'smuggler': 0.625,\n",
       " 'lunacy': 0.625,\n",
       " 'stunned': 0.625,\n",
       " 'infection': 0.625,\n",
       " 'virulence': 0.625,\n",
       " 'ruinous': 0.625,\n",
       " 'sickening': 0.625,\n",
       " 'sarcoma': 0.625,\n",
       " 'artillery': 0.625,\n",
       " 'madman': 0.625,\n",
       " 'prison': 0.625,\n",
       " 'combative': 0.625,\n",
       " 'mercenary': 0.625,\n",
       " 'irreparable': 0.625,\n",
       " 'spiders': 0.625,\n",
       " 'incendiary': 0.625,\n",
       " 'vampire': 0.625,\n",
       " 'landslide': 0.625,\n",
       " 'pestilence': 0.625,\n",
       " 'repression': 0.625,\n",
       " 'turbulent': 0.625,\n",
       " 'enemy': 0.625,\n",
       " 'malice': 0.625,\n",
       " 'wracking': 0.625,\n",
       " 'inhuman': 0.625,\n",
       " 'seize': 0.625,\n",
       " 'thundering': 0.625,\n",
       " 'hurtful': 0.625,\n",
       " 'revolting': 0.625,\n",
       " 'meltdown': 0.625,\n",
       " 'vengeful': 0.625,\n",
       " 'pneumonia': 0.625,\n",
       " 'disfigured': 0.625,\n",
       " 'injure': 0.625,\n",
       " 'wicked': 0.625,\n",
       " 'manic': 0.625,\n",
       " 'ill': 0.621,\n",
       " 'barbarian': 0.62,\n",
       " 'battled': 0.615,\n",
       " 'plummet': 0.613,\n",
       " 'blackmail': 0.612,\n",
       " 'contaminated': 0.61,\n",
       " 'hangman': 0.61,\n",
       " 'darkened': 0.61,\n",
       " 'malaria': 0.609,\n",
       " 'ogre': 0.609,\n",
       " 'interrogation': 0.609,\n",
       " 'homeless': 0.609,\n",
       " 'bleeding': 0.609,\n",
       " 'abandonment': 0.609,\n",
       " 'infanticide': 0.609,\n",
       " 'alienation': 0.609,\n",
       " 'aggression': 0.609,\n",
       " 'injection': 0.609,\n",
       " 'rob': 0.609,\n",
       " 'wrath': 0.609,\n",
       " 'sufferer': 0.609,\n",
       " 'scourge': 0.609,\n",
       " 'oppressor': 0.609,\n",
       " 'deplorable': 0.609,\n",
       " 'insurmountable': 0.609,\n",
       " 'beating': 0.609,\n",
       " 'injuring': 0.609,\n",
       " 'prosecute': 0.609,\n",
       " 'conflagration': 0.609,\n",
       " 'dagger': 0.609,\n",
       " 'oblivion': 0.609,\n",
       " 'despotism': 0.609,\n",
       " 'illness': 0.609,\n",
       " 'merciless': 0.609,\n",
       " 'disintegrate': 0.609,\n",
       " 'butcher': 0.609,\n",
       " 'shackle': 0.609,\n",
       " 'threat': 0.604,\n",
       " 'raid': 0.6,\n",
       " 'nerves': 0.6,\n",
       " 'firearms': 0.6,\n",
       " 'eviction': 0.596,\n",
       " 'villain': 0.595,\n",
       " 'torrent': 0.594,\n",
       " 'tribulation': 0.594,\n",
       " 'masochism': 0.594,\n",
       " 'casket': 0.594,\n",
       " 'deceit': 0.594,\n",
       " 'infidel': 0.594,\n",
       " 'possessed': 0.594,\n",
       " 'accursed': 0.594,\n",
       " 'belligerent': 0.594,\n",
       " 'omen': 0.594,\n",
       " 'haze': 0.594,\n",
       " 'burglar': 0.594,\n",
       " 'flee': 0.594,\n",
       " 'rot': 0.594,\n",
       " 'euthanasia': 0.594,\n",
       " 'ominous': 0.594,\n",
       " 'sickness': 0.594,\n",
       " 'convict': 0.594,\n",
       " 'lightning': 0.594,\n",
       " 'villainous': 0.594,\n",
       " 'restrained': 0.594,\n",
       " 'fraught': 0.594,\n",
       " 'dragon': 0.594,\n",
       " 'paranoia': 0.594,\n",
       " 'hypertrophy': 0.594,\n",
       " 'shelling': 0.594,\n",
       " 'cardiomyopathy': 0.594,\n",
       " 'pain': 0.594,\n",
       " 'goblin': 0.594,\n",
       " 'pounding': 0.594,\n",
       " 'terrible': 0.594,\n",
       " 'tremor': 0.594,\n",
       " 'foe': 0.594,\n",
       " 'anxiety': 0.594,\n",
       " 'sepsis': 0.594,\n",
       " 'wounded': 0.592,\n",
       " 'elimination': 0.588,\n",
       " 'lava': 0.588,\n",
       " 'spank': 0.587,\n",
       " 'hostilities': 0.586,\n",
       " 'dismal': 0.584,\n",
       " 'blockade': 0.582,\n",
       " 'punch': 0.58,\n",
       " 'cringe': 0.578,\n",
       " 'evacuate': 0.578,\n",
       " 'hateful': 0.578,\n",
       " 'coward': 0.578,\n",
       " 'confined': 0.578,\n",
       " 'clashing': 0.578,\n",
       " 'tumultuous': 0.578,\n",
       " 'worry': 0.578,\n",
       " 'infliction': 0.578,\n",
       " 'quarantine': 0.578,\n",
       " 'dire': 0.578,\n",
       " 'loss': 0.578,\n",
       " 'parasite': 0.578,\n",
       " 'apprehensive': 0.578,\n",
       " 'shudder': 0.578,\n",
       " 'eatingdisorders': 0.578,\n",
       " 'grizzly': 0.578,\n",
       " 'haunted': 0.578,\n",
       " 'sostressed': 0.578,\n",
       " 'desecration': 0.578,\n",
       " 'demoralized': 0.578,\n",
       " 'angina': 0.578,\n",
       " 'abyss': 0.578,\n",
       " 'deprivation': 0.578,\n",
       " 'forbidding': 0.578,\n",
       " 'surgery': 0.578,\n",
       " 'bacteria': 0.578,\n",
       " 'volatility': 0.578,\n",
       " 'jail': 0.578,\n",
       " 'failure': 0.578,\n",
       " 'stealing': 0.578,\n",
       " 'pained': 0.578,\n",
       " 'shady': 0.578,\n",
       " 'jeopardy': 0.578,\n",
       " 'curse': 0.578,\n",
       " 'assail': 0.578,\n",
       " 'dispossessed': 0.578,\n",
       " 'mob': 0.577,\n",
       " 'perdition': 0.577,\n",
       " 'comatose': 0.575,\n",
       " 'unholy': 0.575,\n",
       " 'toxin': 0.575,\n",
       " 'pillage': 0.574,\n",
       " 'incest': 0.571,\n",
       " 'wound': 0.571,\n",
       " 'forced': 0.569,\n",
       " 'cowardice': 0.567,\n",
       " 'crypt': 0.566,\n",
       " 'domination': 0.566,\n",
       " 'witch': 0.565,\n",
       " 'smuggle': 0.565,\n",
       " 'powerless': 0.562,\n",
       " 'incrimination': 0.562,\n",
       " 'afflict': 0.562,\n",
       " 'masks': 0.562,\n",
       " 'prisoner': 0.562,\n",
       " 'duel': 0.562,\n",
       " 'evasion': 0.562,\n",
       " 'grave': 0.562,\n",
       " 'eeek': 0.562,\n",
       " 'confine': 0.562,\n",
       " 'martyrdom': 0.562,\n",
       " 'lawsuit': 0.562,\n",
       " 'risky': 0.562,\n",
       " 'overpowering': 0.562,\n",
       " 'thrash': 0.562,\n",
       " 'freak': 0.562,\n",
       " 'sacrifices': 0.562,\n",
       " 'martyr': 0.562,\n",
       " 'mange': 0.562,\n",
       " 'appalling': 0.562,\n",
       " 'incubus': 0.562,\n",
       " 'distressing': 0.562,\n",
       " 'vanished': 0.562,\n",
       " 'pitfall': 0.562,\n",
       " 'apprehend': 0.562,\n",
       " 'banished': 0.562,\n",
       " 'purge': 0.562,\n",
       " 'hunter': 0.562,\n",
       " 'inflict': 0.562,\n",
       " 'corrupting': 0.562,\n",
       " 'degrading': 0.562,\n",
       " 'turbulence': 0.562,\n",
       " 'risk': 0.562,\n",
       " 'gunpowder': 0.562,\n",
       " 'misfortune': 0.562,\n",
       " 'syncope': 0.562,\n",
       " 'impending': 0.562,\n",
       " 'worries': 0.562,\n",
       " 'deterioration': 0.562,\n",
       " 'jitters': 0.562,\n",
       " 'travesty': 0.562,\n",
       " 'ulcer': 0.562,\n",
       " 'punishing': 0.562,\n",
       " 'polio': 0.562,\n",
       " 'unsafe': 0.561,\n",
       " 'sin': 0.56,\n",
       " 'worstfeeling': 0.56,\n",
       " 'perpetrator': 0.56,\n",
       " 'occult': 0.559,\n",
       " 'intimidation': 0.559,\n",
       " 'disable': 0.558,\n",
       " 'autopsy': 0.557,\n",
       " 'affliction': 0.557,\n",
       " 'decay': 0.557,\n",
       " 'vulnerability': 0.548,\n",
       " 'communism': 0.547,\n",
       " 'asylum': 0.547,\n",
       " 'overthrow': 0.547,\n",
       " 'scorpion': 0.547,\n",
       " 'flood': 0.547,\n",
       " 'mad': 0.547,\n",
       " 'thief': 0.547,\n",
       " 'abhor': 0.547,\n",
       " 'beware': 0.547,\n",
       " 'talons': 0.547,\n",
       " 'outcry': 0.547,\n",
       " 'brigade': 0.547,\n",
       " 'plunge': 0.547,\n",
       " 'appendicitis': 0.547,\n",
       " 'derogation': 0.547,\n",
       " 'noxious': 0.547,\n",
       " 'expulsion': 0.547,\n",
       " 'growling': 0.547,\n",
       " 'needles': 0.547,\n",
       " 'deformity': 0.547,\n",
       " 'insanity': 0.547,\n",
       " 'cannon': 0.547,\n",
       " 'coercion': 0.547,\n",
       " 'jeopardize': 0.547,\n",
       " 'samurai': 0.547,\n",
       " 'senile': 0.547,\n",
       " 'adder': 0.547,\n",
       " 'apparition': 0.547,\n",
       " 'ailing': 0.547,\n",
       " 'enmity': 0.547,\n",
       " 'outburst': 0.547,\n",
       " 'gonorrhea': 0.547,\n",
       " 'defenseless': 0.547,\n",
       " 'bondage': 0.547,\n",
       " 'scandal': 0.547,\n",
       " 'neuralgia': 0.547,\n",
       " 'precarious': 0.547,\n",
       " 'siren': 0.547,\n",
       " 'uprising': 0.545,\n",
       " 'retribution': 0.545,\n",
       " 'cemetery': 0.541,\n",
       " 'badness': 0.539,\n",
       " 'phantom': 0.538,\n",
       " 'abandoned': 0.534,\n",
       " 'fled': 0.534,\n",
       " 'rejection': 0.533,\n",
       " 'penetration': 0.531,\n",
       " 'jarring': 0.531,\n",
       " 'buried': 0.531,\n",
       " 'endocarditis': 0.531,\n",
       " 'carnivorous': 0.531,\n",
       " 'broken': 0.531,\n",
       " 'eek': 0.531,\n",
       " 'manifestation': 0.531,\n",
       " 'rebellion': 0.531,\n",
       " 'swastika': 0.531,\n",
       " 'atherosclerosis': 0.531,\n",
       " 'subjugation': 0.531,\n",
       " 'slave': 0.531,\n",
       " 'frenzied': 0.531,\n",
       " 'manipulation': 0.531,\n",
       " 'punish': 0.531,\n",
       " 'cowardly': 0.531,\n",
       " 'impotence': 0.531,\n",
       " 'distrust': 0.531,\n",
       " 'deserted': 0.531,\n",
       " 'saber': 0.531,\n",
       " 'failing': 0.531,\n",
       " 'shaking': 0.531,\n",
       " 'harbinger': 0.531,\n",
       " 'captor': 0.531,\n",
       " 'superstitious': 0.531,\n",
       " 'helpless': 0.531,\n",
       " 'lawlessness': 0.531,\n",
       " 'hopelessness': 0.531,\n",
       " 'freakout': 0.531,\n",
       " 'stressed': 0.531,\n",
       " 'stormy': 0.531,\n",
       " 'unstable': 0.531,\n",
       " 'abandon': 0.531,\n",
       " 'theft': 0.531,\n",
       " 'stalk': 0.531,\n",
       " 'disembodied': 0.531,\n",
       " 'wrangling': 0.531,\n",
       " 'incursion': 0.531,\n",
       " 'bacterium': 0.531,\n",
       " 'leeches': 0.531,\n",
       " 'suspense': 0.529,\n",
       " 'blood': 0.525,\n",
       " 'hiding': 0.524,\n",
       " 'bear': 0.524,\n",
       " 'unlawful': 0.519,\n",
       " 'crazy': 0.519,\n",
       " 'cult': 0.518,\n",
       " 'anxious': 0.518,\n",
       " 'deportation': 0.517,\n",
       " 'captive': 0.517,\n",
       " 'pernicious': 0.516,\n",
       " 'shriek': 0.516,\n",
       " 'growl': 0.516,\n",
       " 'revulsion': 0.516,\n",
       " 'oppress': 0.516,\n",
       " 'smite': 0.516,\n",
       " 'conspirator': 0.516,\n",
       " 'insidious': 0.516,\n",
       " 'emaciated': 0.516,\n",
       " 'palsy': 0.516,\n",
       " 'embolism': 0.516,\n",
       " 'biopsy': 0.516,\n",
       " 'plunder': 0.516,\n",
       " 'sting': 0.516,\n",
       " 'detainee': 0.516,\n",
       " 'enforce': 0.516,\n",
       " 'troublesome': 0.516,\n",
       " 'incite': 0.516,\n",
       " 'suspect': 0.516,\n",
       " 'exacerbation': 0.516,\n",
       " 'darkness': 0.516,\n",
       " 'relapse': 0.516,\n",
       " 'foreboding': 0.516,\n",
       " 'harshness': 0.516,\n",
       " 'grievous': 0.516,\n",
       " 'robber': 0.516,\n",
       " 'intolerance': 0.516,\n",
       " 'exile': 0.516,\n",
       " 'helplessness': 0.516,\n",
       " 'busted': 0.516,\n",
       " 'plight': 0.516,\n",
       " 'chased': 0.516,\n",
       " 'unthinkable': 0.516,\n",
       " 'badfeeling': 0.516,\n",
       " 'fang': 0.516,\n",
       " 'sorcery': 0.516,\n",
       " 'depression': 0.508,\n",
       " 'confinement': 0.507,\n",
       " 'instability': 0.5,\n",
       " 'wasp': 0.5,\n",
       " 'downfall': 0.5,\n",
       " 'snowmageddon': 0.5,\n",
       " 'ruined': 0.5,\n",
       " 'mistrust': 0.5,\n",
       " 'surrender': 0.5,\n",
       " 'constraint': 0.5,\n",
       " 'prohibited': 0.5,\n",
       " 'illegal': 0.5,\n",
       " 'odious': 0.5,\n",
       " 'infarct': 0.5,\n",
       " 'sinful': 0.5,\n",
       " 'suppress': 0.5,\n",
       " 'frenetic': 0.5,\n",
       " 'squeamish': 0.5,\n",
       " 'suppression': 0.5,\n",
       " 'prayforme': 0.5,\n",
       " 'premeditated': 0.5,\n",
       " 'vertigo': 0.5,\n",
       " 'brute': 0.5,\n",
       " 'alcoholism': 0.5,\n",
       " 'hunting': 0.5,\n",
       " 'subvert': 0.5,\n",
       " 'eeeek': 0.5,\n",
       " 'raving': 0.5,\n",
       " 'cliff': 0.5,\n",
       " 'madden': 0.5,\n",
       " 'scalpel': 0.5,\n",
       " 'intolerant': 0.5,\n",
       " 'towering': 0.5,\n",
       " 'blob': 0.5,\n",
       " 'defiance': 0.5,\n",
       " 'woe': 0.491,\n",
       " 'hate': 0.484,\n",
       " 'freakish': 0.484,\n",
       " 'indictment': 0.484,\n",
       " 'prejudiced': 0.484,\n",
       " 'accusing': 0.484,\n",
       " 'slam': 0.484,\n",
       " 'restriction': 0.484,\n",
       " 'poaching': 0.484,\n",
       " 'insecurity': 0.484,\n",
       " 'ohno': 0.484,\n",
       " 'divorce': 0.484,\n",
       " 'retard': 0.484,\n",
       " 'ravenous': 0.484,\n",
       " 'warrior': 0.484,\n",
       " 'ambulance': 0.484,\n",
       " 'rabble': 0.484,\n",
       " 'rat': 0.484,\n",
       " 'jumpy': 0.484,\n",
       " 'perjury': 0.484,\n",
       " 'dismay': 0.484,\n",
       " 'ravine': 0.484,\n",
       " 'blackness': 0.484,\n",
       " 'defamation': 0.484,\n",
       " 'intrusion': 0.484,\n",
       " 'palpitations': 0.484,\n",
       " 'cracked': 0.484,\n",
       " 'syringe': 0.484,\n",
       " 'shiver': 0.484,\n",
       " 'hearse': 0.484,\n",
       " 'armor': 0.484,\n",
       " 'canthandleit': 0.484,\n",
       " 'worrying': 0.484,\n",
       " 'disgusting': 0.484,\n",
       " 'indefensible': 0.484,\n",
       " 'hallucination': 0.484,\n",
       " 'worse': 0.484,\n",
       " 'lash': 0.484,\n",
       " 'sonervous': 0.484,\n",
       " 'lion': 0.484,\n",
       " 'endemic': 0.484,\n",
       " 'cutting': 0.484,\n",
       " 'flinch': 0.484,\n",
       " 'dishonor': 0.484,\n",
       " 'fiend': 0.484,\n",
       " 'coerce': 0.484,\n",
       " 'hospital': 0.484,\n",
       " 'inspection': 0.483,\n",
       " 'averse': 0.483,\n",
       " 'sinner': 0.483,\n",
       " 'missing': 0.474,\n",
       " 'despairing': 0.474,\n",
       " 'darken': 0.471,\n",
       " 'austere': 0.47,\n",
       " 'sinking': 0.469,\n",
       " 'fierce': 0.469,\n",
       " 'precipice': 0.469,\n",
       " 'revoke': 0.469,\n",
       " 'illegality': 0.469,\n",
       " 'thresh': 0.469,\n",
       " 'indict': 0.469,\n",
       " 'accused': 0.469,\n",
       " 'quiver': 0.469,\n",
       " 'toothache': 0.469,\n",
       " 'infidelity': 0.469,\n",
       " 'startle': 0.469,\n",
       " 'nervous': 0.469,\n",
       " 'unhealthy': 0.469,\n",
       " 'aftermath': 0.469,\n",
       " 'intrusive': 0.469,\n",
       " 'soulless': 0.469,\n",
       " 'fever': 0.469,\n",
       " 'asteroid': 0.469,\n",
       " 'regime': 0.469,\n",
       " 'inmate': 0.469,\n",
       " 'subversion': 0.469,\n",
       " 'admonition': 0.469,\n",
       " 'superstition': 0.469,\n",
       " 'criticize': 0.469,\n",
       " 'overwhelmed': 0.469,\n",
       " 'depressed': 0.469,\n",
       " 'decomposition': 0.469,\n",
       " 'scrapie': 0.469,\n",
       " 'animosity': 0.469,\n",
       " 'foreclose': 0.469,\n",
       " 'jaws': 0.469,\n",
       " 'idolatry': 0.469,\n",
       " 'fret': 0.469,\n",
       " 'armored': 0.469,\n",
       " 'breakdown': 0.469,\n",
       " 'spear': 0.468,\n",
       " 'nasty': 0.466,\n",
       " 'worried': 0.466,\n",
       " 'puma': 0.465,\n",
       " 'thirteenth': 0.465,\n",
       " ...}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_intensities = get_word_affect_intensity_dict(emotion)\n",
    "word_intensities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly_emo_int = PolynomialFeatures(10)\n",
    "\n",
    "def get_emo_int_vector(tweet):\n",
    "    score = 0.0\n",
    "    for word in word_intensities.keys():\n",
    "        if word in tweet:\n",
    "            score += tweet.count(word) * float(word_intensities[word])\n",
    "    return normalize(poly_emo_int.fit_transform(np.array([score]).reshape(1, -1))[0].reshape(1, -1))[0]\n",
    "    # return [score]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_emo_int_vector(\"furious\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3) SentiWordNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import sentiwordnet as swn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly_sentiwordnet = PolynomialFeatures(5)\n",
    "\n",
    "def get_sentiwordnetscore(tweet):\n",
    "    \n",
    "    score = np.zeros(2)\n",
    "    \n",
    "    for word in tweet.split():\n",
    "        synsetlist = list(swn.senti_synsets(word))\n",
    "        \n",
    "        if synsetlist:\n",
    "            score[0] += synsetlist[0].pos_score()\n",
    "            score[1] += synsetlist[0].neg_score()\n",
    "            \n",
    "#     return tweet_score.tolist()\n",
    "    return normalize(poly_sentiwordnet.fit_transform(np.array([score]).reshape(1, -1))[0].reshape(1, -1))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9.37500185e-01, 2.34375046e-01, 2.34375046e-01, 5.85937616e-02,\n",
       "       5.85937616e-02, 5.85937616e-02, 1.46484404e-02, 1.46484404e-02,\n",
       "       1.46484404e-02, 1.46484404e-02, 3.66211010e-03, 3.66211010e-03,\n",
       "       3.66211010e-03, 3.66211010e-03, 3.66211010e-03, 9.15527525e-04,\n",
       "       9.15527525e-04, 9.15527525e-04, 9.15527525e-04, 9.15527525e-04,\n",
       "       9.15527525e-04])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_sentiwordnetscore(\"furious\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4) Sentiment Emotion Presence Lexicon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_emotion_lex_file_path = ('%s%s/' %(lexicons_path, paths2[2])) + listdir('%s%s/' %(lexicons_path, paths2[2]))[0]\n",
    "\n",
    "def get_affect_presence_list(emotion):\n",
    "    word_list = list()\n",
    "    \n",
    "    with open(sentiment_emotion_lex_file_path) as sentiment_emotion_lex_file:\n",
    "        lines = sentiment_emotion_lex_file.readlines()[1:] \n",
    "        for line in lines:\n",
    "            word_array = line.replace(\"\\n\", \"\").split(\"\\t\")\n",
    "\n",
    "            if (word_array[1] == emotion and word_array[2] == '1'):\n",
    "                word_list.append(word_array[0])\n",
    "                \n",
    "    return word_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['abandon',\n",
       " 'abandoned',\n",
       " 'abandonment',\n",
       " 'abduction',\n",
       " 'abhor',\n",
       " 'abhorrent',\n",
       " 'abominable',\n",
       " 'abomination',\n",
       " 'abortion',\n",
       " 'absence',\n",
       " 'abuse',\n",
       " 'abyss',\n",
       " 'accident',\n",
       " 'accidental',\n",
       " 'accursed',\n",
       " 'accused',\n",
       " 'accuser',\n",
       " 'accusing',\n",
       " 'acrobat',\n",
       " 'adder',\n",
       " 'adjudicate',\n",
       " 'admonition',\n",
       " 'adrift',\n",
       " 'advance',\n",
       " 'adverse',\n",
       " 'adversity',\n",
       " 'afflict',\n",
       " 'affliction',\n",
       " 'affront',\n",
       " 'afraid',\n",
       " 'aftermath',\n",
       " 'aga',\n",
       " 'aggression',\n",
       " 'aggressive',\n",
       " 'aggressor',\n",
       " 'aghast',\n",
       " 'agonizing',\n",
       " 'agony',\n",
       " 'ailing',\n",
       " 'alarm',\n",
       " 'alarming',\n",
       " 'alcoholism',\n",
       " 'alertness',\n",
       " 'alerts',\n",
       " 'alien',\n",
       " 'alienation',\n",
       " 'ambulance',\n",
       " 'ambush',\n",
       " 'anaconda',\n",
       " 'anarchism',\n",
       " 'anarchist',\n",
       " 'anarchy',\n",
       " 'anathema',\n",
       " 'angina',\n",
       " 'anguish',\n",
       " 'animosity',\n",
       " 'annihilate',\n",
       " 'annihilated',\n",
       " 'annihilation',\n",
       " 'anomaly',\n",
       " 'anthrax',\n",
       " 'antichrist',\n",
       " 'antisocial',\n",
       " 'anxiety',\n",
       " 'anxious',\n",
       " 'apache',\n",
       " 'appalling',\n",
       " 'apparition',\n",
       " 'appendicitis',\n",
       " 'apprehend',\n",
       " 'apprehension',\n",
       " 'apprehensive',\n",
       " 'armament',\n",
       " 'armaments',\n",
       " 'armed',\n",
       " 'armor',\n",
       " 'armored',\n",
       " 'arraignment',\n",
       " 'arsenic',\n",
       " 'arson',\n",
       " 'artillery',\n",
       " 'asp',\n",
       " 'assail',\n",
       " 'assailant',\n",
       " 'assassin',\n",
       " 'assassinate',\n",
       " 'assassination',\n",
       " 'assault',\n",
       " 'astray',\n",
       " 'asylum',\n",
       " 'atherosclerosis',\n",
       " 'atrocity',\n",
       " 'atrophy',\n",
       " 'attack',\n",
       " 'attacking',\n",
       " 'attorney',\n",
       " 'auditor',\n",
       " 'austere',\n",
       " 'autopsy',\n",
       " 'avalanche',\n",
       " 'averse',\n",
       " 'aversion',\n",
       " 'avoid',\n",
       " 'avoidance',\n",
       " 'avoiding',\n",
       " 'awful',\n",
       " 'bacteria',\n",
       " 'bacterium',\n",
       " 'bad',\n",
       " 'badness',\n",
       " 'bailiff',\n",
       " 'bait',\n",
       " 'bale',\n",
       " 'bane',\n",
       " 'bang',\n",
       " 'banger',\n",
       " 'banish',\n",
       " 'banished',\n",
       " 'bankrupt',\n",
       " 'bankruptcy',\n",
       " 'banshee',\n",
       " 'barbarian',\n",
       " 'barbaric',\n",
       " 'barricade',\n",
       " 'batter',\n",
       " 'battered',\n",
       " 'battled',\n",
       " 'battlefield',\n",
       " 'bayonet',\n",
       " 'bear',\n",
       " 'bearish',\n",
       " 'beast',\n",
       " 'beastly',\n",
       " 'beating',\n",
       " 'bee',\n",
       " 'behemoth',\n",
       " 'belittle',\n",
       " 'belligerent',\n",
       " 'belt',\n",
       " 'bestial',\n",
       " 'beware',\n",
       " 'bewildered',\n",
       " 'bewilderment',\n",
       " 'bier',\n",
       " 'bigot',\n",
       " 'bigoted',\n",
       " 'biopsy',\n",
       " 'birch',\n",
       " 'birth',\n",
       " 'bitch',\n",
       " 'blackmail',\n",
       " 'blackness',\n",
       " 'blast',\n",
       " 'bleeding',\n",
       " 'blemish',\n",
       " 'blight',\n",
       " 'blindfold',\n",
       " 'blob',\n",
       " 'blockade',\n",
       " 'bloodshed',\n",
       " 'bloodthirsty',\n",
       " 'bloody',\n",
       " 'blues',\n",
       " 'bomb',\n",
       " 'bombard',\n",
       " 'bombardment',\n",
       " 'bomber',\n",
       " 'bondage',\n",
       " 'bottomless',\n",
       " 'brawl',\n",
       " 'brigade',\n",
       " 'brimstone',\n",
       " 'broke',\n",
       " 'broken',\n",
       " 'brutal',\n",
       " 'brutality',\n",
       " 'brute',\n",
       " 'buck',\n",
       " 'bug',\n",
       " 'bugaboo',\n",
       " 'bully',\n",
       " 'bunker',\n",
       " 'burdensome',\n",
       " 'burglar',\n",
       " 'burial',\n",
       " 'buried',\n",
       " 'burke',\n",
       " 'busted',\n",
       " 'butcher',\n",
       " 'buzz',\n",
       " 'cabal',\n",
       " 'cadaver',\n",
       " 'campaigning',\n",
       " 'cancer',\n",
       " 'cane',\n",
       " 'cannibal',\n",
       " 'cannon',\n",
       " 'captive',\n",
       " 'captor',\n",
       " 'carcass',\n",
       " 'carcinoma',\n",
       " 'cardiomyopathy',\n",
       " 'carnage',\n",
       " 'carnivorous',\n",
       " 'cartridge',\n",
       " 'case',\n",
       " 'cash',\n",
       " 'casket',\n",
       " 'casualty',\n",
       " 'cataract',\n",
       " 'catastrophe',\n",
       " 'caution',\n",
       " 'cautionary',\n",
       " 'cautious',\n",
       " 'cautiously',\n",
       " 'cemetery',\n",
       " 'censor',\n",
       " 'chaff',\n",
       " 'challenge',\n",
       " 'change',\n",
       " 'chaos',\n",
       " 'chargeable',\n",
       " 'chasm',\n",
       " 'chicken',\n",
       " 'chimera',\n",
       " 'cholera',\n",
       " 'clashing',\n",
       " 'claw',\n",
       " 'cleave',\n",
       " 'cliff',\n",
       " 'cloudiness',\n",
       " 'cobra',\n",
       " 'coerce',\n",
       " 'coercion',\n",
       " 'coffin',\n",
       " 'coldness',\n",
       " 'collapse',\n",
       " 'collusion',\n",
       " 'coma',\n",
       " 'comatose',\n",
       " 'combat',\n",
       " 'combatant',\n",
       " 'combative',\n",
       " 'communism',\n",
       " 'compassion',\n",
       " 'concealed',\n",
       " 'concealment',\n",
       " 'concerned',\n",
       " 'condemnation',\n",
       " 'confession',\n",
       " 'confessional',\n",
       " 'confidence',\n",
       " 'confine',\n",
       " 'confined',\n",
       " 'confinement',\n",
       " 'conflagration',\n",
       " 'conflict',\n",
       " 'confusion',\n",
       " 'conquest',\n",
       " 'conspiracy',\n",
       " 'conspirator',\n",
       " 'conspire',\n",
       " 'consternation',\n",
       " 'constrain',\n",
       " 'constraint',\n",
       " 'contagion',\n",
       " 'contagious',\n",
       " 'contaminated',\n",
       " 'contempt',\n",
       " 'contentious',\n",
       " 'contraband',\n",
       " 'convict',\n",
       " 'cop',\n",
       " 'corrosive',\n",
       " 'corrupting',\n",
       " 'counsellor',\n",
       " 'courageous',\n",
       " 'court',\n",
       " 'cove',\n",
       " 'coward',\n",
       " 'cowardice',\n",
       " 'cowardly',\n",
       " 'coy',\n",
       " 'coyote',\n",
       " 'cracked',\n",
       " 'crash',\n",
       " 'crazed',\n",
       " 'crazy',\n",
       " 'creature',\n",
       " 'criminal',\n",
       " 'criminality',\n",
       " 'cringe',\n",
       " 'cripple',\n",
       " 'criticize',\n",
       " 'crocodile',\n",
       " 'cross',\n",
       " 'crouch',\n",
       " 'crouching',\n",
       " 'crucifixion',\n",
       " 'cruel',\n",
       " 'cruelly',\n",
       " 'cruelty',\n",
       " 'crusade',\n",
       " 'crushed',\n",
       " 'crushing',\n",
       " 'crypt',\n",
       " 'cult',\n",
       " 'cupping',\n",
       " 'cur',\n",
       " 'curse',\n",
       " 'cursed',\n",
       " 'cutter',\n",
       " 'cutthroat',\n",
       " 'cutting',\n",
       " 'cyanide',\n",
       " 'cyclone',\n",
       " 'cyst',\n",
       " 'daemon',\n",
       " 'dagger',\n",
       " 'damnation',\n",
       " 'danger',\n",
       " 'dangerous',\n",
       " 'darken',\n",
       " 'darkened',\n",
       " 'darkness',\n",
       " 'dart',\n",
       " 'dashed',\n",
       " 'dastardly',\n",
       " 'deadly',\n",
       " 'death',\n",
       " 'debacle',\n",
       " 'debauchery',\n",
       " 'decay',\n",
       " 'deceit',\n",
       " 'decomposition',\n",
       " 'defamation',\n",
       " 'default',\n",
       " 'defection',\n",
       " 'defend',\n",
       " 'defendant',\n",
       " 'defense',\n",
       " 'defenseless',\n",
       " 'defiance',\n",
       " 'deflation',\n",
       " 'deformity',\n",
       " 'defy',\n",
       " 'degrading',\n",
       " 'delay',\n",
       " 'deleterious',\n",
       " 'deluge',\n",
       " 'delusion',\n",
       " 'delusional',\n",
       " 'demented',\n",
       " 'dementia',\n",
       " 'demise',\n",
       " 'demon',\n",
       " 'demonic',\n",
       " 'demoralized',\n",
       " 'dentistry',\n",
       " 'denunciation',\n",
       " 'dependence',\n",
       " 'deplorable',\n",
       " 'deport',\n",
       " 'deportation',\n",
       " 'depraved',\n",
       " 'depreciated',\n",
       " 'depreciation',\n",
       " 'depress',\n",
       " 'depressed',\n",
       " 'deprivation',\n",
       " 'deranged',\n",
       " 'derogation',\n",
       " 'derogatory',\n",
       " 'descent',\n",
       " 'desecration',\n",
       " 'desert',\n",
       " 'deserted',\n",
       " 'desolation',\n",
       " 'despair',\n",
       " 'despairing',\n",
       " 'despotic',\n",
       " 'despotism',\n",
       " 'destination',\n",
       " 'destitute',\n",
       " 'destroyed',\n",
       " 'destroyer',\n",
       " 'destroying',\n",
       " 'destructive',\n",
       " 'detainee',\n",
       " 'deteriorate',\n",
       " 'deterioration',\n",
       " 'detonate',\n",
       " 'devastate',\n",
       " 'devastating',\n",
       " 'devastation',\n",
       " 'devil',\n",
       " 'devilish',\n",
       " 'diabolical',\n",
       " 'diagnosis',\n",
       " 'dictator',\n",
       " 'dictatorship',\n",
       " 'die',\n",
       " 'difficult',\n",
       " 'difficulty',\n",
       " 'dike',\n",
       " 'dinosaur',\n",
       " 'dire',\n",
       " 'disable',\n",
       " 'disabled',\n",
       " 'disallowed',\n",
       " 'disappear',\n",
       " 'disapprove',\n",
       " 'disaster',\n",
       " 'disastrous',\n",
       " 'discipline',\n",
       " 'discontent',\n",
       " 'discontinuity',\n",
       " 'discourage',\n",
       " 'discrimination',\n",
       " 'disease',\n",
       " 'diseased',\n",
       " 'disembodied',\n",
       " 'disfigured',\n",
       " 'disgust',\n",
       " 'disgusting',\n",
       " 'dishonor',\n",
       " 'disinformation',\n",
       " 'disintegrate',\n",
       " 'dislocated',\n",
       " 'dismal',\n",
       " 'dismay',\n",
       " 'dismemberment',\n",
       " 'dismissal',\n",
       " 'disorder',\n",
       " 'displaced',\n",
       " 'displeased',\n",
       " 'dispossessed',\n",
       " 'disreputable',\n",
       " 'disrespectful',\n",
       " 'disruption',\n",
       " 'dissident',\n",
       " 'dissolution',\n",
       " 'distress',\n",
       " 'distressed',\n",
       " 'distressing',\n",
       " 'distrust',\n",
       " 'disturbance',\n",
       " 'divorce',\n",
       " 'dominant',\n",
       " 'dominate',\n",
       " 'domination',\n",
       " 'dominion',\n",
       " 'doom',\n",
       " 'doomed',\n",
       " 'doomsday',\n",
       " 'doubt',\n",
       " 'downfall',\n",
       " 'dragon',\n",
       " 'dread',\n",
       " 'dreadful',\n",
       " 'dreadfully',\n",
       " 'drown',\n",
       " 'dubious',\n",
       " 'duel',\n",
       " 'dungeon',\n",
       " 'duress',\n",
       " 'dwarfed',\n",
       " 'dying',\n",
       " 'earthquake',\n",
       " 'edict',\n",
       " 'eel',\n",
       " 'elevation',\n",
       " 'elf',\n",
       " 'elimination',\n",
       " 'emaciated',\n",
       " 'embarrassment',\n",
       " 'embolism',\n",
       " 'emergency',\n",
       " 'encroachment',\n",
       " 'encumbrance',\n",
       " 'endanger',\n",
       " 'endangered',\n",
       " 'endemic',\n",
       " 'endless',\n",
       " 'endocarditis',\n",
       " 'enemy',\n",
       " 'enforce',\n",
       " 'enigmatic',\n",
       " 'enmity',\n",
       " 'enslaved',\n",
       " 'entangled',\n",
       " 'epidemic',\n",
       " 'eradication',\n",
       " 'erase',\n",
       " 'eruption',\n",
       " 'escape',\n",
       " 'escaped',\n",
       " 'ethereal',\n",
       " 'euthanasia',\n",
       " 'evacuate',\n",
       " 'evade',\n",
       " 'evasion',\n",
       " 'eventuality',\n",
       " 'eviction',\n",
       " 'evil',\n",
       " 'exacerbation',\n",
       " 'examination',\n",
       " 'excitation',\n",
       " 'excite',\n",
       " 'exclusion',\n",
       " 'excruciating',\n",
       " 'execution',\n",
       " 'executioner',\n",
       " 'exigent',\n",
       " 'exile',\n",
       " 'exorcism',\n",
       " 'expel',\n",
       " 'explode',\n",
       " 'explosion',\n",
       " 'explosive',\n",
       " 'expose',\n",
       " 'expulsion',\n",
       " 'exterminate',\n",
       " 'extermination',\n",
       " 'extrajudicial',\n",
       " 'failing',\n",
       " 'failure',\n",
       " 'fainting',\n",
       " 'falter',\n",
       " 'fanaticism',\n",
       " 'fang',\n",
       " 'fangs',\n",
       " 'fatal',\n",
       " 'fatality',\n",
       " 'fear',\n",
       " 'fearful',\n",
       " 'fearfully',\n",
       " 'fearing',\n",
       " 'fearless',\n",
       " 'feeling',\n",
       " 'felon',\n",
       " 'ferocious',\n",
       " 'fever',\n",
       " 'fiend',\n",
       " 'fierce',\n",
       " 'fight',\n",
       " 'fire',\n",
       " 'firearms',\n",
       " 'fled',\n",
       " 'flee',\n",
       " 'flinch',\n",
       " 'flog',\n",
       " 'flood',\n",
       " 'flounder',\n",
       " 'flu',\n",
       " 'fluctuation',\n",
       " 'flying',\n",
       " 'foe',\n",
       " 'forbidding',\n",
       " 'force',\n",
       " 'forced',\n",
       " 'forcibly',\n",
       " 'foreboding',\n",
       " 'foreclose',\n",
       " 'foreigner',\n",
       " 'forewarned',\n",
       " 'forfeiture',\n",
       " 'forgotten',\n",
       " 'formidable',\n",
       " 'fortress',\n",
       " 'foul',\n",
       " 'fragile',\n",
       " 'frantic',\n",
       " 'fraught',\n",
       " 'freakish',\n",
       " 'frenetic',\n",
       " 'frenzied',\n",
       " 'fret',\n",
       " 'frigate',\n",
       " 'fright',\n",
       " 'frighten',\n",
       " 'frightened',\n",
       " 'frightful',\n",
       " 'fugitive',\n",
       " 'fury',\n",
       " 'gallows',\n",
       " 'gang',\n",
       " 'gash',\n",
       " 'gasping',\n",
       " 'gent',\n",
       " 'ghastly',\n",
       " 'ghetto',\n",
       " 'ghost',\n",
       " 'ghostly',\n",
       " 'giant',\n",
       " 'gladiator',\n",
       " 'glare',\n",
       " 'gnome',\n",
       " 'goblin',\n",
       " 'god',\n",
       " 'gonorrhea',\n",
       " 'gore',\n",
       " 'gory',\n",
       " 'government',\n",
       " 'graduation',\n",
       " 'grave',\n",
       " 'grenade',\n",
       " 'grieve',\n",
       " 'grievous',\n",
       " 'grim',\n",
       " 'grisly',\n",
       " 'grizzly',\n",
       " 'grope',\n",
       " 'grounded',\n",
       " 'growl',\n",
       " 'growling',\n",
       " 'guard',\n",
       " 'guerilla',\n",
       " 'guillotine',\n",
       " 'gulp',\n",
       " 'gun',\n",
       " 'gunpowder',\n",
       " 'hag',\n",
       " 'hallucination',\n",
       " 'halter',\n",
       " 'halting',\n",
       " 'hanging',\n",
       " 'hangman',\n",
       " 'harbinger',\n",
       " 'hardened',\n",
       " 'harm',\n",
       " 'harmful',\n",
       " 'harrowing',\n",
       " 'harshness',\n",
       " 'hate',\n",
       " 'hateful',\n",
       " 'hatred',\n",
       " 'haunt',\n",
       " 'haunted',\n",
       " 'havoc',\n",
       " 'hawk',\n",
       " 'hazard',\n",
       " 'hazardous',\n",
       " 'haze',\n",
       " 'hearing',\n",
       " 'hearse',\n",
       " 'heathen',\n",
       " 'heft',\n",
       " 'heighten',\n",
       " 'hell',\n",
       " 'hellish',\n",
       " 'helmet',\n",
       " 'helpless',\n",
       " 'helplessness',\n",
       " 'hemorrhage',\n",
       " 'hesitation',\n",
       " 'hide',\n",
       " 'hideous',\n",
       " 'hiding',\n",
       " 'highest',\n",
       " 'hiss',\n",
       " 'holiness',\n",
       " 'holocaust',\n",
       " 'homeless',\n",
       " 'homework',\n",
       " 'homicidal',\n",
       " 'homicide',\n",
       " 'honest',\n",
       " 'hood',\n",
       " 'hooded',\n",
       " 'hopeless',\n",
       " 'hopelessness',\n",
       " 'horrible',\n",
       " 'horrid',\n",
       " 'horrific',\n",
       " 'horrified',\n",
       " 'horrifying',\n",
       " 'horror',\n",
       " 'horrors',\n",
       " 'hospital',\n",
       " 'hostage',\n",
       " 'hostile',\n",
       " 'hostilities',\n",
       " 'howl',\n",
       " 'hunter',\n",
       " 'hunting',\n",
       " 'hurricane',\n",
       " 'hurt',\n",
       " 'hurtful',\n",
       " 'hurting',\n",
       " 'hydra',\n",
       " 'hydrocephalus',\n",
       " 'hypertrophy',\n",
       " 'hysteria',\n",
       " 'hysterical',\n",
       " 'idolatry',\n",
       " 'ill',\n",
       " 'illegal',\n",
       " 'illegality',\n",
       " 'illegitimate',\n",
       " 'illicit',\n",
       " 'illness',\n",
       " 'immerse',\n",
       " 'immigrant',\n",
       " 'imminent',\n",
       " 'immoral',\n",
       " 'impeach',\n",
       " 'impending',\n",
       " 'impermeable',\n",
       " 'impotence',\n",
       " 'imprisoned',\n",
       " 'imprisonment',\n",
       " 'incarceration',\n",
       " 'incase',\n",
       " 'incendiary',\n",
       " 'incest',\n",
       " 'incite',\n",
       " 'incrimination',\n",
       " 'incubus',\n",
       " 'incurable',\n",
       " 'incursion',\n",
       " 'indefensible',\n",
       " 'indict',\n",
       " 'indictment',\n",
       " 'indifference',\n",
       " 'indoctrination',\n",
       " 'indomitable',\n",
       " 'ineptitude',\n",
       " 'inequality',\n",
       " 'infamous',\n",
       " 'infant',\n",
       " 'infanticide',\n",
       " 'infarct',\n",
       " 'infection',\n",
       " 'infectious',\n",
       " 'inferno',\n",
       " 'infestation',\n",
       " 'infidel',\n",
       " 'infidelity',\n",
       " 'infirmity',\n",
       " 'inflation',\n",
       " 'inflict',\n",
       " 'infliction',\n",
       " 'inhuman',\n",
       " 'injection',\n",
       " 'injure',\n",
       " 'injured',\n",
       " 'injurious',\n",
       " 'injury',\n",
       " 'inmate',\n",
       " 'insane',\n",
       " 'insanity',\n",
       " 'insecure',\n",
       " 'insecurity',\n",
       " 'insidious',\n",
       " 'insolvency',\n",
       " 'insolvent',\n",
       " 'instability',\n",
       " 'instinctive',\n",
       " 'insulting',\n",
       " 'insurmountable',\n",
       " 'intelligence',\n",
       " 'intense',\n",
       " 'intercede',\n",
       " 'interrogate',\n",
       " 'interrogation',\n",
       " 'interviewer',\n",
       " 'intimately',\n",
       " 'intimidate',\n",
       " 'intimidation',\n",
       " 'intolerance',\n",
       " 'intolerant',\n",
       " 'intrigue',\n",
       " 'intruder',\n",
       " 'intrusion',\n",
       " 'intrusive',\n",
       " 'invade',\n",
       " 'invader',\n",
       " 'iris',\n",
       " 'irrational',\n",
       " 'irreconcilable',\n",
       " 'irreparable',\n",
       " 'isolated',\n",
       " 'jail',\n",
       " 'jarring',\n",
       " 'jaundice',\n",
       " 'jaws',\n",
       " 'jealousy',\n",
       " 'jeopardize',\n",
       " 'jeopardy',\n",
       " 'journey',\n",
       " 'jungle',\n",
       " 'kerosene',\n",
       " 'khan',\n",
       " 'kidnap',\n",
       " 'kill',\n",
       " 'killing',\n",
       " 'knell',\n",
       " 'lace',\n",
       " 'lament',\n",
       " 'landslide',\n",
       " 'languishing',\n",
       " 'lash',\n",
       " 'lava',\n",
       " 'lawlessness',\n",
       " 'lawsuit',\n",
       " 'lawyer',\n",
       " 'laxative',\n",
       " 'leeches',\n",
       " 'legalized',\n",
       " 'leprosy',\n",
       " 'lethal',\n",
       " 'leukemia',\n",
       " 'libel',\n",
       " 'lifeless',\n",
       " 'lightning',\n",
       " 'lines',\n",
       " 'lion',\n",
       " 'litigate',\n",
       " 'lockup',\n",
       " 'locust',\n",
       " 'loneliness',\n",
       " 'lonely',\n",
       " 'loom',\n",
       " 'lose',\n",
       " 'loss',\n",
       " 'loyal',\n",
       " 'lunacy',\n",
       " 'lunatic',\n",
       " 'lynch',\n",
       " 'mace',\n",
       " 'mad',\n",
       " 'madden',\n",
       " 'madman',\n",
       " 'madness',\n",
       " 'mafia',\n",
       " 'mage',\n",
       " 'malaria',\n",
       " 'malevolent',\n",
       " 'malice',\n",
       " 'malicious',\n",
       " 'malignancy',\n",
       " 'malignant',\n",
       " 'mandamus',\n",
       " 'mange',\n",
       " 'mangle',\n",
       " 'maniac',\n",
       " 'manifestation',\n",
       " 'manipulation',\n",
       " 'manslaughter',\n",
       " 'marry',\n",
       " 'martyr',\n",
       " 'martyrdom',\n",
       " 'masochism',\n",
       " 'massacre',\n",
       " 'measles',\n",
       " 'medical',\n",
       " 'melee',\n",
       " 'menace',\n",
       " 'menacing',\n",
       " 'mercenary',\n",
       " 'merciless',\n",
       " 'mighty',\n",
       " 'military',\n",
       " 'militia',\n",
       " 'miscarriage',\n",
       " 'misconception',\n",
       " 'misery',\n",
       " 'misfortune',\n",
       " 'mishap',\n",
       " 'mislead',\n",
       " 'missile',\n",
       " 'missing',\n",
       " 'mistaken',\n",
       " 'mistrust',\n",
       " 'moan',\n",
       " 'mob',\n",
       " 'molestation',\n",
       " 'monster',\n",
       " 'monstrosity',\n",
       " 'morbidity',\n",
       " 'morgue',\n",
       " 'mortality',\n",
       " 'mortgage',\n",
       " 'mortgagor',\n",
       " 'mortification',\n",
       " 'mortuary',\n",
       " 'mournful',\n",
       " 'mug',\n",
       " 'mum',\n",
       " 'murder',\n",
       " 'murderer',\n",
       " 'murderous',\n",
       " 'musket',\n",
       " 'mutilation',\n",
       " 'mutiny',\n",
       " 'muzzle',\n",
       " 'mysterious',\n",
       " 'nasty',\n",
       " 'nefarious',\n",
       " 'nervous',\n",
       " 'nervousness',\n",
       " 'nether',\n",
       " 'neuralgia',\n",
       " 'neurosis',\n",
       " 'neurotic',\n",
       " 'newcomer',\n",
       " 'nightmare',\n",
       " 'noncompliance',\n",
       " 'notoriety',\n",
       " 'noxious',\n",
       " 'nurture',\n",
       " 'obey',\n",
       " 'obi',\n",
       " 'obliging',\n",
       " 'obligor',\n",
       " 'obliterate',\n",
       " 'obliterated',\n",
       " 'obliteration',\n",
       " 'oblivion',\n",
       " 'obstacle',\n",
       " 'obstruct',\n",
       " 'occult',\n",
       " 'odious',\n",
       " 'offender',\n",
       " 'offense',\n",
       " 'ogre',\n",
       " 'omen',\n",
       " 'ominous',\n",
       " 'omnipotence',\n",
       " 'opera',\n",
       " 'operation',\n",
       " 'opium',\n",
       " 'opponent',\n",
       " 'opposed',\n",
       " 'oppress',\n",
       " 'oppression',\n",
       " 'oppressive',\n",
       " 'oppressor',\n",
       " 'orc',\n",
       " 'ordnance',\n",
       " 'orphan',\n",
       " 'outburst',\n",
       " 'outcast',\n",
       " 'outcry',\n",
       " 'outpost',\n",
       " 'outsider',\n",
       " 'overpowering',\n",
       " 'overt',\n",
       " 'overthrow',\n",
       " 'owing',\n",
       " 'pain',\n",
       " 'pained',\n",
       " 'painful',\n",
       " 'palsy',\n",
       " 'pandemic',\n",
       " 'panic',\n",
       " 'parachute',\n",
       " 'parade',\n",
       " 'paralysis',\n",
       " 'paralyzed',\n",
       " 'paranoia',\n",
       " 'parasite',\n",
       " 'pare',\n",
       " 'penal',\n",
       " 'penalty',\n",
       " 'penance',\n",
       " 'penetration',\n",
       " 'perdition',\n",
       " 'peril',\n",
       " 'perilous',\n",
       " 'perish',\n",
       " 'perishing',\n",
       " 'perjury',\n",
       " 'pernicious',\n",
       " 'perpetrator',\n",
       " 'persecute',\n",
       " 'persecution',\n",
       " 'perturbation',\n",
       " 'perverse',\n",
       " 'pessimism',\n",
       " 'pessimist',\n",
       " 'pest',\n",
       " 'pestilence',\n",
       " 'phalanx',\n",
       " 'phantom',\n",
       " 'picket',\n",
       " 'pillage',\n",
       " 'pinion',\n",
       " 'pitfall',\n",
       " 'plague',\n",
       " 'plea',\n",
       " 'plight',\n",
       " 'plummet',\n",
       " 'plunder',\n",
       " 'plunge',\n",
       " 'pneumonia',\n",
       " 'poaching',\n",
       " 'poison',\n",
       " 'poisoned',\n",
       " ...]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_list = get_affect_presence_list(emotion)\n",
    "word_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentiment_emotion_feature(tweet):\n",
    "    \n",
    "    vector = np.zeros(1)\n",
    "    for word in word_list:\n",
    "        if word in tweet.split():\n",
    "            vector[0] = 1.0\n",
    "    \n",
    "    return vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_sentiment_emotion_feature(\"furious\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5) Hashtag Emotion Intensity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "hashtag_emotion_lex_file_path = ('%s%s/' %(lexicons_path, paths2[3])) + listdir('%s%s/' %(lexicons_path, paths2[3]))[0]\n",
    "    \n",
    "def get_hashtag_emotion_intensity(emotion):\n",
    "    hastag_intensities = dict()\n",
    "    \n",
    "    with open(hashtag_emotion_lex_file_path) as hashtag_emotion_lex_file:\n",
    "        for line in hashtag_emotion_lex_file:\n",
    "            word_array = line.replace(\"\\n\", \"\").split(\"\\t\")\n",
    "            \n",
    "            if (word_array[0] == emotion):\n",
    "                hastag_intensities[clean_str(word_array[1])] = float(word_array[2])\n",
    "\n",
    "    return hastag_intensities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "hashtag_emotion_intensities = get_hashtag_emotion_intensity(emotion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly_hashtag_emotion = PolynomialFeatures(10)\n",
    "\n",
    "def get_hashtag_emotion_vector(tweet):\n",
    "    score = 0.0\n",
    "    for word in hashtag_emotion_intensities.keys():\n",
    "        if word in tweet:\n",
    "            score += tweet.count(word) * float(hashtag_emotion_intensities[word])\n",
    "            \n",
    "#     return [score]\n",
    "    return normalize(poly_hashtag_emotion.fit_transform(np.array([score]).reshape(1, -1))[0].reshape(1, -1))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.0290405 , 0.03983464, 0.05464087, 0.07495048, 0.10280902,\n",
       "       0.14102238, 0.19343935, 0.26533932, 0.36396398, 0.4992467 ,\n",
       "       0.68481301])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_hashtag_emotion_vector(\"furious\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6) Emoticon Sentiment LexiconÂ¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bigrams-pmilexicon.txt', 'pairs-pmilexicon.txt', 'unigrams-pmilexicon.txt']"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "listdir('%s%s/' %(lexicons_path, paths2[4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "emoticon_lexicon_unigrams_file_path = ('%s%s/' %(lexicons_path, paths2[4])) + listdir('%s%s/' %(lexicons_path, paths2[4]))[2]\n",
    "emoticon_lexicon_bigrams_file_path = ('%s%s/' %(lexicons_path, paths2[4])) + listdir('%s%s/' %(lexicons_path, paths2[4]))[0]\n",
    "emoticon_lexicon_pairs_file_path = ('%s%s/' %(lexicons_path, paths2[4])) + listdir('%s%s/' %(lexicons_path, paths2[4]))[1]\n",
    "pair_split_string = \"---\"\n",
    "    \n",
    "def get_emoticon_lexicon_unigram_dict():\n",
    "    emoticon_lexicon_unigrams = dict()\n",
    "    with open(emoticon_lexicon_unigrams_file_path, encoding = 'UTF-8') as emoticon_lexicon_file:\n",
    "        for line in emoticon_lexicon_file:\n",
    "            word_array = line.replace(\"\\n\", \"\").split(\"\\t\")\n",
    "            emoticon_lexicon_unigrams[word_array[0]] = np.array([float(val) for val in word_array[1:]])\n",
    "    \n",
    "    return emoticon_lexicon_unigrams\n",
    "\n",
    "def get_emoticon_lexicon_bigram_dict():\n",
    "    emoticon_lexicon_bigrams = dict()\n",
    "    with open(emoticon_lexicon_bigrams_file_path, encoding = 'UTF-8') as emoticon_lexicon_file:\n",
    "        for line in emoticon_lexicon_file:\n",
    "            word_array = line.replace(\"\\n\", \"\").split(\"\\t\")\n",
    "            emoticon_lexicon_bigrams[word_array[0]] = np.array([float(val) for val in word_array[1:]])\n",
    "    \n",
    "    return emoticon_lexicon_bigrams\n",
    "\n",
    "def get_emoticon_lexicon_pairs_dict():\n",
    "    emoticon_lexicon_pairs = dict()\n",
    "    with open(emoticon_lexicon_pairs_file_path, encoding = 'UTF-8') as emoticon_lexicon_file:\n",
    "        for line in emoticon_lexicon_file:\n",
    "            word_array = line.replace(\"\\n\", \"\").split(\"\\t\")\n",
    "            pair = word_array[0].split(pair_split_string)\n",
    "            token_1 = clean_str(pair[0])\n",
    "            token_2 = clean_str(pair[1])\n",
    "            if token_1 and token_2:\n",
    "                token_1_dict = None\n",
    "                if token_1 in emoticon_lexicon_pairs.keys():\n",
    "                    token_1_dict = emoticon_lexicon_pairs[token_1]\n",
    "                else:\n",
    "                    token_1_dict = dict()\n",
    "                    \n",
    "                token_1_dict[token_2] = np.array([float(val) for val in word_array[1:]])\n",
    "                emoticon_lexicon_pairs[token_1] = token_1_dict\n",
    "    \n",
    "    return emoticon_lexicon_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "emoticon_lexicon_unigram_dict = get_emoticon_lexicon_unigram_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "emoticon_lexicon_bigram_dict = get_emoticon_lexicon_bigram_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "emoticon_lexicon_pairs_dict = get_emoticon_lexicon_pairs_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly_emoticon_lexicon = PolynomialFeatures(5)\n",
    "\n",
    "def get_unigram_sentiment_emoticon_lexicon_vector(tokens):\n",
    "    vector_list = np.zeros(3)\n",
    "    counter = 0\n",
    "    for token in tokens:\n",
    "        word = clean_str(token)\n",
    "        if word in emoticon_lexicon_unigram_dict.keys():\n",
    "            vector_list += emoticon_lexicon_unigram_dict[word]\n",
    "            counter += 1\n",
    "    if counter > 0:\n",
    "        vector_list /= counter\n",
    "        \n",
    "#     return vector_list\n",
    "    return normalize(poly_emoticon_lexicon.fit_transform(vector_list.reshape(1, -1))[0].reshape(1, -1))[0]\n",
    "\n",
    "\n",
    "def get_bigram_sentiment_emoticon_lexicon_vector(tokens):\n",
    "    bi_tokens = bigrams(tokens)\n",
    "    vector_list = np.zeros(3)\n",
    "    counter = 0\n",
    "    for bi_token in bi_tokens:\n",
    "        word = clean_str(\" \".join(bi_token))\n",
    "        if word in emoticon_lexicon_bigram_dict.keys():\n",
    "            vector_list += emoticon_lexicon_bigram_dict[word]\n",
    "            counter += 1\n",
    "    if counter > 0:\n",
    "        vector_list /= counter\n",
    "        \n",
    "#     return vector_list\n",
    "    return normalize(poly_emoji_intensity.fit_transform(vector_list.reshape(1, -1))[0].reshape(1, -1))[0].tolist()\n",
    "\n",
    "def get_pair_sentiment_emoticon_lexicon_vector(tokens):\n",
    "    vector_list = np.zeros(3)\n",
    "    counter = 0\n",
    "    \n",
    "    for i in range(len(tokens)):\n",
    "        word_1 = clean_str(tokens[i])\n",
    "        if word_1 in emoticon_lexicon_pairs_dict.keys():\n",
    "            token_1_dict = emoticon_lexicon_pairs_dict[word_1]\n",
    "            for j in range(i, len(tokens)):\n",
    "                word_2 = clean_str(tokens[j])\n",
    "                if word_2 in token_1_dict.keys():\n",
    "                    vector_list += token_1_dict[word_2]\n",
    "                    counter += 1\n",
    "                    \n",
    "    if counter > 0:\n",
    "        vector_list /= counter\n",
    "        \n",
    "#     return vector_list\n",
    "    return normalize(poly_emoji_intensity.fit_transform(vector_list.reshape(1, -1))[0].reshape(1, -1))[0].tolist()\n",
    "\n",
    "def get_sentiment_emoticon_lexicon_vector(tweet):\n",
    "    \n",
    "    tokens = word_tokenize(tweet)\n",
    "    final_list = np.asarray([])\n",
    "    \n",
    "    # Adding unigram features\n",
    "    final_list = np.append(\n",
    "        final_list,\n",
    "        get_unigram_sentiment_emoticon_lexicon_vector(tokens)\n",
    "    )\n",
    "    \n",
    "    final_list = np.append(\n",
    "        final_list,\n",
    "        get_bigram_sentiment_emoticon_lexicon_vector(tokens)\n",
    "    )\n",
    "    \n",
    "    final_list = np.append(\n",
    "        final_list,\n",
    "        get_pair_sentiment_emoticon_lexicon_vector(tokens)\n",
    "    )\n",
    "   \n",
    "    return final_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5.21931637e-10, 1.32048704e-10, 3.39255564e-08, 2.76623768e-08,\n",
       "       3.34083222e-11, 8.58316578e-09, 6.99858133e-09, 2.20516117e-06,\n",
       "       1.79805449e-06, 1.46610597e-06, 8.45230551e-12, 2.17154094e-09,\n",
       "       1.77064108e-09, 5.57905775e-07, 4.54907786e-07, 3.70924810e-07,\n",
       "       1.43335476e-04, 1.16873542e-04, 9.52968880e-05, 7.77036164e-05,\n",
       "       2.13843329e-12, 5.49399858e-10, 4.47972192e-10, 1.41150161e-07,\n",
       "       1.15091670e-07, 9.38439770e-08, 3.62638754e-05, 2.95690061e-05,\n",
       "       2.41101127e-05, 1.96590149e-05, 9.31680593e-03, 7.59678022e-03,\n",
       "       6.19429772e-03, 5.05073506e-03, 4.11829167e-03, 5.41023623e-13,\n",
       "       1.38998164e-10, 1.13336965e-10, 3.57109908e-08, 2.91181925e-08,\n",
       "       2.37425262e-08, 9.17476048e-06, 7.48095854e-06, 6.09985850e-06,\n",
       "       4.97373078e-06, 2.35715190e-03, 1.92198540e-03, 1.56715732e-03,\n",
       "       1.27783597e-03, 1.04192779e-03, 6.05592386e-01, 4.93790715e-01,\n",
       "       4.02629352e-01, 3.28297779e-01, 2.67688958e-01, 2.18269458e-01,\n",
       "       1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_sentiment_emoticon_lexicon_vector(\"furious\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7) Emoticon Sentiment Aff-Neg Lexicon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Emoticon-AFFLEX-NEGLEX-bigrams.txt', 'Emoticon-AFFLEX-NEGLEX-unigrams.txt']"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "listdir('%s%s/' %(lexicons_path, paths2[5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "emoticon_afflex_unigrams_file_path = ('%s%s/' %(lexicons_path, paths2[5])) + listdir('%s%s/' %(lexicons_path, paths2[5]))[1]\n",
    "emoticon_afflex_bigrams_file_path = ('%s%s/' %(lexicons_path, paths2[5])) + listdir('%s%s/' %(lexicons_path, paths2[5]))[0]\n",
    "    \n",
    "def get_emoticon_afflex_unigram_dict():\n",
    "    emoticon_afflex_unigrams = dict()\n",
    "    with open(emoticon_afflex_unigrams_file_path, encoding = 'UTF-8') as emoticon_lexicon_file:\n",
    "        for line in emoticon_lexicon_file:\n",
    "            word_array = line.replace(\"\\n\", \"\").split(\"\\t\")\n",
    "            emoticon_afflex_unigrams[word_array[0]] = np.array([float(val) for val in word_array[1:]])\n",
    "    \n",
    "    return emoticon_afflex_unigrams\n",
    "\n",
    "def get_emoticon_afflex_bigram_dict():\n",
    "    emoticon_afflex_bigrams = dict()\n",
    "    with open(emoticon_afflex_bigrams_file_path, encoding = 'UTF-8') as emoticon_lexicon_file:\n",
    "        for line in emoticon_lexicon_file:\n",
    "            word_array = line.replace(\"\\n\", \"\").split(\"\\t\")\n",
    "            emoticon_afflex_bigrams[word_array[0]] = np.array([float(val) for val in word_array[1:]])\n",
    "    \n",
    "    return emoticon_afflex_bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "emoticon_afflex_unigram_dict = get_emoticon_afflex_unigram_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "emoticon_afflex_bigram_dict = get_emoticon_afflex_bigram_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly_emoticon_lexicon = PolynomialFeatures(5)\n",
    "# poly_emoticon_lexicon = PolynomialFeatures(1)\n",
    "\n",
    "def get_unigram_sentiment_emoticon_afflex_vector(tokens):\n",
    "    vector_list = np.zeros(3)\n",
    "    counter = 0\n",
    "    for token in tokens:\n",
    "        word = clean_str(token)\n",
    "        if word in emoticon_afflex_unigram_dict.keys():\n",
    "            vector_list += emoticon_afflex_unigram_dict[word]\n",
    "            counter += 1\n",
    "    if counter > 0:\n",
    "        vector_list /= counter\n",
    "        \n",
    "#     return vector_list\n",
    "    return normalize(poly_emoticon_lexicon.fit_transform(vector_list.reshape(1, -1))[0].reshape(1, -1))[0]\n",
    "\n",
    "\n",
    "def get_bigram_sentiment_emoticon_afflex_vector(tokens):\n",
    "    bi_tokens = bigrams(tokens)\n",
    "    vector_list = np.zeros(3)\n",
    "    counter = 0\n",
    "    for bi_token in bi_tokens:\n",
    "        word = clean_str(\" \".join(bi_token))\n",
    "        if word in emoticon_afflex_bigram_dict.keys():\n",
    "            vector_list += emoticon_afflex_bigram_dict[word]\n",
    "            counter += 1\n",
    "    if counter > 0:\n",
    "        vector_list /= counter\n",
    "        \n",
    "#     return vector_list\n",
    "    return normalize(poly_emoticon_lexicon.fit_transform(vector_list.reshape(1, -1))[0].reshape(1, -1))[0]\n",
    "\n",
    "def get_sentiment_emoticon_afflex_vector(tweet):\n",
    "    final_list = np.asarray([])\n",
    "    tokens = word_tokenize(tweet)\n",
    "    \n",
    "    # Adding unigram features\n",
    "    final_list = np.append(final_list, get_unigram_sentiment_emoticon_afflex_vector(tokens))\n",
    "    \n",
    "    # Adding bigram featunigram_list =ures\n",
    "    final_list = np.append(final_list, get_bigram_sentiment_emoticon_afflex_vector(tokens))\n",
    "\n",
    "    return final_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.95719929e-10, 1.33357616e-10, 2.77003950e-08, 2.09731562e-08,\n",
       "       4.49415166e-11, 9.33503312e-09, 7.06795365e-09, 1.93902765e-06,\n",
       "       1.46812094e-06, 1.11157728e-06, 1.51452911e-11, 3.14590616e-09,\n",
       "       2.38190038e-09, 6.53452318e-07, 4.94756755e-07, 3.74601543e-07,\n",
       "       1.35731936e-04, 1.02768466e-04, 7.78104096e-05, 5.89135958e-05,\n",
       "       5.10396310e-12, 1.06017038e-09, 8.02700428e-10, 2.20213431e-07,\n",
       "       1.66733027e-07, 1.26240720e-07, 4.57416623e-05, 3.46329729e-05,\n",
       "       2.62221080e-05, 1.98538818e-05, 9.50123549e-03, 7.19379259e-03,\n",
       "       5.44672867e-03, 4.12395171e-03, 3.12242058e-03, 1.72003556e-12,\n",
       "       3.57277417e-10, 2.70510044e-10, 7.42119264e-08, 5.61890300e-08,\n",
       "       4.25431227e-08, 1.54149402e-05, 1.16713119e-05, 8.83685041e-06,\n",
       "       6.69075817e-06, 3.20191636e-03, 2.42430810e-03, 1.83554756e-03,\n",
       "       1.38977173e-03, 1.05225574e-03, 6.65086484e-01, 5.03565481e-01,\n",
       "       3.81271007e-01, 2.88676620e-01, 2.18569441e-01, 1.65488291e-01,\n",
       "       1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_sentiment_emoticon_afflex_vector(\"furious\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8) Hashtag Sentiment Aff-Neg Lexicon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['HS-AFFLEX-NEGLEX-bigrams.txt', 'HS-AFFLEX-NEGLEX-unigrams.txt']"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "listdir('%s%s/' %(lexicons_path, paths2[6]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "hashtag_affneglex_unigrams_file_path = ('%s%s/' %(lexicons_path, paths2[6])) + listdir('%s%s/' %(lexicons_path, paths2[6]))[1]\n",
    "hashtag_affneglex_bigrams_file_path = ('%s%s/' %(lexicons_path, paths2[6])) + listdir('%s%s/' %(lexicons_path, paths2[6]))[0]\n",
    "    \n",
    "def get_hashtag_affneglex_unigram_dict():\n",
    "    hashtag_affneglex_unigrams = dict()\n",
    "    with open(hashtag_affneglex_unigrams_file_path) as hashtag_sent_lex_file:\n",
    "        for line in hashtag_sent_lex_file:\n",
    "            word_array = line.replace(\"\\n\", \"\").split(\"\\t\")\n",
    "            hashtag_affneglex_unigrams[clean_str(word_array[0])] = np.array([float(val) for val in word_array[1:]])\n",
    "    \n",
    "    return hashtag_affneglex_unigrams\n",
    "\n",
    "def get_hashtag_affneglex_bigram_dict():\n",
    "    hashtag_affneglex_bigrams = dict()\n",
    "    with open(hashtag_affneglex_bigrams_file_path) as hashtag_sent_lex_file:\n",
    "        for line in hashtag_sent_lex_file:\n",
    "            word_array = line.replace(\"\\n\", \"\").split(\"\\t\")\n",
    "            hashtag_affneglex_bigrams[clean_str(word_array[0])] = np.array([float(val) for val in word_array[1:]])\n",
    "\n",
    "    return hashtag_affneglex_bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "hashtag_affneglex_unigram_dict = get_hashtag_affneglex_unigram_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "hashtag_affneglex_bigram_dict = get_hashtag_affneglex_bigram_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly_hashtag_sent_affneglex = PolynomialFeatures(5)\n",
    "\n",
    "def get_unigram_sentiment_hashtag_affneglex_vector(tokens):\n",
    "    vector_list = np.zeros(3)\n",
    "    counter = 0\n",
    "    for token in tokens:\n",
    "        word = clean_str(token)\n",
    "        if word in hashtag_affneglex_unigram_dict.keys():\n",
    "            vector_list += hashtag_affneglex_unigram_dict[word]\n",
    "            counter += 1\n",
    "    if counter > 0:\n",
    "        vector_list /= counter\n",
    "        \n",
    "#     return vector_list\n",
    "    return normalize(poly_hashtag_sent_affneglex.fit_transform(vector_list.reshape(1, -1))[0].reshape(1, -1))[0]\n",
    "\n",
    "def get_bigram_sentiment_hashtag_affneglex_vector(tokens):\n",
    "    bi_tokens = bigrams(tokens)\n",
    "    vector_list = np.zeros(3)\n",
    "    counter = 0\n",
    "    for bi_token in bi_tokens:\n",
    "        word = clean_str(\" \".join(bi_token))\n",
    "        if word in hashtag_affneglex_bigram_dict.keys():\n",
    "            vector_list += hashtag_affneglex_bigram_dict[word]\n",
    "            counter += 1\n",
    "    if counter > 0:\n",
    "        vector_list /= counter\n",
    "        \n",
    "#     return vector_list\n",
    "    return normalize(poly_hashtag_sent_affneglex.fit_transform(vector_list.reshape(1, -1))[0].reshape(1, -1))[0]\n",
    "\n",
    "def get_sentiment_hashtag_affneglex_vector(tweet):\n",
    "    final_list = np.asarray([])\n",
    "    tokens = word_tokenize(tweet)\n",
    "    \n",
    "    # Adding unigram features\n",
    "    final_list = np.append(final_list, get_unigram_sentiment_hashtag_affneglex_vector(tokens))\n",
    "    # Adding bigram features\n",
    "    final_list = np.append(final_list, get_bigram_sentiment_hashtag_affneglex_vector(tokens))\n",
    "\n",
    "    return final_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.50661452e-05, -5.16768782e-06,  6.02645810e-05,  1.35595307e-04,\n",
       "        1.77251692e-06, -2.06707513e-05, -4.65091904e-05,  2.41058324e-04,\n",
       "        5.42381229e-04,  1.22035777e-03, -6.07973304e-07,  7.09006769e-06,\n",
       "        1.59526523e-05, -8.26830051e-05, -1.86036762e-04, -4.18582713e-04,\n",
       "        9.64233296e-04,  2.16952492e-03,  4.88143106e-03,  1.09832199e-02,\n",
       "        2.08534843e-07, -2.43189322e-06, -5.47175974e-06,  2.83602708e-05,\n",
       "        6.38106092e-05,  1.43573871e-04, -3.30732020e-04, -7.44147046e-04,\n",
       "       -1.67433085e-03, -3.76724442e-03,  3.85693318e-03,  8.67809966e-03,\n",
       "        1.95257242e-02,  4.39328795e-02,  9.88489790e-02, -7.15274513e-08,\n",
       "        8.34139374e-07,  1.87681359e-06, -9.72757287e-06, -2.18870390e-05,\n",
       "       -4.92458377e-05,  1.13441083e-04,  2.55242437e-04,  5.74295483e-04,\n",
       "        1.29216484e-03, -1.32292808e-03, -2.97658818e-03, -6.69732341e-03,\n",
       "       -1.50689777e-02, -3.39051998e-02,  1.54277327e-02,  3.47123987e-02,\n",
       "        7.81028970e-02,  1.75731518e-01,  3.95395916e-01,  8.89640811e-01,\n",
       "        1.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_sentiment_hashtag_affneglex_vector(\"furious\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9) Hashtag Sentiment Lexicon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['HS-bigrams.txt', 'HS-pairs.txt', 'HS-unigrams.txt']"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "listdir('%s%s/' %(lexicons_path, paths2[7]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "hash_sent_lex_unigrams_file_path = ('%s%s/' %(lexicons_path, paths2[7])) + listdir('%s%s/' %(lexicons_path, paths2[7]))[2]\n",
    "hash_sent_lex_bigrams_file_path = ('%s%s/' %(lexicons_path, paths2[7])) + listdir('%s%s/' %(lexicons_path, paths2[7]))[0]\n",
    "hash_sent_lex_pairs_file_path = ('%s%s/' %(lexicons_path, paths2[7])) + listdir('%s%s/' %(lexicons_path, paths2[7]))[1]\n",
    "pair_split_string = \"---\"\n",
    "\n",
    "\n",
    "def get_hash_sent_lex_unigram_dict():\n",
    "    hash_sent_lex_unigrams = dict()\n",
    "    with open(hash_sent_lex_unigrams_file_path) as hash_sent_lex_file:\n",
    "        for line in hash_sent_lex_file:\n",
    "            word_array = line.replace(\"\\n\", \"\").split(\"\\t\")\n",
    "            if clean_str(word_array[0]):\n",
    "                hash_sent_lex_unigrams[word_array[0]] = np.array([float(val) for val in word_array[1:]])\n",
    "    \n",
    "    return hash_sent_lex_unigrams\n",
    "\n",
    "def get_hash_sent_lex_bigram_dict():\n",
    "    hash_sent_lex_bigrams = dict()\n",
    "    with open(hash_sent_lex_bigrams_file_path) as hash_sent_lex_file:\n",
    "        for line in hash_sent_lex_file:\n",
    "            word_array = line.replace(\"\\n\", \"\").split(\"\\t\")\n",
    "            if clean_str(word_array[0]):\n",
    "                hash_sent_lex_bigrams[word_array[0]] = np.array([float(val) for val in word_array[1:]])\n",
    "    \n",
    "    return hash_sent_lex_bigrams\n",
    "\n",
    "def get_hash_sent_lex_pairs_dict():\n",
    "    hash_sent_lex_pairs = dict()\n",
    "    with open(hash_sent_lex_pairs_file_path) as hash_sent_lex_file:\n",
    "        for line in hash_sent_lex_file:\n",
    "            word_array = line.replace(\"\\n\", \"\").split(\"\\t\")\n",
    "            pair = word_array[0].split(pair_split_string)\n",
    "            token_1 = clean_str(pair[0])\n",
    "            token_2 = clean_str(pair[1])\n",
    "            if token_1 and token_2:\n",
    "                token_1_dict = None\n",
    "                if token_1 in hash_sent_lex_pairs.keys():\n",
    "                    token_1_dict = hash_sent_lex_pairs[token_1]\n",
    "                else:\n",
    "                    token_1_dict = dict()\n",
    "                    \n",
    "                token_1_dict[token_2] = np.array([float(val) for val in word_array[1:]])\n",
    "                hash_sent_lex_pairs[token_1] = token_1_dict\n",
    "    \n",
    "    return hash_sent_lex_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "hash_sent_lex_unigram_dict = get_hash_sent_lex_unigram_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "hash_sent_lex_bigram_dict = get_hash_sent_lex_bigram_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "hash_sent_lex_pairs_dict = get_hash_sent_lex_pairs_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly_hash_sent_lex = PolynomialFeatures(5)\n",
    "\n",
    "def get_unigram_sentiment_hash_sent_lex_vector(tokens):\n",
    "    vector_list = np.zeros(3)\n",
    "    counter = 0\n",
    "    \n",
    "    for token in tokens:\n",
    "        word = clean_str(token)\n",
    "        if word in hash_sent_lex_unigram_dict.keys():\n",
    "            vector_list += hash_sent_lex_unigram_dict[word]\n",
    "            counter += 1\n",
    "\n",
    "    if counter > 0:\n",
    "        vector_list /= counter\n",
    "    \n",
    "#     return vector_list\n",
    "    return normalize(poly_hash_sent_lex.fit_transform(vector_list.reshape(1, -1))[0].reshape(1, -1))[0]\n",
    "    \n",
    "def get_bigram_sentiment_hash_sent_lex_vector(tokens):\n",
    "    bi_tokens = bigrams(tokens)\n",
    "    vector_list = np.zeros(3)\n",
    "    counter = 0\n",
    "    for bi_token in bi_tokens:\n",
    "        word = clean_str(\" \".join(bi_token))\n",
    "        if word in hash_sent_lex_bigram_dict.keys():\n",
    "            vector_list += hash_sent_lex_bigram_dict[word]\n",
    "            counter += 1\n",
    "    if counter > 0:\n",
    "        vector_list /= counter\n",
    "    \n",
    "#     return vector_list\n",
    "    return normalize(poly_hash_sent_lex.fit_transform(vector_list.reshape(1, -1))[0].reshape(1, -1))[0]\n",
    "\n",
    "def get_pair_sentiment_hash_sent_lex_vector(tokens):\n",
    "    vector_list = np.zeros(3)\n",
    "    counter = 0\n",
    "    \n",
    "    for i in range(len(tokens)):\n",
    "        word_1 = clean_str(tokens[i])\n",
    "        if word_1 in hash_sent_lex_pairs_dict.keys():\n",
    "            token_1_dict = hash_sent_lex_pairs_dict[word_1]\n",
    "            for j in range(i, len(tokens)):\n",
    "                word_2 = clean_str(tokens[j])\n",
    "                if word_2 in token_1_dict.keys():\n",
    "                    vector_list += token_1_dict[word_2]\n",
    "                    counter += 1\n",
    "    if counter > 0:\n",
    "        vector_list /= counter\n",
    "        \n",
    "#     return vector_list\n",
    "    return normalize(poly_hash_sent_lex.fit_transform(vector_list.reshape(1, -1))[0].reshape(1, -1))[0]\n",
    "    \n",
    "def get_sentiment_hash_sent_lex_vector(tweet):\n",
    "    final_list = np.asarray([])\n",
    "    \n",
    "    tokens = word_tokenize(tweet)\n",
    "    \n",
    "    # Adding unigram features\n",
    "    final_list = np.append(final_list, get_unigram_sentiment_hash_sent_lex_vector(tokens))\n",
    "    # Adding bigram features\n",
    "    final_list = np.append(final_list, get_bigram_sentiment_hash_sent_lex_vector(tokens))\n",
    "    # Adding pair features\n",
    "    final_list = np.append(final_list, get_pair_sentiment_hash_sent_lex_vector(tokens))\n",
    "\n",
    "    return final_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5.09887390e-09, 3.39075115e-09, 2.09053830e-07, 1.73361713e-07,\n",
       "       2.25484951e-09, 1.39020797e-07, 1.15285539e-07, 8.57120703e-06,\n",
       "       7.10783022e-06, 5.89429823e-06, 1.49947493e-09, 9.24488300e-08,\n",
       "       7.66648834e-08, 5.69985268e-06, 4.72670710e-06, 3.91970833e-06,\n",
       "       3.51419488e-04, 2.91421039e-04, 2.41666228e-04, 2.00406140e-04,\n",
       "       9.97150826e-10, 6.14784720e-08, 5.09821475e-08, 3.79040203e-06,\n",
       "       3.14326022e-06, 2.60660604e-06, 2.33693960e-04, 1.93794991e-04,\n",
       "       1.60708041e-04, 1.33270083e-04, 1.44081990e-02, 1.19482626e-02,\n",
       "       9.90831533e-03, 8.21665174e-03, 6.81380876e-03, 6.63105299e-10,\n",
       "       4.08831839e-08, 3.39031281e-08, 2.52061735e-06, 2.09026805e-06,\n",
       "       1.73339301e-06, 1.55406483e-04, 1.28873669e-04, 1.06870848e-04,\n",
       "       8.86246052e-05, 9.58145235e-03, 7.94559463e-03, 6.58902970e-03,\n",
       "       5.46407341e-03, 4.53118282e-03, 5.90736160e-01, 4.89878767e-01,\n",
       "       4.06240929e-01, 3.36882721e-01, 2.79366159e-01, 2.31669498e-01,\n",
       "       1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_sentiment_hash_sent_lex_vector(\"furious\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10) Depeche Mood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "depeche_mood_file_path = ('%s%s/' %(lexicons_path, paths2[8])) + listdir('%s%s/' %(lexicons_path, paths2[8]))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_depeche_vector_dict():\n",
    "    depeche_vector_dict = dict()\n",
    "    with open(depeche_mood_file_path) as depeche_mood_file:\n",
    "        lines = depeche_mood_file.readlines()[1:] \n",
    "        for line in lines:\n",
    "            word_array = line.replace(\"\\n\", \"\").split(\"\\t\")\n",
    "            depeche_vector_dict[word_array[0].split(\"#\")[0]] = np.array([float(val) for val in word_array[1:]])\n",
    "    \n",
    "    return depeche_vector_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "depeche_vector_dict = get_depeche_vector_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "print(len(depeche_vector_dict[\"0\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly_depm = PolynomialFeatures(5)\n",
    "\n",
    "def get_depeche_mood_vector(tweet):\n",
    "    vector_list = np.zeros(8)\n",
    "    tokens = word_tokenize(tweet)\n",
    "    counter = 0\n",
    "    \n",
    "    for token in tokens:\n",
    "        if token in depeche_vector_dict.keys():\n",
    "            vector_list += np.array(depeche_vector_dict[token])\n",
    "            counter += 1\n",
    "    \n",
    "    if counter > 0:\n",
    "        vector_list /= counter\n",
    "        \n",
    "    return normalize(poly_depm.fit_transform(vector_list.reshape(1, -1))[0].reshape(1, -1))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9.34469068e-01, 5.98056709e-02, 1.49434297e-01, ...,\n",
       "       1.06644824e-05, 5.70178406e-06, 3.04846875e-06])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_depeche_mood_vector(\"i am so mad about power rangers. i am incensed. i am furious.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (3)  Prepare Sentence Vectors as Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_active_vector_method(string):\n",
    "    return int(string)\n",
    "\n",
    "\n",
    "def vectorize_tweets(tweet_list, bin_string, vector_dict):\n",
    "\n",
    "    vectors = list()\n",
    "    frames = list()\n",
    "\n",
    "    '''Pre-trained Word embeddings'''\n",
    "    index = 0\n",
    "    if is_active_vector_method(bin_string[index]):\n",
    "        if index not in vector_dict.keys():\n",
    "            tmp_vector = \\\n",
    "                pd.DataFrame(list(map(lambda x: get_averaged_embeddings(x, wv_model_g, w2v_dimensions_g), tweet_list)))\n",
    "            vector_dict[index] = tmp_vector\n",
    "        frames.append(vector_dict[index])\n",
    "\n",
    "    index = 1\n",
    "    if is_active_vector_method(bin_string[index]):\n",
    "        if index not in vector_dict.keys():\n",
    "            tmp_vector = \\\n",
    "                pd.DataFrame(list(map(lambda x: get_averaged_embeddings(x, wv_model_w, w2v_dimensions_w), tweet_list)))\n",
    "            vector_dict[index] = tmp_vector\n",
    "        frames.append(vector_dict[index])\n",
    "\n",
    "\n",
    "    '''NRC Emotion Intensity Lexicon'''\n",
    "    index = 2\n",
    "    if is_active_vector_method(bin_string[index]):\n",
    "        if index not in vector_dict.keys():\n",
    "            tmp_vector = pd.DataFrame(list(map(lambda x: get_emo_int_vector(x), tweet_list)))\n",
    "            vector_dict[index] = tmp_vector\n",
    "        frames.append(vector_dict[index])\n",
    "\n",
    "    '''WordNet'''\n",
    "    index = 3\n",
    "    if is_active_vector_method(bin_string[index]):\n",
    "        if index not in vector_dict.keys():\n",
    "            tmp_vector = pd.DataFrame(list(map(lambda x: get_sentiwordnetscore(x), tweet_list)))\n",
    "            vector_dict[index] = tmp_vector\n",
    "        frames.append(vector_dict[index])\n",
    "\n",
    "    '''NRC Sentiment Lexicon'''\n",
    "    index = 4\n",
    "    if is_active_vector_method(bin_string[index]):\n",
    "        if index not in vector_dict.keys():\n",
    "            tmp_vector = pd.DataFrame(list(map(lambda x: get_sentiment_emotion_feature(x), tweet_list)))\n",
    "            vector_dict[index] = tmp_vector\n",
    "        frames.append(vector_dict[index])\n",
    "\n",
    "    index = 5\n",
    "    if is_active_vector_method(bin_string[index]):\n",
    "        if index not in vector_dict.keys():\n",
    "            tmp_vector = pd.DataFrame(list(map(lambda x: get_sentiment_emoticon_lexicon_vector(x), tweet_list)))\n",
    "            vector_dict[index] = tmp_vector\n",
    "        frames.append(vector_dict[index])\n",
    "\n",
    "    index = 6\n",
    "    if is_active_vector_method(bin_string[index]):\n",
    "        if index not in vector_dict.keys():\n",
    "            tmp_vector = pd.DataFrame(list(map(lambda x: get_sentiment_emoticon_afflex_vector(x), tweet_list)))\n",
    "            vector_dict[index] = tmp_vector\n",
    "        frames.append(vector_dict[index])\n",
    "\n",
    "    '''NRC Hashtag Lexicon'''\n",
    "    index = 7\n",
    "    if is_active_vector_method(bin_string[index]):\n",
    "        if index not in vector_dict.keys():\n",
    "            tmp_vector = pd.DataFrame(list(map(lambda x: get_hashtag_emotion_vector(x), tweet_list)))\n",
    "            vector_dict[index] = tmp_vector\n",
    "        frames.append(vector_dict[index])\n",
    "\n",
    "    index = 8\n",
    "    if is_active_vector_method(bin_string[index]):\n",
    "        if index not in vector_dict.keys():\n",
    "            tmp_vector = pd.DataFrame(list(map(lambda x: get_sentiment_hash_sent_lex_vector(x), tweet_list)))\n",
    "            vector_dict[index] = tmp_vector\n",
    "        frames.append(vector_dict[index])\n",
    "\n",
    "    index = 9\n",
    "    if is_active_vector_method(bin_string[index]):\n",
    "        if index not in vector_dict.keys():\n",
    "            tmp_vector = pd.DataFrame(list(map(lambda x: get_sentiment_hashtag_affneglex_vector(x), tweet_list)))\n",
    "            vector_dict[index] = tmp_vector\n",
    "        frames.append(vector_dict[index])\n",
    "\n",
    "   \n",
    "    index = 10\n",
    "    if is_active_vector_method(bin_string[index]):\n",
    "        if index not in vector_dict.keys():\n",
    "            tmp_vector = pd.DataFrame(list(map(lambda x: get_emoji_intensity(x), tweet_list)))\n",
    "            vector_dict[index] = tmp_vector\n",
    "        frames.append(vector_dict[index])\n",
    "        \n",
    "    index = 11\n",
    "    if is_active_vector_method(bin_string[index]):\n",
    "        if index not in vector_dict.keys():\n",
    "            tmp_vector = pd.DataFrame(list(map(lambda x: get_depeche_mood_vector(x), tweet_list)))\n",
    "            vector_dict[index] = tmp_vector\n",
    "        frames.append(vector_dict[index])\n",
    "\n",
    "    vectors = pd.concat(frames, axis=1)\n",
    "\n",
    "    return vectors.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_index_mapping = \\\n",
    "    {\n",
    "        0: \"Glove[Twitter]\",\n",
    "        1: \"Word2Vec[Twitter]\",\n",
    "        2: \"NRC-Emotion Intensity Lexicon\",\n",
    "        3: \"Wordnet-Affect\",\n",
    "        4: \"NRC-Emotion-Lexicon\",\n",
    "        5: \"NRC-Emoticon-Lexicon\",\n",
    "        6: \"NRC-Emoticon-AffLexNegLex\",\n",
    "        7: \"NRC-Hashtag-Emotion\",\n",
    "        8: \"NRC-Hashtag-Sentiment-Lexicon\",\n",
    "        9: \"NRC-Hashtag-Sentiment-AffLexNegLex\",\n",
    "        10: \"Emoji Intensity\",\n",
    "        11: \"Depeche Mood\"\n",
    "    \n",
    "    }\n",
    "\n",
    "\n",
    "def get_features_from_identifier(bin_string):\n",
    "    features = list()\n",
    "    for i in range(len(bin_string)):\n",
    "        if int(bin_string[i]):\n",
    "            features.append(feature_index_mapping[i])\n",
    "\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Glove[Twitter]',\n",
       " 'Word2Vec[Twitter]',\n",
       " 'NRC-Emotion-Lexicon',\n",
       " 'NRC-Emoticon-Lexicon',\n",
       " 'NRC-Hashtag-Sentiment-Lexicon',\n",
       " 'Emoji Intensity']"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string1 = \"110011001010\"\n",
    "get_features_from_identifier(string1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vector_dict = dict()\n",
    "test_vector_dict = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = vectorize_tweets(train_tweets, string1, train_vector_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1257\n",
      "943\n"
     ]
    }
   ],
   "source": [
    "print(len(x_train))\n",
    "dimension = len(x_train[0])\n",
    "print(dimension)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.array(x_train)\n",
    "score_train = np.array(train_intensities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = vectorize_tweets(test_tweets, string1, test_vector_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "995\n",
      "943\n"
     ]
    }
   ],
   "source": [
    "print(len(x_test))\n",
    "print(len(x_test[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vectors_path = \"files/\" + emotion + \"_vectors/train_vectors.npy\"\n",
    "test_vectors_path = \"files/\" + emotion + \"_vectors/test_vectors.npy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save vectors_dict\n",
    "import pickle\n",
    "with open(train_vectors_path, 'wb') as train_vectors_file:\n",
    "    pickle.dump(train_vector_dict, train_vectors_file)\n",
    "\n",
    "with open(test_vectors_path, 'wb') as test_vectors_file:\n",
    "    pickle.dump(test_vector_dict, test_vectors_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Restore vectors_dict\n",
    "import pickle\n",
    "with open(train_vectors_path, 'rb') as train_vectors_file:\n",
    "    train_vector_dict = pickle.load(train_vectors_file)\n",
    "\n",
    "with open(test_vectors_path, 'rb') as test_vectors_file:\n",
    "    test_vector_dict = pickle.load(test_vectors_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_vectors_path = \"files/\" + emotion + \"_vectors/x_train.npy\"\n",
    "y_train_vectors_path = \"files/\" + emotion + \"_vectors/y_train.npy\"\n",
    "\n",
    "x_test_vectors_path = \"files/\" + emotion + \"_vectors/x_test.npy\"\n",
    "y_test_vectors_path = \"files/\" + emotion + \"_vectors/y_test.npy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save train_vectors\n",
    "import pickle\n",
    "with open(x_train_vectors_path, 'wb') as x_train_vectors_file:\n",
    "    x_train = pickle.dump(x_train, x_train_vectors_file)\n",
    "with open(y_train_vectors_path, 'wb') as y_train_vectors_file:\n",
    "    score_train = pickle.dump(score_train, y_train_vectors_file)\n",
    "\n",
    "with open(x_test_vectors_path, 'wb') as x_test_vectors_file:\n",
    "    x_test = pickle.dump(x_test, x_test_vectors_file)\n",
    "with open(y_test_vectors_path, 'wb') as y_test_vectors_file:\n",
    "    test_intensities = pickle.dump(test_intensities, y_test_vectors_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Restore vectors_dict\n",
    "with open(x_train_vectors_path, 'rb') as x_train_vectors_file:\n",
    "    x_train = pickle.load(x_train_vectors_file)\n",
    "with open(y_train_vectors_path, 'rb') as y_train_vectors_file:\n",
    "    score_train = pickle.load(y_train_vectors_file)\n",
    "\n",
    "with open(x_test_vectors_path, 'rb') as x_test_vectors_file:\n",
    "    x_test = pickle.load(x_test_vectors_file)\n",
    "with open(y_test_vectors_path, 'rb') as y_test_vectors_file:\n",
    "    test_intensities = pickle.load(y_test_vectors_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.array(x_train)\n",
    "score_train = np.array(score_train)\n",
    "\n",
    "x_test = np.array(x_test)\n",
    "test_intensities = np.array(test_intensities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1257, 943) \n",
      " (1257,) \n",
      " (995, 943) \n",
      " (995,)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape,'\\n',score_train.shape,'\\n',x_test.shape, '\\n', test_intensities.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Train a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "import numpy as np\n",
    "import scipy\n",
    "\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_lists(pred, gold):\n",
    "    if len(pred) == len(gold):\n",
    "        gold_scores=gold\n",
    "        pred_scores=pred         \n",
    "        \n",
    "        # lists storing gold and prediction scores where gold score >= 0.5\n",
    "        gold_scores_range_05_1=[]\n",
    "        pred_scores_range_05_1=[]\n",
    "         \n",
    "            \n",
    "        for i in range(len(gold_scores)):\n",
    "            if(gold_scores[i]>=0.5):\n",
    "                gold_scores_range_05_1.append(gold_scores[i])\n",
    "                pred_scores_range_05_1.append(pred_scores[i])\n",
    "                \n",
    "        # return zero correlation if predictions are constant\n",
    "        if np.std(pred_scores)==0 or np.std(gold_scores)==0:\n",
    "            return (0,0,0,0)\n",
    "        \n",
    "        pears_corr=scipy.stats.pearsonr(pred_scores,gold_scores)[0]                                    \n",
    "        spear_corr=scipy.stats.spearmanr(pred_scores,gold_scores)[0]   \n",
    "\n",
    "\n",
    "        pears_corr_range_05_1=scipy.stats.pearsonr(pred_scores_range_05_1,gold_scores_range_05_1)[0]                                    \n",
    "        spear_corr_range_05_1=scipy.stats.spearmanr(pred_scores_range_05_1,gold_scores_range_05_1)[0]           \n",
    "        \n",
    "      \n",
    "        return np.array([pears_corr,spear_corr,pears_corr_range_05_1,spear_corr_range_05_1])\n",
    "    else:\n",
    "        raise ValueError('Predictions and gold data have different number of lines.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1) XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from sklearn.metrics import make_scorer\n",
    "import scipy\n",
    "def pearson_score(ground_truth, predictions):\n",
    "    score = scipy.stats.pearsonr(predictions,ground_truth)[0]\n",
    "    return score\n",
    "PS = make_scorer(pearson_score, greater_is_better=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "ml_model = XGBRegressor(objective=\"reg:squarederror\",seed=0)\n",
    "\n",
    "# specify parameters and distributions to sample from\n",
    "param_dist = {\n",
    "     \"max_depth\": range(3, 11),\n",
    "     \"n_estimators\": [100,300,500,700,900,1000,3000]\n",
    " }\n",
    "\n",
    "\n",
    "# run randomized search\n",
    "grid_search = GridSearchCV(ml_model,param_grid=param_dist, cv=5, n_jobs=-1,return_train_score=True)\n",
    "\n",
    "trainingtime = pd.DataFrame(columns = [\"Model\", \"Training Time(Seconds)\"])\n",
    "start_time_XG =time.time()\n",
    "\n",
    "grid_search.fit(x_train, score_train)\n",
    "trainingtime.loc[0] = [\"XGBoost\", round((time.time()-start_time_XG), 2)] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-9.384355024236683"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "             colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "             importance_type='gain', interaction_constraints='',\n",
       "             learning_rate=0.300000012, max_delta_step=0, max_depth=3,\n",
       "             min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "             n_estimators=100, n_jobs=0, num_parallel_tree=1,\n",
       "             objective='reg:squarederror', random_state=0, reg_alpha=0,\n",
       "             reg_lambda=1, scale_pos_weight=1, seed=0, subsample=1,\n",
       "             tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.974456636427216"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_estimator_.score(x_train, score_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16.572080</td>\n",
       "      <td>0.049356</td>\n",
       "      <td>0.012367</td>\n",
       "      <td>4.889087e-04</td>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_depth': 3, 'n_estimators': 100}</td>\n",
       "      <td>-9.853485</td>\n",
       "      <td>-10.625332</td>\n",
       "      <td>-9.719376</td>\n",
       "      <td>...</td>\n",
       "      <td>-9.384355</td>\n",
       "      <td>5.234924</td>\n",
       "      <td>1</td>\n",
       "      <td>0.984033</td>\n",
       "      <td>0.988978</td>\n",
       "      <td>0.988325</td>\n",
       "      <td>0.988727</td>\n",
       "      <td>0.984422</td>\n",
       "      <td>0.986897</td>\n",
       "      <td>0.002193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>42.624806</td>\n",
       "      <td>0.286402</td>\n",
       "      <td>0.014364</td>\n",
       "      <td>4.917269e-04</td>\n",
       "      <td>3</td>\n",
       "      <td>300</td>\n",
       "      <td>{'max_depth': 3, 'n_estimators': 300}</td>\n",
       "      <td>-9.778643</td>\n",
       "      <td>-10.684162</td>\n",
       "      <td>-9.766579</td>\n",
       "      <td>...</td>\n",
       "      <td>-9.440823</td>\n",
       "      <td>5.312433</td>\n",
       "      <td>7</td>\n",
       "      <td>0.999812</td>\n",
       "      <td>0.999916</td>\n",
       "      <td>0.999930</td>\n",
       "      <td>0.999887</td>\n",
       "      <td>0.999834</td>\n",
       "      <td>0.999876</td>\n",
       "      <td>0.000046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>57.907535</td>\n",
       "      <td>1.956845</td>\n",
       "      <td>0.015159</td>\n",
       "      <td>3.991127e-04</td>\n",
       "      <td>3</td>\n",
       "      <td>500</td>\n",
       "      <td>{'max_depth': 3, 'n_estimators': 500}</td>\n",
       "      <td>-9.778949</td>\n",
       "      <td>-10.685155</td>\n",
       "      <td>-9.758812</td>\n",
       "      <td>...</td>\n",
       "      <td>-9.436498</td>\n",
       "      <td>5.308855</td>\n",
       "      <td>6</td>\n",
       "      <td>0.999895</td>\n",
       "      <td>0.999994</td>\n",
       "      <td>0.999993</td>\n",
       "      <td>0.999942</td>\n",
       "      <td>0.999919</td>\n",
       "      <td>0.999949</td>\n",
       "      <td>0.000040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>66.871763</td>\n",
       "      <td>1.487044</td>\n",
       "      <td>0.015758</td>\n",
       "      <td>3.991843e-04</td>\n",
       "      <td>3</td>\n",
       "      <td>700</td>\n",
       "      <td>{'max_depth': 3, 'n_estimators': 700}</td>\n",
       "      <td>-9.778979</td>\n",
       "      <td>-10.685118</td>\n",
       "      <td>-9.758786</td>\n",
       "      <td>...</td>\n",
       "      <td>-9.436477</td>\n",
       "      <td>5.308846</td>\n",
       "      <td>5</td>\n",
       "      <td>0.999895</td>\n",
       "      <td>0.999994</td>\n",
       "      <td>0.999993</td>\n",
       "      <td>0.999942</td>\n",
       "      <td>0.999919</td>\n",
       "      <td>0.999949</td>\n",
       "      <td>0.000040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>75.923156</td>\n",
       "      <td>0.993745</td>\n",
       "      <td>0.015758</td>\n",
       "      <td>3.989697e-04</td>\n",
       "      <td>3</td>\n",
       "      <td>900</td>\n",
       "      <td>{'max_depth': 3, 'n_estimators': 900}</td>\n",
       "      <td>-9.779003</td>\n",
       "      <td>-10.685089</td>\n",
       "      <td>-9.758770</td>\n",
       "      <td>...</td>\n",
       "      <td>-9.436460</td>\n",
       "      <td>5.308839</td>\n",
       "      <td>4</td>\n",
       "      <td>0.999895</td>\n",
       "      <td>0.999994</td>\n",
       "      <td>0.999993</td>\n",
       "      <td>0.999942</td>\n",
       "      <td>0.999919</td>\n",
       "      <td>0.999949</td>\n",
       "      <td>0.000040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>81.527768</td>\n",
       "      <td>1.013263</td>\n",
       "      <td>0.016356</td>\n",
       "      <td>4.890838e-04</td>\n",
       "      <td>3</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'max_depth': 3, 'n_estimators': 1000}</td>\n",
       "      <td>-9.779013</td>\n",
       "      <td>-10.685076</td>\n",
       "      <td>-9.758763</td>\n",
       "      <td>...</td>\n",
       "      <td>-9.436452</td>\n",
       "      <td>5.308837</td>\n",
       "      <td>3</td>\n",
       "      <td>0.999895</td>\n",
       "      <td>0.999994</td>\n",
       "      <td>0.999993</td>\n",
       "      <td>0.999942</td>\n",
       "      <td>0.999919</td>\n",
       "      <td>0.999949</td>\n",
       "      <td>0.000040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>173.676132</td>\n",
       "      <td>1.409852</td>\n",
       "      <td>0.020146</td>\n",
       "      <td>3.988983e-04</td>\n",
       "      <td>3</td>\n",
       "      <td>3000</td>\n",
       "      <td>{'max_depth': 3, 'n_estimators': 3000}</td>\n",
       "      <td>-9.779098</td>\n",
       "      <td>-10.684978</td>\n",
       "      <td>-9.758706</td>\n",
       "      <td>...</td>\n",
       "      <td>-9.436366</td>\n",
       "      <td>5.308860</td>\n",
       "      <td>2</td>\n",
       "      <td>0.999895</td>\n",
       "      <td>0.999994</td>\n",
       "      <td>0.999993</td>\n",
       "      <td>0.999942</td>\n",
       "      <td>0.999919</td>\n",
       "      <td>0.999949</td>\n",
       "      <td>0.000040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>18.419939</td>\n",
       "      <td>0.313751</td>\n",
       "      <td>0.012367</td>\n",
       "      <td>4.886361e-04</td>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_depth': 4, 'n_estimators': 100}</td>\n",
       "      <td>-10.521678</td>\n",
       "      <td>-9.634299</td>\n",
       "      <td>-10.689543</td>\n",
       "      <td>...</td>\n",
       "      <td>-9.661415</td>\n",
       "      <td>5.423894</td>\n",
       "      <td>14</td>\n",
       "      <td>0.998975</td>\n",
       "      <td>0.999424</td>\n",
       "      <td>0.999316</td>\n",
       "      <td>0.999599</td>\n",
       "      <td>0.999027</td>\n",
       "      <td>0.999268</td>\n",
       "      <td>0.000237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>39.749895</td>\n",
       "      <td>0.397444</td>\n",
       "      <td>0.014162</td>\n",
       "      <td>3.987790e-04</td>\n",
       "      <td>4</td>\n",
       "      <td>300</td>\n",
       "      <td>{'max_depth': 4, 'n_estimators': 300}</td>\n",
       "      <td>-10.519106</td>\n",
       "      <td>-9.624321</td>\n",
       "      <td>-10.676589</td>\n",
       "      <td>...</td>\n",
       "      <td>-9.657133</td>\n",
       "      <td>5.425929</td>\n",
       "      <td>13</td>\n",
       "      <td>0.999898</td>\n",
       "      <td>0.999995</td>\n",
       "      <td>0.999995</td>\n",
       "      <td>0.999943</td>\n",
       "      <td>0.999922</td>\n",
       "      <td>0.999950</td>\n",
       "      <td>0.000039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>48.816449</td>\n",
       "      <td>0.613008</td>\n",
       "      <td>0.014162</td>\n",
       "      <td>3.989460e-04</td>\n",
       "      <td>4</td>\n",
       "      <td>500</td>\n",
       "      <td>{'max_depth': 4, 'n_estimators': 500}</td>\n",
       "      <td>-10.519074</td>\n",
       "      <td>-9.624285</td>\n",
       "      <td>-10.676565</td>\n",
       "      <td>...</td>\n",
       "      <td>-9.657121</td>\n",
       "      <td>5.425949</td>\n",
       "      <td>12</td>\n",
       "      <td>0.999898</td>\n",
       "      <td>0.999995</td>\n",
       "      <td>0.999995</td>\n",
       "      <td>0.999943</td>\n",
       "      <td>0.999922</td>\n",
       "      <td>0.999950</td>\n",
       "      <td>0.000039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>58.095234</td>\n",
       "      <td>0.515132</td>\n",
       "      <td>0.014362</td>\n",
       "      <td>4.885582e-04</td>\n",
       "      <td>4</td>\n",
       "      <td>700</td>\n",
       "      <td>{'max_depth': 4, 'n_estimators': 700}</td>\n",
       "      <td>-10.519048</td>\n",
       "      <td>-9.624254</td>\n",
       "      <td>-10.676544</td>\n",
       "      <td>...</td>\n",
       "      <td>-9.657110</td>\n",
       "      <td>5.425967</td>\n",
       "      <td>11</td>\n",
       "      <td>0.999898</td>\n",
       "      <td>0.999995</td>\n",
       "      <td>0.999995</td>\n",
       "      <td>0.999943</td>\n",
       "      <td>0.999922</td>\n",
       "      <td>0.999950</td>\n",
       "      <td>0.000039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>67.528406</td>\n",
       "      <td>0.690572</td>\n",
       "      <td>0.014960</td>\n",
       "      <td>3.162980e-07</td>\n",
       "      <td>4</td>\n",
       "      <td>900</td>\n",
       "      <td>{'max_depth': 4, 'n_estimators': 900}</td>\n",
       "      <td>-10.519027</td>\n",
       "      <td>-9.624230</td>\n",
       "      <td>-10.676529</td>\n",
       "      <td>...</td>\n",
       "      <td>-9.657100</td>\n",
       "      <td>5.425982</td>\n",
       "      <td>10</td>\n",
       "      <td>0.999898</td>\n",
       "      <td>0.999995</td>\n",
       "      <td>0.999995</td>\n",
       "      <td>0.999943</td>\n",
       "      <td>0.999922</td>\n",
       "      <td>0.999950</td>\n",
       "      <td>0.000039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>72.046923</td>\n",
       "      <td>0.751320</td>\n",
       "      <td>0.015758</td>\n",
       "      <td>3.989697e-04</td>\n",
       "      <td>4</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'max_depth': 4, 'n_estimators': 1000}</td>\n",
       "      <td>-10.519023</td>\n",
       "      <td>-9.624226</td>\n",
       "      <td>-10.676526</td>\n",
       "      <td>...</td>\n",
       "      <td>-9.657097</td>\n",
       "      <td>5.425988</td>\n",
       "      <td>9</td>\n",
       "      <td>0.999898</td>\n",
       "      <td>0.999995</td>\n",
       "      <td>0.999995</td>\n",
       "      <td>0.999943</td>\n",
       "      <td>0.999922</td>\n",
       "      <td>0.999950</td>\n",
       "      <td>0.000039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>163.584521</td>\n",
       "      <td>1.081631</td>\n",
       "      <td>0.018550</td>\n",
       "      <td>4.886946e-04</td>\n",
       "      <td>4</td>\n",
       "      <td>3000</td>\n",
       "      <td>{'max_depth': 4, 'n_estimators': 3000}</td>\n",
       "      <td>-10.518931</td>\n",
       "      <td>-9.624130</td>\n",
       "      <td>-10.676468</td>\n",
       "      <td>...</td>\n",
       "      <td>-9.657037</td>\n",
       "      <td>5.426101</td>\n",
       "      <td>8</td>\n",
       "      <td>0.999898</td>\n",
       "      <td>0.999995</td>\n",
       "      <td>0.999995</td>\n",
       "      <td>0.999943</td>\n",
       "      <td>0.999922</td>\n",
       "      <td>0.999950</td>\n",
       "      <td>0.000039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>23.092842</td>\n",
       "      <td>0.340252</td>\n",
       "      <td>0.012766</td>\n",
       "      <td>3.987075e-04</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_depth': 5, 'n_estimators': 100}</td>\n",
       "      <td>-10.487485</td>\n",
       "      <td>-10.596366</td>\n",
       "      <td>-8.785534</td>\n",
       "      <td>...</td>\n",
       "      <td>-10.090739</td>\n",
       "      <td>6.354163</td>\n",
       "      <td>29</td>\n",
       "      <td>0.999891</td>\n",
       "      <td>0.999989</td>\n",
       "      <td>0.999991</td>\n",
       "      <td>0.999937</td>\n",
       "      <td>0.999909</td>\n",
       "      <td>0.999944</td>\n",
       "      <td>0.000041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>33.918291</td>\n",
       "      <td>0.429934</td>\n",
       "      <td>0.013564</td>\n",
       "      <td>4.886945e-04</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>{'max_depth': 5, 'n_estimators': 300}</td>\n",
       "      <td>-10.488292</td>\n",
       "      <td>-10.593443</td>\n",
       "      <td>-8.787705</td>\n",
       "      <td>...</td>\n",
       "      <td>-10.091234</td>\n",
       "      <td>6.354878</td>\n",
       "      <td>35</td>\n",
       "      <td>0.999900</td>\n",
       "      <td>0.999995</td>\n",
       "      <td>0.999995</td>\n",
       "      <td>0.999944</td>\n",
       "      <td>0.999923</td>\n",
       "      <td>0.999951</td>\n",
       "      <td>0.000038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>43.569082</td>\n",
       "      <td>0.587969</td>\n",
       "      <td>0.014162</td>\n",
       "      <td>3.986597e-04</td>\n",
       "      <td>5</td>\n",
       "      <td>500</td>\n",
       "      <td>{'max_depth': 5, 'n_estimators': 500}</td>\n",
       "      <td>-10.488322</td>\n",
       "      <td>-10.593480</td>\n",
       "      <td>-8.787685</td>\n",
       "      <td>...</td>\n",
       "      <td>-10.091226</td>\n",
       "      <td>6.354867</td>\n",
       "      <td>34</td>\n",
       "      <td>0.999900</td>\n",
       "      <td>0.999995</td>\n",
       "      <td>0.999995</td>\n",
       "      <td>0.999944</td>\n",
       "      <td>0.999923</td>\n",
       "      <td>0.999951</td>\n",
       "      <td>0.000038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>52.430583</td>\n",
       "      <td>0.492596</td>\n",
       "      <td>0.014162</td>\n",
       "      <td>3.988267e-04</td>\n",
       "      <td>5</td>\n",
       "      <td>700</td>\n",
       "      <td>{'max_depth': 5, 'n_estimators': 700}</td>\n",
       "      <td>-10.488347</td>\n",
       "      <td>-10.593511</td>\n",
       "      <td>-8.787669</td>\n",
       "      <td>...</td>\n",
       "      <td>-10.091220</td>\n",
       "      <td>6.354859</td>\n",
       "      <td>33</td>\n",
       "      <td>0.999900</td>\n",
       "      <td>0.999995</td>\n",
       "      <td>0.999995</td>\n",
       "      <td>0.999944</td>\n",
       "      <td>0.999923</td>\n",
       "      <td>0.999951</td>\n",
       "      <td>0.000038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>61.548998</td>\n",
       "      <td>0.575643</td>\n",
       "      <td>0.014960</td>\n",
       "      <td>2.336015e-07</td>\n",
       "      <td>5</td>\n",
       "      <td>900</td>\n",
       "      <td>{'max_depth': 5, 'n_estimators': 900}</td>\n",
       "      <td>-10.488361</td>\n",
       "      <td>-10.593526</td>\n",
       "      <td>-8.787660</td>\n",
       "      <td>...</td>\n",
       "      <td>-10.091214</td>\n",
       "      <td>6.354857</td>\n",
       "      <td>32</td>\n",
       "      <td>0.999900</td>\n",
       "      <td>0.999995</td>\n",
       "      <td>0.999995</td>\n",
       "      <td>0.999944</td>\n",
       "      <td>0.999923</td>\n",
       "      <td>0.999951</td>\n",
       "      <td>0.000038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>66.233669</td>\n",
       "      <td>0.835263</td>\n",
       "      <td>0.015160</td>\n",
       "      <td>3.988982e-04</td>\n",
       "      <td>5</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'max_depth': 5, 'n_estimators': 1000}</td>\n",
       "      <td>-10.488365</td>\n",
       "      <td>-10.593532</td>\n",
       "      <td>-8.787658</td>\n",
       "      <td>...</td>\n",
       "      <td>-10.091211</td>\n",
       "      <td>6.354858</td>\n",
       "      <td>31</td>\n",
       "      <td>0.999900</td>\n",
       "      <td>0.999995</td>\n",
       "      <td>0.999995</td>\n",
       "      <td>0.999944</td>\n",
       "      <td>0.999923</td>\n",
       "      <td>0.999951</td>\n",
       "      <td>0.000038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>158.248790</td>\n",
       "      <td>0.735994</td>\n",
       "      <td>0.018750</td>\n",
       "      <td>7.466589e-04</td>\n",
       "      <td>5</td>\n",
       "      <td>3000</td>\n",
       "      <td>{'max_depth': 5, 'n_estimators': 3000}</td>\n",
       "      <td>-10.488441</td>\n",
       "      <td>-10.593635</td>\n",
       "      <td>-8.787609</td>\n",
       "      <td>...</td>\n",
       "      <td>-10.091157</td>\n",
       "      <td>6.354869</td>\n",
       "      <td>30</td>\n",
       "      <td>0.999900</td>\n",
       "      <td>0.999995</td>\n",
       "      <td>0.999995</td>\n",
       "      <td>0.999944</td>\n",
       "      <td>0.999923</td>\n",
       "      <td>0.999951</td>\n",
       "      <td>0.000038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>20.099048</td>\n",
       "      <td>0.365392</td>\n",
       "      <td>0.012766</td>\n",
       "      <td>3.988982e-04</td>\n",
       "      <td>6</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_depth': 6, 'n_estimators': 100}</td>\n",
       "      <td>-11.693325</td>\n",
       "      <td>-10.869622</td>\n",
       "      <td>-8.529902</td>\n",
       "      <td>...</td>\n",
       "      <td>-9.946695</td>\n",
       "      <td>5.771545</td>\n",
       "      <td>15</td>\n",
       "      <td>0.999899</td>\n",
       "      <td>0.999996</td>\n",
       "      <td>0.999995</td>\n",
       "      <td>0.999944</td>\n",
       "      <td>0.999922</td>\n",
       "      <td>0.999951</td>\n",
       "      <td>0.000039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>29.250574</td>\n",
       "      <td>0.331922</td>\n",
       "      <td>0.012766</td>\n",
       "      <td>3.988982e-04</td>\n",
       "      <td>6</td>\n",
       "      <td>300</td>\n",
       "      <td>{'max_depth': 6, 'n_estimators': 300}</td>\n",
       "      <td>-11.693269</td>\n",
       "      <td>-10.869687</td>\n",
       "      <td>-8.529942</td>\n",
       "      <td>...</td>\n",
       "      <td>-9.946722</td>\n",
       "      <td>5.771580</td>\n",
       "      <td>16</td>\n",
       "      <td>0.999899</td>\n",
       "      <td>0.999996</td>\n",
       "      <td>0.999995</td>\n",
       "      <td>0.999944</td>\n",
       "      <td>0.999922</td>\n",
       "      <td>0.999951</td>\n",
       "      <td>0.000039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>38.520583</td>\n",
       "      <td>0.722854</td>\n",
       "      <td>0.013364</td>\n",
       "      <td>4.886555e-04</td>\n",
       "      <td>6</td>\n",
       "      <td>500</td>\n",
       "      <td>{'max_depth': 6, 'n_estimators': 500}</td>\n",
       "      <td>-11.693238</td>\n",
       "      <td>-10.869719</td>\n",
       "      <td>-8.529961</td>\n",
       "      <td>...</td>\n",
       "      <td>-9.946735</td>\n",
       "      <td>5.771604</td>\n",
       "      <td>17</td>\n",
       "      <td>0.999899</td>\n",
       "      <td>0.999996</td>\n",
       "      <td>0.999995</td>\n",
       "      <td>0.999944</td>\n",
       "      <td>0.999922</td>\n",
       "      <td>0.999951</td>\n",
       "      <td>0.000039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>48.026162</td>\n",
       "      <td>0.511313</td>\n",
       "      <td>0.014362</td>\n",
       "      <td>4.885387e-04</td>\n",
       "      <td>6</td>\n",
       "      <td>700</td>\n",
       "      <td>{'max_depth': 6, 'n_estimators': 700}</td>\n",
       "      <td>-11.693213</td>\n",
       "      <td>-10.869745</td>\n",
       "      <td>-8.529977</td>\n",
       "      <td>...</td>\n",
       "      <td>-9.946745</td>\n",
       "      <td>5.771625</td>\n",
       "      <td>18</td>\n",
       "      <td>0.999899</td>\n",
       "      <td>0.999996</td>\n",
       "      <td>0.999995</td>\n",
       "      <td>0.999944</td>\n",
       "      <td>0.999922</td>\n",
       "      <td>0.999951</td>\n",
       "      <td>0.000039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>57.557874</td>\n",
       "      <td>0.447407</td>\n",
       "      <td>0.014559</td>\n",
       "      <td>4.917080e-04</td>\n",
       "      <td>6</td>\n",
       "      <td>900</td>\n",
       "      <td>{'max_depth': 6, 'n_estimators': 900}</td>\n",
       "      <td>-11.693200</td>\n",
       "      <td>-10.869757</td>\n",
       "      <td>-8.529984</td>\n",
       "      <td>...</td>\n",
       "      <td>-9.946753</td>\n",
       "      <td>5.771646</td>\n",
       "      <td>19</td>\n",
       "      <td>0.999899</td>\n",
       "      <td>0.999996</td>\n",
       "      <td>0.999995</td>\n",
       "      <td>0.999944</td>\n",
       "      <td>0.999922</td>\n",
       "      <td>0.999951</td>\n",
       "      <td>0.000039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>62.635891</td>\n",
       "      <td>0.961191</td>\n",
       "      <td>0.014960</td>\n",
       "      <td>4.101908e-07</td>\n",
       "      <td>6</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'max_depth': 6, 'n_estimators': 1000}</td>\n",
       "      <td>-11.693196</td>\n",
       "      <td>-10.869762</td>\n",
       "      <td>-8.529986</td>\n",
       "      <td>...</td>\n",
       "      <td>-9.946756</td>\n",
       "      <td>5.771656</td>\n",
       "      <td>20</td>\n",
       "      <td>0.999899</td>\n",
       "      <td>0.999996</td>\n",
       "      <td>0.999995</td>\n",
       "      <td>0.999944</td>\n",
       "      <td>0.999922</td>\n",
       "      <td>0.999951</td>\n",
       "      <td>0.000039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>157.020076</td>\n",
       "      <td>1.422645</td>\n",
       "      <td>0.019151</td>\n",
       "      <td>1.160667e-03</td>\n",
       "      <td>6</td>\n",
       "      <td>3000</td>\n",
       "      <td>{'max_depth': 6, 'n_estimators': 3000}</td>\n",
       "      <td>-11.693111</td>\n",
       "      <td>-10.869859</td>\n",
       "      <td>-8.530023</td>\n",
       "      <td>...</td>\n",
       "      <td>-9.946758</td>\n",
       "      <td>5.771772</td>\n",
       "      <td>21</td>\n",
       "      <td>0.999899</td>\n",
       "      <td>0.999996</td>\n",
       "      <td>0.999995</td>\n",
       "      <td>0.999944</td>\n",
       "      <td>0.999922</td>\n",
       "      <td>0.999951</td>\n",
       "      <td>0.000039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>19.108298</td>\n",
       "      <td>1.012536</td>\n",
       "      <td>0.013364</td>\n",
       "      <td>4.886166e-04</td>\n",
       "      <td>7</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_depth': 7, 'n_estimators': 100}</td>\n",
       "      <td>-11.906965</td>\n",
       "      <td>-9.908395</td>\n",
       "      <td>-9.496265</td>\n",
       "      <td>...</td>\n",
       "      <td>-10.088456</td>\n",
       "      <td>5.872120</td>\n",
       "      <td>22</td>\n",
       "      <td>0.999901</td>\n",
       "      <td>0.999996</td>\n",
       "      <td>0.999996</td>\n",
       "      <td>0.999945</td>\n",
       "      <td>0.999925</td>\n",
       "      <td>0.999953</td>\n",
       "      <td>0.000038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>27.236760</td>\n",
       "      <td>0.238429</td>\n",
       "      <td>0.012965</td>\n",
       "      <td>1.907349e-07</td>\n",
       "      <td>7</td>\n",
       "      <td>300</td>\n",
       "      <td>{'max_depth': 7, 'n_estimators': 300}</td>\n",
       "      <td>-11.906912</td>\n",
       "      <td>-9.908438</td>\n",
       "      <td>-9.496295</td>\n",
       "      <td>...</td>\n",
       "      <td>-10.088484</td>\n",
       "      <td>5.872136</td>\n",
       "      <td>23</td>\n",
       "      <td>0.999901</td>\n",
       "      <td>0.999996</td>\n",
       "      <td>0.999996</td>\n",
       "      <td>0.999945</td>\n",
       "      <td>0.999925</td>\n",
       "      <td>0.999953</td>\n",
       "      <td>0.000038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>37.030169</td>\n",
       "      <td>0.354756</td>\n",
       "      <td>0.013764</td>\n",
       "      <td>7.463784e-04</td>\n",
       "      <td>7</td>\n",
       "      <td>500</td>\n",
       "      <td>{'max_depth': 7, 'n_estimators': 500}</td>\n",
       "      <td>-11.906876</td>\n",
       "      <td>-9.908468</td>\n",
       "      <td>-9.496310</td>\n",
       "      <td>...</td>\n",
       "      <td>-10.088501</td>\n",
       "      <td>5.872142</td>\n",
       "      <td>24</td>\n",
       "      <td>0.999901</td>\n",
       "      <td>0.999996</td>\n",
       "      <td>0.999996</td>\n",
       "      <td>0.999945</td>\n",
       "      <td>0.999925</td>\n",
       "      <td>0.999953</td>\n",
       "      <td>0.000038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>46.259686</td>\n",
       "      <td>0.605682</td>\n",
       "      <td>0.014162</td>\n",
       "      <td>3.988981e-04</td>\n",
       "      <td>7</td>\n",
       "      <td>700</td>\n",
       "      <td>{'max_depth': 7, 'n_estimators': 700}</td>\n",
       "      <td>-11.906846</td>\n",
       "      <td>-9.908494</td>\n",
       "      <td>-9.496322</td>\n",
       "      <td>...</td>\n",
       "      <td>-10.088516</td>\n",
       "      <td>5.872146</td>\n",
       "      <td>25</td>\n",
       "      <td>0.999901</td>\n",
       "      <td>0.999996</td>\n",
       "      <td>0.999996</td>\n",
       "      <td>0.999945</td>\n",
       "      <td>0.999925</td>\n",
       "      <td>0.999953</td>\n",
       "      <td>0.000038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>55.480826</td>\n",
       "      <td>0.189661</td>\n",
       "      <td>0.014362</td>\n",
       "      <td>4.885972e-04</td>\n",
       "      <td>7</td>\n",
       "      <td>900</td>\n",
       "      <td>{'max_depth': 7, 'n_estimators': 900}</td>\n",
       "      <td>-11.906833</td>\n",
       "      <td>-9.908502</td>\n",
       "      <td>-9.496327</td>\n",
       "      <td>...</td>\n",
       "      <td>-10.088524</td>\n",
       "      <td>5.872143</td>\n",
       "      <td>26</td>\n",
       "      <td>0.999901</td>\n",
       "      <td>0.999996</td>\n",
       "      <td>0.999996</td>\n",
       "      <td>0.999945</td>\n",
       "      <td>0.999925</td>\n",
       "      <td>0.999953</td>\n",
       "      <td>0.000038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>60.546279</td>\n",
       "      <td>0.583241</td>\n",
       "      <td>0.014362</td>\n",
       "      <td>4.885971e-04</td>\n",
       "      <td>7</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'max_depth': 7, 'n_estimators': 1000}</td>\n",
       "      <td>-11.906829</td>\n",
       "      <td>-9.908506</td>\n",
       "      <td>-9.496329</td>\n",
       "      <td>...</td>\n",
       "      <td>-10.088529</td>\n",
       "      <td>5.872141</td>\n",
       "      <td>27</td>\n",
       "      <td>0.999901</td>\n",
       "      <td>0.999996</td>\n",
       "      <td>0.999996</td>\n",
       "      <td>0.999945</td>\n",
       "      <td>0.999925</td>\n",
       "      <td>0.999953</td>\n",
       "      <td>0.000038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>154.575215</td>\n",
       "      <td>1.063905</td>\n",
       "      <td>0.018550</td>\n",
       "      <td>4.886945e-04</td>\n",
       "      <td>7</td>\n",
       "      <td>3000</td>\n",
       "      <td>{'max_depth': 7, 'n_estimators': 3000}</td>\n",
       "      <td>-11.906734</td>\n",
       "      <td>-9.908590</td>\n",
       "      <td>-9.496372</td>\n",
       "      <td>...</td>\n",
       "      <td>-10.088612</td>\n",
       "      <td>5.872108</td>\n",
       "      <td>28</td>\n",
       "      <td>0.999901</td>\n",
       "      <td>0.999996</td>\n",
       "      <td>0.999996</td>\n",
       "      <td>0.999945</td>\n",
       "      <td>0.999924</td>\n",
       "      <td>0.999953</td>\n",
       "      <td>0.000038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>16.788103</td>\n",
       "      <td>0.468796</td>\n",
       "      <td>0.013364</td>\n",
       "      <td>4.885972e-04</td>\n",
       "      <td>8</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_depth': 8, 'n_estimators': 100}</td>\n",
       "      <td>-11.785573</td>\n",
       "      <td>-9.885503</td>\n",
       "      <td>-9.884064</td>\n",
       "      <td>...</td>\n",
       "      <td>-10.540118</td>\n",
       "      <td>6.448946</td>\n",
       "      <td>42</td>\n",
       "      <td>0.999902</td>\n",
       "      <td>0.999997</td>\n",
       "      <td>0.999997</td>\n",
       "      <td>0.999946</td>\n",
       "      <td>0.999925</td>\n",
       "      <td>0.999953</td>\n",
       "      <td>0.000038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>25.944216</td>\n",
       "      <td>0.114920</td>\n",
       "      <td>0.012965</td>\n",
       "      <td>6.306756e-04</td>\n",
       "      <td>8</td>\n",
       "      <td>300</td>\n",
       "      <td>{'max_depth': 8, 'n_estimators': 300}</td>\n",
       "      <td>-11.785527</td>\n",
       "      <td>-9.885552</td>\n",
       "      <td>-9.884025</td>\n",
       "      <td>...</td>\n",
       "      <td>-10.540096</td>\n",
       "      <td>6.448907</td>\n",
       "      <td>41</td>\n",
       "      <td>0.999902</td>\n",
       "      <td>0.999997</td>\n",
       "      <td>0.999997</td>\n",
       "      <td>0.999946</td>\n",
       "      <td>0.999925</td>\n",
       "      <td>0.999953</td>\n",
       "      <td>0.000038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>35.490088</td>\n",
       "      <td>0.597320</td>\n",
       "      <td>0.012965</td>\n",
       "      <td>2.611745e-07</td>\n",
       "      <td>8</td>\n",
       "      <td>500</td>\n",
       "      <td>{'max_depth': 8, 'n_estimators': 500}</td>\n",
       "      <td>-11.785495</td>\n",
       "      <td>-9.885580</td>\n",
       "      <td>-9.884006</td>\n",
       "      <td>...</td>\n",
       "      <td>-10.540086</td>\n",
       "      <td>6.448880</td>\n",
       "      <td>40</td>\n",
       "      <td>0.999902</td>\n",
       "      <td>0.999997</td>\n",
       "      <td>0.999997</td>\n",
       "      <td>0.999946</td>\n",
       "      <td>0.999925</td>\n",
       "      <td>0.999953</td>\n",
       "      <td>0.000038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>44.735961</td>\n",
       "      <td>0.615264</td>\n",
       "      <td>0.013763</td>\n",
       "      <td>7.463785e-04</td>\n",
       "      <td>8</td>\n",
       "      <td>700</td>\n",
       "      <td>{'max_depth': 8, 'n_estimators': 700}</td>\n",
       "      <td>-11.785470</td>\n",
       "      <td>-9.885603</td>\n",
       "      <td>-9.883990</td>\n",
       "      <td>...</td>\n",
       "      <td>-10.540077</td>\n",
       "      <td>6.448856</td>\n",
       "      <td>37</td>\n",
       "      <td>0.999902</td>\n",
       "      <td>0.999997</td>\n",
       "      <td>0.999997</td>\n",
       "      <td>0.999946</td>\n",
       "      <td>0.999925</td>\n",
       "      <td>0.999953</td>\n",
       "      <td>0.000038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>54.104906</td>\n",
       "      <td>0.502498</td>\n",
       "      <td>0.013963</td>\n",
       "      <td>9.536743e-08</td>\n",
       "      <td>8</td>\n",
       "      <td>900</td>\n",
       "      <td>{'max_depth': 8, 'n_estimators': 900}</td>\n",
       "      <td>-11.785458</td>\n",
       "      <td>-9.885613</td>\n",
       "      <td>-9.883983</td>\n",
       "      <td>...</td>\n",
       "      <td>-10.540077</td>\n",
       "      <td>6.448843</td>\n",
       "      <td>36</td>\n",
       "      <td>0.999902</td>\n",
       "      <td>0.999997</td>\n",
       "      <td>0.999997</td>\n",
       "      <td>0.999946</td>\n",
       "      <td>0.999925</td>\n",
       "      <td>0.999953</td>\n",
       "      <td>0.000038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>58.658927</td>\n",
       "      <td>0.100898</td>\n",
       "      <td>0.014162</td>\n",
       "      <td>3.988982e-04</td>\n",
       "      <td>8</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'max_depth': 8, 'n_estimators': 1000}</td>\n",
       "      <td>-11.785453</td>\n",
       "      <td>-9.885618</td>\n",
       "      <td>-9.883981</td>\n",
       "      <td>...</td>\n",
       "      <td>-10.540077</td>\n",
       "      <td>6.448836</td>\n",
       "      <td>38</td>\n",
       "      <td>0.999902</td>\n",
       "      <td>0.999997</td>\n",
       "      <td>0.999997</td>\n",
       "      <td>0.999946</td>\n",
       "      <td>0.999925</td>\n",
       "      <td>0.999953</td>\n",
       "      <td>0.000038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>151.961206</td>\n",
       "      <td>1.577624</td>\n",
       "      <td>0.017553</td>\n",
       "      <td>4.885971e-04</td>\n",
       "      <td>8</td>\n",
       "      <td>3000</td>\n",
       "      <td>{'max_depth': 8, 'n_estimators': 3000}</td>\n",
       "      <td>-11.785348</td>\n",
       "      <td>-9.885710</td>\n",
       "      <td>-9.883931</td>\n",
       "      <td>...</td>\n",
       "      <td>-10.540084</td>\n",
       "      <td>6.448709</td>\n",
       "      <td>39</td>\n",
       "      <td>0.999902</td>\n",
       "      <td>0.999997</td>\n",
       "      <td>0.999997</td>\n",
       "      <td>0.999946</td>\n",
       "      <td>0.999924</td>\n",
       "      <td>0.999953</td>\n",
       "      <td>0.000038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>16.892623</td>\n",
       "      <td>0.340219</td>\n",
       "      <td>0.012766</td>\n",
       "      <td>3.988028e-04</td>\n",
       "      <td>9</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_depth': 9, 'n_estimators': 100}</td>\n",
       "      <td>-11.913126</td>\n",
       "      <td>-10.594389</td>\n",
       "      <td>-9.958569</td>\n",
       "      <td>...</td>\n",
       "      <td>-10.887083</td>\n",
       "      <td>6.720698</td>\n",
       "      <td>43</td>\n",
       "      <td>0.999902</td>\n",
       "      <td>0.999997</td>\n",
       "      <td>0.999997</td>\n",
       "      <td>0.999946</td>\n",
       "      <td>0.999926</td>\n",
       "      <td>0.999954</td>\n",
       "      <td>0.000038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>26.376062</td>\n",
       "      <td>0.396882</td>\n",
       "      <td>0.012965</td>\n",
       "      <td>3.162980e-07</td>\n",
       "      <td>9</td>\n",
       "      <td>300</td>\n",
       "      <td>{'max_depth': 9, 'n_estimators': 300}</td>\n",
       "      <td>-11.913084</td>\n",
       "      <td>-10.594436</td>\n",
       "      <td>-9.958605</td>\n",
       "      <td>...</td>\n",
       "      <td>-10.887113</td>\n",
       "      <td>6.720717</td>\n",
       "      <td>44</td>\n",
       "      <td>0.999902</td>\n",
       "      <td>0.999997</td>\n",
       "      <td>0.999997</td>\n",
       "      <td>0.999946</td>\n",
       "      <td>0.999926</td>\n",
       "      <td>0.999954</td>\n",
       "      <td>0.000038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>35.549928</td>\n",
       "      <td>0.179738</td>\n",
       "      <td>0.014763</td>\n",
       "      <td>2.225330e-03</td>\n",
       "      <td>9</td>\n",
       "      <td>500</td>\n",
       "      <td>{'max_depth': 9, 'n_estimators': 500}</td>\n",
       "      <td>-11.913053</td>\n",
       "      <td>-10.594465</td>\n",
       "      <td>-9.958625</td>\n",
       "      <td>...</td>\n",
       "      <td>-10.887133</td>\n",
       "      <td>6.720727</td>\n",
       "      <td>45</td>\n",
       "      <td>0.999902</td>\n",
       "      <td>0.999997</td>\n",
       "      <td>0.999997</td>\n",
       "      <td>0.999946</td>\n",
       "      <td>0.999926</td>\n",
       "      <td>0.999954</td>\n",
       "      <td>0.000038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>45.455637</td>\n",
       "      <td>0.282850</td>\n",
       "      <td>0.013962</td>\n",
       "      <td>9.536743e-08</td>\n",
       "      <td>9</td>\n",
       "      <td>700</td>\n",
       "      <td>{'max_depth': 9, 'n_estimators': 700}</td>\n",
       "      <td>-11.913028</td>\n",
       "      <td>-10.594492</td>\n",
       "      <td>-9.958640</td>\n",
       "      <td>...</td>\n",
       "      <td>-10.887151</td>\n",
       "      <td>6.720734</td>\n",
       "      <td>46</td>\n",
       "      <td>0.999902</td>\n",
       "      <td>0.999997</td>\n",
       "      <td>0.999997</td>\n",
       "      <td>0.999946</td>\n",
       "      <td>0.999926</td>\n",
       "      <td>0.999954</td>\n",
       "      <td>0.000038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>54.831961</td>\n",
       "      <td>0.503145</td>\n",
       "      <td>0.014162</td>\n",
       "      <td>3.988982e-04</td>\n",
       "      <td>9</td>\n",
       "      <td>900</td>\n",
       "      <td>{'max_depth': 9, 'n_estimators': 900}</td>\n",
       "      <td>-11.913018</td>\n",
       "      <td>-10.594515</td>\n",
       "      <td>-9.958647</td>\n",
       "      <td>...</td>\n",
       "      <td>-10.887168</td>\n",
       "      <td>6.720741</td>\n",
       "      <td>47</td>\n",
       "      <td>0.999902</td>\n",
       "      <td>0.999997</td>\n",
       "      <td>0.999997</td>\n",
       "      <td>0.999946</td>\n",
       "      <td>0.999926</td>\n",
       "      <td>0.999954</td>\n",
       "      <td>0.000038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>58.649751</td>\n",
       "      <td>0.581775</td>\n",
       "      <td>0.014164</td>\n",
       "      <td>7.460200e-04</td>\n",
       "      <td>9</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'max_depth': 9, 'n_estimators': 1000}</td>\n",
       "      <td>-11.913013</td>\n",
       "      <td>-10.594526</td>\n",
       "      <td>-9.958650</td>\n",
       "      <td>...</td>\n",
       "      <td>-10.887176</td>\n",
       "      <td>6.720744</td>\n",
       "      <td>48</td>\n",
       "      <td>0.999902</td>\n",
       "      <td>0.999997</td>\n",
       "      <td>0.999997</td>\n",
       "      <td>0.999946</td>\n",
       "      <td>0.999926</td>\n",
       "      <td>0.999954</td>\n",
       "      <td>0.000038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>153.170771</td>\n",
       "      <td>1.476729</td>\n",
       "      <td>0.017954</td>\n",
       "      <td>6.306087e-04</td>\n",
       "      <td>9</td>\n",
       "      <td>3000</td>\n",
       "      <td>{'max_depth': 9, 'n_estimators': 3000}</td>\n",
       "      <td>-11.912918</td>\n",
       "      <td>-10.594611</td>\n",
       "      <td>-9.958711</td>\n",
       "      <td>...</td>\n",
       "      <td>-10.887271</td>\n",
       "      <td>6.720735</td>\n",
       "      <td>49</td>\n",
       "      <td>0.999902</td>\n",
       "      <td>0.999997</td>\n",
       "      <td>0.999997</td>\n",
       "      <td>0.999946</td>\n",
       "      <td>0.999926</td>\n",
       "      <td>0.999954</td>\n",
       "      <td>0.000038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>17.675530</td>\n",
       "      <td>0.418713</td>\n",
       "      <td>0.012167</td>\n",
       "      <td>3.989458e-04</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_depth': 10, 'n_estimators': 100}</td>\n",
       "      <td>-12.761759</td>\n",
       "      <td>-10.217927</td>\n",
       "      <td>-11.633507</td>\n",
       "      <td>...</td>\n",
       "      <td>-11.384796</td>\n",
       "      <td>6.812050</td>\n",
       "      <td>50</td>\n",
       "      <td>0.999903</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.999947</td>\n",
       "      <td>0.999927</td>\n",
       "      <td>0.999954</td>\n",
       "      <td>0.000038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>27.244340</td>\n",
       "      <td>0.506015</td>\n",
       "      <td>0.015558</td>\n",
       "      <td>3.656409e-03</td>\n",
       "      <td>10</td>\n",
       "      <td>300</td>\n",
       "      <td>{'max_depth': 10, 'n_estimators': 300}</td>\n",
       "      <td>-12.761810</td>\n",
       "      <td>-10.217873</td>\n",
       "      <td>-11.633544</td>\n",
       "      <td>...</td>\n",
       "      <td>-11.384826</td>\n",
       "      <td>6.812077</td>\n",
       "      <td>51</td>\n",
       "      <td>0.999903</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.999947</td>\n",
       "      <td>0.999927</td>\n",
       "      <td>0.999954</td>\n",
       "      <td>0.000038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>37.522054</td>\n",
       "      <td>1.637269</td>\n",
       "      <td>0.017154</td>\n",
       "      <td>7.393786e-03</td>\n",
       "      <td>10</td>\n",
       "      <td>500</td>\n",
       "      <td>{'max_depth': 10, 'n_estimators': 500}</td>\n",
       "      <td>-12.761840</td>\n",
       "      <td>-10.217838</td>\n",
       "      <td>-11.633563</td>\n",
       "      <td>...</td>\n",
       "      <td>-11.384845</td>\n",
       "      <td>6.812090</td>\n",
       "      <td>52</td>\n",
       "      <td>0.999903</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.999947</td>\n",
       "      <td>0.999927</td>\n",
       "      <td>0.999954</td>\n",
       "      <td>0.000038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>46.320125</td>\n",
       "      <td>0.679024</td>\n",
       "      <td>0.013763</td>\n",
       "      <td>3.988506e-04</td>\n",
       "      <td>10</td>\n",
       "      <td>700</td>\n",
       "      <td>{'max_depth': 10, 'n_estimators': 700}</td>\n",
       "      <td>-12.761866</td>\n",
       "      <td>-10.217809</td>\n",
       "      <td>-11.633579</td>\n",
       "      <td>...</td>\n",
       "      <td>-11.384862</td>\n",
       "      <td>6.812100</td>\n",
       "      <td>53</td>\n",
       "      <td>0.999903</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.999947</td>\n",
       "      <td>0.999927</td>\n",
       "      <td>0.999954</td>\n",
       "      <td>0.000038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>55.034021</td>\n",
       "      <td>0.422074</td>\n",
       "      <td>0.013763</td>\n",
       "      <td>3.986121e-04</td>\n",
       "      <td>10</td>\n",
       "      <td>900</td>\n",
       "      <td>{'max_depth': 10, 'n_estimators': 900}</td>\n",
       "      <td>-12.761877</td>\n",
       "      <td>-10.217797</td>\n",
       "      <td>-11.633585</td>\n",
       "      <td>...</td>\n",
       "      <td>-11.384871</td>\n",
       "      <td>6.812101</td>\n",
       "      <td>54</td>\n",
       "      <td>0.999903</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.999947</td>\n",
       "      <td>0.999927</td>\n",
       "      <td>0.999954</td>\n",
       "      <td>0.000038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>55.643990</td>\n",
       "      <td>1.197637</td>\n",
       "      <td>0.010771</td>\n",
       "      <td>1.716194e-03</td>\n",
       "      <td>10</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'max_depth': 10, 'n_estimators': 1000}</td>\n",
       "      <td>-12.761880</td>\n",
       "      <td>-10.217792</td>\n",
       "      <td>-11.633588</td>\n",
       "      <td>...</td>\n",
       "      <td>-11.384875</td>\n",
       "      <td>6.812100</td>\n",
       "      <td>55</td>\n",
       "      <td>0.999903</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.999947</td>\n",
       "      <td>0.999927</td>\n",
       "      <td>0.999954</td>\n",
       "      <td>0.000038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>93.678273</td>\n",
       "      <td>4.995996</td>\n",
       "      <td>0.010971</td>\n",
       "      <td>1.092623e-03</td>\n",
       "      <td>10</td>\n",
       "      <td>3000</td>\n",
       "      <td>{'max_depth': 10, 'n_estimators': 3000}</td>\n",
       "      <td>-12.761954</td>\n",
       "      <td>-10.217688</td>\n",
       "      <td>-11.633640</td>\n",
       "      <td>...</td>\n",
       "      <td>-11.384953</td>\n",
       "      <td>6.812083</td>\n",
       "      <td>56</td>\n",
       "      <td>0.999903</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.999947</td>\n",
       "      <td>0.999926</td>\n",
       "      <td>0.999954</td>\n",
       "      <td>0.000038</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>56 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0       16.572080      0.049356         0.012367    4.889087e-04   \n",
       "1       42.624806      0.286402         0.014364    4.917269e-04   \n",
       "2       57.907535      1.956845         0.015159    3.991127e-04   \n",
       "3       66.871763      1.487044         0.015758    3.991843e-04   \n",
       "4       75.923156      0.993745         0.015758    3.989697e-04   \n",
       "5       81.527768      1.013263         0.016356    4.890838e-04   \n",
       "6      173.676132      1.409852         0.020146    3.988983e-04   \n",
       "7       18.419939      0.313751         0.012367    4.886361e-04   \n",
       "8       39.749895      0.397444         0.014162    3.987790e-04   \n",
       "9       48.816449      0.613008         0.014162    3.989460e-04   \n",
       "10      58.095234      0.515132         0.014362    4.885582e-04   \n",
       "11      67.528406      0.690572         0.014960    3.162980e-07   \n",
       "12      72.046923      0.751320         0.015758    3.989697e-04   \n",
       "13     163.584521      1.081631         0.018550    4.886946e-04   \n",
       "14      23.092842      0.340252         0.012766    3.987075e-04   \n",
       "15      33.918291      0.429934         0.013564    4.886945e-04   \n",
       "16      43.569082      0.587969         0.014162    3.986597e-04   \n",
       "17      52.430583      0.492596         0.014162    3.988267e-04   \n",
       "18      61.548998      0.575643         0.014960    2.336015e-07   \n",
       "19      66.233669      0.835263         0.015160    3.988982e-04   \n",
       "20     158.248790      0.735994         0.018750    7.466589e-04   \n",
       "21      20.099048      0.365392         0.012766    3.988982e-04   \n",
       "22      29.250574      0.331922         0.012766    3.988982e-04   \n",
       "23      38.520583      0.722854         0.013364    4.886555e-04   \n",
       "24      48.026162      0.511313         0.014362    4.885387e-04   \n",
       "25      57.557874      0.447407         0.014559    4.917080e-04   \n",
       "26      62.635891      0.961191         0.014960    4.101908e-07   \n",
       "27     157.020076      1.422645         0.019151    1.160667e-03   \n",
       "28      19.108298      1.012536         0.013364    4.886166e-04   \n",
       "29      27.236760      0.238429         0.012965    1.907349e-07   \n",
       "30      37.030169      0.354756         0.013764    7.463784e-04   \n",
       "31      46.259686      0.605682         0.014162    3.988981e-04   \n",
       "32      55.480826      0.189661         0.014362    4.885972e-04   \n",
       "33      60.546279      0.583241         0.014362    4.885971e-04   \n",
       "34     154.575215      1.063905         0.018550    4.886945e-04   \n",
       "35      16.788103      0.468796         0.013364    4.885972e-04   \n",
       "36      25.944216      0.114920         0.012965    6.306756e-04   \n",
       "37      35.490088      0.597320         0.012965    2.611745e-07   \n",
       "38      44.735961      0.615264         0.013763    7.463785e-04   \n",
       "39      54.104906      0.502498         0.013963    9.536743e-08   \n",
       "40      58.658927      0.100898         0.014162    3.988982e-04   \n",
       "41     151.961206      1.577624         0.017553    4.885971e-04   \n",
       "42      16.892623      0.340219         0.012766    3.988028e-04   \n",
       "43      26.376062      0.396882         0.012965    3.162980e-07   \n",
       "44      35.549928      0.179738         0.014763    2.225330e-03   \n",
       "45      45.455637      0.282850         0.013962    9.536743e-08   \n",
       "46      54.831961      0.503145         0.014162    3.988982e-04   \n",
       "47      58.649751      0.581775         0.014164    7.460200e-04   \n",
       "48     153.170771      1.476729         0.017954    6.306087e-04   \n",
       "49      17.675530      0.418713         0.012167    3.989458e-04   \n",
       "50      27.244340      0.506015         0.015558    3.656409e-03   \n",
       "51      37.522054      1.637269         0.017154    7.393786e-03   \n",
       "52      46.320125      0.679024         0.013763    3.988506e-04   \n",
       "53      55.034021      0.422074         0.013763    3.986121e-04   \n",
       "54      55.643990      1.197637         0.010771    1.716194e-03   \n",
       "55      93.678273      4.995996         0.010971    1.092623e-03   \n",
       "\n",
       "   param_max_depth param_n_estimators  \\\n",
       "0                3                100   \n",
       "1                3                300   \n",
       "2                3                500   \n",
       "3                3                700   \n",
       "4                3                900   \n",
       "5                3               1000   \n",
       "6                3               3000   \n",
       "7                4                100   \n",
       "8                4                300   \n",
       "9                4                500   \n",
       "10               4                700   \n",
       "11               4                900   \n",
       "12               4               1000   \n",
       "13               4               3000   \n",
       "14               5                100   \n",
       "15               5                300   \n",
       "16               5                500   \n",
       "17               5                700   \n",
       "18               5                900   \n",
       "19               5               1000   \n",
       "20               5               3000   \n",
       "21               6                100   \n",
       "22               6                300   \n",
       "23               6                500   \n",
       "24               6                700   \n",
       "25               6                900   \n",
       "26               6               1000   \n",
       "27               6               3000   \n",
       "28               7                100   \n",
       "29               7                300   \n",
       "30               7                500   \n",
       "31               7                700   \n",
       "32               7                900   \n",
       "33               7               1000   \n",
       "34               7               3000   \n",
       "35               8                100   \n",
       "36               8                300   \n",
       "37               8                500   \n",
       "38               8                700   \n",
       "39               8                900   \n",
       "40               8               1000   \n",
       "41               8               3000   \n",
       "42               9                100   \n",
       "43               9                300   \n",
       "44               9                500   \n",
       "45               9                700   \n",
       "46               9                900   \n",
       "47               9               1000   \n",
       "48               9               3000   \n",
       "49              10                100   \n",
       "50              10                300   \n",
       "51              10                500   \n",
       "52              10                700   \n",
       "53              10                900   \n",
       "54              10               1000   \n",
       "55              10               3000   \n",
       "\n",
       "                                     params  split0_test_score  \\\n",
       "0     {'max_depth': 3, 'n_estimators': 100}          -9.853485   \n",
       "1     {'max_depth': 3, 'n_estimators': 300}          -9.778643   \n",
       "2     {'max_depth': 3, 'n_estimators': 500}          -9.778949   \n",
       "3     {'max_depth': 3, 'n_estimators': 700}          -9.778979   \n",
       "4     {'max_depth': 3, 'n_estimators': 900}          -9.779003   \n",
       "5    {'max_depth': 3, 'n_estimators': 1000}          -9.779013   \n",
       "6    {'max_depth': 3, 'n_estimators': 3000}          -9.779098   \n",
       "7     {'max_depth': 4, 'n_estimators': 100}         -10.521678   \n",
       "8     {'max_depth': 4, 'n_estimators': 300}         -10.519106   \n",
       "9     {'max_depth': 4, 'n_estimators': 500}         -10.519074   \n",
       "10    {'max_depth': 4, 'n_estimators': 700}         -10.519048   \n",
       "11    {'max_depth': 4, 'n_estimators': 900}         -10.519027   \n",
       "12   {'max_depth': 4, 'n_estimators': 1000}         -10.519023   \n",
       "13   {'max_depth': 4, 'n_estimators': 3000}         -10.518931   \n",
       "14    {'max_depth': 5, 'n_estimators': 100}         -10.487485   \n",
       "15    {'max_depth': 5, 'n_estimators': 300}         -10.488292   \n",
       "16    {'max_depth': 5, 'n_estimators': 500}         -10.488322   \n",
       "17    {'max_depth': 5, 'n_estimators': 700}         -10.488347   \n",
       "18    {'max_depth': 5, 'n_estimators': 900}         -10.488361   \n",
       "19   {'max_depth': 5, 'n_estimators': 1000}         -10.488365   \n",
       "20   {'max_depth': 5, 'n_estimators': 3000}         -10.488441   \n",
       "21    {'max_depth': 6, 'n_estimators': 100}         -11.693325   \n",
       "22    {'max_depth': 6, 'n_estimators': 300}         -11.693269   \n",
       "23    {'max_depth': 6, 'n_estimators': 500}         -11.693238   \n",
       "24    {'max_depth': 6, 'n_estimators': 700}         -11.693213   \n",
       "25    {'max_depth': 6, 'n_estimators': 900}         -11.693200   \n",
       "26   {'max_depth': 6, 'n_estimators': 1000}         -11.693196   \n",
       "27   {'max_depth': 6, 'n_estimators': 3000}         -11.693111   \n",
       "28    {'max_depth': 7, 'n_estimators': 100}         -11.906965   \n",
       "29    {'max_depth': 7, 'n_estimators': 300}         -11.906912   \n",
       "30    {'max_depth': 7, 'n_estimators': 500}         -11.906876   \n",
       "31    {'max_depth': 7, 'n_estimators': 700}         -11.906846   \n",
       "32    {'max_depth': 7, 'n_estimators': 900}         -11.906833   \n",
       "33   {'max_depth': 7, 'n_estimators': 1000}         -11.906829   \n",
       "34   {'max_depth': 7, 'n_estimators': 3000}         -11.906734   \n",
       "35    {'max_depth': 8, 'n_estimators': 100}         -11.785573   \n",
       "36    {'max_depth': 8, 'n_estimators': 300}         -11.785527   \n",
       "37    {'max_depth': 8, 'n_estimators': 500}         -11.785495   \n",
       "38    {'max_depth': 8, 'n_estimators': 700}         -11.785470   \n",
       "39    {'max_depth': 8, 'n_estimators': 900}         -11.785458   \n",
       "40   {'max_depth': 8, 'n_estimators': 1000}         -11.785453   \n",
       "41   {'max_depth': 8, 'n_estimators': 3000}         -11.785348   \n",
       "42    {'max_depth': 9, 'n_estimators': 100}         -11.913126   \n",
       "43    {'max_depth': 9, 'n_estimators': 300}         -11.913084   \n",
       "44    {'max_depth': 9, 'n_estimators': 500}         -11.913053   \n",
       "45    {'max_depth': 9, 'n_estimators': 700}         -11.913028   \n",
       "46    {'max_depth': 9, 'n_estimators': 900}         -11.913018   \n",
       "47   {'max_depth': 9, 'n_estimators': 1000}         -11.913013   \n",
       "48   {'max_depth': 9, 'n_estimators': 3000}         -11.912918   \n",
       "49   {'max_depth': 10, 'n_estimators': 100}         -12.761759   \n",
       "50   {'max_depth': 10, 'n_estimators': 300}         -12.761810   \n",
       "51   {'max_depth': 10, 'n_estimators': 500}         -12.761840   \n",
       "52   {'max_depth': 10, 'n_estimators': 700}         -12.761866   \n",
       "53   {'max_depth': 10, 'n_estimators': 900}         -12.761877   \n",
       "54  {'max_depth': 10, 'n_estimators': 1000}         -12.761880   \n",
       "55  {'max_depth': 10, 'n_estimators': 3000}         -12.761954   \n",
       "\n",
       "    split1_test_score  split2_test_score  ...  mean_test_score  \\\n",
       "0          -10.625332          -9.719376  ...        -9.384355   \n",
       "1          -10.684162          -9.766579  ...        -9.440823   \n",
       "2          -10.685155          -9.758812  ...        -9.436498   \n",
       "3          -10.685118          -9.758786  ...        -9.436477   \n",
       "4          -10.685089          -9.758770  ...        -9.436460   \n",
       "5          -10.685076          -9.758763  ...        -9.436452   \n",
       "6          -10.684978          -9.758706  ...        -9.436366   \n",
       "7           -9.634299         -10.689543  ...        -9.661415   \n",
       "8           -9.624321         -10.676589  ...        -9.657133   \n",
       "9           -9.624285         -10.676565  ...        -9.657121   \n",
       "10          -9.624254         -10.676544  ...        -9.657110   \n",
       "11          -9.624230         -10.676529  ...        -9.657100   \n",
       "12          -9.624226         -10.676526  ...        -9.657097   \n",
       "13          -9.624130         -10.676468  ...        -9.657037   \n",
       "14         -10.596366          -8.785534  ...       -10.090739   \n",
       "15         -10.593443          -8.787705  ...       -10.091234   \n",
       "16         -10.593480          -8.787685  ...       -10.091226   \n",
       "17         -10.593511          -8.787669  ...       -10.091220   \n",
       "18         -10.593526          -8.787660  ...       -10.091214   \n",
       "19         -10.593532          -8.787658  ...       -10.091211   \n",
       "20         -10.593635          -8.787609  ...       -10.091157   \n",
       "21         -10.869622          -8.529902  ...        -9.946695   \n",
       "22         -10.869687          -8.529942  ...        -9.946722   \n",
       "23         -10.869719          -8.529961  ...        -9.946735   \n",
       "24         -10.869745          -8.529977  ...        -9.946745   \n",
       "25         -10.869757          -8.529984  ...        -9.946753   \n",
       "26         -10.869762          -8.529986  ...        -9.946756   \n",
       "27         -10.869859          -8.530023  ...        -9.946758   \n",
       "28          -9.908395          -9.496265  ...       -10.088456   \n",
       "29          -9.908438          -9.496295  ...       -10.088484   \n",
       "30          -9.908468          -9.496310  ...       -10.088501   \n",
       "31          -9.908494          -9.496322  ...       -10.088516   \n",
       "32          -9.908502          -9.496327  ...       -10.088524   \n",
       "33          -9.908506          -9.496329  ...       -10.088529   \n",
       "34          -9.908590          -9.496372  ...       -10.088612   \n",
       "35          -9.885503          -9.884064  ...       -10.540118   \n",
       "36          -9.885552          -9.884025  ...       -10.540096   \n",
       "37          -9.885580          -9.884006  ...       -10.540086   \n",
       "38          -9.885603          -9.883990  ...       -10.540077   \n",
       "39          -9.885613          -9.883983  ...       -10.540077   \n",
       "40          -9.885618          -9.883981  ...       -10.540077   \n",
       "41          -9.885710          -9.883931  ...       -10.540084   \n",
       "42         -10.594389          -9.958569  ...       -10.887083   \n",
       "43         -10.594436          -9.958605  ...       -10.887113   \n",
       "44         -10.594465          -9.958625  ...       -10.887133   \n",
       "45         -10.594492          -9.958640  ...       -10.887151   \n",
       "46         -10.594515          -9.958647  ...       -10.887168   \n",
       "47         -10.594526          -9.958650  ...       -10.887176   \n",
       "48         -10.594611          -9.958711  ...       -10.887271   \n",
       "49         -10.217927         -11.633507  ...       -11.384796   \n",
       "50         -10.217873         -11.633544  ...       -11.384826   \n",
       "51         -10.217838         -11.633563  ...       -11.384845   \n",
       "52         -10.217809         -11.633579  ...       -11.384862   \n",
       "53         -10.217797         -11.633585  ...       -11.384871   \n",
       "54         -10.217792         -11.633588  ...       -11.384875   \n",
       "55         -10.217688         -11.633640  ...       -11.384953   \n",
       "\n",
       "    std_test_score  rank_test_score  split0_train_score  split1_train_score  \\\n",
       "0         5.234924                1            0.984033            0.988978   \n",
       "1         5.312433                7            0.999812            0.999916   \n",
       "2         5.308855                6            0.999895            0.999994   \n",
       "3         5.308846                5            0.999895            0.999994   \n",
       "4         5.308839                4            0.999895            0.999994   \n",
       "5         5.308837                3            0.999895            0.999994   \n",
       "6         5.308860                2            0.999895            0.999994   \n",
       "7         5.423894               14            0.998975            0.999424   \n",
       "8         5.425929               13            0.999898            0.999995   \n",
       "9         5.425949               12            0.999898            0.999995   \n",
       "10        5.425967               11            0.999898            0.999995   \n",
       "11        5.425982               10            0.999898            0.999995   \n",
       "12        5.425988                9            0.999898            0.999995   \n",
       "13        5.426101                8            0.999898            0.999995   \n",
       "14        6.354163               29            0.999891            0.999989   \n",
       "15        6.354878               35            0.999900            0.999995   \n",
       "16        6.354867               34            0.999900            0.999995   \n",
       "17        6.354859               33            0.999900            0.999995   \n",
       "18        6.354857               32            0.999900            0.999995   \n",
       "19        6.354858               31            0.999900            0.999995   \n",
       "20        6.354869               30            0.999900            0.999995   \n",
       "21        5.771545               15            0.999899            0.999996   \n",
       "22        5.771580               16            0.999899            0.999996   \n",
       "23        5.771604               17            0.999899            0.999996   \n",
       "24        5.771625               18            0.999899            0.999996   \n",
       "25        5.771646               19            0.999899            0.999996   \n",
       "26        5.771656               20            0.999899            0.999996   \n",
       "27        5.771772               21            0.999899            0.999996   \n",
       "28        5.872120               22            0.999901            0.999996   \n",
       "29        5.872136               23            0.999901            0.999996   \n",
       "30        5.872142               24            0.999901            0.999996   \n",
       "31        5.872146               25            0.999901            0.999996   \n",
       "32        5.872143               26            0.999901            0.999996   \n",
       "33        5.872141               27            0.999901            0.999996   \n",
       "34        5.872108               28            0.999901            0.999996   \n",
       "35        6.448946               42            0.999902            0.999997   \n",
       "36        6.448907               41            0.999902            0.999997   \n",
       "37        6.448880               40            0.999902            0.999997   \n",
       "38        6.448856               37            0.999902            0.999997   \n",
       "39        6.448843               36            0.999902            0.999997   \n",
       "40        6.448836               38            0.999902            0.999997   \n",
       "41        6.448709               39            0.999902            0.999997   \n",
       "42        6.720698               43            0.999902            0.999997   \n",
       "43        6.720717               44            0.999902            0.999997   \n",
       "44        6.720727               45            0.999902            0.999997   \n",
       "45        6.720734               46            0.999902            0.999997   \n",
       "46        6.720741               47            0.999902            0.999997   \n",
       "47        6.720744               48            0.999902            0.999997   \n",
       "48        6.720735               49            0.999902            0.999997   \n",
       "49        6.812050               50            0.999903            0.999998   \n",
       "50        6.812077               51            0.999903            0.999998   \n",
       "51        6.812090               52            0.999903            0.999998   \n",
       "52        6.812100               53            0.999903            0.999998   \n",
       "53        6.812101               54            0.999903            0.999998   \n",
       "54        6.812100               55            0.999903            0.999998   \n",
       "55        6.812083               56            0.999903            0.999998   \n",
       "\n",
       "    split2_train_score  split3_train_score  split4_train_score  \\\n",
       "0             0.988325            0.988727            0.984422   \n",
       "1             0.999930            0.999887            0.999834   \n",
       "2             0.999993            0.999942            0.999919   \n",
       "3             0.999993            0.999942            0.999919   \n",
       "4             0.999993            0.999942            0.999919   \n",
       "5             0.999993            0.999942            0.999919   \n",
       "6             0.999993            0.999942            0.999919   \n",
       "7             0.999316            0.999599            0.999027   \n",
       "8             0.999995            0.999943            0.999922   \n",
       "9             0.999995            0.999943            0.999922   \n",
       "10            0.999995            0.999943            0.999922   \n",
       "11            0.999995            0.999943            0.999922   \n",
       "12            0.999995            0.999943            0.999922   \n",
       "13            0.999995            0.999943            0.999922   \n",
       "14            0.999991            0.999937            0.999909   \n",
       "15            0.999995            0.999944            0.999923   \n",
       "16            0.999995            0.999944            0.999923   \n",
       "17            0.999995            0.999944            0.999923   \n",
       "18            0.999995            0.999944            0.999923   \n",
       "19            0.999995            0.999944            0.999923   \n",
       "20            0.999995            0.999944            0.999923   \n",
       "21            0.999995            0.999944            0.999922   \n",
       "22            0.999995            0.999944            0.999922   \n",
       "23            0.999995            0.999944            0.999922   \n",
       "24            0.999995            0.999944            0.999922   \n",
       "25            0.999995            0.999944            0.999922   \n",
       "26            0.999995            0.999944            0.999922   \n",
       "27            0.999995            0.999944            0.999922   \n",
       "28            0.999996            0.999945            0.999925   \n",
       "29            0.999996            0.999945            0.999925   \n",
       "30            0.999996            0.999945            0.999925   \n",
       "31            0.999996            0.999945            0.999925   \n",
       "32            0.999996            0.999945            0.999925   \n",
       "33            0.999996            0.999945            0.999925   \n",
       "34            0.999996            0.999945            0.999924   \n",
       "35            0.999997            0.999946            0.999925   \n",
       "36            0.999997            0.999946            0.999925   \n",
       "37            0.999997            0.999946            0.999925   \n",
       "38            0.999997            0.999946            0.999925   \n",
       "39            0.999997            0.999946            0.999925   \n",
       "40            0.999997            0.999946            0.999925   \n",
       "41            0.999997            0.999946            0.999924   \n",
       "42            0.999997            0.999946            0.999926   \n",
       "43            0.999997            0.999946            0.999926   \n",
       "44            0.999997            0.999946            0.999926   \n",
       "45            0.999997            0.999946            0.999926   \n",
       "46            0.999997            0.999946            0.999926   \n",
       "47            0.999997            0.999946            0.999926   \n",
       "48            0.999997            0.999946            0.999926   \n",
       "49            0.999998            0.999947            0.999927   \n",
       "50            0.999998            0.999947            0.999927   \n",
       "51            0.999998            0.999947            0.999927   \n",
       "52            0.999998            0.999947            0.999927   \n",
       "53            0.999998            0.999947            0.999927   \n",
       "54            0.999998            0.999947            0.999927   \n",
       "55            0.999998            0.999947            0.999926   \n",
       "\n",
       "    mean_train_score  std_train_score  \n",
       "0           0.986897         0.002193  \n",
       "1           0.999876         0.000046  \n",
       "2           0.999949         0.000040  \n",
       "3           0.999949         0.000040  \n",
       "4           0.999949         0.000040  \n",
       "5           0.999949         0.000040  \n",
       "6           0.999949         0.000040  \n",
       "7           0.999268         0.000237  \n",
       "8           0.999950         0.000039  \n",
       "9           0.999950         0.000039  \n",
       "10          0.999950         0.000039  \n",
       "11          0.999950         0.000039  \n",
       "12          0.999950         0.000039  \n",
       "13          0.999950         0.000039  \n",
       "14          0.999944         0.000041  \n",
       "15          0.999951         0.000038  \n",
       "16          0.999951         0.000038  \n",
       "17          0.999951         0.000038  \n",
       "18          0.999951         0.000038  \n",
       "19          0.999951         0.000038  \n",
       "20          0.999951         0.000038  \n",
       "21          0.999951         0.000039  \n",
       "22          0.999951         0.000039  \n",
       "23          0.999951         0.000039  \n",
       "24          0.999951         0.000039  \n",
       "25          0.999951         0.000039  \n",
       "26          0.999951         0.000039  \n",
       "27          0.999951         0.000039  \n",
       "28          0.999953         0.000038  \n",
       "29          0.999953         0.000038  \n",
       "30          0.999953         0.000038  \n",
       "31          0.999953         0.000038  \n",
       "32          0.999953         0.000038  \n",
       "33          0.999953         0.000038  \n",
       "34          0.999953         0.000038  \n",
       "35          0.999953         0.000038  \n",
       "36          0.999953         0.000038  \n",
       "37          0.999953         0.000038  \n",
       "38          0.999953         0.000038  \n",
       "39          0.999953         0.000038  \n",
       "40          0.999953         0.000038  \n",
       "41          0.999953         0.000038  \n",
       "42          0.999954         0.000038  \n",
       "43          0.999954         0.000038  \n",
       "44          0.999954         0.000038  \n",
       "45          0.999954         0.000038  \n",
       "46          0.999954         0.000038  \n",
       "47          0.999954         0.000038  \n",
       "48          0.999954         0.000038  \n",
       "49          0.999954         0.000038  \n",
       "50          0.999954         0.000038  \n",
       "51          0.999954         0.000038  \n",
       "52          0.999954         0.000038  \n",
       "53          0.999954         0.000038  \n",
       "54          0.999954         0.000038  \n",
       "55          0.999954         0.000038  \n",
       "\n",
       "[56 rows x 22 columns]"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(grid_search.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 3, 'n_estimators': 100}"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "             colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "             importance_type='gain', interaction_constraints='',\n",
       "             learning_rate=0.300000012, max_delta_step=0, max_depth=3,\n",
       "             min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "             n_estimators=100, n_jobs=0, num_parallel_tree=1,\n",
       "             objective='reg:squarederror', random_state=0, reg_alpha=0,\n",
       "             reg_lambda=1, scale_pos_weight=1, seed=0, subsample=1,\n",
       "             tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ml_model_best = grid_search.best_estimator_\n",
    "\n",
    "ml_model_best.fit(x_train, score_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import learning_curve\n",
    "def plot_learningcurve(classifier, X, y, plt_titile):\n",
    "    # check whether there is overfitting or underfitting by learning_curve\n",
    "    # choose five kinds of fraction of the maximum size of the training set: np.linspace(0.1,1.0,5)\n",
    "    train_size, train_score, test_score = learning_curve(classifier, X, y, cv=5, train_sizes=np.linspace(0.1,1.0,5))\n",
    "    train_scores_mean = np.mean(train_score, axis=1)\n",
    "    train_scores_std = np.std(train_score, axis=1)\n",
    "    test_scores_mean = np.mean(test_score, axis=1)\n",
    "    test_scores_std = np.std(test_score, axis=1)\n",
    "    plt.fill_between(train_size, train_scores_mean - train_scores_std, train_scores_mean + train_scores_std, alpha=0.1, color=\"r\")\n",
    "    plt.fill_between(train_size, test_scores_mean - test_scores_std, test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n",
    "    plt.plot(train_size, train_scores_mean,'o--', color=\"r\",label=\"Training score\")\n",
    "    plt.plot(train_size, test_scores_mean,'o-', color=\"g\",label=\"Testing score\")\n",
    "    plt.grid()\n",
    "    plt.title(plt_titile)\n",
    "    plt.legend(loc=\"best\")\n",
    "    return plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX8AAAEICAYAAAC3Y/QeAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nO3deXwU9f348dd7N5v74JJADgRvuaQQoqKtqKh4VUutF0prrajVevSrFau/alttrfbwrmBLaxWh/Vat2mKpWvOtVuUUkUMFq0LCoVCFXJvs8f79MbObTbKBXJtNsu+n7oPdz2dm9jOfnbxn5jOf+YyoKsYYY1KLJ9kFMMYY0/Ms+BtjTAqy4G+MMSnIgr8xxqQgC/7GGJOCLPgbY0wKsuBveiUReUFEvp7sciSDiPxURK5LdjkSQUSWiciYZJfDWPA3LYjIRyIyLdnlUNVTVfWxRCxbRPJF5F4R2SwiNSKyyf08JBHf18Gy7QfMAua6n88Uke0iMihmmrNEpEpECtzPIiJXi8gaEalzp68QkfNj5qkQEb+7vrtF5F8iMi7B6/J7EbmjRfLPgR8l8ntN+1jwNz1ORNKS+N3pwMvAGGA6kA9MAXYB5Z1YXnevyzeAxapaD6CqzwP/BH7lft8A4NfAlaq6253nfuA64H+AwUAxcCvO+sW6WlVz3WkqgMe7uezt8RxwvIgMT8J3m1iqai97RV/AR8C0NvLOAFYDnwOvA+Nj8uYAHwDVwHrgKzF53wD+jRPA/gvc4aa9hnMk+BnwIXBqzDwVwLdi5t/btKOAf7nf/RLwEPBEG+vwLWAHkLuXOlDgoJjPvwfucN9PBSqBm4DtOAF0A3BGzPRpwE5govv5KLe+PgfeBqbu5bv/CVzUIm0I8AlwCvA7YGFM3iFACCjbx+8arU/382igMeZzBnAvsNV93QtkxORfBmxyf7/ngCI3Xdzf9RNgN7AGGAvMBgJAI1ADPB+zrBeBryd7W0/1lx35m3YRkYnAfOBynCPHucBzIpLhTvIB8EWgAPgh8ESLo7sjgf8AQ4E7Y9LewwludwO/FRFpowh7m/ZJYJlbrtuBi/eyKtOAv6tqzb7Xuk3DgEHA/jhBbiFwQUz+KcBOVV0lIsXA33B2eIOAG4Cn3OadeMbhrGeUqu4ErgUW4OyAr4nJPgHYoqor2lt49+xnJvBmTPItODupCcAROGdBt7rTnwD8FDgXGA58DCxy5zsZ+BLOTmgAcB6wS1XnueW9W1VzVfXMmO/a4H6HSSIL/qa9LgPmqupSVQ2p0x7fgBMwUNX/VdWtqhpW1T8CG2nejLJVVR9Q1aC6TRrAx6r6qKqGgMdwAkthG98fd1oRGQFMBn6gqo2q+hrOkWlbBgPbOlUDTcLAbara4K7Lk8CXRSTbzb/QTQO4CKcZZ7FbNy8CK4DT2lj2AJwzmJbexNmx/kNVP41JH4JzBhIlIpUi8rnbxr9/TNb9IvI5zpH41Tg76YiZwI9U9RN3+T+kaSc6E5ivqqtUtQG4GThaREbiHN3nAYcBoqobVHVf9VvtrqdJIgv+pr32B/7HDSqfu0GkFCgCEJFZIrI6Jm8sTmCK2BJnmdGgpap17tvcNr6/rWmLgP/GpLX1XRG7cHYcXfGpqvpjyrMJ52j2THcH8GWagv/+wNda1NuxeynDZzjBtKV5wB+A00RkSkx6q/VR1RKcus/AaZaJuEZVBwCZOGcQfxaR8W5eEc4RfcTHblqrPPesaRdQrKr/BB7EaWrbISLzRCS/jXWLyMNpAjNJZMHftNcW4E5VHRDzylbVhe7R5aM4R5OD3QCzluaBJ1HDx24DBsUcdYOzU2rLS8ApIpKzl2nqgNjlDWuRH29dIk0/ZwHr3R0COPX2eIt6y1HVu9r47jU4TShRInIpzjp9G/g+8KjbdAPONYISESnby/o0L7xzBvIqThv+yW7yVpwdVcQIN61Vnlt3g4Eqd3n3q+oknIvohwA3Rr6qjSIcjnPtwySRBX8Tj09EMmNeaTjB/QoROdLtWpgjIqeLSB6Qg/OH/imAiFyCc+SfcKr6MU4zyu0iki4iRwNn7mWWx3EC8lMicpiIeERksIh8X0QiTTGrgQtFxCsi04Hj2lGURTiB9EqajvoBnsA5IzjFXV6miEwVkZI2lrM49vtEpAi4B7jMbXJ5BOeo+xZ3/d/Duf6ySEROEpEsEfHi9GBqk1tPo4F1btJC4FYR2c/t8voDt+y463OJiExwr/H8BFiqqh+JyGR3m/ABtYAf5wI0OBfWD2jxvRnAJJyLviaJLPibeBYD9TGv290LipfhnOJ/hnPU+A0AVV0P/AJ4A+cPfhxO756eMhM4Gico3gH8Eed6RCtuAJ0GvIsTgPbgXCweAix1J7sWZwfyubvsv+yrAG479xs4QfePMelbcM4Gvo+zc9yCc2Tc1t9epGkny/38MLDIPVJHVRXnd7gu5mapq3C6e/4SpzdOJfBjnIuvm2OW/aDbz78GZyd4q6q+4ObdgbMTXQO8A6xy01DVl4H/BzyFc6Z1IBC5hyAf58DgM5ymoV04vbIAfguMdpu7InX4ZaBCVSNnFSZJxNmWjOk/ROSPwLuqeluyy9IZIvIT4BNVvTfZZeluIrIUuFRV1ya7LKnOgr/p80RkMs4R74c4TS9/AY5W1beSWjBjerGk3WlpTDcaBjyNcxGyEufuVwv8xuyFHfkbY0wKsgu+xhiTgvpMs8+QIUN05MiRyS5Gp9XW1pKTs7eu5anF6qOJ1UUTq4sm3VEXK1eu3KmqcYcS6TPBf+TIkaxY0e7hS3qdiooKpk6dmuxi9BpWH02sLppYXTTpjroQkY/byrNmH2OMSUEW/I0xJgVZ8DfGmBRkwd8YY1KQBX9jjElB/Tv4L1gAI0eCx+P8u2BBskvUu1l9dYzVV8dYfXXI0JdeSmh99Zmunh22YAHMng117jM+Pv7Y+Qwwc2byytVbWX11jNVXx1h9dcyCBRz6859Dgzs4bQLqK2nDO7jjpN8HeIHf7OXhFgCUlZVph/r5jxzpVFhLBQVwzTXwta/BuHHwn//A73/ferqZM+HQQ2HDBli4sHX+N7/pfMfbb8NTT7XOv/JKGD4cli+H55/no48+otlNatdeC4MHw2uvwT/+0Xr+G2+EvDx4+WX4v/9rnX/rrZCeDi+8AG+80TxPBH7oPqHv2Wdh5crm+RkZcMstzvs//QnWroX774fdu1t/z+DB8O1vN08bMsSpQ4D581vXc1ERXH658/7Xv4bt25vnjxpFxciRTh/m++6D//63ef6hh8KFFzrv77kHalo8bnfcODjnHOf9HXdAINA8v6wMzjwTwuGmeog1ZQqccgr4/fDTn7bOP/54mDoV9uyBX/yidf706XDBBW1vXy+/DJMmQVUVzJvXeppzzmna9h57rPW2MXMmHHIIvPsuLFrUev5LLoH994c1a+Dpp1vnX365s+2tWAF//Wvr/O98x/ld//1veDHOsPo33AC5ufDKK/G3ve9/39n2liyBN99snX+bO5jq88/DqlXO+1/9Kv72VVAA118f/bhpxw4Oevhh58OTT8LGjc2nHzwYrr7aef+738Hmzc3zi4rgssuc9/Pmtd72Ro6EWbOc9w8+2HrbO+QQON8drfoXv4Da2ub5Y8fCjBnO+7vuar3tTZwIp58Oqs622dLRR8O0ac62d889rfOPOw6+9CUYMQK2xHkg3f77w0cftU5vg4isVNX4D/pJxlPjcQL+BzgPekjHearP6L3NM2nSJO0QEVXnJ2j9ElF9+GHVqirVP/7R+dzy9dhjTv78+fHzn3rKyX/ggfj5S5Y4+T/9qaqIhlvmv/qqk3/rrfHnf+stJ//66+Pnb9zo5F92Wes8j8fJq6pSnTmzdX5+fjQ/9OUva1hEw23UVRic/JhX4MBRumPT2/rJpjXaMHliq3kC48bozk3v6M5N72jg8MNa5TceXa4vLXlB//ufdRrcf0Tr/Gkn6Of/2aB7PnxPQ0OGtM4/60yt/uh9rf7ofQ1nZbXOv/B8rfloo9b8572469Q4+1ta+/EmrXvnrfj5371O6z/+QOuX/jtufuAHtzi/Z1vb1913O/X7t7/Fz4/d9uLlx2578fJjt714+bHbXrz82G0vXn5k27vuuvj5kW3vW9+K/7cV2fYuvLDtOmrj5R88uGn+E05oPc2BBzblH3lk6/wjjmjKHzOmdf6UKU35I0e2zj/55Kb8/fZrnf+VrzTlx9n29KKLnLwtW+Kv4xVXOPkbNsTPv+EGJ7+t7UukQ2EQWNFWTE3Kkb/7FKHbVfUU9/PN7o4ozmGYo9uO/EtLYd261ukJVrF8OVMnT+7x7w2FQ4Q0RCgcIqhBGoMBGsONNIQaCIQDRH7/Ucecga+q9XO3A8XD2fLGklbp2uYT+uKnt9zOPnh3GwceNrzN5bS1XSogzZ4O2VSeDqdLnHRt3/SjppzeRn0N4+PXX8DrSSNNvKR50tyX814QPOJp9npt5SqmTi5vtaxeS9U5u2wrdkTqKTZ/7Nj4R7Klpc6Zp6ti+XKmlpe3nn9fy48tm8e9lBkOx5+/u/JDodZ5Ik6+avz525s/ZkzCj/yT1eZfTPOHbFcCR7acSERmA7MBCgsLqaioaPcXDL3oIg79+c/xNjQ90CmUkcF7s2bxSctmkB5QU1dHRYK+V1Gc/53/whp29u5uOuA8TdeJnNHgFhvMGmbNYvQv721VX+/OmsX2jS1OnbtBY0OQDzd92u3L7Slt19fX2b7p0+jvAXF2lC0+NtQ3sGTp69HfQ5wfCUEQkabfy02Pvu9Dhs6a1fbfY6RpCKipr0/Y30lfMnTWLA75+c9Ja1lfF13EJx2Ig3uTrOAfb8tttRtX1XnAPHCO/Ds0zsXUqXD44U7b9ubNMGIE3jvvZPTMmYzuXJm7pLPjdIQ1HD16D4aDBEIBGkPOkXtjqJFwOAzSdMTq8ThHk2meNLzijXt0G9fkMew5sIS8H96Ft3IroZIiqm+bw+BzZzC4w6Xet3XL1zFm8ph9T9hbdWN9ReoirOHoS9Xdibs784h4ZyZpnjS8Hi9e8eL1xJ5tpDU7wxBpftbRo9r592hj+7imTmU9MPqJJxIWv5IV/CuB0pjPJUD3P9Nz5sxe35NAVaOBPRR2/vUH/TSGGgmEAgTCASeAu0eSXo8Xj3jwipestKz2B/d2qD93BvXnzui25fV33V1fnQ3KkR2G06zXGD3ri91pQFNTWmTnEdlpRA4UYj+3bJqK3Xl0Wh/4e+xNPpk2jdHxLhp3k2QF/+XAwSIyCqjCeRj0hUkqS0JFgrui1DbWEgwHnSP3oHPkHtRgNLBHTvEjR+7paelkSmayV8H0cl3daQTCARq0oc2dBjTfccTuJFruOOLtNCI7DtO7JCX4q2pQRK4GluD0/Jmvqj1/FbYbRE7Pg+GgcwQfCkabZBpDjQTCAVBoDDVSuacy+sfg9XgtuJuk6sxOI3YHEQgHaAg1RP8GwhpuO8hr8zONlt8f+TcUDvFZ/WfN0mJ3HrHXq1peu4pcI+nIdKksaTd5qepiYHGyvr8jYtvcQ+FQtM29IdhAMBx0LrNG2mKFZm2vGWkZgLMB52XkJXlNjOma2LPTjmi504icSUQvirufgxpkV/2uZvO4E7oFoOlzzPtob6yY6WL/Jlstw33vcXvuePBEL7LH7nRa7pwiO6J9TdfWDinezmlv00XPuBKws+q/d/h2QPTI3Q3ykSaZyCu2N03sqWyaJ410b7odRRizD+3daXjEQ7Yvu4dKRbOdUMsdUljDhDTU5nTRZcSZt+XOCWhzhxRvx4VCQ7CBjf/diFe8jBwwEq/H241rniLBP9JjJtI0EwgFaAg2RPu6h8PhZj+Ax+OJHr1n+7ItuBvTT7XsXtubeDwectNzqWmo2ct9NZ3X74N/MBzk488/dvbgMad6kSP37u4xY4wxfUG/D/6R3ja56bnJLooxxvQa/XtIZ2OMMXFZ8DfGmF7o5U9epvzRcg576DAOvP9AFrxj4/kbY0y/9uf1f+bejffSEHbG9tm8ezOzn3fG8585rnvukrbgb4wx7aSqNIYaqQ/WUx+od/4N1lMXqKM+UI8/6G9KDzTPi0wbm18XqGs+j5seCAdafXddoI5bXr7Fgr8xpm95esPT3PXaXWyt3kpRXhFzjp3DjMO7b2wkVXUCaYsAGy/gxgvEkUDtD/hbBffY+eINf7EvmWmZZKVlkeXLIisti2xfNlm+LPIz8inMKYymR/59cPmDcZezeffmuOmdYcHfGJNwT294mu+9+D3qg/UAVFVXccM/bmDjro1MLp4cDbQfbPuAf6/8d/uOpuME744SJBqIY4NvVloWA7MGUuQrap4e8292Wpz5YvN92WSlZZGRltHhO6KfefcZqqqrWqWPKBjR4XVsiwV/Y0y3UFU+839G5Z5KtuzewpY9W6jaU8WWPVt45aNXCIaDzaZvCDVw/7L7Wy9ok/OPV7zRwBwJtJlpmWT5shiaM7RDgThecM/yZZHhzeiV9/nMOXYONyy5IdrmD5Dty+bOE+/stu+w4G+MaRdVZVf9rlaBPfZ9XaCu2Ty56bmU5pe2CvwRgvDs+c9Gj5Q3r9vMhLIJZKVl4fP6emK1eqUZh8+g8j+VPLH1CbZWb6W0oJSfnPiTbmvvBwv+xhhXWMN8WvspW/ZsoXJPpXMEHxPYK/dU4g/6m80zIGMAxfnFjBowii/u/0VK8ksozS+lJL+EkvwSCjIKEBHKHy2P24xRlFfEpKJJ0c+16bXkZ+QnfF37ghOHnsg1p19DTUMNBww6IDoaanex4G9MigiFQ+yo3dEssFfurqSy2mmmqaquojHU2GyeQVmDKMkv4ZDBh3DiqBOjQT3yam+gnnPsnGZt/gBZaVnMOXZOt66jaT8L/sb0E8FwkO0129myewuV1ZVU7q5sdhS/tXprqy6EQ7KHUJpfytihY5l+0PRWR+456TndUrZIr55E9vYxHWPB35g+IhAKsLV6a5vt7duqt0WHII4ozCmkJL+ELwz7AmceciYlBU3BvTivmCxfVo+Vf8bhMyzY70Xs87ojD8ipbqhO2AVpC/7G9BINwQaqqquaN8tE3u/ewo7aHc36mAvCsNxhlBaUUl5U3iywl+SXUJRXRGaaPSku2SJPOQuFQ82eERA7fr8geMWLz+sjw5uBz+vD5/FRkl8SfVxmd7Pgb0wndfSmpfpAfTS4R9vb91Ty/tb3+e+q/7K9dnuz6b3iZXjecErzSzlmxDGU5pdSml9KcX4xpfmlDM8bTro3PdGradoQGTE4EtSbPcoy5iEtaeI8vjIzLZN0b3rTs4/dZx57xRv3Occe8XRbs1s8FvyN6YR4Ny3d+OKNbK/ZzqGDD23VS6ZyTyWf1n3abBlpnjSK84oZ4BnAcSOOaxbYSwtKGZY7LCFHfGbvIk0ukcCuaKsHPimK1+PF5/GR7k2Pvrweb/RBUJHA3hvvIwAL/sZ0WFjD/PhfP251R6k/6OfOV5tuwkn3plOcV0xJfgknHXASJQUllOSVUFrgNM0U5hTi9XhZt3wdYyaP6enVSEmxTS+RI/WWj1yMPMkv3ZtOti8bn8eHz+uLBvNIYO/oXbu9TcKCv4jcA5wJNAIfAJeo6udu3s3ApUAIuEZVlySqHMZ0VUOwgTU71rC0ailLq5aycutKdjfsbnP6Z89/lpL8EobmDO3zAaKvaHmxtFm7esyzc31eH2metGZNMJGjdY94ooE9FSTyyP9F4GZVDYrIz4CbgZtEZDRwPjAGKAJeEpFDVFt0UzAmSfY07GHF1hUsrVrK8qrlrN6+moaQc5v9QYMO4oxDzmDxxsV85v+s1bzFecWUFZX1dJH7rZYXS8Majj4wPfa5u2mShs/bvAkmEsxjA7tpkrDgr6r/iPn4JnCO+/4sYJGqNgAfisgmoBx4I1FlMWZvttdsjwb6pVVL2fDpBhQlzZPGuKHj+MaEb1BeXM7koskMzh4MwFElR9lNS10QOTqPDeyRtvaahhpnInEuevo8PjLTMqPNL2metFaBvbe2q/dmPdXm/03gj+77YpydQUSlm2ZMwqkqH3z2AUsrl7Js6zKWVS2LDpOb7ctm0vBJfPfo71JeXM7E4RPJ9mXHXY7dtNQxYQ3TEGwgGA4iCB6PJ3q0nuPLwefxkeZNo8pTxf4D9o8GdgvqiSOquu+p2ppZ5CVgWJysW1T1WXeaW4AyYIaqqog8BLyhqk+4+b8FFqvqU3GWPxuYDVBYWDhp0aJFHS6j4jx8IdnteP5aP5k51uc6oqfqIxgOsql2E2t3r2XtnrWs272O3UGnvb7AV8C4/HGMKRjDuPxxHJDT/eOntEe/3TYUwjRdUI0cpe/tb7Gmpobc3NyeK2Mv1h11cfzxx69U1bjtkF3a0lV12t7yReTrwBnAidq0l6kESmMmKwG2trH8ecA8gLKyMp06dWqHyxgIBfjw8w/JTU/uBmU9OppLVH3UNtayctvKaBPOqm2rok0zIwtGcsqhp1BeVE55STkHDDigVxxZ9qdtIxQO4Q/6CWsYn8dHfkY+Oek5ZKZltquuKyoq6MzfeX+U6LpIZG+f6cBNwHGqGjvO63PAkyLyS5wLvgcDyxJVDtO/7azbGQ30y6qWsfaTtYQ0hEc8jN5vNBeMvYDyEqe9flhuvJNU01XBcJCGYIMT8L0+BmcPJseXQ7o3vVfsXE18iTzHfRDIAF50N4A3VfUKVV0nIn8C1gNB4Crr6WPaQ1X5ePfHLKtaFn198NkHAGR4M/jCsC9wVflVHFl8JBOHT7ShgROoMdRIY7ARRcnwZjAkewg56Tl2x3EfksjePgftJe9OoPseSWP6pVA4xIadG5oF+x21OwBnHPmy4jLOH3s+k4snM37oeDLSMpJc4v6tIdgQHRU0My2TYbnDyPKl9kNX+jK7w9f0Gv6gn9XbV0e7Xa7YuoLqxmrAeejHlNIplBeXU15cziGDD0n6Rfz+TlVpCDUQDDlP4cr2ZbNfzn5kpmXasBP9gP2CJmk+93/O8q3Lo232a3asiT5M5NDBh3L2YWdTXlzOkcVHUpxvvYF7gqriD/oJhoPRgcUKcgrITMu0m6T6GQv+psdUVVexrHIZy7Yu418b/8VHr34EgM/jY3zheL71hW8xuXgyk4smMzBrYHILm0IiffBD4RAiQl56HvmZ+WSmZdrZVT9mwd8kRFjDbNy10bmRyg34lXsqAeeh3oflHMbXJnyNI4uPZMKwCT36UBHjXE9pCDk9dDzioSCjgNz0XDLSMizgpwgL/qZbNIYaWbNjTbQJZ/nW5Xzu/xyAoTlDKS8uZ/bE2RxZciSHDTmM91a+12/6tvcVzbpkenwMzBxITnoOGd4M65KZgiz4m06paaxh5daV0f71b21/C3/QD8ABAw9g+oHTKS8pp7yonJEDRlpwSZJAKEBjqJGwhkn3pjMkewjZvmzrg28s+Jsme3sy1Se1nzTrcrnu03WENYxXvIwdOpaLxl/EkcVHMrloMvvl7JfkNUltsX3wM9MyGZozlCxflvXBN81Y8DdA/CdTfXfJd1mwZgHba7fz0ecfAU7/7onDJ3LtkddGBz9L9tAZqU7VGb8q0lMq25dtffDNPlnwN4AzOmXLJ1MFwgGWVS3jpANP4uLxF1NeXM64oeMsoPQCkT74gVAAQcjNyLU++KZDbCsxAGytjju2Hooy/6z5PVwaE0+zYZFFyE/PJy8nz/rgm06x4J/iVJXH1zyOEn9o76K8oh4ukYkV1jD+oJ9Q2BmsriDT6ZJpffBNV1nwT2G1jbXc9NJNPPPuMxw++HA+3P1htMcO2JOpkqXlsMgDMgaQm5FrXTJNt7Lgn6Le3/U+s5+fzQeffcCNU27kmiOv4S/v/sWeTJUkNiyy6WkW/FPQU+uf4qaXbiInPYeFX13IsSOOBZxHE1qw7zmRLpnhcJhwOGzDIpseZcE/hfiDfn7wyg9Y8M4Cjiw+kodPf9gecNLDIsMiqypZviyG5Q6jKq2KkQNHJrtoJsVY8E8RH33+EZf/9XLWfrKWqyZfxfeO+Z51CewB7RkWWbBmHdPz7K8/Bfx909+5fsn1CMLvzvodJx94crKL1K/ZsMimL7Dg348FQgF++tpPmbtyLkcUHsEjZzzCiIIRyS5Wv9RyWOT8jHzyMvKsS6bptSz491Nbq7fy7b99m+Vbl/P1I77ObcfdZo85TID6QD3BcBCvx2vDIps+xYJ/P/Svj//FVYuvwh/08/BpD3PWYWclu0j9SmyzTl5GHgMzB5KZlmldMk2fYsG/HwmFQ9z75r386s1fccjgQ5h35jwOGnRQsovVb6gq9cF6QuEQBRkFDMwaaGdTps9KePAXkRuAe4D9VHWnOIdH9wGnAXXAN1R1VaLL0d/trNvJ1Yuv5tXNr3LO6HP46Yk/JduXnexi9QuqSl2gDkUZkDmAAZkDrC++6fMSGvxFpBQ4Cdgck3wqcLD7OhL4tfuv6aRlVcu48q9X8pn/M+456R4uGHuBNUF0g7CGqQ/Uo6oMyhpEQWaBjWhq+o1EH/n/Cvge8GxM2lnAH1RVgTdFZICIDFfVbQkuS7+jqsxdOZefvPoTSvNLee6C5xg7dGyyi9XnhTVMXWMdIsLg7MHkZ+TbPRGm30nYFi0iXwaqVPXtFkehxcCWmM+VbpoF/w7Y7d/N9UuuZ8kHSzjtoNP4xSm/ID8jP9nF6tNC4RD1wXo8eNgvZz/yM/KtX77pt7oU/EXkJSDe+AC3AN8H4t1NFK89Iu54wiIyG5gNUFhYSEVFRYfLqDhPOUp21zt/rZ91y9d1y7Ler36fO969g08bPuWKA67gK8O+wpY1W/Y9Yy/SnfXRVaqKqoJAmicNr3ippLLHvr+mpqZT23Z/ZHXRJNF10aXgr6rT4qWLyDhgFBA56i8BVolIOc6RfmnM5CVA3CeJqOo8YB5AWVmZTp06tcNlDIQCfPj5h0l/1OC65esYM3lMl5YRGXv/tnduY3DWYJ4++2nKisq6qYQ9qzvqo6sCoQD+oB+fx8eQ7CHkZuQm5SChoqKCzmzb/ZHVRZNE10VCmn1U9R1gaOSziHwElLm9fZ4DrhaRRTgXendbe/++xY69P3X/qTxw2gMMyhqU7I13TSUAAB7wSURBVGL1SY2hRhqCDfi8PoryishNz7UL5CblJOMq1mKcbp6bcLp6XpKEMvQp8cbeT3YzVl/UEGygMdRIhjeDkvwSsn3ZFvRNyuqR4K+qI2PeK3BVT3xvfxA79v6TX32SL474YrKL1Of4g34CoQBZvixKc0vJSsuyoG9SnvVf66Vs7P2ui4y7k+PLYXjucLJ8WckukjG9hgX/Xih27P1vl32bm469yfqZt1PLcXcGZQ0iMy0z2cUyptexiNLL2Nj7nWPj7hjTMRb8e4nYsffHF45n7hlzbez9dlBV6gP1hDTEwKyBNu6OMe1kwb8XsLH3O87G3TGmayz4J1ns2PsPnfYQZx92drKL1KuFwiHqA/U27o4xXWR/NUliY+93jI27Y0z3suCfBLFj73/18K9y17S7bOz9NgTDQfwBP16Pl8KcQvIy8uwGN2O6gQX/HhY79v7d0+7mwnEX2g1HccSOuzMsd1jSxt0xpr+y4N9DVJVHVjxiY+/vQ2TcnXRvOsX5xeT4cmznaEwCWPDvAbv9u7l9w+28sesNTj3oVH55yi9t7P0WGoINNAQbyEzLtHF3jOkBFvwTbM2ONVz+18up2lPFbcfdxmUTL7OgFsMf9NMYaiTHl8OwAcNsCAZjeogF/wSJjr1f4Yy9//PxP+fcSecmu1i9RljD7PHvIS8jj6K8IhuCwZgeZsE/AeKNvb9trT2yIHbcHY94GDVwlN3MZkySWPDvZpGx9zf9dxM3TLmBa4+8Fo942JbCjyiOHXdnQOYABmYNZJtnmwV+Y5LIgn83ih17f+E5C1N+7P2whvEH/NFxdwZmDrQhGIzpJSz4dwMbe7+5luPuDMgaYEMwGNPL2F9kF9nY+01C4RD+oB+AwdmDKcgosCEYjOmlUjNKdRMbe9/RctydvPQ8C/rG9HIW/DvBxt53BMNB6gP1zhAMOTYEgzF9iQX/DrKx952dX32gnvS0dIryishJz7Ggb0wfk9DgLyLfAa4GgsDfVPV7bvrNwKVACLhGVZckshzdJdXH3m8MNeIP+sn0ZlJaUGpDMBjThyUs+IvI8cBZwHhVbRCRoW76aOB8YAxQBLwkIoeoaihRZemqVB97PzLuTpYvixEFI8hKy7Kgb0wfl8gj/yuBu1S1AUBVP3HTzwIWuekfisgmoBx4I4Fl6bRUHnvfxt0xpv8SVU3MgkVWA88C0wE/cIOqLheRB4E3VfUJd7rfAi+o6p/jLGM2MBugsLBw0qJFizpcDkVpDDV2qk167e613PnunewJ7OGqA6/i1GGndvqI11/rJzOnb4xfE9YwqorX4yXNk4bQ/Uf5NTU15Obmdvty+yKriyZWF026oy6OP/74lapaFi+vS0f+IvISEO9uplvcZQ8EjgImA38SkQMgbiSJuwdS1XnAPICysjKdOnVqh8sYCAX48PMPyU1vfyWqKnNXzuUn7zhj7z957pNdHnt/3fJ1jJk8pkvL6Al1jXVk+bIYkj0koReyKyoq6Mzv2R9ZXTSxumiS6LroUvBX1Wlt5YnIlcDT6pxaLBORMDAEqARKYyYtAbZ2pRzdabd/N9cvuZ4lHyxJubH3A6EAHvEwLHeY9dM3pp9LZP+8vwAnAIjIIUA6sBN4DjhfRDJEZBRwMLAsgeVotzU71jB9wXRe/vBlbjvuNh4989GUCfyqSn2gnuF5wy3wG5MCEnnBdz4wX0TWAo3A192zgHUi8idgPU4X0KuS3dOn5dj7fz73z0wumpzMIvW4msYahuYOtYu6xqSIhAV/VW0ELmoj707gzkR9d0fEG3t/UNagZBerR9UH6sn2ZTMwc2Cyi2KM6SEpfYdvW2Pvp5JQOEQoHGJYwTDru29MCknZ4G9j7ztqG2spzi+2cfaNSTEpF/xt7P0mtY21DMwaSF5GXrKLYozpYSkV/G3s/SaNoUa84mVI9pBkF8UYkwT9OvIteGcB33/5+2zZvYVBWYOobawlIy0jpcfeh6YHqY8cMNK6dRqTovpt8F/wzgJmPz+bukAdALvqdyEIc46dk9KBH9xunTlDyUzrG8NNGGO6X7/t2nLLy7dEA3+Eojy66tEklah3sG6dxhjox8F/8+7NcdO3VveakSR6XCgcIqxhhuVat05jUl2/Df5tPVaxKK+oh0vSe9Q21jIsd5h16zTG9N/gf+eJd7Yadz8rLYs5x85JUomSy7p1GmNi9dvgP3PcTOadOY8RBSMQhOK8Yu4+6W5mHD4j2UXrcdat0xjTUr/t7QPODuDc0ed2eDz//iSsYevWaYxppd8e+RtHbWMthTmF1q3TGNOMBf9+LNKtc0DmgGQXxRjTy1jw76esW6cxZm8s+PdDqmrdOo0xe2XBvx+qC9RZt05jzF5Z8O9nGkONeD1e9svZL9lFMcb0Yhb8+5FIt86ivKKUeyKZMaZjLEL0I9at0xjTXhb8+wnr1mmM6YiEBX8RmSAib4rIahFZISLlbrqIyP0isklE1ojIxESVIVUEw0Hr1mmM6ZBEHvnfDfxQVScAP3A/A5wKHOy+ZgO/TmAZ+r1It87hucOtW6cxpt0SGfwVyHffFwCRgfTPAv6gjjeBASIyPIHl6NdqG2sZlDWI3IzUHLvIGNM5oqqJWbDI4cASQHB2MlNU9WMR+Stwl6q+5k73MnCTqq6Is4zZOGcHFBYWTlq0aFGHy6EojaHGpPd+8df6yczp3guxkd8u3ZvercvtCTU1NeTm2g4LrC5iWV006Y66OP7441eqalm8vC6N6ikiLwHD4mTdApwIXK+qT4nIucBvgWk4O4OW4u6BVHUeMA+grKxMp06d2uEyBkKBXjGq57rl6xgzeUy3LS+sYWobaxk5YCQZaRndttyeUlFRQWd+z/7I6qKJ1UWTRNdFl4K/qk5rK09E/gBc6378X+A37vtKoDRm0hKamoRMO9U21jI0Z2ifDPzGmORLZFvIVuA49/0JwEb3/XPALLfXz1HAblXdlsBy9Dv1gXpy03OtW6cxptMS+TCXy4D7RCQN8OO23QOLgdOATUAdcEkCy9DvBMNBVJXC3ELr1mmM6bSEBX/3gu6kOOkKXJWo7+3PVJW6QB2l+aWkefr1Q9iMMQlmd/j2IbWNtQzOGkxOek6yi2KM6eMs+PcRDcEGfF4fg7MHJ7soxph+wIJ/HxDWMI2hRhut0xjTbSyS9AE1DTUU5hZat05jTLex4N/L1QfqycvIoyCjINlFMcb0Ixb8ezHr1mmMSRQL/r1UpFvn8Lzh1q3TGNPtLPj3Utat0xiTSBb8e6GGYAPp3nTr1mmMSRgL/r1MpFvn8Lzh1q3TGJMwFl16mZqGGoblDrNuncaYhLLg34vUBerIy8gjPyN/3xMbY0wXWPDvJYLhICjWrdMY0yMs+PcCkW6dRflF1q3TGNMjLPj3ArUBp1tnti872UUxxqQIC/5J1hBsIN1j3TqNMT3Lgn8ShTVMIBywbp3GmB5nESeJahtrKcyx0TqNMT3Pgn+S1AfqyUu3bp3GmOSw4J8EgVAAgKG5Q61bpzEmKSz49zBVpT5Qb6N1GmOSqkvBX0S+JiLrRCQsImUt8m4WkU0i8p6InBKTPt1N2yQic7ry/X1RbaCWIdlDrFunMSapunrkvxaYAfwrNlFERgPnA2OA6cDDIuIVES/wEHAqMBq4wJ02JfiDfjK8GQzKHpTsohhjUlyX2h1UdQMQr936LGCRqjYAH4rIJqDczdukqv9x51vkTru+K+XoKwKhACUDS6xbpzEm6RLV6FwMvBnzudJNA9jSIv3IthYiIrOB2QCFhYVUVFR0uCCK0hhqTHrAra+tp+qdKrbJtqSWo7eoqanp1O/ZH1ldNLG6aJLouthn8BeRl4BhcbJuUdVn25otTpoSv5lJ2/puVZ0HzAMoKyvTqVOn7r2wcQRCAT78/ENy03M7PG93qWus48O3P+SE409IWhl6m4qKCjrze/ZHVhdNrC6aJLou9hn8VXVaJ5ZbCZTGfC4Btrrv20rvlwKhACKCz+NLdlGMMSYqUW0hzwHni0iGiIwCDgaWAcuBg0VklIik41wUfi5BZUi6SLfOoryiZBfFGGOa6VKbv4h8BXgA2A/4m4isVtVTVHWdiPwJ50JuELhKVUPuPFcDSwAvMF9V13VpDXqxSLfOLF9WsotijDHNdLW3zzPAM23k3QncGSd9MbC4K9/bF1i3TmNMb2Z9DhMgFA4RDAVttE5jTK9lkSkBagO1DMsdRro3PdlFMcaYuCz4d7O6xjoKMgrIz7TROo0xvZcF/24U6dY5NGdosotijDF7ZcG/m8R26/R6vMkujjHG7JUF/25S01jD0Nyh1q3TGNMnWPDvBv6gn8y0TAZmDkx2UYwxpl0s+HdRbLdOeyqXMaavsODfRdat0xjTF1nw7wLr1mmM6ass+HdSIBTAIx7r1mmM6ZMs+HdC7EPYrVunMaYvsuDfCdat0xjT1yXqMY49IhAIUFlZid/vb3MaVSUYDtIojd3ynWHCCMIOzw52sKPd8xUUFLBhw4ZuKUNfk5mZSUlJCT6fPdDGmN6iTwf/yspK8vLyGDlyZJvdLMMa7r5n+KqzvPS09A4vr7q6mry8vK6XoY9RVXbt2kVlZSWjRo1KdnGMMa4+3ezj9/sZPHhwj/WvD2kIn9dnwzR3gIgwePDgvZ6dGWN6Xp+PYj0V+MMaJs2TZhd4O8FufjOm9+nzwb8nqCqCkObp061kxhgTlVLB3/PkQnwHHIzPl4nvgIPxPLmwXfOFNYzP62t2BLtr1y4mTJjAhAkTGDZsGMXFxdHPjY3tu7h8ySWX8N577+11moceeogFCxa0a3nGGNNeKXMo63lyId4rvo3U1TkJmzfjveLbAIQvvKDN+cLhcNx2/sGDB7N69WoAbr/9dnJzc7nhhhuaTaOqqCoeT/x97O9+97t9lvuqq67a5zTJsK91M8b0bv3rL3fq1Navh38NgPeWW5sCv0vq6vBe/13nw86dpJ1wUrNXWMN4xINX2t/Ov2nTJsaOHcsVV1zBxIkT2bZtG7Nnz+a4445jzJgx/OhHP4pOe+yxx7J69WqCwSADBgxgzpw5HHHEERx99NF88sknANx6663ce++90ennzJlDeXk5hx56KK+//joAtbW1fPWrX+WII47gggsuoKysLLpjinXjjTcyevRoxo8fz0033QTA9u3bOeussxg/fjxHHHEES5cuBeDuu+9m7NixjB07lgceeKDNdXvhhRc4+uijmThxIueddx61tbXtritjTPJ0KfiLyNdEZJ2IhEWkLCb9JBFZKSLvuP+eEJM3yU3fJCL3S09dDaysip++6797nS3Nm9bhC5br16/n0ksv5a233qK4uJi77rqL//u//+Ptt9/mxRdfZP369a3m2b17N8cddxxvv/02Rx99NPPnz4+7bFVl2bJl3HPPPdEdyQMPPMCwYcN4++23mTNnDm+99Var+Xbs2MHixYtZt24da9as4eabbwacM4uTTjqJNWvWsHLlSg4//HCWLVvGggULWLZsGW+88QYPP/wwa9asabVuPp+Pu+66i5dffplVq1Yxfvx47rvvvg7VlTEmObra7LMWmAHMbZG+EzhTVbeKyFhgCVDs5v0amA28CSwGpgMvdLEcjoqK1mkahlAjlJbC5s2t80eMcP4dMoTgP1+MJofCIdI9nevWeeCBBzJ58uTo54ULF/Loo48SDofZunUr69evZ/To0c3mycrK4tRTTwVg0qRJvPrqq3GXPWPGjOg0H330EQCvvfZa9Ej+iCOOYMyYMa3mGzRoEB6Ph8suu4zTTz+dM844A4CKigoWLVoEQFpaGvn5+bz66qt89atfJTs7G4Czzz6b1157jZNPPrnZur3++uusX7+eKVOmANDY2Mixxx7b4foyxvS8Lh35q+oGVW11xVJV31LVre7HdUCmiGSIyHAgX1XfUFUF/gCc3ZUytFfojh+hbjCLljM7m9AdP2o1bVe7debk5ETfb9y4kfvuu4/nn3+eNWvWMH369Lh93tPTm4aE9nq9BIPBuMvOyMhoNY1TlXvn8/lYsWIFZ599Nk899RSnn356NK/lmc3elhe7bqrK9OnTWb16NatXr2b9+vXMmzdvn2UxxiRfT1zw/Srwlqo2iEgxUBmTV0nTGUErIjIb5yyBwsJCKloc2RcUFFBdXb3XL1ecC5ONZ32FtIYAmT/6EVJZiZaU4P/BDwie9RWo9TebHsAjHvy078akhoYGfD4f1dXV1NTUEA6Ho+Xatm0bOTk55OTksHHjRv7+979z3HHHUV1dTSgUora2Njpt5N/6+noCgQDV1dU0NDTg9/tbTR/7PZMnT+aJJ55gwoQJrFu3jvXr1zdbbmTZDQ0N0WsPkydPprq6mi9+8Yvce++9XH755dHlT5o0ieuuu44rrriCUCjEM888w+9///tW6zZ+/HiuueYa1qxZw6hRo6itrWXbtm0cdNBBrerI7/c3+/1qampa/Z6pyuqiidVFk0TXxT6Dv4i8BAyLk3WLqj67j3nHAD8DTo4kxZmszcNMVZ0HzAMoKyvTqVOnNsvfsGHDPodMaDa8wyWzCF4yK5qXRusKCIVDZKRldKi5JyMjg4yMDPLy8sjNzcXj8UTL9cUvfpGxY8cyZcoUDjroII499liysrLIy8vD6/WSk5MTnTbyb1ZWFj6fj7y8PDIyMsjMzGw1fW1tbfR7brjhBmbNmsUxxxzDxIkTGTt2LEVFRc3qZvfu3Zx33nk0NDQQDof51a9+RV5eHo888giXXXYZjz32GGlpacydO5fjjz+emTNncsIJzqWaq666iqOOOopNmzY1W7e8vDzmz5/PpZdeGu3e+pOf/IQvfOELreooMzOzWXpFRQUtf89UZXXRxOqiScLrItJlrysvoAIoa5FWArwPHBOTNhx4N+bzBcDc9nzHpEmTtKX169e3SmspFA5pfaBeG4IN+3zVN9ZrIBTY5zI7Y8+ePQlZrqpqIBDQ+vp6VVV9//33deTIkRoIJGY9Oqvlb/XKK68kpyC9kNVFE6uLJt1RF8AKbSOmJqTZR0QGAH8DblbVf8fsaLaJSLWIHAUsBWYBDySiDB3VmW6dvUVNTQ0nnngiwWAQVWXu3LmkpaXMLRzGmE7oUoQQka/gBO/9gL+JyGpVPQW4GjgI+H8i8v/cyU9W1U+AK4HfA1k4vXy6p6dPV7gNT53p1tkbDBgwgJUrVya7GMaYPqRLwV9VnwGeiZN+B3BHG/OsAMZ25Xu7W0hDpHs7PkyzMcb0VSkf7Wy0TmNMKkrp4K82WqcxJkWldPCPN1qnMcakgpQK/gvXLuTgBw4m845MDrr/IP68/s+dbufvjiGdAebPn8/27dujn9szzLMxxnRVyrR3LFy7kG//7dvUBZyRPbfs2cIVf7sCj8fDzHEzO7y89gzp3B7z589n4sSJDBvm3EfXnmGekyEYDFr3UWP6kX7z13zd369j9fbWwxiD07yzrGoZDaGGZul1gTouffZSHl35aNz5JgybwL3T7+1wWR577DEeeughGhsbmTJlCg8++CDBYJCLL76Y1atXo6rMnj2bwsJCVq9ezXnnnUdWVhbLli3jhBNO4MEHH2Ts2LEMGTKEK664ghdeeIHs7GyeffZZhg4dysaNG7noootQVU455RQeeOABPv/882ZlqK6u5txzz2Xr1q2EQiFuv/12zjnnHJYuXcp1111HXV0dmZmZvPLKK4gIV1xxBatWrcLn83HvvffypS99id/85je89NJL1NTU0NDQwIsvvshdd93F008/jd/v55xzzuEHP/hBh+vHGJN8KdPs0zLw7yu9s9auXcszzzzD66+/Hh2rf9GiRbz11lvs3LmTd955h7Vr1zJr1izOO+88JkyYwB//+EdWr17dbHA3aHuY5+985zvccMMNLFu2jMLCwrjlWLx4MSNHjuTtt99m7dq1nHTSSfj9fs4//3weeugh3n77bf7xj3+QkZHB/fffT3p6Ou+88w6PP/44F198cbTp6o033uDxxx/nxRdfZPHixWzevJmlS5eyevVqXn/99egzBYwxfUu/OfJv6wg9MrbPoQ8eyubdrYd03r9gfyq+UdFt5XjppZdYvnw5ZWXO4w3q6+spLS1lypQpvPfee1x77bWcdtppnHzyyftYUtvDPC9dupTFixcDcOGFF3Lrrbe2mnf8+PHMmTOHOXPmcOaZZ3LMMcfw1ltvMWLECCZOnAg4A+OBMyT0jTfeCMCYMWMoKipi06ZNAJx88skMHDgQgH/84x+88MIL0TF6ampqeP/996NDOhtj+o5+E/z35UdTf+S0+QebnuaV7cvmzhPv7NbvUVW++c1v8uMf/7hZenV1NWvWrOGFF17g/vvv56mnntrn8MftHeY5nsMPP5wVK1awePFibrzxRs444wymT58et2eTdmAI51tvvZVLL7203eUwxvROqdHso3DemPOYe+Zc9i/YH0HYv2B/5p05r1MXe/dm2rRp/OlPf2Lnzp2A0yto8+bN7Ny5E1Xla1/7Gj/84Q9ZtWoV4IyMua9hqVsqLy/nmWecG6sjD2JpqaqqitzcXC6++GK++93vsmrVKsaMGcPHH38c/e49e/YQCoX40pe+FH1I/IYNG9oclvmUU07ht7/9bfRRjZWVldH1NMb0LSlx5K8oPq+Pi8ZfxEXjL0rod40bN47bbruNadOmOQ9/9/l45JFH8Pv9zJgxw7mxTISf/exngNO181vf+lb0gm973H///Vx88cX87Gc/47TTTos238SKPNLR4/GQnp7OI488QkZGBgsXLuTKK6/E7/eTlZXFP//5T77zne9w+eWXM27cOHw+H3/4wx9aXX8AOO2003j33Xc56qijAGfH9eSTTzJkyJAu1JgxJinaGu6zt706O6RzOBzWxmCjhsPhfU6bSN05pHNNTU10fR5//HGdMWNGty07UWxI57ZZXTSxumjSJ4d07k1EBJ/Xl+xidKvly5dz3XXXEQ6HGThwYK+9N8AY03v1++DfH02dOjV6g5kxxnRGn7/gq+14eLlJLvuNjOl9+nTwz8zMZNeuXRZcejFVZdeuXWRmZia7KMaYGH262aekpITKyko+/fTTZBdln/x+f8oGwMzMTEpKSpJdDGNMjD4d/H0+H6NGjUp2MdqloqIiemesMcYkW59u9jHGGNM5FvyNMSYFWfA3xpgUJH2lp4yIfAp8nOxydMEQwAbCaWL10cTqoonVRZPuqIv9VXW/eBl9Jvj3dSKyQlXLkl2O3sLqo4nVRROriyaJrgtr9jHGmBRkwd8YY1KQBf+es/cnt6Qeq48mVhdNrC6aJLQurM3fGGNSkB35G2NMCrLgb4wxKciCfzcRkVIReUVENojIOhG51k0fJCIvishG99+BbrqIyP0isklE1ojIxOSuQfcTEa+IvCUif3U/jxKRpW5d/FFE0t30DPfzJjd/ZDLL3d1EZICI/FlE3nW3j6NTdbsQkevdv4+1IrJQRDJTabsQkfki8omIrI1J6/C2ICJfd6ffKCJf70xZLPh3nyDwP6p6OHAUcJWIjAbmAC+r6sHAy+5ngFOBg93XbODXPV/khLsW2BDz+WfAr9y6+Ay41E2/FPhMVQ8CfuVO15/cB/xdVQ8DjsCpk5TbLkSkGLgGKFPVsYAXOJ/U2i5+D0xvkdahbUFEBgG3AUcC5cBtkR1Gh7T1fEd7de0FPAucBLwHDHfThgPvue/nAhfETB+drj+8gBJ3Qz4B+CsgOHcrprn5RwNL3PdLgKPd92nudJLsdeimesgHPmy5Pqm4XQDFwBZgkPs7/xU4JdW2C2AksLaz2wJwATA3Jr3ZdO192ZF/Arinp18AlgKFqroNwP13qDtZ5A8hotJN6y/uBb4HhN3Pg4HPVTXofo5d32hduPm73en7gwOAT4HfuU1gvxGRHFJwu1DVKuDnwGZgG87vvJLU3C5idXRb6JZtxIJ/NxORXOAp4DpV3bO3SeOk9Yt+tyJyBvCJqq6MTY4zqbYjr69LAyYCv1bVLwC1NJ3Wx9Nv68JtmjgLGAUUATk4TRstpcJ20R5trX+31IsF/24kIj6cwL9AVZ92k3eIyHA3fzjwiZteCZTGzF4CbO2psibYMcCXReQjYBFO08+9wAARiTxAKHZ9o3Xh5hcA/+3JAidQJVCpqkvdz3/G2Rmk4nYxDfhQVT9V1QDwNDCF1NwuYnV0W+iWbcSCfzcREQF+C2xQ1V/GZD0HRK7Gfx3nWkAkfZZ7Rf8oYHfk1K+vU9WbVbVEVUfiXND7p6rOBF4BznEna1kXkTo6x52+Xxzhqep2YIuIHOomnQisJwW3C5zmnqNEJNv9e4nURcptFy10dFtYApwsIgPds6mT3bSOSfbFj/7yAo7FOfVaA6x2X6fhtFG+DGx0/x3kTi/AQ8AHwDs4PSCSvh4JqJepwF/d9wcAy4BNwP8CGW56pvt5k5t/QLLL3c11MAFY4W4bfwEGpup2AfwQeBdYCzwOZKTSdgEsxLneEcA5gr+0M9sC8E23XjYBl3SmLDa8gzHGpCBr9jHGmBRkwd8YY1KQBX9jjElBFvyNMSYFWfA3xpgUZMHfGGNSkAV/Y4xJQf8fSeTids1+zHMAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_learningcurve(grid_search.best_estimator_, x_train, score_train, 'Learning Curve (XGBoost)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.61227687, 0.59220551, 0.48891744, 0.44293422])"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = ml_model_best.predict(x_test)\n",
    "\n",
    "score1 = evaluate_lists(y_pred, test_intensities)\n",
    "score1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgboost_path = \"files/final_models/\" + \"xgboost_\"+ emotion + \".dat\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(xgboost_path, 'wb') as xgboost_file:\n",
    "    pickle.dump(grid_search.best_estimator_, xgboost_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = pickle.load(open(xgboost_path,'rb'))\n",
    "#model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2) Feedfoward Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "class LinearModel(torch.nn.Module):\n",
    "    def __init__(self,n_feature,n_hidden,n_output):\n",
    "        super(LinearModel,self).__init__() \n",
    "        self.hidden = torch.nn.Linear(n_feature,n_hidden)\n",
    "        self.hidden.weight = torch.nn.init.xavier_normal(self.hidden.weight)\n",
    "        self.dropout = torch.nn.Dropout(p=0.25)\n",
    "        self.predict = torch.nn.Linear(n_hidden,n_output)\n",
    "    def forward(self,x):\n",
    "        out=F.relu(self.hidden(x))\n",
    "        out=self.dropout(out)\n",
    "        out=F.sigmoid(self.predict(out))\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.1900, -0.0127,  0.0895,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.1851, -0.0244,  0.0297,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.1619,  0.0482, -0.0301,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        ...,\n",
      "        [ 0.1762, -0.0948, -0.1589,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.2051, -0.0705, -0.0957,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.1300,  0.2885,  0.2466,  ...,  0.0000,  0.0000,  0.0000]]) \n",
      " tensor([0.4560, 0.4380, 0.3120, 0.7290, 0.3750, 0.4500, 0.3330, 0.8330, 0.6600,\n",
      "        0.6460, 0.6670, 0.2710, 0.3330, 0.2710, 0.5210, 0.2920, 0.7400, 0.3750,\n",
      "        0.3540, 0.3360, 0.4790, 0.5210, 0.5420, 0.6570, 0.3120, 0.4790, 0.3800,\n",
      "        0.5000, 0.7420, 0.6880, 0.2710, 0.5830, 0.5310, 0.7290, 0.6550, 0.5420,\n",
      "        0.8330, 0.6600, 0.3330, 0.3540, 0.6670, 0.1880, 0.8120, 0.5420, 0.5620,\n",
      "        0.5620, 0.5420, 0.3750, 0.4580, 0.6670, 0.2460, 0.7710, 0.6880, 0.7920,\n",
      "        0.3360, 0.6460, 0.2920, 0.7760, 0.3120, 0.9790, 0.4470, 0.4380, 0.5620,\n",
      "        0.2920, 0.2710, 0.5830, 0.6040, 0.4790, 0.8120, 0.5420, 0.4750, 0.3540,\n",
      "        0.4120, 0.5210, 0.5420, 0.5000, 0.1600, 0.3750, 0.3750, 0.3750, 0.8750,\n",
      "        0.3330, 0.6670, 0.4120, 0.5210, 0.6460, 0.1880, 0.1250, 0.5830, 0.4170,\n",
      "        0.3120, 0.6250, 0.6150, 0.5210, 0.6880, 0.4790, 0.5920, 0.4170, 0.6460,\n",
      "        0.7290, 0.5000, 0.3960, 0.2710, 0.4380, 0.5000, 0.5420, 0.5400, 0.6250,\n",
      "        0.1670, 0.5420, 0.5000, 0.4790, 0.6460, 0.3270, 0.7000, 0.2710, 0.4170,\n",
      "        0.5830, 0.2500, 0.8120, 0.3330, 0.4790, 0.6670, 0.3120, 0.7290, 0.5210,\n",
      "        0.2940, 0.1040])\n"
     ]
    }
   ],
   "source": [
    "import torch.utils.data as Data\n",
    "batch_size = 128\n",
    "dataset = Data.TensorDataset(torch.tensor(x_train.astype(np.float32)), torch.tensor(score_train.astype(np.float32)))\n",
    "data_iter = Data.DataLoader(dataset = dataset,batch_size = batch_size, shuffle = True, num_workers = 2)\n",
    "\n",
    "for X,y in data_iter:\n",
    "    print(X, '\\n', y)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearModel(\n",
      "  (hidden): Linear(in_features=943, out_features=10000, bias=True)\n",
      "  (dropout): Dropout(p=0.25, inplace=False)\n",
      "  (predict): Linear(in_features=10000, out_features=1, bias=True)\n",
      ")\n",
      "<generator object Module.parameters at 0x00000214C8321468>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dell\\Anaconda3\\envs\\tf2\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: nn.init.xavier_normal is now deprecated in favor of nn.init.xavier_normal_.\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "# architecure: 1â†’10000â†’1\n",
    "net = LinearModel(x_train.shape[1],10000,1)\n",
    "print(net)\n",
    "print(net.parameters())    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Parameter containing:\n",
      "tensor([[-0.0127,  0.0019, -0.0048,  ...,  0.0002, -0.0037, -0.0012],\n",
      "        [-0.0194, -0.0038,  0.0072,  ..., -0.0044,  0.0067,  0.0013],\n",
      "        [-0.0142,  0.0153, -0.0161,  ..., -0.0004,  0.0050, -0.0174],\n",
      "        ...,\n",
      "        [-0.0042, -0.0074, -0.0243,  ..., -0.0084,  0.0070,  0.0052],\n",
      "        [-0.0128,  0.0157,  0.0232,  ...,  0.0164, -0.0264, -0.0231],\n",
      "        [ 0.0078,  0.0079,  0.0235,  ...,  0.0094, -0.0252,  0.0232]],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([ 1.7754e-02, -3.7641e-03,  1.7847e-02,  ...,  2.2087e-02,\n",
      "         4.1105e-05, -1.9185e-03], requires_grad=True), Parameter containing:\n",
      "tensor([[-0.0048,  0.0037,  0.0049,  ...,  0.0048, -0.0025,  0.0075]],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([-0.0063], requires_grad=True)]\n"
     ]
    }
   ],
   "source": [
    "para = list(net.parameters())\n",
    "print(para)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    lr: 0.001\n",
      "    weight_decay: 0\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(net.parameters())\n",
    "print(optimizer)\n",
    "\n",
    "loss_func = torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_test = Data.TensorDataset(torch.tensor(x_test.astype(np.float32)), torch.tensor(test_intensities.astype(np.float32)))\n",
    "data_iter_test = Data.DataLoader(dataset = dataset_test,batch_size = batch_size, num_workers = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dell\\Anaconda3\\envs\\tf2\\lib\\site-packages\\torch\\nn\\functional.py:1351: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch10,train_loss0.008271485567092896\n",
      "epoch10,test_loss0.023965589702129364\n",
      "epoch20,train_loss0.004425784107297659\n",
      "epoch20,test_loss0.027594229206442833\n",
      "epoch30,train_loss0.0018233108567073941\n",
      "epoch30,test_loss0.028662938624620438\n",
      "epoch40,train_loss0.0029294583946466446\n",
      "epoch40,test_loss0.02939189411699772\n",
      "epoch50,train_loss0.0016472670249640942\n",
      "epoch50,test_loss0.028723834082484245\n",
      "epoch60,train_loss0.0010940004140138626\n",
      "epoch60,test_loss0.028544284403324127\n",
      "epoch70,train_loss0.0011265248758718371\n",
      "epoch70,test_loss0.029867641627788544\n",
      "epoch80,train_loss0.0010267578763887286\n",
      "epoch80,test_loss0.028669167309999466\n",
      "epoch90,train_loss0.0007449268014170229\n",
      "epoch90,test_loss0.02895493246614933\n",
      "epoch100,train_loss0.0008018884691409767\n",
      "epoch100,test_loss0.02879510074853897\n",
      "epoch110,train_loss0.0005962011637166142\n",
      "epoch110,test_loss0.02949398197233677\n",
      "epoch120,train_loss0.0010657733073458076\n",
      "epoch120,test_loss0.028603622689843178\n",
      "epoch130,train_loss0.0007596294744871557\n",
      "epoch130,test_loss0.02936149388551712\n",
      "epoch140,train_loss0.0004717173578683287\n",
      "epoch140,test_loss0.029098602011799812\n",
      "epoch150,train_loss0.0008594553219154477\n",
      "epoch150,test_loss0.02915266528725624\n",
      "epoch160,train_loss0.0006779523682780564\n",
      "epoch160,test_loss0.02928462252020836\n",
      "epoch170,train_loss0.0004621080297511071\n",
      "epoch170,test_loss0.029367908835411072\n",
      "epoch180,train_loss0.000407196581363678\n",
      "epoch180,test_loss0.029020274057984352\n",
      "epoch190,train_loss0.0005036769434809685\n",
      "epoch190,test_loss0.02901344560086727\n",
      "epoch200,train_loss0.0012779943645000458\n",
      "epoch200,test_loss0.02776009775698185\n",
      "epoch210,train_loss0.00048621033784002066\n",
      "epoch210,test_loss0.02835017442703247\n",
      "epoch220,train_loss0.0005135248065926135\n",
      "epoch220,test_loss0.027579892426729202\n",
      "epoch230,train_loss0.0006293632322922349\n",
      "epoch230,test_loss0.028076602146029472\n",
      "epoch240,train_loss0.00028664953424595296\n",
      "epoch240,test_loss0.02815578691661358\n",
      "epoch250,train_loss0.0013800278538838029\n",
      "epoch250,test_loss0.027783667668700218\n",
      "epoch260,train_loss0.0009098565205931664\n",
      "epoch260,test_loss0.029132859781384468\n",
      "epoch270,train_loss0.0004190273175481707\n",
      "epoch270,test_loss0.028353946283459663\n",
      "epoch280,train_loss0.00031684900750406086\n",
      "epoch280,test_loss0.02848302200436592\n",
      "epoch290,train_loss0.00025667576119303703\n",
      "epoch290,test_loss0.028331397101283073\n",
      "epoch300,train_loss0.00026282898033969104\n",
      "epoch300,test_loss0.028043724596500397\n",
      "epoch310,train_loss0.00033139699371531606\n",
      "epoch310,test_loss0.02827371284365654\n",
      "epoch320,train_loss0.00033319834619760513\n",
      "epoch320,test_loss0.02877681702375412\n",
      "epoch330,train_loss0.00022658269153907895\n",
      "epoch330,test_loss0.02790927141904831\n",
      "epoch340,train_loss0.0008285734802484512\n",
      "epoch340,test_loss0.028621811419725418\n",
      "epoch350,train_loss0.0003217409539502114\n",
      "epoch350,test_loss0.027934540063142776\n",
      "epoch360,train_loss0.0002569147909525782\n",
      "epoch360,test_loss0.027640903368592262\n",
      "epoch370,train_loss0.00020998119725845754\n",
      "epoch370,test_loss0.028037743642926216\n",
      "epoch380,train_loss0.00041548506123945117\n",
      "epoch380,test_loss0.028371794149279594\n",
      "epoch390,train_loss0.00023908718139864504\n",
      "epoch390,test_loss0.027814913541078568\n",
      "epoch400,train_loss0.0004967841086909175\n",
      "epoch400,test_loss0.028145765885710716\n",
      "epoch410,train_loss0.00030177930602803826\n",
      "epoch410,test_loss0.027973443269729614\n",
      "epoch420,train_loss0.00041486058034934103\n",
      "epoch420,test_loss0.027307946234941483\n",
      "epoch430,train_loss0.00035179854603484273\n",
      "epoch430,test_loss0.028120379894971848\n",
      "epoch440,train_loss0.0004060543142259121\n",
      "epoch440,test_loss0.028406718745827675\n",
      "epoch450,train_loss0.0005156851839274168\n",
      "epoch450,test_loss0.028036709874868393\n",
      "epoch460,train_loss0.00021351565374061465\n",
      "epoch460,test_loss0.02799726091325283\n",
      "epoch470,train_loss0.00030328441062010825\n",
      "epoch470,test_loss0.028152992948889732\n",
      "epoch480,train_loss0.00018144903879147023\n",
      "epoch480,test_loss0.02752731367945671\n",
      "epoch490,train_loss0.00024059553106781095\n",
      "epoch490,test_loss0.027378223836421967\n",
      "epoch500,train_loss0.0002456588263157755\n",
      "epoch500,test_loss0.0277363620698452\n",
      "epoch510,train_loss0.0003090958925895393\n",
      "epoch510,test_loss0.028127005323767662\n",
      "epoch520,train_loss0.00023483671247959137\n",
      "epoch520,test_loss0.02765127830207348\n",
      "epoch530,train_loss0.00023897203209344298\n",
      "epoch530,test_loss0.027773747220635414\n",
      "epoch540,train_loss0.00026287976652383804\n",
      "epoch540,test_loss0.028359543532133102\n",
      "epoch550,train_loss0.00034415427944622934\n",
      "epoch550,test_loss0.027631964534521103\n",
      "epoch560,train_loss0.00025308571639470756\n",
      "epoch560,test_loss0.02790033258497715\n",
      "epoch570,train_loss0.000255622377153486\n",
      "epoch570,test_loss0.027536168694496155\n",
      "epoch580,train_loss0.00027278944617137313\n",
      "epoch580,test_loss0.027050107717514038\n",
      "epoch590,train_loss0.0002245297800982371\n",
      "epoch590,test_loss0.027666890993714333\n",
      "epoch600,train_loss0.00027787499129772186\n",
      "epoch600,test_loss0.02763216197490692\n",
      "epoch610,train_loss0.00019911136769223958\n",
      "epoch610,test_loss0.027741001918911934\n",
      "epoch620,train_loss0.0001923247764352709\n",
      "epoch620,test_loss0.027235286310315132\n",
      "epoch630,train_loss0.0002679702010937035\n",
      "epoch630,test_loss0.027217376977205276\n",
      "epoch640,train_loss0.00023949687601998448\n",
      "epoch640,test_loss0.027146821841597557\n",
      "epoch650,train_loss0.00024583371123299\n",
      "epoch650,test_loss0.02754863165318966\n",
      "epoch660,train_loss0.0005074800574220717\n",
      "epoch660,test_loss0.027818268164992332\n",
      "epoch670,train_loss0.00019546541443560272\n",
      "epoch670,test_loss0.02733016572892666\n",
      "epoch680,train_loss0.0003041217860300094\n",
      "epoch680,test_loss0.028239022940397263\n",
      "epoch690,train_loss0.00021547805226873606\n",
      "epoch690,test_loss0.027445560321211815\n",
      "epoch700,train_loss0.00020309975661803037\n",
      "epoch700,test_loss0.028009992092847824\n",
      "epoch710,train_loss0.00016711762873455882\n",
      "epoch710,test_loss0.027580395340919495\n",
      "epoch720,train_loss0.00014630587247665972\n",
      "epoch720,test_loss0.027573373168706894\n",
      "epoch730,train_loss0.00017569046758580953\n",
      "epoch730,test_loss0.02746516279876232\n",
      "epoch740,train_loss0.0002909654867835343\n",
      "epoch740,test_loss0.027575263753533363\n",
      "epoch750,train_loss0.0002181019081035629\n",
      "epoch750,test_loss0.027319831773638725\n",
      "epoch760,train_loss0.0002863098052330315\n",
      "epoch760,test_loss0.027603179216384888\n",
      "epoch770,train_loss0.00017118777032010257\n",
      "epoch770,test_loss0.027387917041778564\n",
      "epoch780,train_loss0.0003190233837813139\n",
      "epoch780,test_loss0.027603833004832268\n",
      "epoch790,train_loss0.000190997205208987\n",
      "epoch790,test_loss0.027437422424554825\n",
      "epoch800,train_loss0.00023730707471258938\n",
      "epoch800,test_loss0.026979349553585052\n",
      "epoch810,train_loss0.0002607281494420022\n",
      "epoch810,test_loss0.027446558699011803\n",
      "epoch820,train_loss0.0001807106746127829\n",
      "epoch820,test_loss0.027100661769509315\n",
      "epoch830,train_loss0.0002349283022340387\n",
      "epoch830,test_loss0.0272795632481575\n",
      "epoch840,train_loss0.00021983482292853296\n",
      "epoch840,test_loss0.02684478648006916\n",
      "epoch850,train_loss0.00023026729468256235\n",
      "epoch850,test_loss0.027516236528754234\n",
      "epoch860,train_loss0.0003702763351611793\n",
      "epoch860,test_loss0.028193851932883263\n",
      "epoch870,train_loss0.00016698369290679693\n",
      "epoch870,test_loss0.027343517169356346\n",
      "epoch880,train_loss0.00013900954218115658\n",
      "epoch880,test_loss0.027460666373372078\n",
      "epoch890,train_loss0.00017394589667674154\n",
      "epoch890,test_loss0.027179427444934845\n",
      "epoch900,train_loss0.00032622303115203977\n",
      "epoch900,test_loss0.0268879272043705\n",
      "epoch910,train_loss0.00015336362412199378\n",
      "epoch910,test_loss0.027661215513944626\n",
      "epoch920,train_loss0.00023645262990612537\n",
      "epoch920,test_loss0.02737032249569893\n",
      "epoch930,train_loss0.00022695028746966273\n",
      "epoch930,test_loss0.0269825030118227\n",
      "epoch940,train_loss0.00018442036525812\n",
      "epoch940,test_loss0.027682844549417496\n",
      "epoch950,train_loss0.00016099966887850314\n",
      "epoch950,test_loss0.027103101834654808\n",
      "epoch960,train_loss0.00017941340047400445\n",
      "epoch960,test_loss0.02765914425253868\n",
      "epoch970,train_loss0.00018628104589879513\n",
      "epoch970,test_loss0.027459677308797836\n",
      "epoch980,train_loss0.00021466432372108102\n",
      "epoch980,test_loss0.02737484872341156\n",
      "epoch990,train_loss0.00013409032544586807\n",
      "epoch990,test_loss0.027364680543541908\n",
      "epoch1000,train_loss0.00013662523997481912\n",
      "epoch1000,test_loss0.026947496458888054\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "\n",
    "\n",
    "start_time_NN =time.time()\n",
    "\n",
    "train_losses = []\n",
    "\n",
    "test_losses = []\n",
    "\n",
    "num_epochs = 1000\n",
    "train_interval = 10\n",
    "test_interval = 10\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    net.train()\n",
    "    for X,y in data_iter:\n",
    "        prediction = net(X)\n",
    "        loss = loss_func(prediction,y.view(-1,1))\n",
    "    \n",
    "    # reset gradient, equal to net.zero_grad()\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward() \n",
    "        optimizer.step()\n",
    "        \n",
    "        \n",
    "\n",
    "    if((epoch+1)%train_interval==0):\n",
    "        print(\"epoch{},train_loss{}\".format(epoch+1,loss.data))\n",
    "        train_losses.append(loss.item())\n",
    "   \n",
    "\n",
    "      \n",
    "    net.eval()\n",
    "    with torch.no_grad():\n",
    "        \n",
    "        for X_test, y_test in data_iter_test:\n",
    "            \n",
    "            prediction1 = net(X_test)\n",
    "            loss1 = loss_func(prediction1, y_test.view(-1,1))\n",
    "            \n",
    "    if ((epoch+1) % test_interval == 0):       \n",
    "        print(\"epoch{},test_loss{}\".format(epoch+1,loss1.data))\n",
    "        #test_loss += float(loss1.item())\n",
    "        test_losses.append(loss1.item())\n",
    "        \n",
    "trainingtime.loc[1] = [\"Simple Neural Network\", round((time.time()-start_time_NN), 2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = range(len(train_losses))\n",
    "train_y = train_losses\n",
    "\n",
    "train_iters = len(data_iter)\n",
    "#test_x = np.arange(1, len(test_losses)+1) * train_iters*test_interval \n",
    "test_x = range(len(test_losses))\n",
    "test_y = test_losses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8,8))\n",
    "plt.plot(train_x, train_y, label='Train')\n",
    "plt.plot(test_x, test_y, label='Test')\n",
    "plt.legend(loc='lower right')\n",
    "plt.ylabel('loss value')\n",
    "plt.xlabel('Iteration')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(995,)"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_tensor = net(torch.tensor(x_test.astype(np.float32)))\n",
    "# len(y_pred)\n",
    "y_pred_array = y_pred_tensor.detach().numpy()\n",
    "y_pred_a = np.concatenate((y_pred_array), axis=None)\n",
    "y_pred_a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.68440515, 0.6673127 , 0.52440074, 0.48796956])"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score2 = evaluate_lists(y_pred_a, test_intensities)\n",
    "score2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'files/final_models/simpleNN_fear.pkl.tar'"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_neural_network_path = \"files/final_models/\" + \"simpleNN_\"+ emotion + \".pkl.tar\"\n",
    "simple_neural_network_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.save(net, simple_neural_network_path) \n",
    "torch.save({'state_dict': net.state_dict()}, simple_neural_network_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Compare the Performance and Training Time Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Training Time(Seconds)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>1442.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Simple Neural Network</td>\n",
       "      <td>3109.89</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Model  Training Time(Seconds)\n",
       "0                XGBoost                 1442.09\n",
       "1  Simple Neural Network                 3109.89"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainingtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingtime.to_csv(\"training_time_\"+emotion+\".csv\",mode='w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pears-corr</th>\n",
       "      <th>spear-corr</th>\n",
       "      <th>pears-corr-range-05-1</th>\n",
       "      <th>spear-corr-range-05-1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>xgboost</th>\n",
       "      <td>0.612277</td>\n",
       "      <td>0.592206</td>\n",
       "      <td>0.488917</td>\n",
       "      <td>0.442934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>simpleNN</th>\n",
       "      <td>0.684405</td>\n",
       "      <td>0.667313</td>\n",
       "      <td>0.524401</td>\n",
       "      <td>0.487970</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          pears-corr  spear-corr  pears-corr-range-05-1  spear-corr-range-05-1\n",
       "xgboost     0.612277    0.592206               0.488917               0.442934\n",
       "simpleNN    0.684405    0.667313               0.524401               0.487970"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_score = pd.DataFrame(data = [score1,score2], columns = ['pears-corr','spear-corr','pears-corr-range-05-1','spear-corr-range-05-1'],\\\n",
    "             index = ['xgboost','simpleNN'])\n",
    "all_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_score.to_csv('score_'+emotion+'.csv',mode='w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
